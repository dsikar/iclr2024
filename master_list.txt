{'title': 'Decision-Making with Auto-Encoding Variational Bayes', 'paperID': '1ec049a29d369294a5a5ffdfb67e872dce899dac', 'arxivId': '2002.07217', 'publication_year': 2020, 'abstract': None}
{'title': 'Meta-Learning with Warped Gradient Descent', 'paperID': 'e13ca1bd60af3325afc64dc09979e3322818e365', 'arxivId': '1909.00025', 'publication_year': 2019, 'abstract': None}
{'title': 'Fast and Flexible Multi-Task Classification Using Conditional Neural Adaptive Processes', 'paperID': 'd8bafd3a23c5ce9a7ebef036d5f2c67e1386ff11', 'arxivId': '1906.07697', 'publication_year': 2019, 'abstract': None}
{'title': 'Meta-Dataset: A Dataset of Datasets for Learning to Learn from Few Examples', 'paperID': '712f4f21b9d3e6a7f110a2ecd9b3a2f900397b9f', 'arxivId': '1903.03096', 'publication_year': 2019, 'abstract': None}
{'title': 'Amortized Bayesian Meta-Learning', 'paperID': '2686aef553af3ebd43cb0ea98a538a9435f7dd5f', 'arxivId': None, 'publication_year': 2018, 'abstract': None}
{'title': 'Meta-Learning with Latent Embedding Optimization', 'paperID': '04f739a0c29b75877243731aeead512bf0ed1dff', 'arxivId': '1807.05960', 'publication_year': 2018, 'abstract': None}
{'title': 'Bayesian Model-Agnostic Meta-Learning', 'paperID': '849c91ff8bb3ff67d278adb5295fee78049c6288', 'arxivId': '1806.03836', 'publication_year': 2018, 'abstract': None}
{'title': 'Probabilistic Model-Agnostic Meta-Learning', 'paperID': '38e2f851b705faa0d0a698ed9885bd6834440073', 'arxivId': '1806.02817', 'publication_year': 2018, 'abstract': None}
{'title': 'Meta-Learning Probabilistic Inference for Prediction', 'paperID': '7b0aad12a6917b7d444ba2f87c7f8ccc5357797a', 'arxivId': '1805.09921', 'publication_year': 2018, 'abstract': None}
{'title': 'TADAM: Task dependent adaptive metric for improved few-shot learning', 'paperID': 'e6a83abec5cffb0bf1669f2f2c1efdf2b15cb171', 'arxivId': '1805.10123', 'publication_year': 2018, 'abstract': None}
{'title': 'Meta-learning with differentiable closed-form solvers', 'paperID': '208cd4b25768f0096fb2e80e7690473da0e2a563', 'arxivId': '1805.08136', 'publication_year': 2018, 'abstract': None}
{'title': 'On First-Order Meta-Learning Algorithms', 'paperID': '90dc22818bd2d97d8deaff168b0137b75a962767', 'arxivId': '1803.02999', 'publication_year': 2018, 'abstract': None}
{'title': 'Meta-Learning for Semi-Supervised Few-Shot Classification', 'paperID': 'df093d69cd98cf4b26542f53614a79754754eb78', 'arxivId': '1803.00676', 'publication_year': 2018, 'abstract': None}
{'title': 'Gradient-Based Meta-Learning with Learned Layerwise Metric and Subspace', 'paperID': 'd4c4a5f0c71eba13d2827b24f70bbfdc3bd858ec', 'arxivId': None, 'publication_year': 2018, 'abstract': None}
{'title': 'Learning to Compare: Relation Network for Few-Shot Learning', 'paperID': 'bfe284e4338e62f0a61bb33398353efd687f206f', 'arxivId': '1711.06025', 'publication_year': 2017, 'abstract': None}
{'title': 'Fashion-MNIST: a Novel Image Dataset for Benchmarking Machine Learning Algorithms', 'paperID': 'f9c602cc436a9ea2f9e7db48c77d924e09ce3c32', 'arxivId': '1708.07747', 'publication_year': 2017, 'abstract': None}
{'title': 'Meta-SGD: Learning to Learn Quickly for Few Shot Learning', 'paperID': 'd33ad6a25264ba1747d8c93f6621c7f90a7ec601', 'arxivId': '1707.09835', 'publication_year': 2017, 'abstract': None}
{'title': 'Few-Shot Image Recognition by Predicting Parameters from Activations', 'paperID': '3e08a3912ebe494242f6bcd772929cc65307129c', 'arxivId': '1706.03466', 'publication_year': 2017, 'abstract': None}
{'title': 'Prototypical Networks for Few-shot Learning', 'paperID': 'c269858a7bb34e8350f2442ccf37797856ae9bca', 'arxivId': '1703.05175', 'publication_year': 2017, 'abstract': None}
{'title': 'Deep Sets', 'paperID': 'a456265138c088a894301c0433dae938705a9bec', 'arxivId': '1703.06114', 'publication_year': 2017, 'abstract': None}
{'title': 'Model-Agnostic Meta-Learning for Fast Adaptation of Deep Networks', 'paperID': 'c889d6f98e6d79b89c3a6adf8a921f88fa6ba518', 'arxivId': '1703.03400', 'publication_year': 2017, 'abstract': None}
{'title': 'Optimization as a Model for Few-Shot Learning', 'paperID': '29c887794eed2ca9462638ff853e6fe1ab91d5d8', 'arxivId': None, 'publication_year': 2016, 'abstract': None}
{'title': 'Meta-Learning with Memory-Augmented Neural Networks', 'paperID': '3904315e2eca50d0086e4b7273f7fd707c652230', 'arxivId': None, 'publication_year': 2016, 'abstract': None}
{'title': 'Matching Networks for One Shot Learning', 'paperID': 'be1bb4e4aa1fcf70281b4bd24d8cd31c04864bb6', 'arxivId': '1606.04080', 'publication_year': 2016, 'abstract': None}
{'title': 'Towards a Neural Statistician', 'paperID': '405c31c85a324942811f3c9dc53ce3528f9284df', 'arxivId': '1606.02185', 'publication_year': 2016, 'abstract': None}
{'title': 'Human-level concept learning through probabilistic program induction', 'paperID': '815c84ab906e43f3e6322f2ca3fd5e1360c64285', 'arxivId': None, 'publication_year': 2015, 'abstract': None}
{'title': 'ImageNet Large Scale Visual Recognition Challenge', 'paperID': 'e74f9b7f8eec6ba4704c206b93bc8079af3da4bd', 'arxivId': '1409.0575', 'publication_year': 2014, 'abstract': None}
{'title': 'Describing Textures in the Wild', 'paperID': '18c125ce0f64e85577f7d30132cf0e92ec664bf4', 'arxivId': '1311.3618', 'publication_year': 2013, 'abstract': None}
{'title': 'Detection of traffic signs in real-world images: The German traffic sign detection benchmark', 'paperID': 'ba640d55b77407f3170e9c1bd5f2cfbcbfd67df5', 'arxivId': None, 'publication_year': 2013, 'abstract': None}
{'title': 'Fine-Grained Visual Classification of Aircraft', 'paperID': '522d65a3db7431015aeaa201a7fc4450a57e40c3', 'arxivId': '1306.5151', 'publication_year': 2013, 'abstract': None}
{'title': 'Automated Flower Classification over a Large Number of Classes', 'paperID': '02b28f3b71138a06e40dbd614abf8568420ae183', 'arxivId': None, 'publication_year': 2008, 'abstract': None}
{'title': 'Machine learning : an artificial intelligence approach', 'paperID': '696e44a895bd153006b90a47be0c6bfba0a6ef4c', 'arxivId': None, 'publication_year': 1988, 'abstract': None}
{'title': 'Learning to Learn', 'paperID': '53bb7789be36a58f865f2ec84f6d8f816ddaae6a', 'arxivId': None, 'publication_year': 2017, 'abstract': None}
{'title': 'Meta-Learning with Memory-Augmented Neural Networks', 'paperID': 'd3fde30a26bff87d24aba05400334a8dd5aba2c3', 'arxivId': None, 'publication_year': 2016, 'abstract': None}
{'title': 'Reading Digits in Natural Images with Unsupervised Feature Learning', 'paperID': '02227c94dd41fe0b439e050d377b0beb5d427cda', 'arxivId': None, 'publication_year': 2011, 'abstract': None}
{'title': 'Learning to Balance: Bayesian Meta-Learning for Imbalanced and Out-of-distribution Tasks', 'paperID': '96f8e5820c5b59e65c2331d577aa738676e8c605', 'arxivId': '1905.12917', 'publication_year': '2019', 'abstract': 'While tasks could come with varying the number of instances and classes in realistic settings, the existing meta-learning approaches for few-shot classification assume that the number of instances per task and class is fixed. Due to such restriction, they learn to equally utilize the meta-knowledge across all the tasks, even when the number of instances per task and class largely varies. Moreover, they do not consider distributional difference in unseen tasks, on which the meta-knowledge may have less usefulness depending on the task relatedness. To overcome these limitations, we propose a novel meta-learning model that adaptively balances the effect of the meta-learning and task-specific learning within each task. Through the learning of the balancing variables, we can decide whether to obtain a solution by relying on the meta-knowledge or task-specific learning. We formulate this objective into a Bayesian inference framework and tackle it using variational inference. We validate our Bayesian Task-Adaptive Meta-Learning (Bayesian TAML) on multiple realistic task- and class-imbalanced datasets, on which it significantly outperforms existing meta-learning approaches. Further ablation study confirms the effectiveness of each balancing component and the Bayesian learning framework.'}
{'title': 'Detecting Out-of-Distribution Inputs to Deep Generative Models Using a Test for Typicality', 'paperID': '5647d92d8e7248cd2d4770edfe0688c1c0a2181b', 'arxivId': '1906.02994', 'publication_year': 2019, 'abstract': None}
{'title': 'Likelihood Ratios for Out-of-Distribution Detection', 'paperID': '925182b91f51f8f2b747f7829e9d25ffc2729e5d', 'arxivId': '1906.02845', 'publication_year': 2019, 'abstract': None}
{'title': 'Data Discovery and Anomaly Detection Using Atypicality for Real-Valued Data', 'paperID': '37c790f3d5506195c2d9b0b3d59effd932359a96', 'arxivId': None, 'publication_year': 2019, 'abstract': None}
{'title': 'WAIC, but Why? Generative Ensembles for Robust Anomaly Detection', 'paperID': '4bb3301a284d646b4c1ffabcca78ee85c11d1cda', 'arxivId': None, 'publication_year': 2018, 'abstract': None}
{'title': 'Deep Anomaly Detection with Outlier Exposure', 'paperID': '2d8c97db4bae00ff243d122b957091a236a697a7', 'arxivId': '1812.04606', 'publication_year': 2018, 'abstract': None}
{'title': "Do Deep Generative Models Know What They Don't Know?", 'paperID': '6507909a8f77c88144c3a67b9336bd1c85e84cac', 'arxivId': '1810.09136', 'publication_year': 2018, 'abstract': None}
{'title': 'A Simple Unified Framework for Detecting Out-of-Distribution Samples and Adversarial Attacks', 'paperID': 'd03ca175e2b2745126e792fdc31dfadae4c63afa', 'arxivId': '1807.03888', 'publication_year': 2018, 'abstract': None}
{'title': 'Glow: Generative Flow with Invertible 1x1 Convolutions', 'paperID': '21b786b3f870fc7fa247c143aa41de88b1fc6141', 'arxivId': '1807.03039', 'publication_year': 2018, 'abstract': None}
{'title': 'Uncertainty in the Variational Information Bottleneck', 'paperID': '1d078f860ffafc2cb7fcabd29c47584be79c5f2c', 'arxivId': '1807.00906', 'publication_year': 2018, 'abstract': None}
{'title': 'Automatic differentiation in PyTorch', 'paperID': 'b36a5bb1707bb9c70025294b3a310138aae8327a', 'arxivId': None, 'publication_year': 2017, 'abstract': None}
{'title': 'Data Discovery and Anomaly Detection Using Atypicality: Theory', 'paperID': '79f618ec9ea278efb3381375d41f83ddf964edf2', 'arxivId': '1709.03189', 'publication_year': 2017, 'abstract': None}
{'title': 'Enhancing The Reliability of Out-of-distribution Image Detection in Neural Networks', 'paperID': '547c854985629cfa9404a5ba8ca29367b5f8c25f', 'arxivId': '1706.02690', 'publication_year': 2017, 'abstract': None}
{'title': 'PixelCNN++: Improving the PixelCNN with Discretized Logistic Mixture Likelihood and Other Modifications', 'paperID': '2e77b99e8bd10b9e4551a780c0bde9dd10fdbe9b', 'arxivId': '1701.05517', 'publication_year': 2017, 'abstract': None}
{'title': 'Simple and Scalable Predictive Uncertainty Estimation using Deep Ensembles', 'paperID': '802168a81571dde28f5ddb94d84677bc007afa7b', 'arxivId': '1612.01474', 'publication_year': 2016, 'abstract': None}
{'title': 'A Baseline for Detecting Misclassified and Out-of-Distribution Examples in Neural Networks', 'paperID': '6ff2a434578ff2746b9283e45abf296887f48a2d', 'arxivId': '1610.02136', 'publication_year': 2016, 'abstract': None}
{'title': 'A note on the evaluation of generative models', 'paperID': '39e0c341351f8f4a39ac890b96217c7f4bde5369', 'arxivId': '1511.01844', 'publication_year': 2015, 'abstract': None}
{'title': 'Deep neural networks are easily fooled: High confidence predictions for unrecognizable images', 'paperID': '4543670c4b2d88a9b67525e0084044adef94ae76', 'arxivId': '1412.1897', 'publication_year': 2014, 'abstract': None}
{'title': 'Deep Learning Face Attributes in the Wild', 'paperID': '6424b69f3ff4d35249c0bb7ef912fbc2c86f4ff4', 'arxivId': '1411.7766', 'publication_year': 2014, 'abstract': None}
{'title': 'A data-driven approach to cleaning large face datasets', 'paperID': '0d3bb75852098b25d90f31d2f48fd0cb4944702b', 'arxivId': None, 'publication_year': 2014, 'abstract': None}
{'title': 'The German Traffic Sign Recognition Benchmark: A multi-class classification competition', 'paperID': '22fe619996b59c09cb73be40103a123d2e328111', 'arxivId': None, 'publication_year': 2011, 'abstract': None}
{'title': 'ImageNet: A large-scale hierarchical image database', 'paperID': 'd2c733e34d48784a37d717fe43d9e93277a8c53e', 'arxivId': None, 'publication_year': 2009, 'abstract': None}
{'title': 'An introduction to ROC analysis', 'paperID': 'd40ee5dd758c525dfb9932d726bb4e844b7b8478', 'arxivId': None, 'publication_year': 2006, 'abstract': None}
{'title': 'Measures of complexity: a nonexhaustive list', 'paperID': 'a69db833affd92308c7ef5c2cff098c217714f9d', 'arxivId': None, 'publication_year': 2001, 'abstract': None}
{'title': 'Learning Multiple Layers of Features from Tiny Images', 'paperID': '5d90f06bb70a0a3dced62413346235c02b1aa086', 'arxivId': None, 'publication_year': 2009, 'abstract': None}
{'title': 'The mnist database of handwritten digits', 'paperID': 'dc52d1ede1b90bf9d296bc5b34c9310b7eaa99a2', 'arxivId': None, 'publication_year': 2005, 'abstract': None}
{'title': 'Information Theory, Inference, and Learning Algorithms', 'paperID': 'f7f15848cd0fbb3d08f351595da833b1627de9c3', 'arxivId': None, 'publication_year': 2004, 'abstract': None}
{'title': 'Novelty detection and neural network validation', 'paperID': '4bdf6ec7229d307d172e6cce48052b11524b8789', 'arxivId': None, 'publication_year': 1994, 'abstract': None}
{'title': 'On Tables of Random Numbers', 'paperID': 'b9de7b4b1cbc6fe6fd83bd8e0f174735b296630b', 'arxivId': None, 'publication_year': 1993, 'abstract': None}
{'title': 'Elements of Information Theory', 'paperID': '7dbdb4209626fd92d2436a058663206216036e68', 'arxivId': None, 'publication_year': 1991, 'abstract': None}
{'title': 'Input Complexity and Out-of-distribution Detection with Likelihood-based Generative Models', 'paperID': '1322719978980a831e1aee78aa80a141379c44dd', 'arxivId': '1909.11480', 'publication_year': '2019', 'abstract': "Likelihood-based generative models are a promising resource to detect out-of-distribution (OOD) inputs which could compromise the robustness or reliability of a machine learning system. However, likelihoods derived from such models have been shown to be problematic for detecting certain types of inputs that significantly differ from training data. In this paper, we pose that this problem is due to the excessive influence that input complexity has in generative models' likelihoods. We report a set of experiments supporting this hypothesis, and use an estimate of input complexity to derive an efficient and parameter-free OOD score, which can be seen as a likelihood-ratio, akin to Bayesian model comparison. We find such score to perform comparably to, or even better than, existing OOD detection approaches under a wide range of data sets, models, model sizes, and complexity estimates."}
{'title': 'Domain-Adaptive Few-Shot Learning', 'paperID': 'e91f12d3306f704717d6ae7b18f6de920c63c045', 'arxivId': '2003.08626', 'publication_year': 2020, 'abstract': None}
{'title': 'Cross-Domain Few-Shot Classification via Learned Feature-Wise Transformation', 'paperID': '17b99c60d6b2fdd656af6a7661b8d6af05255792', 'arxivId': '2001.08735', 'publication_year': 2020, 'abstract': None}
{'title': 'Adversarial Examples Improve Image Recognition', 'paperID': '948839277bface5780896e8e8791906818aa41ac', 'arxivId': '1911.09665', 'publication_year': 2019, 'abstract': None}
{'title': 'Uncertainty-guided Continual Learning with Bayesian Neural Networks', 'paperID': '59aa504c75b12cb6e5100049f4446ced5b031042', 'arxivId': '1906.02425', 'publication_year': 2019, 'abstract': None}
{'title': 'Domain-Symmetric Networks for Adversarial Domain Adaptation', 'paperID': 'cb4e58d9de165a4fb64eccbe2f4b49c1cd83b650', 'arxivId': '1904.04663', 'publication_year': 2019, 'abstract': None}
{'title': 'The importance of better models in stochastic optimization', 'paperID': '7ccb657207d1de7e6016ba5ca6f6f68eb7204662', 'arxivId': '1903.08619', 'publication_year': 2019, 'abstract': None}
{'title': 'A Survey of Unsupervised Deep Domain Adaptation', 'paperID': '8195787260dfc6bc9abea3b1dac1ce15f747caa2', 'arxivId': '1812.02849', 'publication_year': 2018, 'abstract': None}
{'title': 'Adversarial Meta-Learning', 'paperID': '3a26e26cfa8e8dbd70145f76e058d55fd83997f7', 'arxivId': '1806.03316', 'publication_year': 2018, 'abstract': None}
{'title': 'Flipout: Efficient Pseudo-Independent Weight Perturbations on Mini-Batches', 'paperID': '32760a5d2a55a586b2a9aab7278db89de065eae3', 'arxivId': '1803.04386', 'publication_year': 2018, 'abstract': None}
{'title': 'Recasting Gradient-Based Meta-Learning as Hierarchical Bayes', 'paperID': '46b072cf918ec6f50403568a73d4347ea86b7e66', 'arxivId': '1801.08930', 'publication_year': 2018, 'abstract': None}
{'title': 'Few-Shot Adversarial Domain Adaptation', 'paperID': '1c60ac28884d2414efcf0eec90561fae2a377311', 'arxivId': '1711.02536', 'publication_year': 2017, 'abstract': None}
{'title': 'Bridging the gap between constant step size stochastic gradient descent and Markov chains', 'paperID': '1b11679c3a2c0f2f65e70d40ec3bcb8cfc8e6f8a', 'arxivId': '1707.06386', 'publication_year': 2017, 'abstract': None}
{'title': 'A Simple Neural Attentive Meta-Learner', 'paperID': '7e9c1e0d247b20a0683f4797d9ea248c3b53d424', 'arxivId': None, 'publication_year': 2017, 'abstract': None}
{'title': 'Towards Deep Learning Models Resistant to Adversarial Attacks', 'paperID': '7aa38b85fa8cba64d6a4010543f6695dbf5f1386', 'arxivId': '1706.06083', 'publication_year': 2017, 'abstract': None}
{'title': 'Adversarial Discriminative Domain Adaptation', 'paperID': '345afa0e85cb2f5cb438ae44027499ff2c392409', 'arxivId': '1702.05464', 'publication_year': 2017, 'abstract': None}
{'title': 'DeepFool: A Simple and Accurate Method to Fool Deep Neural Networks', 'paperID': '52693bcf4627bdbc31734e7f3dbcf5ea7eef4d35', 'arxivId': '1511.04599', 'publication_year': 2015, 'abstract': None}
{'title': 'Weight Uncertainty in Neural Network', 'paperID': '62adfea3cc1cd9eb6b53e0e8a40be5dfda2adf8d', 'arxivId': None, 'publication_year': 2015, 'abstract': None}
{'title': 'Adam: A Method for Stochastic Optimization', 'paperID': 'a6cb366736791bcccc5c8639de5a8f9636bf87e8', 'arxivId': '1412.6980', 'publication_year': 2014, 'abstract': None}
{'title': 'Explaining and Harnessing Adversarial Examples', 'paperID': 'bee044c8e8903fb67523c1f8c105ab4718600cdb', 'arxivId': '1412.6572', 'publication_year': 2014, 'abstract': None}
{'title': 'Generative adversarial networks', 'paperID': '1fc7e419bd7a44cf43abe3cf7d811d3d96e2252d', 'arxivId': '1406.2661', 'publication_year': 2014, 'abstract': None}
{'title': 'Visualizing and Understanding Convolutional Networks', 'paperID': '1a2a770d23b4a171fa81de62a78a3deb0588f238', 'arxivId': '1311.2901', 'publication_year': 2013, 'abstract': None}
{'title': 'A theory of learning from different domains', 'paperID': '66d398aeaeb7ec24ededb1adaa4b4f09a6c1bcde', 'arxivId': None, 'publication_year': 2010, 'abstract': None}
{'title': 'Handbook of Semiconductor Manufacturing Technology', 'paperID': '76073b1cf23e392f6c16c72fa3a2f8f31322eacf', 'arxivId': None, 'publication_year': 2007, 'abstract': None}
{'title': 'Handbook of Semiconductor Manufacturing Technology', 'paperID': '0500862417b0349c664586d3566aef416cb5786e', 'arxivId': None, 'publication_year': 2001, 'abstract': None}
{'title': 'Conference Paper', 'paperID': 'df24c3011fc42b72195e876ce052a0a072a1d923', 'arxivId': None, 'publication_year': 2009, 'abstract': None}
{'title': 'Repurposing Pretrained Models for Robust Out-of-domain Few-Shot Learning', 'paperID': 'b6c4a3f913ee819afa49e115f9739fe31ecf13f5', 'arxivId': '2103.09027', 'publication_year': '2021', 'abstract': 'Model-agnostic meta-learning (MAML) is a popular method for few-shot learning but assumes that we have access to the meta-training set. In practice, training on the meta-training set may not always be an option due to data privacy concerns, intellectual property issues, or merely lack of computing resources. In this paper, we consider the novel problem of repurposing pretrained MAML checkpoints to solve new few-shot classification tasks. Because of the potential distribution mismatch, the original MAML steps may no longer be optimal. Therefore we propose an alternative meta-testing procedure and combine MAML gradient steps with adversarial training and uncertainty-based stepsize adaptation. Our method outperforms "vanilla" MAML on same-domain and cross-domains benchmarks using both SGD and Adam optimizers and shows improved robustness to the choice of base stepsize.'}
{'title': 'White Matter Development from Birth to 6\xa0Years of Age: A Longitudinal Study.', 'paperID': '30b22164a29d34994b497bf9815076781555ff4e', 'arxivId': None, 'publication_year': 2020, 'abstract': None}
{'title': 'Improved Techniques for Training Score-Based Generative Models', 'paperID': '1156e277fa7ec195b043161d3c5c97715da17658', 'arxivId': '2006.09011', 'publication_year': 2020, 'abstract': None}
{'title': 'Individual Variation of Human Cortical Structure Is Established in the First Year of Life.', 'paperID': '7f5b344f292645011a19801b23277d3820acc70e', 'arxivId': None, 'publication_year': 2020, 'abstract': None}
{'title': 'Your Classifier is Secretly an Energy Based Model and You Should Treat it Like One', 'paperID': '97cd86d8d8c0f27cd3e64c6ca5cfdeb957ee39f4', 'arxivId': '1912.03263', 'publication_year': 2019, 'abstract': None}
{'title': 'Normalizing Flows for Probabilistic Modeling and Inference', 'paperID': '501c02c7caa7fc2c7077405299b4cbe7d294b170', 'arxivId': '1912.02762', 'publication_year': 2019, 'abstract': None}
{'title': 'Neural Density Estimation and Likelihood-free Inference', 'paperID': 'c178e64c65f5401e61d775e95649d46fb43c1965', 'arxivId': '1910.13233', 'publication_year': 2019, 'abstract': None}
{'title': 'Models Genesis: Generic Autodidactic Models for 3D Medical Image Analysis', 'paperID': 'd756e0bb4b3576a644b1c20c50bb60e20ae45a9d', 'arxivId': None, 'publication_year': 2019, 'abstract': None}
{'title': 'Generative Modeling by Estimating Gradients of the Data Distribution', 'paperID': '965359b3008ab50dd04e171551220ec0e7f83aba', 'arxivId': '1907.05600', 'publication_year': 2019, 'abstract': None}
{'title': 'The Adolescent Brain Cognitive Development (ABCD) study: Imaging acquisition across 21 sites', 'paperID': 'abeb5bc02ea3f80b67cf58e3e290448af38933e5', 'arxivId': None, 'publication_year': 2018, 'abstract': None}
{'title': 'Learning Confidence for Out-of-Distribution Detection in Neural Networks', 'paperID': '431ba9fae8fccad1665979d455c6307786e47318', 'arxivId': '1802.04865', 'publication_year': 2018, 'abstract': None}
{'title': 'Training Confidence-calibrated Classifiers for Detecting Out-of-Distribution Samples', 'paperID': '36653f8705b56e39642bcd123494eb680cd1636b', 'arxivId': '1711.09325', 'publication_year': 2017, 'abstract': None}
{'title': 'Masked Autoregressive Flow for Density Estimation', 'paperID': '585bf7bea8fa5267738bc465611d6f197e0f87dd', 'arxivId': '1705.07057', 'publication_year': 2017, 'abstract': None}
{'title': 'Concrete Problems in AI Safety', 'paperID': 'e86f71ca2948d17b003a5f068db1ecb2b77827f7', 'arxivId': '1606.06565', 'publication_year': 2016, 'abstract': None}
{'title': 'Deep Structured Energy Based Models for Anomaly Detection', 'paperID': '10a498003e9204f5fc1328e706510a37e514d8c7', 'arxivId': '1605.07717', 'publication_year': 2016, 'abstract': None}
{'title': 'Deep Residual Learning for Image Recognition', 'paperID': '2c03df8b48bf3fa39054345bafabfeff15bfd11d', 'arxivId': '1512.03385', 'publication_year': 2015, 'abstract': None}
{'title': 'LSUN: Construction of a Large-scale Image Dataset using Deep Learning with Humans in the Loop', 'paperID': '4dcdae25a5e33682953f0853ee4cf7ca93be58a9', 'arxivId': '1506.03365', 'publication_year': 2015, 'abstract': None}
{'title': 'TurkerGaze: Crowdsourcing Saliency with Webcam based Eye Tracking', 'paperID': '3433627f803953280b66ae1576d083fc9a68385a', 'arxivId': '1504.06755', 'publication_year': 2015, 'abstract': None}
{'title': 'Intriguing properties of neural networks', 'paperID': 'd891dc72cbd40ffaeefdc79f2e7afe1e530a23ad', 'arxivId': '1312.6199', 'publication_year': 2013, 'abstract': None}
{'title': 'A Connection Between Score Matching and Denoising Autoencoders', 'paperID': '872bae24c109f7c30e052ac218b17a8b028d08a0', 'arxivId': None, 'publication_year': 2011, 'abstract': None}
{'title': 'Estimation of Non-Normalized Statistical Models by Score Matching', 'paperID': '9966e890f2eedb4577e11b9d5a66380a4d9341fe', 'arxivId': None, 'publication_year': 2005, 'abstract': None}
{'title': 'Multiscale Score Matching for Out-of-Distribution Detection', 'paperID': '703ffd7ab0bdfcb091400ebb9c7b92446204831f', 'arxivId': '2010.13132', 'publication_year': '2020', 'abstract': 'We present a new methodology for detecting out-of-distribution (OOD) images by utilizing norms of the score estimates at multiple noise scales. A score is defined to be the gradient of the log density with respect to the input data. Our methodology is completely unsupervised and follows a straight forward training scheme. First, we train a deep network to estimate scores for levels of noise. Once trained, we calculate the noisy score estimates for N in-distribution samples and take the L2-norms across the input dimensions (resulting in an NxL matrix). Then we train an auxiliary model (such as a Gaussian Mixture Model) to learn the in-distribution spatial regions in this L-dimensional space. This auxiliary model can now be used to identify points that reside outside the learned space. Despite its simplicity, our experiments show that this methodology significantly outperforms the state-of-the-art in detecting out-of-distribution images. For example, our method can effectively separate CIFAR-10 (inlier) and SVHN (OOD) images, a setting which has been previously shown to be difficult for deep likelihood models.'}
{'title': 'BREEDS: Benchmarks for Subpopulation Shift', 'paperID': '767c6702045f2290012a259744db9edb4d55bcb8', 'arxivId': '2008.04859', 'publication_year': 2020, 'abstract': None}
{'title': 'On the Theory of Transfer Learning: The Importance of Task Diversity', 'paperID': '6e2d24dbf959aeb855926430bf1cb476346719b3', 'arxivId': '2006.11650', 'publication_year': 2020, 'abstract': None}
{'title': 'Rethinking Pre-training and Self-training', 'paperID': '368c72c2298e5f8276398b2cb198702281eac4f8', 'arxivId': '2006.06882', 'publication_year': 2020, 'abstract': None}
{'title': 'Self-training Avoids Using Spurious Features Under Domain Shift', 'paperID': '3d4c4cd680da0ebd2d774c5b5236b9db3da15185', 'arxivId': '2006.10032', 'publication_year': 2020, 'abstract': None}
{'title': 'Using publicly available satellite imagery and deep learning to understand economic well-being in Africa', 'paperID': '7bfaca28948164006002a3a71a38165d36af51c5', 'arxivId': None, 'publication_year': 2020, 'abstract': None}
{'title': 'Understanding and Improving Information Transfer in Multi-Task Learning', 'paperID': '7438c34a128c13e811aca2e599028bb3760e1816', 'arxivId': '2005.00944', 'publication_year': 2020, 'abstract': None}
{'title': 'Meta-Learning for Few-Shot Land Cover Classification', 'paperID': '7d0029510d7f47d3ee716aa8e01b69e353f9e143', 'arxivId': '2004.13390', 'publication_year': 2020, 'abstract': None}
{'title': 'Understanding Self-Training for Gradual Domain Adaptation', 'paperID': '8dc871b80e50135c9d99de9f8eb8c64b63ee924f', 'arxivId': '2002.11361', 'publication_year': 2020, 'abstract': None}
{'title': 'Understanding and Mitigating the Tradeoff Between Robustness and Accuracy', 'paperID': '3f8e190773a8898ef296da67b646e40dca1374cb', 'arxivId': '2002.10716', 'publication_year': 2020, 'abstract': None}
{'title': 'Few-Shot Learning via Learning the Representation, Provably', 'paperID': '02841af780570666389643f2815460a10d9ae286', 'arxivId': '2002.09434', 'publication_year': 2020, 'abstract': None}
{'title': 'Weakly Supervised Deep Learning for Segmentation of Remote Sensing Imagery', 'paperID': '6eb53e1763f2eab95093eb1e6f67d34d2618fa9b', 'arxivId': None, 'publication_year': 2020, 'abstract': None}
{'title': 'Self-Training With Noisy Student Improves ImageNet Classification', 'paperID': '20ba55ee3229db5cb190a00e788c59f08d2a767d', 'arxivId': '1911.04252', 'publication_year': 2019, 'abstract': None}
{'title': 'Using Self-Supervised Learning Can Improve Model Robustness and Uncertainty', 'paperID': 'db787640c9b42416ff8d7015546e667e58267177', 'arxivId': '1906.12340', 'publication_year': 2019, 'abstract': None}
{'title': 'Tackling Climate Change with Machine Learning', 'paperID': '998039a4876edc440e0cabb0bc42239b0eb29644', 'arxivId': '1906.05433', 'publication_year': 2019, 'abstract': None}
{'title': 'Unlabeled Data Improves Adversarial Robustness', 'paperID': 'b3f1aa12dde233aaf543bb9ccb27213c494e0fd5', 'arxivId': '1905.13736', 'publication_year': 2019, 'abstract': None}
{'title': 'Are Labels Required for Improving Adversarial Robustness?', 'paperID': '6d12401822a24b2ff5542a7fa72158d891960c62', 'arxivId': '1905.13725', 'publication_year': 2019, 'abstract': None}
{'title': '1D Convolutional Neural Networks and Applications: A Survey', 'paperID': 'a8420e6a3a196a4c34566b5b8717318743eb6e4b', 'arxivId': '1905.03554', 'publication_year': 2019, 'abstract': None}
{'title': 'Robustness to Adversarial Perturbations in Learning from Incomplete Data', 'paperID': '3f7bc67330b3eff749459568e7995f0017dfe645', 'arxivId': '1905.13021', 'publication_year': 2019, 'abstract': None}
{'title': 'Do ImageNet Classifiers Generalize to ImageNet?', 'paperID': '4e0bb8c1c683b43357c5d5216f6b74ff2cb32434', 'arxivId': '1902.10811', 'publication_year': 2019, 'abstract': None}
{'title': 'Using Pre-Training Can Improve Model Robustness and Uncertainty', 'paperID': 'aa5741c74b7fac10680c1cfbdd49d9ffb5751a68', 'arxivId': '1901.09960', 'publication_year': 2019, 'abstract': None}
{'title': 'A high-performance and in-season classification system of field-level crop types using time-series Landsat data and a machine learning approach', 'paperID': '12c77ac9898c049474850c84235439ec564221bf', 'arxivId': None, 'publication_year': 2018, 'abstract': None}
{'title': 'Deep learning for segmentation of brain tumors: Impact of cross‐institutional training and testing', 'paperID': '05447ad7c0bc55f8b3766e23da1578bb13f46bbf', 'arxivId': None, 'publication_year': 2018, 'abstract': None}
{'title': 'A DIRT-T Approach to Unsupervised Domain Adaptation', 'paperID': '008c901b3fd9e46ee8d3bddb616121e2887b7e67', 'arxivId': '1802.08735', 'publication_year': 2018, 'abstract': None}
{'title': 'Implementation of machine-learning classification in remote sensing: an applied review', 'paperID': 'b3de1062d8a462dfdc2938558258f8884abe9f4e', 'arxivId': None, 'publication_year': 2018, 'abstract': None}
{'title': 'CyCADA: Cycle-Consistent Adversarial Domain Adaptation', 'paperID': '907a90967f68da4311802247408e0515e363f930', 'arxivId': '1711.03213', 'publication_year': 2017, 'abstract': None}
{'title': 'Snorkel: Rapid Training Data Creation with Weak Supervision', 'paperID': '18bc1d4271abe8dd6e16179cdb06524a4f396e16', 'arxivId': '1711.10160', 'publication_year': 2017, 'abstract': None}
{'title': 'Adversarial Examples for Evaluating Reading Comprehension Systems', 'paperID': 'ffb949d3493c3b2f3c9acf9c75cb03938933ddf0', 'arxivId': '1707.07328', 'publication_year': 2017, 'abstract': None}
{'title': 'Deep Learning Classification of Land Cover and Crop Types Using Remote Sensing Data', 'paperID': '7a9e471e31ac156cf22a5e2a5c1463697df866ab', 'arxivId': None, 'publication_year': 2017, 'abstract': None}
{'title': 'Combining satellite imagery and machine learning to predict poverty', 'paperID': '4f975da00a5b2a2f7236e34edcb7274e5fdab937', 'arxivId': None, 'publication_year': 2016, 'abstract': None}
{'title': 'Data Programming: Creating Large Training Sets, Quickly', 'paperID': '37acbbbcfe9d8eb89e5b01da28dac6d44c3903ee', 'arxivId': '1605.07723', 'publication_year': 2016, 'abstract': None}
{'title': 'Crop yield forecasting on the Canadian Prairies by remotely sensed vegetation indices and machine learning methods', 'paperID': 'c8f9a5a2f6da022a08b1b0c5b7c4d311fcb1ce34', 'arxivId': None, 'publication_year': 2016, 'abstract': None}
{'title': 'Transfer Learning from Deep Features for Remote Sensing and Poverty Mapping', 'paperID': 'a04622cfd1154dd6dc04591cbb25188207bc6142', 'arxivId': '1510.00098', 'publication_year': 2015, 'abstract': None}
{'title': 'Domain-Adversarial Training of Neural Networks', 'paperID': '1d5972b32a9b5a455a6eef389de5b7fca25771ad', 'arxivId': '1505.07818', 'publication_year': 2015, 'abstract': None}
{'title': 'U-Net: Convolutional Networks for Biomedical Image Segmentation', 'paperID': '6364fdaa0a0eccd823a779fcdd489173f938e91a', 'arxivId': '1505.04597', 'publication_year': 2015, 'abstract': None}
{'title': 'Very Deep Convolutional Networks for Large-Scale Image Recognition', 'paperID': 'eb42cf88027de515750f230b23b1a057dc782108', 'arxivId': '1409.1556', 'publication_year': 2014, 'abstract': None}
{'title': 'ImageNet classification with deep convolutional neural networks', 'paperID': 'abd1c342495432171beb7ca8fd9551ef13cbd0ff', 'arxivId': None, 'publication_year': 2012, 'abstract': None}
{'title': 'Topics in Random Matrix Theory', 'paperID': '611503ed9d36bad843374774c59ab335ebf7eac4', 'arxivId': None, 'publication_year': 2012, 'abstract': None}
{'title': 'Random Design Analysis of Ridge Regression', 'paperID': '900b806495ce8a175e66cff13755fd99ec525ab5', 'arxivId': '1106.2363', 'publication_year': 2011, 'abstract': None}
{'title': 'A Survey on Transfer Learning', 'paperID': 'a25fbcbbae1e8f79c4360d26aa11a3abf1a11972', 'arxivId': None, 'publication_year': 2010, 'abstract': None}
{'title': 'Covariate Shift Adaptation by Importance Weighted Cross Validation', 'paperID': '424c3ab98f1ae2d9e9ecf892e15a12c09f4e9ffe', 'arxivId': None, 'publication_year': 2007, 'abstract': None}
{'title': 'Estimating crop yield from multi-temporal satellite data using multivariate regression and neural network techniques', 'paperID': '0adf759f449435bc8343c9a8a2a25ad5bb63e5b8', 'arxivId': None, 'publication_year': 2007, 'abstract': None}
{'title': 'Land-cover change detection using multi-temporal MODIS NDVI data', 'paperID': '723d063248ac896fe63325d4c88d750162d10bfc', 'arxivId': None, 'publication_year': 2006, 'abstract': None}
{'title': 'Random Forests for land cover classification', 'paperID': '7ad785d8cd5d45ee07a82a2c0d7d4c733b1251d5', 'arxivId': None, 'publication_year': 2006, 'abstract': None}
{'title': 'Benefitting from the Variables that Variable Selection Discards', 'paperID': '5bbff3807fef66bbf758874d523f95cf75d945cd', 'arxivId': None, 'publication_year': 2003, 'abstract': None}
{'title': 'Multitask Learning', 'paperID': '161ffb54a3fdf0715b198bb57bd22f910242eb49', 'arxivId': None, 'publication_year': 1997, 'abstract': None}
{'title': 'Global discrimination of land cover types from metrics derived from AVHRR pathfinder data', 'paperID': '5b6e487e98785c5f44fd0ffd1e1bafdb3aac1456', 'arxivId': None, 'publication_year': 1995, 'abstract': None}
{'title': 'NDVI-derived land cover classifications at a global scale', 'paperID': '35a8b3dee2fe190bc34fa79222269325ee1d08c7', 'arxivId': None, 'publication_year': 1994, 'abstract': None}
{'title': 'BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding', 'paperID': 'df2b0e26d0599ce3e70df8a9da02e51594e0e992', 'arxivId': '1810.04805', 'publication_year': 2019, 'abstract': None}
{'title': 'Machine learning in geosciences and remote sensing', 'paperID': '32e29041fa352a9df0889f42807ed6141bc0b5ff', 'arxivId': None, 'publication_year': 2016, 'abstract': None}
{'title': 'Estimating soil moisture using remote sensing data: A machine learning approach', 'paperID': '6b96f4daa52f7fe7e6334bf2b2e3d8e245f652c7', 'arxivId': None, 'publication_year': 2010, 'abstract': None}
{'title': 'Domain adaptation of natural language processing systems', 'paperID': 'ecbd467eacde24de43f43bc703c891df447ff389', 'arxivId': None, 'publication_year': 2008, 'abstract': None}
{'title': 'ImageNet Classiﬁcation with Deep Convolutional Neural Networks', 'paperID': 'f6a883e5ce485ab9300d56cb440e8634d9aa1105', 'arxivId': None, 'publication_year': None, 'abstract': None}
{'title': 'In-N-Out: Pre-Training and Self-Training using Auxiliary Information for Out-of-Distribution Robustness', 'paperID': '0f4374e62ae889dd2a35dc4c97b9a0510146fa87', 'arxivId': '2012.04550', 'publication_year': '2020', 'abstract': 'Consider a prediction setting where a few inputs (e.g., satellite images) are expensively annotated with the prediction targets (e.g., crop types), and many inputs are cheaply annotated with auxiliary information (e.g., climate information). How should we best leverage this auxiliary information for the prediction task? Empirically across three image and time-series datasets, and theoretically in a multi-task linear regression setting, we show that (i) using auxiliary information as input features improves in-distribution error but can hurt out-of-distribution (OOD) error; while (ii) using auxiliary information as outputs of auxiliary tasks to pre-train a model improves OOD error. To get the best of both worlds, we introduce In-N-Out, which first trains a model with auxiliary inputs and uses it to pseudolabel all the in-distribution inputs, then pre-trains a model on OOD auxiliary outputs and fine-tunes this model with the pseudolabels (self-training). We show both theoretically and empirically that In-N-Out outperforms auxiliary inputs or outputs alone on both in-distribution and OOD error.'}
{'title': 'Adversarial Robustness on In- and Out-Distribution Improves Explainability', 'paperID': '36dfaba17bd6c23d869143838c49e0041f10e7fa', 'arxivId': '2003.09461', 'publication_year': 2020, 'abstract': None}
{'title': 'Adversarial Vertex Mixup: Toward Better Adversarially Robust Generalization', 'paperID': '365fb36b15f13c0c69596a9fc98ddcaed3fe739c', 'arxivId': '2003.02484', 'publication_year': 2020, 'abstract': None}
{'title': 'Reliable evaluation of adversarial robustness with an ensemble of diverse parameter-free attacks', 'paperID': '18939eadc9c4460c8385e0591cde214a1ead067b', 'arxivId': '2003.01690', 'publication_year': 2020, 'abstract': None}
{'title': 'Hold me tight! Influence of discriminative features on deep network boundaries', 'paperID': '65c63d4143b70ba718c423743bb1a4c43513e7fc', 'arxivId': '2002.06349', 'publication_year': 2020, 'abstract': None}
{'title': 'What It Thinks Is Important Is Important: Robustness Transfers Through Input Gradients', 'paperID': '2d75cf1dc599d7274fa57a02af5c2da2747db36c', 'arxivId': '1912.05699', 'publication_year': 2019, 'abstract': None}
{'title': 'Square Attack: a query-efficient black-box adversarial attack via random search', 'paperID': '8733fe2371b615609b04e2e910b1ecfa8e77cbc2', 'arxivId': '1912.00049', 'publication_year': 2019, 'abstract': None}
{'title': 'Learning De-biased Representations with Biased Representations', 'paperID': 'ec570b827cf0cd132da7ebd37537df4f0bb7f877', 'arxivId': '1910.02806', 'publication_year': 2019, 'abstract': None}
{'title': 'Minimally distorted Adversarial Examples with a Fast Adaptive Boundary Attack', 'paperID': '91a05cb84f1c7dbb0354da2ff11ae92549152435', 'arxivId': '1907.02044', 'publication_year': 2019, 'abstract': None}
{'title': 'High-Frequency Component Helps Explain the Generalization of Convolutional Neural Networks', 'paperID': 'bceeb52a9d4a4127d6664eea4870e8a60b378eff', 'arxivId': '1905.13545', 'publication_year': 2019, 'abstract': None}
{'title': 'Cross-Domain Transferability of Adversarial Perturbations', 'paperID': 'bc1138738f24c4a23d865d7786fc4c8229e4662a', 'arxivId': '1905.11736', 'publication_year': 2019, 'abstract': None}
{'title': 'CutMix: Regularization Strategy to Train Strong Classifiers With Localizable Features', 'paperID': 'ed17929e66da7f8fbc3666bf5eb613d302ddde0c', 'arxivId': '1905.04899', 'publication_year': 2019, 'abstract': None}
{'title': 'Adversarial Examples Are Not Bugs, They Are Features', 'paperID': '1f4294d8e0b0c8559479fac569fc0ea91b4dc0bd', 'arxivId': '1905.02175', 'publication_year': 2019, 'abstract': None}
{'title': 'Theoretically Principled Trade-off between Robustness and Accuracy', 'paperID': '6c405d4b5dc41a86be05acd59c06ed19daf01d14', 'arxivId': '1901.08573', 'publication_year': 2019, 'abstract': None}
{'title': 'Why ReLU Networks Yield High-Confidence Predictions Far Away From the Training Data and How to Mitigate the Problem', 'paperID': 'a25b63a6a0071d7d88ff4671c1fd40f320a08533', 'arxivId': '1812.05720', 'publication_year': 2018, 'abstract': None}
{'title': 'ImageNet-trained CNNs are biased towards texture; increasing shape bias improves accuracy and robustness', 'paperID': '0f50b7483f1b200ebf88c4dd7698de986399a0f3', 'arxivId': '1811.12231', 'publication_year': 2018, 'abstract': None}
{'title': 'Places: A 10 Million Image Database for Scene Recognition', 'paperID': 'f986968735459e789890f24b6b277b0920a9725d', 'arxivId': None, 'publication_year': 2018, 'abstract': None}
{'title': 'Robustness May Be at Odds with Accuracy', 'paperID': '1b9c6022598085dd892f360122c0fa4c630b3f18', 'arxivId': '1805.12152', 'publication_year': 2018, 'abstract': None}
{'title': 'Adversarially Robust Generalization Requires More Data', 'paperID': '804fb9542f4f56e264dd2df57c255a9a2011c00f', 'arxivId': '1804.11285', 'publication_year': 2018, 'abstract': None}
{'title': 'Adversarial Logit Pairing', 'paperID': 'f2c5c3cfe1675dd9239121f1f09069438f047aea', 'arxivId': '1803.06373', 'publication_year': 2018, 'abstract': None}
{'title': 'Obfuscated Gradients Give a False Sense of Security: Circumventing Defenses to Adversarial Examples', 'paperID': '651adaa058f821a890f2c5d1053d69eb481a8352', 'arxivId': '1802.00420', 'publication_year': 2018, 'abstract': None}
{'title': 'Generative Adversarial Perturbations', 'paperID': 'e8da4ff1519011ed018202bb96dee4b611f5d842', 'arxivId': '1712.02328', 'publication_year': 2017, 'abstract': None}
{'title': 'mixup: Beyond Empirical Risk Minimization', 'paperID': '4feef0fd284feb1233399b400eb897f59ec92755', 'arxivId': '1710.09412', 'publication_year': 2017, 'abstract': None}
{'title': 'VisDA: The Visual Domain Adaptation Challenge', 'paperID': '33d682c52eb24875c556ec007bc38068d3e682c0', 'arxivId': '1710.06924', 'publication_year': 2017, 'abstract': None}
{'title': 'Good Semi-supervised Learning That Requires a Bad GAN', 'paperID': '3c57a1aa483d8bffe1339914b80d2913f2dc8376', 'arxivId': '1705.09783', 'publication_year': 2017, 'abstract': None}
{'title': 'Understanding deep learning requires rethinking generalization', 'paperID': '54ddb00fa691728944fd8becea90a373d21597cf', 'arxivId': '1611.03530', 'publication_year': 2016, 'abstract': None}
{'title': 'Universal Adversarial Perturbations', 'paperID': '16aa01ca0834a924c25faad5d8bfef3fd1acfcfe', 'arxivId': '1610.08401', 'publication_year': 2016, 'abstract': None}
{'title': 'Towards Evaluating the Robustness of Neural Networks', 'paperID': 'df40ce107a71b770c9d0354b78fdd8989da80d2f', 'arxivId': '1608.04644', 'publication_year': 2016, 'abstract': None}
{'title': 'Wide Residual Networks', 'paperID': '1c4e9156ca07705531e45960b7a919dc473abb51', 'arxivId': '1605.07146', 'publication_year': 2016, 'abstract': None}
{'title': 'Identity Mappings in Deep Residual Networks', 'paperID': '77f0a39b8e02686fd85b01971f8feb7f60971f80', 'arxivId': '1603.05027', 'publication_year': 2016, 'abstract': None}
{'title': 'Deep Neural Networks for Acoustic Modeling in Speech Recognition', 'paperID': 'e33cbb25a8c7390aec6a398e36381f4f7770c283', 'arxivId': None, 'publication_year': 2012, 'abstract': None}
{'title': 'Robust Solutions of Optimization Problems Affected by Uncertain Probabilities', 'paperID': '583b55367f787eb0c4e295707b642e63547b9806', 'arxivId': None, 'publication_year': 2011, 'abstract': None}
{'title': '80 Million Tiny Images: A Large Data Set for Nonparametric Object and Scene Recognition', 'paperID': '54d2b5c64a67f65c5dd812b89e07973f97699552', 'arxivId': None, 'publication_year': 2008, 'abstract': None}
{'title': 'A standardized set of 260 pictures: norms for name agreement, image agreement, familiarity, and visual complexity.', 'paperID': '144adacded5ed56c35a5f157fe231a0459620ec8', 'arxivId': None, 'publication_year': 1980, 'abstract': None}
{'title': 'Adaptive Control Processes: A Guided Tour', 'paperID': '1729f731482a628177a0fb81050966514c385e5e', 'arxivId': None, 'publication_year': 1961, 'abstract': None}
{'title': 'The curse of dimensionality', 'paperID': '1ea82cc13f6b7352943aba6c987e3895e5161b9b', 'arxivId': None, 'publication_year': 2000, 'abstract': None}
{'title': 'Removing Undesirable Feature Contributions Using Out-of-Distribution Data', 'paperID': '2be5c2f23b997e1cb22479dc1d5d1735997ad4be', 'arxivId': '2101.06639', 'publication_year': '2021', 'abstract': 'Several data augmentation methods deploy unlabeled-in-distribution (UID) data to bridge the gap between the training and inference of neural networks. However, these methods have clear limitations in terms of availability of UID data and dependence of algorithms on pseudo-labels. Herein, we propose a data augmentation method to improve generalization in both adversarial and standard learning by using out-of-distribution (OOD) data that are devoid of the abovementioned issues. We show how to improve generalization theoretically using OOD data in each learning scenario and complement our theoretical analysis with experiments on CIFAR-10, CIFAR-100, and a subset of ImageNet. The results indicate that undesirable features are shared even among image data that seem to have little correlation from a human point of view. We also present the advantages of the proposed method through comparison with other data augmentation methods, which can be used in the absence of UID data. Furthermore, we demonstrate that the proposed method can further improve the existing state-of-the-art adversarial training.'}
{'title': 'Towards Out-Of-Distribution Generalization: A Survey', 'paperID': 'e5b2e2a284db5ba7c2c011daba9769d2c56b6586', 'arxivId': '2108.13624', 'publication_year': 2021, 'abstract': None}
{'title': 'Amplitude-Phase Recombination: Rethinking Robustness of Convolutional Neural Networks in Frequency Domain', 'paperID': 'a0bd9ac2544efe6624a8d2861471e1df9c485e7d', 'arxivId': '2108.08487', 'publication_year': 2021, 'abstract': None}
{'title': 'Representative Batch Normalization with Feature Calibration', 'paperID': '498b323fc8d2eaf9e5a29a8b33d18971c3ed1408', 'arxivId': None, 'publication_year': 2021, 'abstract': None}
{'title': 'Reducing Domain Gap by Reducing Style Bias', 'paperID': '94001e6bdf94fd61be3fba6ab9e6e77fbd888867', 'arxivId': None, 'publication_year': 2021, 'abstract': None}
{'title': 'Generalizable Person Re-identification with Relevance-aware Mixture of Experts', 'paperID': '7ffbc531bbb0f1cf38b47e1d728a0e297f8b4dec', 'arxivId': '2105.09156', 'publication_year': 2021, 'abstract': None}
{'title': 'Domain Generalization with MixStyle', 'paperID': '4f6eafafc9563a5b904535078df7e74afe39ef59', 'arxivId': '2104.02008', 'publication_year': 2021, 'abstract': None}
{'title': 'RobustNet: Improving Domain Generalization in Urban-Scene Segmentation via Instance Selective Whitening', 'paperID': 'cd8394d8b6679bb446cf154a6d123cf9a00e561e', 'arxivId': '2103.15597', 'publication_year': 2021, 'abstract': None}
{'title': 'Domain Generalization: A Survey', 'paperID': 'b249fe4e5e2bada6655ce5d61e7f50da5d471cb4', 'arxivId': '2103.02503', 'publication_year': 2021, 'abstract': None}
{'title': 'Generalizing to Unseen Domains: A Survey on Domain Generalization', 'paperID': '085907c9b2bfbf39bcaf6fe3d16bd1dadcef5af5', 'arxivId': '2103.03097', 'publication_year': 2021, 'abstract': None}
{'title': 'Permuted AdaIN: Reducing the Bias Towards Global Statistics in Image Classification', 'paperID': '1403fd998f477256482474a0876d4341075ebd4b', 'arxivId': '2010.05785', 'publication_year': 2020, 'abstract': None}
{'title': 'Revisiting Batch Normalization for Improving Corruption Robustness', 'paperID': '639b07626d140513a2aeac68ff52c3bb6db90bed', 'arxivId': '2010.03630', 'publication_year': 2020, 'abstract': None}
{'title': 'Learning to Balance Specificity and Invariance for In and Out of Domain Generalization', 'paperID': 'f6e289df5734c06d235cc9eb71585955c27f2005', 'arxivId': '2008.12839', 'publication_year': 2020, 'abstract': None}
{'title': 'Robust and Generalizable Visual Representation Learning via Random Convolutions', 'paperID': 'b27ad18e20d27efe8a9fbc54b1c2dcef8b2da19f', 'arxivId': '2007.13003', 'publication_year': 2020, 'abstract': None}
{'title': 'Classes Matter: A Fine-grained Adversarial Approach to Cross-domain Semantic Segmentation', 'paperID': 'c57d53767654948647cbf4a68e459851e56ea553', 'arxivId': '2007.09222', 'publication_year': 2020, 'abstract': None}
{'title': 'Transferable Calibration with Lower Bias and Variance in Domain Adaptation', 'paperID': '7167f44f61fe3306bb49e8c834e7211bf8c495e5', 'arxivId': '2007.08259', 'publication_year': 2020, 'abstract': None}
{'title': 'Closed-Form Factorization of Latent Semantics in GANs', 'paperID': 'dc0092d06ab76465431edfd51b08d823b7d1ff3f', 'arxivId': '2007.06600', 'publication_year': 2020, 'abstract': None}
{'title': 'Learning to Generate Novel Domains for Domain Generalization', 'paperID': '3f88e25db654ea030c2241f540f49b56b2d727ec', 'arxivId': '2007.03304', 'publication_year': 2020, 'abstract': None}
{'title': 'Self-Challenging Improves Cross-Domain Generalization', 'paperID': '09472ff0d3c3f975ef1fdc02cfb1605d3d4275fa', 'arxivId': '2007.02454', 'publication_year': 2020, 'abstract': None}
{'title': 'Efficient Domain Generalization via Common-Specific Low-Rank Decomposition', 'paperID': 'dddc3f4a6d2d668eb9a840ca8ff7c2d83366a507', 'arxivId': '2003.12815', 'publication_year': 2020, 'abstract': None}
{'title': 'Data Uncertainty Learning in Face Recognition', 'paperID': 'd0d955edbc44067e7fb469d1884eb59236dc770b', 'arxivId': '2003.11339', 'publication_year': 2020, 'abstract': None}
{'title': 'Domain Adaptive Ensemble Learning', 'paperID': '1f49f005859e966af8d8fcfb2ec3e880e5afde94', 'arxivId': '2003.07325', 'publication_year': 2020, 'abstract': None}
{'title': 'On Feature Normalization and Data Augmentation', 'paperID': '46803220e5f6b636b65ef0ff87c0c9c4b95dec31', 'arxivId': '2002.11102', 'publication_year': 2020, 'abstract': None}
{'title': 'Mutual Mean-Teaching: Pseudo Label Refinery for Unsupervised Domain Adaptation on Person Re-identification', 'paperID': '22b52d3f18eaf43993a3a91053f5efe6267144e7', 'arxivId': '2001.01526', 'publication_year': 2020, 'abstract': None}
{'title': 'Implicit Semantic Data Augmentation for Deep Networks', 'paperID': '11babff42b5bf9841ebb87781bfc21f74acb3d28', 'arxivId': '1909.12220', 'publication_year': 2019, 'abstract': None}
{'title': 'Learning to Optimize Domain Specific Normalization for Domain Generalization', 'paperID': '9fcd6d95bea171c9a5156cf9d4b6c8654a7b684f', 'arxivId': '1907.04275', 'publication_year': 2019, 'abstract': None}
{'title': 'Probabilistic Face Embeddings', 'paperID': '53ea629b5933430eafa98692edf39ab2bd737d09', 'arxivId': '1904.09658', 'publication_year': 2019, 'abstract': None}
{'title': 'Benchmarking Neural Network Robustness to Common Corruptions and Perturbations', 'paperID': '49b64383fe36268410c430352637ed23b16820c5', 'arxivId': '1903.12261', 'publication_year': 2019, 'abstract': None}
{'title': 'Deep Domain Generalization via Conditional Invariant Adversarial Networks', 'paperID': 'a60540a8407fd117fd8e6857d4728e661f53dcc8', 'arxivId': None, 'publication_year': 2018, 'abstract': None}
{'title': 'Two at Once: Enhancing Learning and Generalization Capacities via IBN-Net', 'paperID': 'd39a5ea57b1c242a0450385523fd3471b172458c', 'arxivId': '1807.09441', 'publication_year': 2018, 'abstract': None}
{'title': 'Manifold Mixup: Better Representations by Interpolating Hidden States', 'paperID': '1b59eea8ec4684381a885b59acd09c9151a49487', 'arxivId': None, 'publication_year': 2018, 'abstract': None}
{'title': 'Domain Generalization with Adversarial Feature Learning', 'paperID': 'ba6ba7f488c1ece0803f4b9e1c83a3196d061610', 'arxivId': None, 'publication_year': 2018, 'abstract': None}
{'title': 'Generalizing Across Domains via Cross-Gradient Training', 'paperID': 'cabc42832388b1995d1f815f9fc4253f3f593993', 'arxivId': '1804.10745', 'publication_year': 2018, 'abstract': None}
{'title': 'Learning to Generalize: Meta-Learning for Domain Generalization', 'paperID': 'b39b45a59c27a0cb3214d5a84547f54722d40c69', 'arxivId': '1710.03463', 'publication_year': 2017, 'abstract': None}
{'title': 'Deeper, Broader and Artier Domain Generalization', 'paperID': 'b1e7f07965a53491690bd31fdab626bfac606eae', 'arxivId': '1710.03077', 'publication_year': 2017, 'abstract': None}
{'title': 'Deep Hashing Network for Unsupervised Domain Adaptation', 'paperID': 'b8ebda42e272d3617375118542d4675a0c0e501d', 'arxivId': '1706.07522', 'publication_year': 2017, 'abstract': None}
{'title': 'Arbitrary Style Transfer in Real-Time with Adaptive Instance Normalization', 'paperID': 'be0ef77fb0345c5851bb5d297f3ed84ae3c581ee', 'arxivId': '1703.06868', 'publication_year': 2017, 'abstract': None}
{'title': 'Performance Measures and a Data Set for Multi-target, Multi-camera Tracking', 'paperID': '85aefde69e916523d9587b6abd01419420039474', 'arxivId': '1609.01775', 'publication_year': 2016, 'abstract': None}
{'title': 'Playing for Data: Ground Truth from Computer Games', 'paperID': '4d9d25e67ebabbfc0acd63798f1a260cb2c8a9bd', 'arxivId': '1608.02192', 'publication_year': 2016, 'abstract': None}
{'title': 'DeepLab: Semantic Image Segmentation with Deep Convolutional Nets, Atrous Convolution, and Fully Connected CRFs', 'paperID': 'cab372bc3824780cce20d9dd1c22d4df39ed081a', 'arxivId': '1606.00915', 'publication_year': 2016, 'abstract': None}
{'title': 'The Cityscapes Dataset for Semantic Urban Scene Understanding', 'paperID': 'c8c494ee5488fe20e0aa01bddf3fc4632086d654', 'arxivId': '1604.01685', 'publication_year': 2016, 'abstract': None}
{'title': 'Scalable Person Re-identification: A Benchmark', 'paperID': 'e24c261f5cfcd58a595efb7ca684aedcb2a2f22c', 'arxivId': None, 'publication_year': 2015, 'abstract': None}
{'title': 'Dropout as a Bayesian Approximation: Representing Model Uncertainty in Deep Learning', 'paperID': 'f35de4f9b1a7c4d3fa96a0d2ab1bf8937671f6b6', 'arxivId': '1506.02142', 'publication_year': 2015, 'abstract': None}
{'title': 'Auto-Encoding Variational Bayes', 'paperID': '5f5dc5b9a2ba710937e2c413b37b053cd673df02', 'arxivId': '1312.6114', 'publication_year': 2013, 'abstract': None}
{'title': 'Generalizing from Several Related Classification Tasks to a New Unlabeled Sample', 'paperID': '5cb309a35313308d0e75e409be84c176dc64c61c', 'arxivId': None, 'publication_year': 2011, 'abstract': None}
{'title': 'An overview of statistical learning theory', 'paperID': '4609f6bdc3beab00c9beceaa12dd8101fefe6f1c', 'arxivId': None, 'publication_year': 1999, 'abstract': None}
{'title': 'Principles of Risk Minimization for Learning Theory', 'paperID': '9642a175637a400b425f0ac0cb6a2b067cc8fe6b', 'arxivId': None, 'publication_year': 1991, 'abstract': None}
{'title': 'Transferable Normalization: Towards Improving Transferability of Deep Neural Networks', 'paperID': 'e7c642fbbe31fea90cf3c643c380e354c20d9aa4', 'arxivId': None, 'publication_year': 2019, 'abstract': None}
{'title': 'Dropout: a simple way to prevent neural networks from overfitting', 'paperID': '34f25a8704614163c4095b3ee2fc969b60de4698', 'arxivId': None, 'publication_year': 2014, 'abstract': None}
{'title': 'Visualizing Data using t-SNE', 'paperID': '1c46943103bd7b7a2c7be86859995a4144d1938b', 'arxivId': None, 'publication_year': 2008, 'abstract': None}
{'title': 'Uncertainty Modeling for Out-of-Distribution Generalization', 'paperID': '3485aa52bf7a8310e80e139907d8c2e649e3ab66', 'arxivId': '2202.03958', 'publication_year': '2022', 'abstract': 'Though remarkable progress has been achieved in various vision tasks, deep neural networks still suffer obvious performance degradation when tested in out-of-distribution scenarios. We argue that the feature statistics (mean and standard deviation), which carry the domain characteristics of the training data, can be properly manipulated to improve the generalization ability of deep learning models. Common methods often consider the feature statistics as deterministic values measured from the learned features and do not explicitly consider the uncertain statistics discrepancy caused by potential domain shifts during testing. In this paper, we improve the network generalization ability by modeling the uncertainty of domain shifts with synthesized feature statistics during training. Specifically, we hypothesize that the feature statistic, after considering the potential uncertainties, follows a multivariate Gaussian distribution. Hence, each feature statistic is no longer a deterministic value, but a probabilistic point with diverse distribution possibilities. With the uncertain feature statistics, the models can be trained to alleviate the domain perturbations and achieve better robustness against potential domain shifts. Our method can be readily integrated into networks without additional parameters. Extensive experiments demonstrate that our proposed method consistently improves the network generalization ability on multiple vision tasks, including image classification, semantic segmentation, and instance retrieval. The code can be available at https://github.com/lixiaotong97/DSU.'}
{'title': 'Avoiding Inference Heuristics in Few-shot Prompt-based Finetuning', 'paperID': 'fccce60283729934467877f0730317c3e9fcc61e', 'arxivId': '2109.04144', 'publication_year': 2021, 'abstract': None}
{'title': 'Robust fine-tuning of zero-shot models', 'paperID': '9289826beb6206eeaf500105f7329d6d5a495d8a', 'arxivId': '2109.01903', 'publication_year': 2021, 'abstract': None}
{'title': 'Learning to Prompt for Vision-Language Models', 'paperID': '96ea07447d2f9adefe03852a878517a2a6d45b96', 'arxivId': '2109.01134', 'publication_year': 2021, 'abstract': None}
{'title': 'Accuracy on the Line: on the Strong Correlation Between Out-of-Distribution and In-Distribution Generalization', 'paperID': '106cc848e51ad0938e73c1b3b2ebb90d4bdea143', 'arxivId': '2107.04649', 'publication_year': 2021, 'abstract': None}
{'title': 'The Evolution of Out-of-Distribution Robustness Throughout Fine-Tuning', 'paperID': '4b1db6ebbdfcfe8ef67c5db511b6ad169fcc8f7f', 'arxivId': '2106.15831', 'publication_year': 2021, 'abstract': None}
{'title': 'Iterative Feature Matching: Toward Provable Domain Generalization with Logarithmic Environments', 'paperID': 'd5d375628b5ed09a4e40c54eccdd1ae97a3a31fc', 'arxivId': '2106.09913', 'publication_year': 2021, 'abstract': None}
{'title': 'How Fine-Tuning Allows for Effective Meta-Learning', 'paperID': 'd4d37dfff71691cda8b4ff2314884b172fb5671b', 'arxivId': '2105.02221', 'publication_year': 2021, 'abstract': None}
{'title': 'The Power of Scale for Parameter-Efficient Prompt Tuning', 'paperID': 'ffdbd7f0b03b85747b001b4734d5ee31b5229aa4', 'arxivId': '2104.08691', 'publication_year': 2021, 'abstract': None}
{'title': 'An Empirical Study of Training Self-Supervised Vision Transformers', 'paperID': '739ceacfafb1c4eaa17509351b647c773270b3ae', 'arxivId': '2104.02057', 'publication_year': 2021, 'abstract': None}
{'title': 'Learning Transferable Visual Models From Natural Language Supervision', 'paperID': '6f870f7f02a8c59c3e23f407f3ef00dd1dcf8fc4', 'arxivId': '2103.00020', 'publication_year': 2021, 'abstract': None}
{'title': 'A Theory of Label Propagation for Subpopulation Shift', 'paperID': '602f1f77058b67212d1c03559ddf0e86c23a919d', 'arxivId': '2102.11203', 'publication_year': 2021, 'abstract': None}
{'title': 'Partial transfusion: on the expressive influence of trainable batch norm parameters for transfer learning', 'paperID': 'a81912ad6c66e999f514927d5b05a9218d1d55af', 'arxivId': '2102.05543', 'publication_year': 2021, 'abstract': None}
{'title': 'Does Invariant Risk Minimization Capture Invariance?', 'paperID': '1fc4470c1766aea4c435015f5ef873b066f50121', 'arxivId': '2101.01134', 'publication_year': 2021, 'abstract': None}
{'title': 'WILDS: A Benchmark of in-the-Wild Distribution Shifts', 'paperID': '40848b41ed8c9c255ecd8a920006877691b52d03', 'arxivId': '2012.07421', 'publication_year': 2020, 'abstract': None}
{'title': 'Removing Spurious Features can Hurt Accuracy and Affect Groups Disproportionately', 'paperID': '753c96b2b770272e2f30d6247b228c2282224440', 'arxivId': '2012.04104', 'publication_year': 2020, 'abstract': None}
{'title': 'Geography-Aware Self-Supervised Learning', 'paperID': '0ab72e9a9c4c89d92898d5f883563fac3b1a1260', 'arxivId': '2011.09980', 'publication_year': 2020, 'abstract': None}
{'title': 'The Risks of Invariant Risk Minimization', 'paperID': '1e76e2fbf27198986271a672f462dc38d790d00f', 'arxivId': '2010.05761', 'publication_year': 2020, 'abstract': None}
{'title': 'Better Fine-Tuning by Reducing Representational Collapse', 'paperID': 'b88c11922cac84e5ea902f82d27ae21c3dda2e04', 'arxivId': '2008.03156', 'publication_year': 2020, 'abstract': None}
{'title': 'Measuring Robustness to Natural Distribution Shifts in Image Classification', 'paperID': '569ef4e3c9f5ae968fc94000c12d212a2b679907', 'arxivId': '2007.00644', 'publication_year': 2020, 'abstract': None}
{'title': 'The Many Faces of Robustness: A Critical Analysis of Out-of-Distribution Generalization', 'paperID': '022622e024890d6e044ac50e2da6b44c59bdf418', 'arxivId': '2006.16241', 'publication_year': 2020, 'abstract': None}
{'title': 'Composed Fine-Tuning: Freezing Pre-Trained Denoising Autoencoders for Improved Generalization', 'paperID': '9e0aa0df70aedd3fda5f37fc3210eacaa5395ebf', 'arxivId': '2006.16205', 'publication_year': 2020, 'abstract': None}
{'title': 'Improved Baselines with Momentum Contrastive Learning', 'paperID': 'a1b8a8df281bbaec148a897927a49ea47ea31515', 'arxivId': '2003.04297', 'publication_year': 2020, 'abstract': None}
{'title': 'A Simple Framework for Contrastive Learning of Visual Representations', 'paperID': '34733eaf66007516347a40ad5d9bbe1cc9dacb6b', 'arxivId': '2002.05709', 'publication_year': 2020, 'abstract': None}
{'title': 'Side-Tuning: A Baseline for Network Adaptation via Additive Side Networks', 'paperID': '292475b9280d21ee5ad1a81ef6dac5244efd364e', 'arxivId': None, 'publication_year': 2019, 'abstract': None}
{'title': 'Momentum Contrast for Unsupervised Visual Representation Learning', 'paperID': 'add2f205338d70e10ce5e686df4a690e2851bdfc', 'arxivId': '1911.05722', 'publication_year': 2019, 'abstract': None}
{'title': 'SMART: Robust and Efficient Fine-Tuning for Pre-trained Natural Language Models through Principled Regularized Optimization', 'paperID': 'ab70853cd5912c470f6ff95e95481980f0a2a41b', 'arxivId': '1911.03437', 'publication_year': 2019, 'abstract': None}
{'title': 'Class-Imbalanced Domain Adaptation: An Empirical Odyssey', 'paperID': '024462d02d81b882b782df5a4270c13f4db10d7a', 'arxivId': None, 'publication_year': 2019, 'abstract': None}
{'title': 'FreeLB: Enhanced Adversarial Training for Natural Language Understanding', 'paperID': 'd01fa0311e8e15b8b874b376123530c815f52852', 'arxivId': '1909.11764', 'publication_year': 2019, 'abstract': None}
{'title': 'The Generalization Error of Random Features Regression: Precise Asymptotics and the Double Descent Curve', 'paperID': '41c0be3adfd33cb6d0cb24c6fb1de109929276ca', 'arxivId': '1908.05355', 'publication_year': 2019, 'abstract': None}
{'title': 'Natural Adversarial Examples', 'paperID': '45557cc70cd6989ab6b03e5aeb787e34299099f7', 'arxivId': '1907.07174', 'publication_year': 2019, 'abstract': None}
{'title': 'Benign overfitting in linear regression', 'paperID': 'c563c0e06684f42bc5d76dfc7304581c11312393', 'arxivId': '1906.11300', 'publication_year': 2019, 'abstract': None}
{'title': 'A Structural Probe for Finding Syntax in Word Representations', 'paperID': '455a8838cde44f288d456d01c76ede95b56dc675', 'arxivId': None, 'publication_year': 2019, 'abstract': None}
{'title': 'A New Look at an Old Problem: A Universal Learning Approach to Linear Regression', 'paperID': '369eb43e6a1ec995f741b621f3e2be88dff79183', 'arxivId': '1905.04708', 'publication_year': 2019, 'abstract': None}
{'title': 'Learning Robust Global Representations by Penalizing Local Predictive Power', 'paperID': '4ae0c4a511697e960c477ea3e37b3e11bf3e0e02', 'arxivId': '1905.13549', 'publication_year': 2019, 'abstract': None}
{'title': 'Implicit Regularization of Discrete Gradient Dynamics in Deep Linear Neural Networks', 'paperID': 'c232afff29037ca4058f2b45e987cd12081bae0a', 'arxivId': '1904.13262', 'publication_year': 2019, 'abstract': None}
{'title': 'Harmless interpolation of noisy data in regression', 'paperID': 'bd949f2a0c23742427d8886e43c1d8c98c1865ea', 'arxivId': '1903.09139', 'publication_year': 2019, 'abstract': None}
{'title': 'Surprises in High-Dimensional Ridgeless Least Squares Interpolation', 'paperID': 'e58ef5ecbd163465658025a83729e27ade57e61c', 'arxivId': '1903.08560', 'publication_year': 2019, 'abstract': None}
{'title': 'Two models of double descent for weak features', 'paperID': 'f8a5278d4142215b33b516db5df1d9eb0d1d066e', 'arxivId': '1903.07571', 'publication_year': 2019, 'abstract': None}
{'title': 'To Tune or Not to Tune? Adapting Pretrained Representations to Diverse Tasks', 'paperID': '8659bf379ca8756755125a487c43cfe8611ce842', 'arxivId': '1903.05987', 'publication_year': 2019, 'abstract': None}
{'title': 'Parameter-Efficient Transfer Learning for NLP', 'paperID': '29ddc1f43f28af7c846515e32cc167bc66886d0c', 'arxivId': '1902.00751', 'publication_year': 2019, 'abstract': None}
{'title': 'Moment Matching for Multi-Source Domain Adaptation', 'paperID': '3217278e346fefbd34f0727321059c7ea5792612', 'arxivId': '1812.01754', 'publication_year': 2018, 'abstract': None}
{'title': 'SpotTune: Transfer Learning Through Adaptive Fine-Tuning', 'paperID': 'e87b5f4c64056431dfc62ebff0f23d9c94252598', 'arxivId': '1811.08737', 'publication_year': 2018, 'abstract': None}
{'title': 'Algorithmic Regularization in Learning Deep Homogeneous Models: Layers are Automatically Balanced', 'paperID': '0e662587c790e5d11475f5b0bce3638b4d1effa0', 'arxivId': '1806.00900', 'publication_year': 2018, 'abstract': None}
{'title': 'Do CIFAR-10 Classifiers Generalize to CIFAR-10?', 'paperID': 'f445493badf53febbaeab340a4fca98d9e4ab7f7', 'arxivId': '1806.00451', 'publication_year': 2018, 'abstract': None}
{'title': 'Do Better ImageNet Models Transfer Better?', 'paperID': '8a8cfa45b4c0d071fbffa091c02670b19c94b693', 'arxivId': '1805.08974', 'publication_year': 2018, 'abstract': None}
{'title': 'BDD100K: A Diverse Driving Dataset for Heterogeneous Multitask Learning', 'paperID': 'c01e8108b4ca599eb2b1e6f26b2ecf1c42e323a9', 'arxivId': '1805.04687', 'publication_year': 2018, 'abstract': None}
{'title': 'On the Optimization of Deep Networks: Implicit Acceleration by Overparameterization', 'paperID': '6ea8cbf0cc4cda3d981348a279b464524a8485cc', 'arxivId': '1802.06509', 'publication_year': 2018, 'abstract': None}
{'title': 'Deep Contextualized Word Representations', 'paperID': '3febb2bed8865945e7fddc99efd791887bb7e14f', 'arxivId': '1802.05365', 'publication_year': 2018, 'abstract': None}
{'title': 'Explicit Inductive Bias for Transfer Learning with Convolutional Networks', 'paperID': '5f1141287c577f2e45f8c35a5fd30cfb91311257', 'arxivId': '1802.01483', 'publication_year': 2018, 'abstract': None}
{'title': 'Universal Language Model Fine-tuning for Text Classification', 'paperID': '1e077413b25c4d34945cc2707e17e46ed4fe784a', 'arxivId': None, 'publication_year': 2018, 'abstract': None}
{'title': 'Deep linear neural networks with arbitrary loss: All local minima are global', 'paperID': 'e3b7201deb277dbc1ce1f1849cf099c71b2ff3a1', 'arxivId': None, 'publication_year': 2017, 'abstract': None}
{'title': 'Functional Map of the World', 'paperID': 'a588d38ec81c0337b445931eadf6f443aea13380', 'arxivId': '1711.07846', 'publication_year': 2017, 'abstract': None}
{'title': 'Self-ensembling for visual domain adaptation', 'paperID': '1c012e5b3ddb8a60420e8f92162d32ad135f9ba1', 'arxivId': None, 'publication_year': 2017, 'abstract': None}
{'title': 'Implicit Regularization in Matrix Factorization', 'paperID': '4e8917e73e02c76d55ded62e43541d44684a4c8a', 'arxivId': '1705.09280', 'publication_year': 2017, 'abstract': None}
{'title': 'What do Neural Machine Translation Models Learn about Morphology?', 'paperID': '263210f256603e3b62476ffb5b9bbbbc6403b646', 'arxivId': '1704.03471', 'publication_year': 2017, 'abstract': None}
{'title': 'Borrowing Treasures from the Wealthy: Deep Transfer Learning through Selective Joint Fine-Tuning', 'paperID': 'cad99e8f78618510eb37394be948c8e993af57ed', 'arxivId': '1702.08690', 'publication_year': 2017, 'abstract': None}
{'title': 'End-to-End Training of Deep Visuomotor Policies', 'paperID': 'b6b8a1b80891c96c28cc6340267b58186157e536', 'arxivId': '1504.00702', 'publication_year': 2015, 'abstract': None}
{'title': 'An Introduction to Matrix Concentration Inequalities', 'paperID': '3504565c8c3cbae18a50247604f07a7e01cde801', 'arxivId': '1501.01571', 'publication_year': 2015, 'abstract': None}
{'title': 'In Search of the Real Inductive Bias: On the Role of Implicit Regularization in Deep Learning', 'paperID': '4b675d8f63888d7d6d7d77a0834efa5eaded64c5', 'arxivId': '1412.6614', 'publication_year': 2014, 'abstract': None}
{'title': 'Exact solutions to the nonlinear dynamics of learning in deep linear neural networks', 'paperID': '99c970348b8f70ce23d6641e201904ea49266b6e', 'arxivId': '1312.6120', 'publication_year': 2013, 'abstract': None}
{'title': 'An Analysis of Single-Layer Networks in Unsupervised Feature Learning', 'paperID': 'be9a17321537d9289875fe475b71f4821457b435', 'arxivId': None, 'publication_year': 2011, 'abstract': None}
{'title': 'Understanding the difficulty of training deep feedforward neural networks', 'paperID': 'b71ac1e9fb49420d13e084ac67254a0bbd40f83f', 'arxivId': None, 'publication_year': 2010, 'abstract': None}
{'title': 'Smallest singular value of a random rectangular matrix', 'paperID': '5bcb1fcf2004b6994e7a8068aa2aead8a55596fd', 'arxivId': '0802.3956', 'publication_year': 2008, 'abstract': None}
{'title': 'Prefix-Tuning: Optimizing Continuous Prompts for Generation', 'paperID': '53d8b356551a2361020a948f64454a6d599af69f', 'arxivId': '2101.00190', 'publication_year': 2021, 'abstract': None}
{'title': 'Matrix Computations', 'paperID': '444d70e3331b5083b40ef32e49390ef683a65e67', 'arxivId': None, 'publication_year': 2011, 'abstract': None}
{'title': 'Fine-Tuning can Distort Pretrained Features and Underperform Out-of-Distribution', 'paperID': '29b77089a0a40f46372ce2dca9c3bb2dd5d46b1d', 'arxivId': '2202.10054', 'publication_year': '2022', 'abstract': 'When transferring a pretrained model to a downstream task, two popular methods are full fine-tuning (updating all the model parameters) and linear probing (updating only the last linear layer—the “head”). It is well known that fine-tuning leads to better accuracy in-distribution (ID). However, in this paper, we find that fine-tuning can achieve worse accuracy than linear probing out-of-distribution (OOD) when the pretrained features are good and the distribution shift is large. On 10 distribution shift datasets (Breeds-Living17, Breeds-Entity30, DomainNet, CIFAR → STL, CIFAR10.1, FMoW, ImageNetV2, ImageNet-R, ImageNet-A, ImageNet-Sketch), fine-tuning obtains on average 2% higher accuracy ID but 7% lower accuracy OOD than linear probing. We show theoretically that this tradeoff between ID and OOD accuracy arises even in a simple setting: fine-tuning overparameterized two-layer linear networks. We prove that the OOD error of fine-tuning is high when we initialize with a fixed or random head—this is because while fine-tuning learns the head, the lower layers of the neural network change simultaneously and distort the pretrained features. Our analysis suggests that the easy two-step strategy of linear probing then full fine-tuning (LP-FT), sometimes used as a fine-tuning heuristic, combines the benefits of both fine-tuning and linear probing. Empirically, LP-FT outperforms both fine-tuning and linear probing on the above datasets (1% better ID, 10% better OOD than full fine-tuning).'}
{'title': 'A Simple Fix to Mahalanobis Distance for Improving Near-OOD Detection', 'paperID': '4c7d664761c359cffd20c9d555031271ec67ab3c', 'arxivId': '2106.09022', 'publication_year': 2021, 'abstract': None}
{'title': 'Adversarial Robustness via Fisher-Rao Regularization', 'paperID': 'e0e19d99bf487ba7a471af23acc96542ee19ba36', 'arxivId': '2106.06685', 'publication_year': 2021, 'abstract': None}
{'title': 'Geometric Deep Learning: Grids, Groups, Graphs, Geodesics, and Gauges', 'paperID': '14014c024674991149f3ecf9314c93f7e029ef1a', 'arxivId': '2104.13478', 'publication_year': 2021, 'abstract': None}
{'title': 'Performance analysis of out-of-distribution detection on trained neural networks', 'paperID': '06572d93ca5edee2dfa651b6a16c1d5d525a866f', 'arxivId': '2204.12378', 'publication_year': 2021, 'abstract': None}
{'title': 'Understanding the Failure Modes of Out-of-Distribution Generalization', 'paperID': '1b4a54670bb4fe15bcb0d06de0391d5b6d10ace2', 'arxivId': '2010.15775', 'publication_year': 2020, 'abstract': None}
{'title': 'Energy-based Out-of-distribution Detection', 'paperID': '35b966347dae2f0d496ea713edf03a68211838a5', 'arxivId': '2010.03759', 'publication_year': 2020, 'abstract': None}
{'title': 'Certifiably Adversarially Robust Detection of Out-of-Distribution Data', 'paperID': '0930f7234a861c34050685070e117c295ebb184a', 'arxivId': None, 'publication_year': 2020, 'abstract': None}
{'title': 'Detecting Out-of-Distribution Examples with Gram Matrices', 'paperID': 'bfc65dba18cdbe559f87dfe2cb8848452a2ee8d3', 'arxivId': None, 'publication_year': 2020, 'abstract': None}
{'title': 'Contrastive Training for Improved Out-of-Distribution Detection', 'paperID': '94192bcdf3507e3543910c03b16bd06c5338fd47', 'arxivId': '2007.05566', 'publication_year': 2020, 'abstract': None}
{'title': 'Why Normalizing Flows Fail to Detect Out-of-Distribution Data', 'paperID': 'c2eff53cc9db9eaca8d9ffe06f2d618b0e360c9d', 'arxivId': '2006.08545', 'publication_year': 2020, 'abstract': None}
{'title': 'Self-Supervised Learning for Generalizable Out-of-Distribution Detection', 'paperID': '5771af144ce1d4d783a0af70c190a74e5123d0a0', 'arxivId': None, 'publication_year': 2020, 'abstract': None}
{'title': 'The Fisher–Rao Distance between Multivariate Normal Distributions: Special Cases, Bounds and Applications', 'paperID': '3368fc9f59480f3b7b755b66dee0488916774f1f', 'arxivId': None, 'publication_year': 2020, 'abstract': None}
{'title': 'Hybrid Models for Open Set Recognition', 'paperID': '549e8e5eea04b301cbb805f5502afffef492d344', 'arxivId': '2003.12506', 'publication_year': 2020, 'abstract': None}
{'title': 'Likelihood Regret: An Out-of-Distribution Detection Score For Variational Auto-encoder', 'paperID': '47cbd8cfd6fcba83d3b3714faef480260bc9d5de', 'arxivId': '2003.02977', 'publication_year': 2020, 'abstract': None}
{'title': 'Generalized ODIN: Detecting Out-of-Distribution Image Without Learning From Out-of-Distribution Data', 'paperID': 'ae9bf201f128cabaa4350b54ff6607525c736cd5', 'arxivId': '2002.11297', 'publication_year': 2020, 'abstract': None}
{'title': 'Out-of-Distribution Detection with Distance Guarantee in Deep Generative Models', 'paperID': '1aeeaf9c03897d68fc09a8d929a3366aa8ecf9b1', 'arxivId': None, 'publication_year': 2020, 'abstract': None}
{'title': 'Deep Residual Flow for Out of Distribution Detection', 'paperID': 'af5b1a35271efd17ff3d5ddd152bacc96dff0e81', 'arxivId': None, 'publication_year': 2020, 'abstract': None}
{'title': 'Deep Residual Flow for Novelty Detection', 'paperID': '5fda9d3b9d658b64139b1cb077d98ec5a580b880', 'arxivId': '2001.05419', 'publication_year': 2020, 'abstract': None}
{'title': 'Out-of-distribution Detection in Classifiers via Generation', 'paperID': '33fc67c7425c669bac36b4dba7fd427e55d309fe', 'arxivId': '1910.04241', 'publication_year': 2019, 'abstract': None}
{'title': "Can You Trust Your Model's Uncertainty? Evaluating Predictive Uncertainty Under Dataset Shift", 'paperID': '1eb7f46b1a0a7df823194d86543e5554aa21021a', 'arxivId': '1906.02530', 'publication_year': 2019, 'abstract': None}
{'title': 'Generative Ensembles for Robust Anomaly Detection', 'paperID': '50577b1a6aa575f401bce336e015e7a4eaf7edcb', 'arxivId': '1810.01392', 'publication_year': 2018, 'abstract': None}
{'title': 'Detecting Out-Of-Distribution Samples Using Low-Order Deep Features Statistics', 'paperID': '6e1f7b326dd795377a631cf76fc5e5df05f1dce2', 'arxivId': None, 'publication_year': 2018, 'abstract': None}
{'title': 'Out-of-Distribution Detection Using an Ensemble of Self Supervised Leave-out Classifiers', 'paperID': 'e31fa9510047c0df23fb4dd37ee7c70783a3fa60', 'arxivId': '1809.03576', 'publication_year': 2018, 'abstract': None}
{'title': 'Out-of-Distribution Detection using Multiple Semantic Label Representations', 'paperID': '5ea5224de74847ba3a5d15c718af8f04fa50efe7', 'arxivId': '1808.06664', 'publication_year': 2018, 'abstract': None}
{'title': 'Unsupervised Anomaly Detection with Generative Adversarial Networks to Guide Marker Discovery', 'paperID': 'e163a2e89c136cb4442e34c72f7173a0ff46dc79', 'arxivId': '1703.05921', 'publication_year': 2017, 'abstract': None}
{'title': 'Densely Connected Convolutional Networks', 'paperID': '5694e46284460a648fe29117cbc55f6c9be3fa3c', 'arxivId': '1608.06993', 'publication_year': 2016, 'abstract': None}
{'title': 'Clustering using the fisher-rao distance', 'paperID': '81acb0286de78f6d14b68e529a1a37d6ae658d3d', 'arxivId': None, 'publication_year': 2016, 'abstract': None}
{'title': 'MLaaS: Machine Learning as a Service', 'paperID': 'ed5ab1cff7dd3a902eea4a811b15aa5ea3a36b30', 'arxivId': None, 'publication_year': 2015, 'abstract': None}
{'title': 'Towards Open Set Deep Networks', 'paperID': 'd094fb0af5bc6a26fa9c27d638c4a3a0725d8b5c', 'arxivId': '1511.06233', 'publication_year': 2015, 'abstract': None}
{'title': 'A review of novelty detection', 'paperID': '9acc51b06f54b07836fad4cc24633187dc21317f', 'arxivId': None, 'publication_year': 2014, 'abstract': None}
{'title': 'SUN database: Large-scale scene recognition from abbey to zoo', 'paperID': '908091b4a8757c3b2f7d9cfa2c4f616ee12c5157', 'arxivId': None, 'publication_year': 2010, 'abstract': None}
{'title': 'Dataset Shift in Machine Learning', 'paperID': 'c62043a7d2537bbf40a84b9913957452a47fdb83', 'arxivId': None, 'publication_year': 2009, 'abstract': None}
{'title': 'Character Recognition in Natural Images', 'paperID': 'dbbd5fdc09349bbfdee7aa7365a9d37716852b32', 'arxivId': None, 'publication_year': 2009, 'abstract': None}
{'title': 'An Analysis of Variance Test for Normality (Complete Samples)', 'paperID': 'e4a742a4f0585b4e4069726f6628f4d4285a0827', 'arxivId': None, 'publication_year': 1965, 'abstract': None}
{'title': 'Tiny ImageNet Visual Recognition Challenge', 'paperID': '384ce792cf2b2afbe001f2168bfe7d5e7804c736', 'arxivId': None, 'publication_year': 2015, 'abstract': None}
{'title': "Rao's distance measure", 'paperID': '3e8c2d811bf231d4744b8df9019f4676223f9bae', 'arxivId': None, 'publication_year': 1981, 'abstract': None}
{'title': 'On the generalized distance in statistics', 'paperID': 'fa97c2238a16e9226f386ecffe22095e3d3d9dff', 'arxivId': None, 'publication_year': 1936, 'abstract': None}
{'title': 'On the Mathematical Foundations of Theoretical Statistics', 'paperID': 'bd2e048c676ad778351bd7d7660240a978422117', 'arxivId': None, 'publication_year': 1922, 'abstract': None}
{'title': 'Igeood: An Information Geometry Approach to Out-of-Distribution Detection', 'paperID': '2815a5e7ba661ae278aa7c19e08ac884cde17bf7', 'arxivId': '2203.07798', 'publication_year': '2022', 'abstract': 'Reliable out-of-distribution (OOD) detection is fundamental to implementing safer modern machine learning (ML) systems. In this paper, we introduce Igeood, an effective method for detecting OOD samples. Igeood applies to any pre-trained neural network, works under various degrees of access to the ML model, does not require OOD samples or assumptions on the OOD data but can also benefit (if available) from OOD samples. By building on the geodesic (Fisher-Rao) distance between the underlying data distributions, our discriminator can combine confidence scores from the logits outputs and the learned features of a deep neural network. Empirically, we show that Igeood outperforms competing state-of-the-art methods on a variety of network architectures and datasets.'}
{'title': 'A Review of Uncertainty Quantification in Deep Learning: Techniques, Applications and Challenges', 'paperID': '172b266f190d89ec6e2164560eba3707e8936e6e', 'arxivId': '2011.06225', 'publication_year': 2020, 'abstract': None}
{'title': 'Prediction Intervals: Split Normal Mixture from Quality-Driven Deep Ensembles', 'paperID': 'f2ef185250e909026bf33024f59e2dcc545e3bca', 'arxivId': '2007.09670', 'publication_year': 2020, 'abstract': None}
{'title': 'Hands-On Bayesian Neural Networks—A Tutorial for Deep Learning Users', 'paperID': '9eebd3c7971a239cf69a0358563f397bd8a8f99c', 'arxivId': '2007.06823', 'publication_year': 2020, 'abstract': None}
{'title': 'PIVEN: A Deep Neural Network for Prediction Intervals with Specific Value Prediction', 'paperID': '7e4e71d25edb6ac73376c9ea28d835dfaa5728de', 'arxivId': '2006.05139', 'publication_year': 2020, 'abstract': None}
{'title': 'Deep Evidential Regression', 'paperID': '14703aaffc186e98bdf3468c3ee70ddce0ccd90d', 'arxivId': '1910.02600', 'publication_year': 2019, 'abstract': None}
{'title': 'Single-Model Uncertainties for Deep Learning', 'paperID': '3995dab2b1c3f0a036352e47a324b0edb8542b4f', 'arxivId': None, 'publication_year': 2018, 'abstract': None}
{'title': 'Uncertainty in Neural Networks: Approximately Bayesian Ensembling', 'paperID': 'f8a54ba839f6194198b4886097169a53905fbb37', 'arxivId': '1810.05546', 'publication_year': 2018, 'abstract': None}
{'title': 'Quantile Regression', 'paperID': '0c0a97ebb11b9773900f682618815443b2b5153a', 'arxivId': None, 'publication_year': 2018, 'abstract': None}
{'title': 'High-Quality Prediction Intervals for Deep Learning: A Distribution-Free, Ensembled Approach', 'paperID': '7a0ba4f62a1d98ad5f1e0bab1bdd78dba9ca8ecc', 'arxivId': '1802.07167', 'publication_year': 2018, 'abstract': None}
{'title': 'Bayesian Optimization with Robust Bayesian Neural Networks', 'paperID': '30423f985355d74295546f1d14ed2ddd33cdef99', 'arxivId': None, 'publication_year': 2016, 'abstract': None}
{'title': 'Understanding Deep Neural Networks with Rectified Linear Units', 'paperID': '9375729d21a344a5ccccd5f53556ddf90b957cd9', 'arxivId': '1611.01491', 'publication_year': 2016, 'abstract': None}
{'title': 'A Survey on Bayesian Deep Learning', 'paperID': 'b0e6fd0c22865fa8ca7a02d18681087052c9f6c5', 'arxivId': None, 'publication_year': 2016, 'abstract': None}
{'title': 'Gaussian Processes for Big Data', 'paperID': 'e301beb0e17805dbabf5add06d99c53e8703ea34', 'arxivId': '1309.6835', 'publication_year': 2013, 'abstract': None}
{'title': 'Stochastic variational inference', 'paperID': 'bccb2f99a9d1c105699f5d88c479569085e2c7ba', 'arxivId': '1206.7051', 'publication_year': 2012, 'abstract': None}
{'title': 'Lower Upper Bound Estimation Method for Construction of Neural Network-Based Prediction Intervals', 'paperID': 'fad253f283561cd4cd19a732da5288ab1820a21b', 'arxivId': None, 'publication_year': 2011, 'abstract': None}
{'title': 'Confidence and prediction intervals for neural network ensembles', 'paperID': 'c18e584b430cd69451a0c3149639dc88f2d2ac3e', 'arxivId': None, 'publication_year': 1999, 'abstract': None}
{'title': 'Prediction intervals for neural networks via nonlinear regression', 'paperID': 'c669bf2e309831f416226f464d5f413c03494d51', 'arxivId': None, 'publication_year': 1998, 'abstract': None}
{'title': 'Prediction Intervals for Artificial Neural Networks', 'paperID': '1f004dc69520636c8daee383ac3a7c9c5cce133f', 'arxivId': None, 'publication_year': 1997, 'abstract': None}
{'title': 'Practical Confidence and Prediction Intervals', 'paperID': 'd0188b1ce2f3da36fe64a36901248d16d17ff218', 'arxivId': None, 'publication_year': 1996, 'abstract': None}
{'title': 'A Practical Bayesian Framework for Backpropagation Networks', 'paperID': 'b959164d1efca4b73986ba5d21e664aadbbc0457', 'arxivId': None, 'publication_year': 1992, 'abstract': None}
{'title': 'Non-Crossing Quantile Regression for Distributional Reinforcement Learning', 'paperID': '9f873fecd24e0cfb800249a30ecd8e3b3155e709', 'arxivId': None, 'publication_year': 2020, 'abstract': None}
{'title': 'Regression Quantiles', 'paperID': 'c09db7439505f49a0958f68e782df94b3807341a', 'arxivId': None, 'publication_year': 2007, 'abstract': None}
{'title': 'PI3NN: Out-of-distribution-aware Prediction Intervals from Three Neural Networks', 'paperID': '9b799db46342be286610f79a924079f5757976c3', 'arxivId': '2108.02327', 'publication_year': '2021', 'abstract': 'We propose a novel prediction interval (PI) method for uncertainty quantification, which addresses three major issues with the state-of-the-art PI methods. First, existing PI methods require retraining of neural networks (NNs) for every given confidence level and suffer from the crossing issue in calculating multiple PIs. Second, they usually rely on customized loss functions with extra sensitive hyperparameters for which fine tuning is required to achieve a well-calibrated PI. Third, they usually underestimate uncertainties of out-of-distribution (OOD) samples leading to over-confident PIs. Our PI3NN method calculates PIs from linear combinations of three NNs, each of which is independently trained using the standard mean squared error loss. The coefficients of the linear combinations are computed using root-finding algorithms to ensure tight PIs for a given confidence level. We theoretically prove that PI3NN can calculate PIs for a series of confidence levels without retraining NNs and it completely avoids the crossing issue. Additionally, PI3NN does not introduce any unusual hyperparameters resulting in a stable performance. Furthermore, we address OOD identification challenge by introducing an initialization scheme which provides reasonably larger PIs of the OOD samples than those of the in-distribution samples. Benchmark and real-world experiments show that our method outperforms several state-of-the-art approaches with respect to predictive uncertainty quality, robustness, and OOD samples identification.'}
{'title': 'Invariant Causal Representation Learning for Out-of-Distribution Generalization', 'paperID': '164b72b345a4cb03f62547abf62a033dcbd784ae', 'arxivId': None, 'publication_year': None, 'abstract': None}
{'title': 'Revisiting flow generative models for Out-of-distribution detection', 'paperID': '31278cec03fa87b45a02f43d275dd92b678fbc5b', 'arxivId': None, 'publication_year': None, 'abstract': None}
{'title': 'Can Subnetwork Structure be the Key to Out-of-Distribution Generalization?', 'paperID': '4a9244d0fc9b2b87eca5fa7579835f4a05eb8866', 'arxivId': '2106.02890', 'publication_year': 2021, 'abstract': None}
{'title': 'Counterfactual Invariance to Spurious Correlations: Why and How to Pass Stress Tests', 'paperID': '6aecc93c2d61da073b70dec19795172ca1ff3405', 'arxivId': '2106.00545', 'publication_year': 2021, 'abstract': None}
{'title': 'Causally-motivated Shortcut Removal Using Auxiliary Labels', 'paperID': 'de656b3de564933e1ef2351107e2369c0deae6b4', 'arxivId': '2105.06422', 'publication_year': 2021, 'abstract': None}
{'title': 'Blind Pareto Fairness and Subgroup Robustness', 'paperID': '14d8d5e612028842d35cb5865f8fecf9ecc63c00', 'arxivId': None, 'publication_year': 2021, 'abstract': None}
{'title': 'On Calibration and Out-of-domain Generalization', 'paperID': 'bfc7bd9442c6a7ecbf0d4f2bf4e23a8861792c01', 'arxivId': '2102.10395', 'publication_year': 2021, 'abstract': None}
{'title': 'Out-of-distribution Prediction with Invariant Risk Minimization: The Limitation and An Effective Fix', 'paperID': '340bd0cfeeab5d117a9fdffffa9e05fe2afaf64f', 'arxivId': '2101.07732', 'publication_year': 2021, 'abstract': None}
{'title': 'Robustness to Spurious Correlations in Text Classification via Automatically Generated Counterfactuals', 'paperID': 'a5b1169e536b806c2344261ebbbe3d97bc6e1cdb', 'arxivId': '2012.10040', 'publication_year': 2020, 'abstract': None}
{'title': 'X-CAL: Explicit Calibration for Survival Analysis', 'paperID': 'a1506424cf3a24f50b7291db1e70927ab8e17bb6', 'arxivId': '2101.05346', 'publication_year': 2020, 'abstract': None}
{'title': 'Environment Inference for Invariant Learning', 'paperID': '00325cb5408da77827951abd3fa93ec3bd019608', 'arxivId': '2010.07249', 'publication_year': 2020, 'abstract': None}
{'title': 'A Brief Review of Domain Adaptation', 'paperID': '115bbc50cf015990dc6f35bc8f99575ad2a68253', 'arxivId': '2010.03978', 'publication_year': 2020, 'abstract': None}
{'title': 'Identifying spurious correlations for robust text classification', 'paperID': '7d990e5cc46cf2066f1fcf0d30223033858c5995', 'arxivId': '2010.02458', 'publication_year': 2020, 'abstract': None}
{'title': 'Model Patching: Closing the Subgroup Performance Gap with Data Augmentation', 'paperID': '9207480a5cd071a3e85f408082b09283413cbfa5', 'arxivId': '2008.06775', 'publication_year': 2020, 'abstract': None}
{'title': 'Learning Invariant Feature Representation to Improve Generalization across Chest X-ray Datasets', 'paperID': '51e267ea751f74173358dd7c87ac80a0a3a71322', 'arxivId': '2008.04152', 'publication_year': 2020, 'abstract': None}
{'title': 'Domain Generalization with Optimal Transport and Metric Learning', 'paperID': '4f2be2daf44475b8d652c6d456668cab94683b9d', 'arxivId': None, 'publication_year': 2020, 'abstract': None}
{'title': 'Accounting for Unobserved Confounding in Domain Generalization', 'paperID': '396d97307650347d154bf599a9b168828e67baa8', 'arxivId': '2007.10653', 'publication_year': 2020, 'abstract': None}
{'title': 'In Search of Lost Domain Generalization', 'paperID': '6a5efb990b6558c21d9fdded4884c00ba152cb7c', 'arxivId': '2007.01434', 'publication_year': 2020, 'abstract': None}
{'title': 'Domain Generalization using Causal Matching', 'paperID': '2b5a8e6fd214e1471c5d61bf80e4ff9f774765b6', 'arxivId': '2006.07500', 'publication_year': 2020, 'abstract': None}
{'title': 'Fairness without Demographics through Adversarially Reweighted Learning', 'paperID': '08cb7d416bcd1b1e4d6492a0cd0b01424abd9515', 'arxivId': '2006.13114', 'publication_year': 2020, 'abstract': None}
{'title': 'An Investigation of Why Overparameterization Exacerbates Spurious Correlations', 'paperID': '26e858cf3c82b66bbd539bb79356b0e885bdc694', 'arxivId': '2005.04345', 'publication_year': 2020, 'abstract': None}
{'title': 'Shortcut learning in deep neural networks', 'paperID': '1b04936c2599e59b120f743fbb30df2eed3fd782', 'arxivId': '2004.07780', 'publication_year': 2020, 'abstract': None}
{'title': 'Invariant Rationalization', 'paperID': '60d7279168e1e1c9e151b68a3a9fc94ad5137ce5', 'arxivId': '2003.09772', 'publication_year': 2020, 'abstract': None}
{'title': 'Out-of-Distribution Generalization via Risk Extrapolation (REx)', 'paperID': '3621fff4a1c791901ea4a1359c10575193ec712d', 'arxivId': '2003.00688', 'publication_year': 2020, 'abstract': None}
{'title': 'Distributionally Robust Neural Networks for Group Shifts: On the Importance of Regularization for Worst-Case Generalization', 'paperID': '193092aef465bec868d1089ccfcac0279b914bda', 'arxivId': '1911.08731', 'publication_year': 2019, 'abstract': None}
{'title': 'Representation Learning with Statistical Independence to Mitigate Bias', 'paperID': '4efafeba13d7e22238583bab2ed3d5b9a3359465', 'arxivId': None, 'publication_year': 2019, 'abstract': None}
{'title': 'Can we trust deep learning models diagnosis? The impact of domain shift in chest radiograph classification', 'paperID': '31e77344130d14f56999be17d48af6d6d7fb3b6e', 'arxivId': '1909.01940', 'publication_year': 2019, 'abstract': None}
{'title': 'Invariant Risk Minimization', 'paperID': '753b7a701adc1b6072378bd048cfa8567885d9c7', 'arxivId': '1907.02893', 'publication_year': 2019, 'abstract': None}
{'title': 'Generating Diverse High-Fidelity Images with VQ-VAE-2', 'paperID': '6be216d93421bf19c1659e7721241ae73d483baf', 'arxivId': '1906.00446', 'publication_year': 2019, 'abstract': None}
{'title': 'A Universal Hierarchy of Shift-Stable Distributions and the Tradeoff Between Stability and Performance', 'paperID': 'bff67430f3c2413a63f0e7e1f7276004333c1f15', 'arxivId': None, 'publication_year': 2019, 'abstract': None}
{'title': 'Adversarial Invariant Feature Learning with Accuracy Constraint for Domain Generalization', 'paperID': '8fe578a3daede41faea142eb414cb8c95d5adbf6', 'arxivId': '1904.12543', 'publication_year': 2019, 'abstract': None}
{'title': 'CheXpert: A Large Chest Radiograph Dataset with Uncertainty Labels and Expert Comparison', 'paperID': '89a816719613e220a64ab2590c938c23bbfe187e', 'arxivId': '1901.07031', 'publication_year': 2019, 'abstract': None}
{'title': 'MIMIC-CXR: A large publicly available database of labeled chest radiographs', 'paperID': '74d8eb801c838d1dce814a1e9ce1074bd2c47721', 'arxivId': '1901.07042', 'publication_year': 2019, 'abstract': None}
{'title': 'Preventing Failures Due to Dataset Shift: Learning Predictive Models That Transport', 'paperID': '53bd10108f32ff2c98f333c97cf35570703239a3', 'arxivId': None, 'publication_year': 2018, 'abstract': None}
{'title': 'What is the Effect of Importance Weighting in Deep Learning?', 'paperID': 'b661520bf0061b7d96ccf12016e351dd3a6ee780', 'arxivId': '1812.03372', 'publication_year': 2018, 'abstract': None}
{'title': 'Deep learning predicts hip fracture using confounding patient and healthcare variables', 'paperID': '00192b5adb3dea34a60ca7ebe58b48fc44e80efd', 'arxivId': '1811.03695', 'publication_year': 2018, 'abstract': None}
{'title': 'Trainable Calibration Measures For Neural Networks From Kernel Mean Embeddings', 'paperID': '2bdf35c191cb4df4dcfb7fb18d6582cd032d1c40', 'arxivId': None, 'publication_year': 2018, 'abstract': None}
{'title': 'Variable generalization performance of a deep learning model to detect pneumonia in chest radiographs: A cross-sectional study', 'paperID': 'fbda91cfacd2b792794fb726e9417aef58480c72', 'arxivId': '1807.00431', 'publication_year': 2018, 'abstract': None}
{'title': 'Mitigating Unwanted Biases with Adversarial Learning', 'paperID': 'c7330852a07170cd0e6990f5fbde5fca12b6ccd6', 'arxivId': '1801.07593', 'publication_year': 2018, 'abstract': None}
{'title': 'On Calibration of Modern Neural Networks', 'paperID': 'd65ce2b8300541414bfe51d03906fca72e93523c', 'arxivId': '1706.04599', 'publication_year': 2017, 'abstract': None}
{'title': 'Controllable Invariance through Adversarial Feature Learning', 'paperID': '9a334566b79bc6c6906e2b5285d5ea50b9b99479', 'arxivId': '1705.11122', 'publication_year': 2017, 'abstract': None}
{'title': 'Statistics of Robust Optimization: A Generalized Empirical Likelihood Approach', 'paperID': 'ff6167e71af0f1bce3a28ddaf016a373379c742e', 'arxivId': '1610.03425', 'publication_year': 2016, 'abstract': None}
{'title': 'On causal and anticausal learning', 'paperID': 'f1bb50162b731dfd41bdd3648ba5239579420ac0', 'arxivId': '1206.6471', 'publication_year': 2012, 'abstract': None}
{'title': 'Density Ratio Estimation in Machine Learning', 'paperID': '90848562905d26873b57bbf3f2f98319e38e5bde', 'arxivId': None, 'publication_year': 2012, 'abstract': None}
{'title': 'Frustratingly Easy Domain Adaptation', 'paperID': '9f62067945d991cd78a62cf647de17f01d1b54d3', 'arxivId': '0907.1815', 'publication_year': 2007, 'abstract': None}
{'title': 'Analysis of Representations for Domain Adaptation', 'paperID': '96c6bc559b79d8fd518f431c707e8b44ce3bc4de', 'arxivId': None, 'publication_year': 2006, 'abstract': None}
{'title': 'Domain-adversarial training of neural networks', 'paperID': '922dc3bf6458ebab934608d064374d95ea323cd3', 'arxivId': None, 'publication_year': 2016, 'abstract': None}
{'title': 'Theory of point estimation', 'paperID': 'ba56155267c29d1b540e089df044db8f22c55a9a', 'arxivId': None, 'publication_year': 1950, 'abstract': None}
{'title': 'Out-of-distribution Generalization in the Presence of Nuisance-Induced Spurious Correlations', 'paperID': '440c098ce8c0ff2042543d3e4188ebb95acdb75a', 'arxivId': '2107.00520', 'publication_year': '2021', 'abstract': 'In many prediction problems, spurious correlations are induced by a changing relationship between the label and a nuisance variable that is also correlated with the covariates. For example, in classifying animals in natural images, the background, which is a nuisance, can predict the type of animal. This nuisance-label relationship does not always hold, and the performance of a model trained under one such relationship may be poor on data with a different nuisance-label relationship. To build predictive models that perform well regardless of the nuisance-label relationship, we develop Nuisance-Randomized Distillation (NURD). We introduce the nuisance-randomized distribution, a distribution where the nuisance and the label are independent. Under this distribution, we define the set of representations such that conditioning on any member, the nuisance and the label remain independent. We prove that the representations in this set always perform better than chance, while representations outside of this set may not. NURD finds a representation from this set that is most informative of the label under the nuisance-randomized distribution, and we prove that this representation achieves the highest performance regardless of the nuisance-label relationship. We evaluate NURD on several tasks including chest X-ray classification where, using non-lung patches as the nuisance, NURD produces models that predict pneumonia under strong spurious correlations.'}
{'title': 'Out-of-distribution Detection with Deep Nearest Neighbors', 'paperID': '8b1233107bff00355d4d1656795ec62d4f85e523', 'arxivId': '2204.06507', 'publication_year': 2022, 'abstract': None}
{'title': 'ReAct: Out-of-distribution Detection With Rectified Activations', 'paperID': '7f9760a76e9cf424da0b72d42f75594cefc4a329', 'arxivId': '2111.12797', 'publication_year': 2021, 'abstract': None}
{'title': 'SSD: A Unified Framework for Self-Supervised Outlier Detection', 'paperID': '0fe615dc0a422100e85cfb7e26c9306c481f6c75', 'arxivId': '2103.12051', 'publication_year': 2021, 'abstract': None}
{'title': 'Hopfield Networks is All You Need', 'paperID': '804a6d7c23335bbca6eec3b7d3c8366dcbe395a5', 'arxivId': '2008.02217', 'publication_year': 2020, 'abstract': None}
{'title': 'Unsupervised Out-of-Distribution Detection by Maximum Classifier Discrepancy', 'paperID': 'b9bd435b65d8214f1bcab9268ac2fce509cfffe6', 'arxivId': '1908.04951', 'publication_year': 2019, 'abstract': None}
{'title': 'Improving Reconstruction Autoencoder Out-of-distribution Detection with Mahalanobis Distance', 'paperID': '25e82c473fbbc54433ac2a70f10efdb9423fbf5a', 'arxivId': '1812.02765', 'publication_year': 2018, 'abstract': None}
{'title': 'The iNaturalist Species Classification and Detection Dataset', 'paperID': '05eb6eb4ea7d2b332295dfa5aeb64d5f47c1e628', 'arxivId': None, 'publication_year': 2017, 'abstract': None}
{'title': 'YOLO9000: Better, Faster, Stronger', 'paperID': '7d39d69b23424446f0400ef603b2e3e22d0309d6', 'arxivId': '1612.08242', 'publication_year': 2016, 'abstract': None}
{'title': 'Dense Associative Memory for Pattern Recognition', 'paperID': 'ed332c92664cd64843a7ba9373d992e9547230f6', 'arxivId': '1606.01164', 'publication_year': 2016, 'abstract': None}
{'title': 'Neurons with graded response have collective computational properties like those of two-state neurons.', 'paperID': '24b9eebe49cf7e00cf50cf7b7d9243386a23fe7c', 'arxivId': None, 'publication_year': 1984, 'abstract': None}
{'title': 'Neural networks and physical systems with emergent collective computational abilities.', 'paperID': '98b4d4e24aab57ab4e1124ff8106909050645cfa', 'arxivId': None, 'publication_year': 1982, 'abstract': None}
{'title': 'Out-of-Distribution Detection based on In-Distribution Data Patterns Memorization with Modern Hopfield Energy', 'paperID': 'cfd5982c81538f128bd7aa755929c8c0f4ee2bbe', 'arxivId': None, 'publication_year': None, 'abstract': 'Out-of-Distribution (OOD) detection is essential for safety-critical applications of deep neural networks. OOD detection is challenging since DNN models may produce very high logits value even for OOD samples. Hence, it is of great difficulty to discriminate OOD data by directly adopting Softmax on output logits as the confidence score. Differently, we detect the OOD sample with Hopfield energy in a store-then-compare paradigm. In more detail, penultimate layer outputs on the training set are considered as the representations of in-distribution (ID) data. Thus they can be transformed into stored patterns that serve as anchors to measure the discrepancy of unseen data for OOD detection. Starting from the energy function defined in Modern Hopfield Network for the discrepancy score calculation, we derive a simplified version SHE with theoretical analysis. In SHE, we utilize only one stored pattern to present each class, and these patterns can be obtained by simply averaging the penultimate layer outputs of training samples within this class. SHE has the advantages of hyperparameterfree and high computational efficiency. The evaluations of nine widely-used OOD datasets show the promising performance of such a simple yet effective approach and its superiority over State-of-the-Art models. Code is available at https://github.com/zjs975584714/SHE ood detection.'}
{'title': 'Are Data-Driven Explanations Robust Against Out-of-Distribution Data?', 'paperID': '2bf13c1ad79954bb24a65767514e2255e7988dfc', 'arxivId': '2303.16390', 'publication_year': 2023, 'abstract': None}
{'title': 'Graph-Relational Domain Adaptation', 'paperID': 'd590b67abd90934abc7d75224eb3594064383afc', 'arxivId': '2202.03628', 'publication_year': 2022, 'abstract': None}
{'title': 'Deep Learning for Spatiotemporal Modeling of Urbanization', 'paperID': '868b2b07c24bf9f69ecc8847ce5c212bb5d68dbd', 'arxivId': '2112.09668', 'publication_year': 2021, 'abstract': None}
{'title': 'Out-of-domain Generalization from a Single Source: A Uncertainty Quantification Approach', 'paperID': 'c4c0de6755c06f4167ffd2cc24b049c7902a10ca', 'arxivId': '2108.02888', 'publication_year': 2021, 'abstract': None}
{'title': 'Heterogeneous Risk Minimization', 'paperID': 'dfe5c82d7289468f51f35b5a4664b268ecc7558e', 'arxivId': '2105.03818', 'publication_year': 2021, 'abstract': None}
{'title': 'Gradient Matching for Domain Generalization', 'paperID': '525dd120c0b5808ddcbbf703677b46346fb0729b', 'arxivId': '2104.09937', 'publication_year': 2021, 'abstract': None}
{'title': 'Uncertainty-guided Model Generalization to Unseen Domains', 'paperID': '2c0ccf919d5347b87677e7a16a3ba5e555f51710', 'arxivId': '2103.07531', 'publication_year': 2021, 'abstract': None}
{'title': "Diffusion Earth Mover's Distance and Distribution Embeddings", 'paperID': '1f32677b1a61c30be6c1ba443df0663eee2b19a4', 'arxivId': '2102.12833', 'publication_year': 2021, 'abstract': None}
{'title': 'Model-Based Domain Generalization', 'paperID': '693d3fd92c6cf825cfe988cb32cf92e733d6230a', 'arxivId': '2102.11436', 'publication_year': 2021, 'abstract': None}
{'title': 'Gradient Starvation: A Learning Proclivity in Neural Networks', 'paperID': '29877659966f5ca2f198712a313cc653789edef1', 'arxivId': '2011.09468', 'publication_year': 2020, 'abstract': None}
{'title': 'Maximum-Entropy Adversarial Data Augmentation for Improved Generalization and Robustness', 'paperID': '07d251a8d721b5f3da6cc8a92e75840b563927f2', 'arxivId': '2010.08001', 'publication_year': 2020, 'abstract': None}
{'title': 'Large-Scale Methods for Distributionally Robust Optimization', 'paperID': '66488a38c3bae5d928bb22aa615fd0e64ccac62b', 'arxivId': '2010.05893', 'publication_year': 2020, 'abstract': None}
{'title': 'Out-of-Distribution Generalization with Maximal Invariant Predictor', 'paperID': '99bc80389f5957c7472906a5970e35a46281b469', 'arxivId': None, 'publication_year': 2020, 'abstract': None}
{'title': 'Sen1Floods11: a georeferenced dataset to train and test deep learning flood algorithms for Sentinel-1', 'paperID': 'e184f730775262869952b0b6de99d0967147301a', 'arxivId': None, 'publication_year': 2020, 'abstract': None}
{'title': 'Learning to Learn Single Domain Generalization', 'paperID': '89b95fb53727ee45be440045efef656718517c4c', 'arxivId': '2003.13216', 'publication_year': 2020, 'abstract': None}
{'title': 'Task-Robust Model-Agnostic Meta-Learning', 'paperID': '4aebc6a6c1390c62e37a6bf0c4ddd390d7bf3983', 'arxivId': None, 'publication_year': 2020, 'abstract': None}
{'title': 'Incorporating Unlabeled Data into Distributionally Robust Learning', 'paperID': '1d26ab851edfe193213ab4dd7fa91167f14ff8d4', 'arxivId': '1912.07729', 'publication_year': 2019, 'abstract': None}
{'title': 'Rethinking Kernel Methods for Node Representation Learning on Graphs', 'paperID': 'e4bf23cfe18acdb9d9b6a8dbdd54e447358e6f63', 'arxivId': '1910.02548', 'publication_year': 2019, 'abstract': None}
{'title': 'Distributionally Robust Optimization and Generalization in Kernel Methods', 'paperID': '72e0763428b55a788ffa16b7d206f8d3e20a9db9', 'arxivId': '1905.10943', 'publication_year': 2019, 'abstract': None}
{'title': 'Agnostic Federated Learning', 'paperID': '159395b0f7a2b9ea04f9a758d18887bcb970ee78', 'arxivId': '1902.00146', 'publication_year': 2019, 'abstract': None}
{'title': 'Learning Models with Uniform Performance via Distributionally Robust Optimization', 'paperID': 'a1fb7236d104ae0343c1a09e3590ee2283483240', 'arxivId': '1810.08750', 'publication_year': 2018, 'abstract': None}
{'title': 'Wasserstein Distributionally Robust Kalman Filtering', 'paperID': 'd81277895554106a2d42049453c1cd5a4fe6a1e7', 'arxivId': '1809.08830', 'publication_year': 2018, 'abstract': None}
{'title': 'Recognition in Terra Incognita', 'paperID': '2d15a7546c16d5821ffa8f769eb7ec18e435e64d', 'arxivId': '1807.04975', 'publication_year': 2018, 'abstract': None}
{'title': 'Robust Optimization over Multiple Domains', 'paperID': '12a17d5dfd222abfa47e121b734c93ae988d05b4', 'arxivId': '1805.07588', 'publication_year': 2018, 'abstract': None}
{'title': 'Hölder–Lipschitz Norms and Their Duals on Spaces with Semigroups, with Applications to Earth Mover’s Distance', 'paperID': '06268b47de80e55609d31c0fcc7d21ca88529bf4', 'arxivId': None, 'publication_year': 2016, 'abstract': None}
{'title': 'Minimizing the Maximal Loss: How and Why', 'paperID': '8c18d5afe6b8ab0c47e46a3d11d3b3cc0d404492', 'arxivId': '1602.01690', 'publication_year': 2016, 'abstract': None}
{'title': 'Unbiased Metric Learning: On the Utilization of Multiple Datasets and Web Images for Softening Bias', 'paperID': '10478ed2892f24c49ca0be1588c1c0e29841abb1', 'arxivId': None, 'publication_year': 2013, 'abstract': None}
{'title': 'Robust Stochastic Approximation Approach to Stochastic Programming', 'paperID': '96167ed3ebc9a2c3270f6ae96043e6f086eed4de', 'arxivId': None, 'publication_year': 2008, 'abstract': None}
{'title': 'Convex Optimization', 'paperID': '0b14178e7d79ac426d0a39700e1ac8b2c6f2e752', 'arxivId': None, 'publication_year': 2005, 'abstract': None}
{'title': 'A measure of betweenness centrality based on random walks', 'paperID': 'cf6f8ff055b3dc67d38a571be00365a6b121fc2f', 'arxivId': 'cond-mat/0309045', 'publication_year': 2003, 'abstract': None}
{'title': 'A set of measures of centrality based upon betweenness', 'paperID': 'ef4481cbc18c91e7bf0e53693bb77f3608743626', 'arxivId': None, 'publication_year': 1977, 'abstract': None}
{'title': 'Stochastic Gradient Methods for Distributionally Robust Optimization with f-divergences', 'paperID': 'e4350e816a350662ddb5f9ef92437aa8f3fd44f6', 'arxivId': None, 'publication_year': 2016, 'abstract': None}
{'title': 'Applied and Computational Harmonic Analysis', 'paperID': 'f4825634e91a1934e00c2bf29c29b5f37696bfff', 'arxivId': None, 'publication_year': 2010, 'abstract': None}
{'title': 'Diffusion maps', 'paperID': '012eb8da8885060d22c2598e287e61b25cec2121', 'arxivId': None, 'publication_year': 2006, 'abstract': None}
{'title': 'Statistical learning theory', 'paperID': '385197d4c02593e2823c71e4f90a0993b703620e', 'arxivId': None, 'publication_year': 1998, 'abstract': None}
{'title': 'INFORMS DOI 10.1287/xxxx.0000.0000 c ○ 0000 INFORMS Distributionally Robust Optimization under Moment Uncertainty with Application to Data-Driven Problems', 'paperID': '8d56d4bc69a8c562434b9a129542bb79e9d6f1d6', 'arxivId': None, 'publication_year': None, 'abstract': None}
{'title': 'Topology-aware Robust Optimization for Out-of-Distribution Generalization', 'paperID': 'eba7eb5d82c08ad1ba700afa08153168993de963', 'arxivId': '2307.13943', 'publication_year': '2023', 'abstract': 'Out-of-distribution (OOD) generalization is a challenging machine learning problem yet highly desirable in many high-stake applications. Existing methods suffer from overly pessimistic modeling with low generalization confidence. As generalizing to arbitrary test distributions is impossible, we hypothesize that further structure on the topology of distributions is crucial in developing strong OOD resilience. To this end, we propose topology-aware robust optimization (TRO) that seamlessly integrates distributional topology in a principled optimization framework. More specifically, TRO solves two optimization objectives: (1) Topology Learning which explores data manifold to uncover the distributional topology; (2) Learning on Topology which exploits the topology to constrain robust optimization for tightly-bounded generalization risks. We theoretically demonstrate the effectiveness of our approach and empirically show that it significantly outperforms the state of the arts in a wide range of tasks including classification, regression, and semantic segmentation. Moreover, we empirically find the data-driven distributional topology is consistent with domain knowledge, enhancing the explainability of our approach.'}
{'title': 'ViM: Out-Of-Distribution with Virtual-logit Matching', 'paperID': '3b0284d501e9b1b6c199d8b07c6826a165c4b4f2', 'arxivId': '2203.10807', 'publication_year': 2022, 'abstract': None}
{'title': "VOS: Learning What You Don't Know by Virtual Outlier Synthesis", 'paperID': '80ac4250b3cba55228684756acb55922042d7aaf', 'arxivId': '2202.01197', 'publication_year': 2022, 'abstract': None}
{'title': 'Standardized Max Logits: A Simple yet Effective Approach for Identifying Unexpected Road Obstacles in Urban-Scene Segmentation', 'paperID': 'a50495072b04b0bbb890917dfb2412fb50d3e8e7', 'arxivId': '2107.11264', 'publication_year': 2021, 'abstract': None}
{'title': 'Data-Free Knowledge Distillation for Heterogeneous Federated Learning', 'paperID': '3fdcf2d8fe58dcbc2c353e5974e2030f8281c799', 'arxivId': '2105.10056', 'publication_year': 2021, 'abstract': None}
{'title': 'MOOD: Multi-level Out-of-distribution Detection', 'paperID': '3471032918f2e6fd65677ad491a79ffa14b1c289', 'arxivId': '2104.14726', 'publication_year': 2021, 'abstract': None}
{'title': 'FedBN: Federated Learning on Non-IID Features via Local Batch Normalization', 'paperID': '2c0f4711c9c124a8dc056eaee82a2ca5ef276da8', 'arxivId': '2102.07623', 'publication_year': 2021, 'abstract': None}
{'title': 'Dense open-set recognition with synthetic outliers generated by Real NVP', 'paperID': '27875e4bdc53e20d9b555927097816244f5cf86e', 'arxivId': '2011.11094', 'publication_year': 2020, 'abstract': None}
{'title': 'HeteroFL: Computation and Communication Efficient Federated Learning for Heterogeneous Clients', 'paperID': '076af769eeb1ff3e9d1d398b3eed052ecbeb9aae', 'arxivId': '2010.01264', 'publication_year': 2020, 'abstract': None}
{'title': 'CSI: Novelty Detection via Contrastive Learning on Distributionally Shifted Instances', 'paperID': 'e1bb329621de73d08c47beae9b5439a1c244eb1a', 'arxivId': '2007.08176', 'publication_year': 2020, 'abstract': None}
{'title': "Federated Learning's Blessing: FedAvg has Linear Speedup", 'paperID': 'e1f2588ee4a7503aa2cf37f338ed50a92b0d0e65', 'arxivId': None, 'publication_year': 2020, 'abstract': None}
{'title': 'Catastrophic forgetting and mode collapse in GANs', 'paperID': '982e937583efffc247bab32a8f0156863beb22a6', 'arxivId': None, 'publication_year': 2020, 'abstract': None}
{'title': 'Adaptive Federated Optimization', 'paperID': '47c528344fedb6cb67a38e43d095b41c34715330', 'arxivId': '2003.00295', 'publication_year': 2020, 'abstract': None}
{'title': 'Salvaging Federated Learning by Local Adaptation', 'paperID': '1fad7869d48782062ea345b47081324b21e52f5d', 'arxivId': '2002.04758', 'publication_year': 2020, 'abstract': None}
{'title': 'Advances and Open Problems in Federated Learning', 'paperID': '07912741c6c96e6ad5b2c2d6c6c3b2de5c8a271b', 'arxivId': '1912.04977', 'publication_year': 2019, 'abstract': None}
{'title': 'Federated Learning with Personalization Layers', 'paperID': '35aebe08b34e5cb0d012a16563e5c3f6fd17a906', 'arxivId': '1912.00818', 'publication_year': 2019, 'abstract': None}
{'title': 'SCAFFOLD: Stochastic Controlled Averaging for Federated Learning', 'paperID': 'a95d102ed27f62cf328ab7c5a8732502f2b69012', 'arxivId': None, 'publication_year': 2019, 'abstract': None}
{'title': 'Measuring the Effects of Non-Identical Data Distribution for Federated Visual Classification', 'paperID': '46d8c9e2dc9c12615eb5f6813d18f967d61c7e0d', 'arxivId': '1909.06335', 'publication_year': 2019, 'abstract': None}
{'title': 'Federated Learning: Challenges, Methods, and Future Directions', 'paperID': '49bdeb07b045dd77f0bfe2b44436608770235a23', 'arxivId': '1908.07873', 'publication_year': 2019, 'abstract': None}
{'title': 'Qsparse-Local-SGD: Distributed SGD With Quantization, Sparsification, and Local Computations', 'paperID': '8000a4a63ac97ffb84917f910e2ce747e48d409f', 'arxivId': '1906.02367', 'publication_year': 2019, 'abstract': None}
{'title': 'Mode Seeking Generative Adversarial Networks for Diverse Image Synthesis', 'paperID': 'cec3bffdb0968cd820863005af54cc519704c24a', 'arxivId': '1903.05628', 'publication_year': 2019, 'abstract': None}
{'title': 'Federated Optimization in Heterogeneous Networks', 'paperID': 'cfb40a6546904f03e74be62fe3183cea61ad5ef9', 'arxivId': '1812.06127', 'publication_year': 2018, 'abstract': None}
{'title': 'Cooperative SGD: A unified Framework for the Design and Analysis of Communication-Efficient SGD Algorithms', 'paperID': '7a96002fe623c7b138584b1161a9bf2eb0a41876', 'arxivId': '1808.07576', 'publication_year': 2018, 'abstract': None}
{'title': 'VEEGAN: Reducing Mode Collapse in GANs using Implicit Variational Learning', 'paperID': '81d5740cac256489978c2751e867128e97620eae', 'arxivId': '1705.07761', 'publication_year': 2017, 'abstract': None}
{'title': 'Federated Learning: Strategies for Improving Communication Efficiency', 'paperID': '7fcb90f68529cbfab49f471b54719ded7528d0ef', 'arxivId': '1610.05492', 'publication_year': 2016, 'abstract': None}
{'title': 'Communication-Efficient Learning of Deep Networks from Decentralized Data', 'paperID': 'd1dbf643447405984eeef098b1b320dee0b3b8a7', 'arxivId': '1602.05629', 'publication_year': 2016, 'abstract': None}
{'title': 'Fine-grained Out-of-Distribution Detection with Mixup Outlier Exposure', 'paperID': 'd748b5e803f595c3a4c154cd87124556e00f7eb2', 'arxivId': None, 'publication_year': 2021, 'abstract': None}
{'title': 'Turning the Curse of Heterogeneity in Federated Learning into a Blessing for Out-of-Distribution Detection', 'paperID': '195d86d6b6a8420e9553fdbfc67cdfa4c87179aa', 'arxivId': None, 'publication_year': None, 'abstract': 'Deep neural networks have witnessed huge successes in many challenging prediction tasks and yet they often suffer from out-of-distribution (OoD) samples, misclassifying them with high confidence. Recent advances show promising OoD detection performance for centralized training, and however, OoD detection in federated learning (FL) is largely overlooked, even though many security sensitive applications such as autonomous driving and voice recognition authorization are commonly trained using FL for data privacy concerns. The main challenge that prevents previous state-of-the-art OoD detection methods from being incorporated to FL is that they require large amount of real OoD samples. However, in real-world scenarios, such large-scale OoD training data can be costly or even infeasible to obtain, especially for resource-limited local devices. On the other hand, a notorious challenge in FL is data heterogeneity where each client collects non-identically and independently distributed (non-iid) data. We propose to take advantage of such heterogeneity and turn the curse into a blessing that facilitates OoD detection in FL. The key is that for each client, non-iid data from other clients (unseen external classes) can serve as an alternative to real OoD samples. Specifically, we propose a novel Federated Out-of-Distribution Synthesizer (FOSTER), which learns a class-conditional generator to synthesize virtual external-class OoD samples, and maintains data confidentiality and communication efficiency required by FL. Experimental results show that our method outperforms the state-of-the-art for OoD tasks by 2.49%, 2.88%, 1.42% AUROC, and 0.01%, 0.89%, 1.74% ID accuracy, on CIFAR-10, CIFAR-100, and STL10, respectively. Codes are available: https://github.com/illidanlab/FOSTER.'}
{'title': 'Sample Efficient Deep Reinforcement Learning via Local Planning', 'paperID': '2d9b75da46989bed3cffe8f51e050d674d5b5d15', 'arxivId': '2301.12579', 'publication_year': 2023, 'abstract': None}
{'title': 'Are AlphaZero-like Agents Robust to Adversarial Perturbations?', 'paperID': '4dac673eb5c4849d3cbe710ab06c64c92b1457c7', 'arxivId': '2211.03769', 'publication_year': 2022, 'abstract': None}
{'title': 'The Difficulty of Passive Learning in Deep Reinforcement Learning', 'paperID': '17609f260d7deb836702029521c7f120c61ad6a9', 'arxivId': '2110.14020', 'publication_year': 2021, 'abstract': None}
{'title': 'Efficient Local Planning with Linear Function Approximation', 'paperID': '43b8a2a4c64f80bc90f6c1f73bb77cd7bb749584', 'arxivId': '2108.05533', 'publication_year': 2021, 'abstract': None}
{'title': 'Adaptable Agent Populations via a Generative Model of Policies', 'paperID': '2d84f9f1483a73acff0f349826c6bc0ac4025075', 'arxivId': '2107.07506', 'publication_year': 2021, 'abstract': None}
{'title': 'Robust Stochastic Linear Contextual Bandits Under Adversarial Attacks', 'paperID': 'ae6e8f470bc28f14741a6d7b94afc29f52efc90b', 'arxivId': '2106.02978', 'publication_year': 2021, 'abstract': None}
{'title': 'Robust Reinforcement Learning on State Observations with Learned Optimal Adversary', 'paperID': '1a627d2a169d71563109546da590a7cceb0b349a', 'arxivId': '2101.08452', 'publication_year': 2021, 'abstract': None}
{'title': 'Emergent Complexity and Zero-shot Transfer via Unsupervised Environment Design', 'paperID': '93b2788fb1f2aed0e545d9f9d7dca1c05a63208a', 'arxivId': '2012.02096', 'publication_year': 2020, 'abstract': None}
{'title': 'Exploring Restart Distributions.', 'paperID': 'd5ba07e4ef58bbbe8edee8c08ca02477e1b7af58', 'arxivId': None, 'publication_year': 2020, 'abstract': None}
{'title': 'Conservative Q-Learning for Offline Reinforcement Learning', 'paperID': '28db20a81eec74a50204686c3cf796c42a020d2e', 'arxivId': '2006.04779', 'publication_year': 2020, 'abstract': None}
{'title': 'Language Conditioned Imitation Learning Over Unstructured Data', 'paperID': '1301e9d11b728268ed1ff3f1a9adc155308d5250', 'arxivId': '2005.07648', 'publication_year': 2020, 'abstract': None}
{'title': 'Offline Reinforcement Learning: Tutorial, Review, and Perspectives on Open Problems', 'paperID': '5e7bc93622416f14e6948a500278bfbe58cd3890', 'arxivId': '2005.01643', 'publication_year': 2020, 'abstract': None}
{'title': 'Implementation Matters in Deep RL: A Case Study on PPO and TRPO', 'paperID': 'f1697ce4dddb58533d7d3f937fed74807d46edb8', 'arxivId': None, 'publication_year': 2020, 'abstract': None}
{'title': 'Robust Deep Reinforcement Learning against Adversarial Perturbations on State Observations', 'paperID': '9bb3d04c94a09e92375ae5377ab5187e1af3f6aa', 'arxivId': '2003.08938', 'publication_year': 2020, 'abstract': None}
{'title': 'Challenges and Countermeasures for Adversarial Attacks on Deep Reinforcement Learning', 'paperID': '690e880ef82a9665db56c545880ae1d8307d58be', 'arxivId': '2001.09684', 'publication_year': 2020, 'abstract': None}
{'title': 'Teacher algorithms for curriculum learning of Deep RL in continuously parameterized environments', 'paperID': '20b9c2ea1a49ed7789b99ae4c84b1b517b65bff5', 'arxivId': '1910.07224', 'publication_year': 2019, 'abstract': None}
{'title': 'Investigating Generalisation in Continuous Deep Reinforcement Learning', 'paperID': 'd81dd2dc0ee02d996763f3ea1703eaff681485d7', 'arxivId': '1902.07015', 'publication_year': 2019, 'abstract': None}
{'title': 'Go-Explore: a New Approach for Hard-Exploration Problems', 'paperID': 'c520bf47db3360ae3a52219771390a354ed8a91f', 'arxivId': '1901.10995', 'publication_year': 2019, 'abstract': None}
{'title': 'Sim-To-Real via Sim-To-Sim: Data-Efficient Robotic Grasping via Randomized-To-Canonical Adaptation Networks', 'paperID': 'c0dccd9be123057ec82a6747d8fec9cc34699a6d', 'arxivId': '1812.07252', 'publication_year': 2018, 'abstract': None}
{'title': 'Quantifying Generalization in Reinforcement Learning', 'paperID': 'ef2bc452812d6005ab0a66af6c3f97b6b0ba837e', 'arxivId': '1812.02341', 'publication_year': 2018, 'abstract': None}
{'title': 'Natural Environment Benchmarks for Reinforcement Learning', 'paperID': '53ff8d142b3ce64ac9649450ddb7be12cfaefcd6', 'arxivId': '1811.06032', 'publication_year': 2018, 'abstract': None}
{'title': 'BabyAI: A Platform to Study the Sample Efficiency of Grounded Language Learning', 'paperID': '1b19f433a3e8497e9d9bd67efb108521d16b5b85', 'arxivId': '1810.08272', 'publication_year': 2018, 'abstract': None}
{'title': 'Assessing Generalization in Deep Reinforcement Learning', 'paperID': 'caea502325b6a82b1b437c62585992609b5aa542', 'arxivId': '1810.12282', 'publication_year': 2018, 'abstract': None}
{'title': 'A Dissection of Overfitting and Generalization in Continuous Reinforcement Learning', 'paperID': 'a622be547caf0b1223626de5e69377c20ae11265', 'arxivId': '1806.07937', 'publication_year': 2018, 'abstract': None}
{'title': 'Data-Efficient Hierarchical Reinforcement Learning', 'paperID': '39b7007e6f3dd0744833f292f07ed77973503bfd', 'arxivId': '1805.08296', 'publication_year': 2018, 'abstract': None}
{'title': 'Addressing Function Approximation Error in Actor-Critic Methods', 'paperID': '4debb99c0c63bfaa97dd433bc2828e4dac81c48b', 'arxivId': '1802.09477', 'publication_year': 2018, 'abstract': None}
{'title': 'Continual Reinforcement Learning with Complex Synapses', 'paperID': '4b0e8a4df3605d5e22c9eacc3cb360ff08eb8c4e', 'arxivId': '1802.07239', 'publication_year': 2018, 'abstract': None}
{'title': 'Soft Actor-Critic: Off-Policy Maximum Entropy Deep Reinforcement Learning with a Stochastic Actor', 'paperID': '811df72e210e20de99719539505da54762a11c6d', 'arxivId': '1801.01290', 'publication_year': 2018, 'abstract': None}
{'title': 'Population Based Training of Neural Networks', 'paperID': 'af10f3c1c0859aa620623f760c8a29e78f177f7f', 'arxivId': '1711.09846', 'publication_year': 2017, 'abstract': None}
{'title': 'Sim-to-Real Transfer of Robotic Control with Dynamics Randomization', 'paperID': '0af8cdb71ce9e5bf37ad2a11f05af293cfe62172', 'arxivId': '1710.06537', 'publication_year': 2017, 'abstract': None}
{'title': 'CARLA: An Open Urban Driving Simulator', 'paperID': 'ebf0615fc4d98cf1dbe527c79146ce1e50dce9af', 'arxivId': '1711.03938', 'publication_year': 2017, 'abstract': None}
{'title': 'Proximal Policy Optimization Algorithms', 'paperID': 'dce6f9d4017b1785979e7520fd0834ef8cf02f4b', 'arxivId': '1707.06347', 'publication_year': 2017, 'abstract': None}
{'title': 'Domain randomization for transferring deep neural networks from simulation to the real world', 'paperID': '32ceb28e45a445df4d89df281bb0e3ab5aab1a2a', 'arxivId': '1703.06907', 'publication_year': 2017, 'abstract': None}
{'title': 'Robust Adversarial Reinforcement Learning', 'paperID': '9c4082bfbd46b781e70657f14895306c57c842e3', 'arxivId': '1703.02702', 'publication_year': 2017, 'abstract': None}
{'title': 'Adversarial Attacks on Neural Network Policies', 'paperID': 'c8c16a56d2a9520197da9a1546f517db5f19b204', 'arxivId': '1702.02284', 'publication_year': 2017, 'abstract': None}
{'title': 'MuJoCo: A physics engine for model-based control', 'paperID': 'b354ee518bfc1ac0d8ac447eece9edb69e92eae1', 'arxivId': None, 'publication_year': 2012, 'abstract': None}
{'title': 'A Tutorial on Bayesian Optimization of Expensive Cost Functions, with Application to Active User Modeling and Hierarchical Reinforcement Learning', 'paperID': 'cd5a26b89f0799db1cbc1dff5607cb6815739fe7', 'arxivId': '1012.2599', 'publication_year': 2010, 'abstract': None}
{'title': 'Adversarial Training Blocks Generalization in Neural Policies', 'paperID': '5296e2f5339bb9099d9c3805c37f77f62e3fec40', 'arxivId': None, 'publication_year': 2021, 'abstract': None}
{'title': 'A Survey of Generalisation in Deep Reinforcement Learning', 'paperID': '42edbc3c29af476c27f102b3de9f04e56b5c642d', 'arxivId': None, 'publication_year': 2021, 'abstract': None}
{'title': 'Can Agents Run Relay Race with Strangers? Generalization of RL to Out-of-Distribution Trajectories', 'paperID': 'c7e4da026f47339697a522508893f2fa261b52ea', 'arxivId': '2304.13424', 'publication_year': '2023', 'abstract': 'In this paper, we define, evaluate, and improve the ``relay-generalization\'\' performance of reinforcement learning (RL) agents on the out-of-distribution ``controllable\'\' states. Ideally, an RL agent that generally masters a task should reach its goal starting from any controllable state of the environment instead of memorizing a small set of trajectories. For example, a self-driving system should be able to take over the control from humans in the middle of driving and must continue to drive the car safely. To practically evaluate this type of generalization, we start the test agent from the middle of other independently well-trained \\emph{stranger} agents\' trajectories. With extensive experimental evaluation, we show the prevalence of \\emph{generalization failure} on controllable states from stranger agents. For example, in the Humanoid environment, we observed that a well-trained Proximal Policy Optimization (PPO) agent, with only 3.9\\% failure rate during regular testing, failed on 81.6\\% of the states generated by well-trained stranger PPO agents. To improve"relay generalization,"we propose a novel method called Self-Trajectory Augmentation (STA), which will reset the environment to the agent\'s old states according to the Q function during training. After applying STA to the Soft Actor Critic\'s (SAC) training procedure, we reduced the failure rate of SAC under relay-evaluation by more than three times in most settings without impacting agent performance and increasing the needed number of environment interactions. Our code is available at https://github.com/lan-lc/STA.'}
{'title': 'NodeFormer: A Scalable Graph Structure Learning Transformer for Node Classification', 'paperID': '01de6d0c00e7e77050a90945246b2b4acde497a2', 'arxivId': '2306.08385', 'publication_year': 2023, 'abstract': None}
{'title': 'Predicting the Silent Majority on Graphs: Knowledge Transferable Graph Neural Network', 'paperID': '31baf6130cc7837e0c67b6424bd6de11ae8a5904', 'arxivId': '2302.00873', 'publication_year': 2023, 'abstract': None}
{'title': 'DIFFormer: Scalable (Graph) Transformers Induced by Energy Constrained Diffusion', 'paperID': '9b4f564e5d33625fa88fc4e1045e9d5681fa0cca', 'arxivId': '2301.09474', 'publication_year': 2023, 'abstract': None}
{'title': 'Geometric Knowledge Distillation: Topology Compression for Graph Neural Networks', 'paperID': '3598a1932a5b4042f223f1fd2e9b3f93eb78e0be', 'arxivId': '2210.13014', 'publication_year': 2022, 'abstract': None}
{'title': 'Towards Out-of-Distribution Sequential Event Prediction: A Causal Treatment', 'paperID': 'c35c7240bad9b62394a63ee8cc3ae428fd204c74', 'arxivId': '2210.13005', 'publication_year': 2022, 'abstract': None}
{'title': 'Towards OOD Detection in Graph Classification from Uncertainty Estimation Perspective', 'paperID': '951f3f2449eb9a743543d67ab92e7769352f3413', 'arxivId': '2206.10691', 'publication_year': 2022, 'abstract': None}
{'title': 'Breaking Down Out-of-Distribution Detection: Many Methods Based on OOD Training Data Estimate a Combination of the Same Core Quantities', 'paperID': 'ca9974ac55dacf8db6eb4a57f489756068797cab', 'arxivId': '2206.09880', 'publication_year': 2022, 'abstract': None}
{'title': 'Handling Distribution Shifts on Graphs: An Invariance Perspective', 'paperID': '4818381d399636a4caefc24710b5c26a1e6e906c', 'arxivId': '2202.02466', 'publication_year': 2022, 'abstract': None}
{'title': 'Graph Posterior Network: Bayesian Predictive Uncertainty for Node Classification', 'paperID': '66ee16c1a274f1c9205b0ef4fbda0b4a8a481f81', 'arxivId': '2110.14012', 'publication_year': 2021, 'abstract': None}
{'title': 'Towards Open-World Feature Extrapolation: An Inductive Graph Learning Approach', 'paperID': '564e726cc687f325d70b46d0bb3be6863b362237', 'arxivId': '2110.04514', 'publication_year': 2021, 'abstract': None}
{'title': 'Subgroup Generalization and Fairness of Graph Neural Networks', 'paperID': '86c4bb73bcc10a17faee13034a1742008cb001df', 'arxivId': '2106.15535', 'publication_year': 2021, 'abstract': None}
{'title': 'Size-Invariant Graph Representations for Graph Classification Extrapolations', 'paperID': 'a72c85ccb30db1c76feafb3799481fa7599c8b98', 'arxivId': '2103.05045', 'publication_year': 2021, 'abstract': None}
{'title': 'Twitch Gamers: a Dataset for Evaluating Proximity Preserving and Structural Role-based Node Embeddings', 'paperID': '59a6a6c3110d8cfee9426ba7d8c11c37e58cfb43', 'arxivId': '2101.03091', 'publication_year': 2021, 'abstract': None}
{'title': 'Uncertainty Aware Semi-Supervised Learning on Graph Data', 'paperID': '71a35aa42cd1ed6f213e58122154739dfd6340e8', 'arxivId': '2010.12783', 'publication_year': 2020, 'abstract': None}
{'title': 'Graph-based semi-supervised learning: A review', 'paperID': '9569b51674a032b3255e874e85f508a844a17183', 'arxivId': None, 'publication_year': 2020, 'abstract': None}
{'title': 'Open Graph Benchmark: Datasets for Machine Learning on Graphs', 'paperID': '597bd2e45427563cdf025e53a3239006aa364cfc', 'arxivId': '2005.00687', 'publication_year': 2020, 'abstract': None}
{'title': 'A Benchmark for Anomaly Segmentation', 'paperID': 'c8c70d1a201f41af78b4e3f11810d0f8c6c452b3', 'arxivId': None, 'publication_year': 2019, 'abstract': None}
{'title': 'MixHop: Higher-Order Graph Convolutional Architectures via Sparsified Neighborhood Mixing', 'paperID': '4efb9a950f252138a30eeb942ed02663a3ea29d1', 'arxivId': '1905.00067', 'publication_year': 2019, 'abstract': None}
{'title': 'Dark Model Adaptation: Semantic Image Segmentation from Daytime to Nighttime', 'paperID': '3a7d5410c52213a53d3e1d8567a88a404684c045', 'arxivId': '1810.02575', 'publication_year': 2018, 'abstract': None}
{'title': 'Discriminative out-of-distribution detection for semantic segmentation', 'paperID': '2da694d7f494265a8193f17dfc492c577ad4db1e', 'arxivId': '1808.07703', 'publication_year': 2018, 'abstract': None}
{'title': 'Representation Learning on Graphs with Jumping Knowledge Networks', 'paperID': '5aea95e1ae78a66474051a330ded374e199b658c', 'arxivId': '1806.03536', 'publication_year': 2018, 'abstract': None}
{'title': 'Graph Attention Networks', 'paperID': '33998aff64ce51df8dee45989cdca4b6b1329ec4', 'arxivId': '1710.10903', 'publication_year': 2017, 'abstract': None}
{'title': 'Semi-Supervised Classification with Graph Convolutional Networks', 'paperID': '36eff562f65125511b5dfab68ce7f7a943c27478', 'arxivId': '1609.02907', 'publication_year': 2016, 'abstract': None}
{'title': 'A Theory of Generative ConvNet', 'paperID': '2da0ccacb4931f1e89cf7febdafd23a3cff079a4', 'arxivId': '1602.03264', 'publication_year': 2016, 'abstract': None}
{'title': 'Image-Based Recommendations on Styles and Substitutes', 'paperID': 'fab4d19ed77dad7c437d885eceb8aa65fae5a783', 'arxivId': '1506.04757', 'publication_year': 2015, 'abstract': None}
{'title': 'An Overview of Microsoft Academic Service (MAS) and Applications', 'paperID': '8ebc4145aef6a575cbaffcfeec56b20586db573a', 'arxivId': None, 'publication_year': 2015, 'abstract': None}
{'title': 'Domain Generalization via Invariant Feature Representation', 'paperID': '79c286bf03ed97fb94d33511f3355770dcee0aec', 'arxivId': '1301.2115', 'publication_year': 2013, 'abstract': None}
{'title': 'Collective Classification in Network Data', 'paperID': '43d2ed5c3c55c1100450cd74dc1031afa24d37b2', 'arxivId': None, 'publication_year': 2008, 'abstract': None}
{'title': 'A Unified Energy-Based Framework for Unsupervised Learning', 'paperID': '306ddd8b7ea3ead125491efc3e8a9f738ce65b89', 'arxivId': None, 'publication_year': 2007, 'abstract': None}
{'title': 'Manifold Regularization: A Geometric Framework for Learning from Labeled and Unlabeled Examples', 'paperID': '19bb0dce99466077e9bc5a2ad4941607fc28b40c', 'arxivId': None, 'publication_year': 2006, 'abstract': None}
{'title': 'Transductive reliability estimation for medical diagnosis', 'paperID': '6064c3ab52c63ba525e1a5b7a0614ed7b177be6f', 'arxivId': None, 'publication_year': 2003, 'abstract': None}
{'title': 'Semi-Supervised Learning Using Gaussian Fields and Harmonic Functions', 'paperID': '125842668eab7decac136db8a59d392dc5e4e395', 'arxivId': None, 'publication_year': 2003, 'abstract': None}
{'title': 'Learning Substructure Invariance for Out-of-Distribution Molecular Representations', 'paperID': '650756338094ca801ee6fc9947970cb3c376410c', 'arxivId': None, 'publication_year': 2022, 'abstract': None}
{'title': 'GraphDE: A Generative Framework for Debiased Learning and Out-of-Distribution Detection on Graphs', 'paperID': '301e14edd925fb191714ddfa13593e67c6e5b2fd', 'arxivId': None, 'publication_year': 2022, 'abstract': None}
{'title': 'OoD-Bench: Benchmarking and Understanding Out-of-Distribution Generalization Datasets and Algorithms', 'paperID': 'db72d07e5b1ae573ef59111a7b8c04e5b3252c12', 'arxivId': None, 'publication_year': 2021, 'abstract': None}
{'title': 'The Graph Neural Network Model', 'paperID': '3efd851140aa28e95221b55fcc5659eea97b172d', 'arxivId': None, 'publication_year': 2009, 'abstract': None}
{'title': 'Collective Classi!cation in Network Data', 'paperID': 'b6b26564df790262abbe48fa18079d9610189b29', 'arxivId': None, 'publication_year': 2008, 'abstract': None}
{'title': 'Energy-based Out-of-Distribution Detection for Graph Neural Networks', 'paperID': '0dcf24bb23ce5bc17aab8138903af5f049a4db91', 'arxivId': '2302.02914', 'publication_year': '2023', 'abstract': 'Learning on graphs, where instance nodes are inter-connected, has become one of the central problems for deep learning, as relational structures are pervasive and induce data inter-dependence which hinders trivial adaptation of existing approaches that assume inputs to be i.i.d.~sampled. However, current models mostly focus on improving testing performance of in-distribution data and largely ignore the potential risk w.r.t. out-of-distribution (OOD) testing samples that may cause negative outcome if the prediction is overconfident on them. In this paper, we investigate the under-explored problem, OOD detection on graph-structured data, and identify a provably effective OOD discriminator based on an energy function directly extracted from graph neural networks trained with standard classification loss. This paves a way for a simple, powerful and efficient OOD detection model for GNN-based learning on graphs, which we call GNNSafe. It also has nice theoretical properties that guarantee an overall distinguishable margin between the detection scores for in-distribution and OOD samples, which, more critically, can be further strengthened by a learning-free energy belief propagation scheme. For comprehensive evaluation, we introduce new benchmark settings that evaluate the model for detecting OOD data from both synthetic and real distribution shifts (cross-domain graph shifts and temporal graph shifts). The results show that GNNSafe achieves up to $17.0\\%$ AUROC improvement over state-of-the-arts and it could serve as simple yet strong baselines in such an under-developed area.'}
{'title': 'Delving into Out-of-Distribution Detection with Vision-Language Representations', 'paperID': 'ed0cbe81d615361e29196baec62de899c59463bf', 'arxivId': '2211.13445', 'publication_year': 2022, 'abstract': None}
{'title': 'POEM: Out-of-Distribution Detection with Posterior Sampling', 'paperID': '16ad01309dbfc406e3133bf0d62ea2be826423fe', 'arxivId': '2206.13687', 'publication_year': 2022, 'abstract': None}
{'title': 'Mitigating Neural Network Overconfidence with Logit Normalization', 'paperID': 'c2d29e2b10572d229e83e8c0005f9b48223332eb', 'arxivId': '2205.09310', 'publication_year': 2022, 'abstract': None}
{'title': 'On the Importance of Gradients for Detecting Distributional Shifts in the Wild', 'paperID': '3b316377f1d7cbcf3c907c4d8b08c05f4521b541', 'arxivId': '2110.00218', 'publication_year': 2021, 'abstract': None}
{'title': 'Learning from Noisy Data with Robust Representation Learning', 'paperID': '8d761be2fa1a4dc60f5699d6c8542c6b7591595e', 'arxivId': None, 'publication_year': 2021, 'abstract': None}
{'title': 'Distance-based Hyperspherical Classification for Multi-source Open-Set Domain Adaptation', 'paperID': '84643a19b825f27343d95e1b7ddd76a7bafb366c', 'arxivId': '2107.02067', 'publication_year': 2021, 'abstract': None}
{'title': 'MOS: Towards Scaling Out-of-distribution Detection for Large Semantic Space', 'paperID': 'f19092561296244e1dafe7d799e7906e96a63773', 'arxivId': '2105.01879', 'publication_year': 2021, 'abstract': None}
{'title': 'Semi-Supervised Learning of Visual Features by Non-Parametrically Predicting View Assignments with Support Samples', 'paperID': '57119dde4f6c45b195d9768e00e441032da7a650', 'arxivId': '2104.13963', 'publication_year': 2021, 'abstract': None}
{'title': 'Understanding the Behaviour of Contrastive Loss', 'paperID': '57eaad10369de402d3363c1d99c93810463eb03c', 'arxivId': '2012.09740', 'publication_year': 2020, 'abstract': None}
{'title': 'Contrastive Learning with Hard Negative Samples', 'paperID': '7097137596f6755675f6aafcdd80969a747322ae', 'arxivId': '2010.04592', 'publication_year': 2020, 'abstract': None}
{'title': 'MoPro: Webly Supervised Learning with Momentum Prototypes', 'paperID': '1cb29798801b315d6287aae1093f5432f54673dc', 'arxivId': '2009.07995', 'publication_year': 2020, 'abstract': None}
{'title': 'Understanding Contrastive Representation Learning through Alignment and Uniformity on the Hypersphere', 'paperID': '9a56ab8b1aba50dc2fea3cf4b531d30891a88ba9', 'arxivId': '2005.10242', 'publication_year': 2020, 'abstract': None}
{'title': 'Prototypical Contrastive Learning of Unsupervised Representations', 'paperID': '8bf6c69bae0956db13aa9129fedc69fdc1256dce', 'arxivId': '2005.04966', 'publication_year': 2020, 'abstract': None}
{'title': 'Supervised Contrastive Learning', 'paperID': '38643c2926b10f6f74f122a7037e2cd20d77c0f1', 'arxivId': '2004.11362', 'publication_year': 2020, 'abstract': None}
{'title': 'ProxyNCA++: Revisiting and Revitalizing Proxy Neighborhood Component Analysis', 'paperID': '2cb80d51c771614b38924a24bf853e3a42dddabe', 'arxivId': '2004.01113', 'publication_year': 2020, 'abstract': None}
{'title': 'Proxy Anchor Loss for Deep Metric Learning', 'paperID': 'f7646cccbd6edbc148d08fea37e31bcd0592c992', 'arxivId': '2003.13911', 'publication_year': 2020, 'abstract': None}
{'title': 'Distance-Based Learning from Errors for Confidence Calibration', 'paperID': '096033bd0d4bc867c7be1b8220d9afdc22c03cdc', 'arxivId': '1912.01730', 'publication_year': 2019, 'abstract': None}
{'title': 'Deep Metric Learning Beyond Binary Supervision', 'paperID': '249f0a2ae3540dbe4f2a11806d2ac38581b9ad6b', 'arxivId': '1904.09626', 'publication_year': 2019, 'abstract': None}
{'title': 'UMAP: Uniform Manifold Approximation and Projection', 'paperID': '5df8b7279e0d80b6f418f7d5cb79b27cdba9ed16', 'arxivId': None, 'publication_year': 2018, 'abstract': None}
{'title': 'Representation Learning with Contrastive Predictive Coding', 'paperID': 'b227f3e4c0dc96e5ac5426b85485a70f2175a205', 'arxivId': '1807.03748', 'publication_year': 2018, 'abstract': None}
{'title': 'CosFace: Large Margin Cosine Loss for Deep Face Recognition', 'paperID': '9dc915697768dd1f7c7b97e2c25c90b02241958b', 'arxivId': '1801.09414', 'publication_year': 2018, 'abstract': None}
{'title': 'ArcFace: Additive Angular Margin Loss for Deep Face Recognition', 'paperID': 'd4f100ca5edfe53b562f1d170b2c48939bab0e27', 'arxivId': None, 'publication_year': 2018, 'abstract': None}
{'title': 'SphereFace: Deep Hypersphere Embedding for Face Recognition', 'paperID': 'bd8f77b7d3b9d272f7a68defc1412f73e5ac3135', 'arxivId': '1704.08063', 'publication_year': 2017, 'abstract': None}
{'title': 'Beyond Triplet Loss: A Deep Quadruplet Network for Person Re-identification', 'paperID': '4901eaa5a3b8cca41e4bb664ef0446d6118bd87c', 'arxivId': '1704.01719', 'publication_year': 2017, 'abstract': None}
{'title': 'No Fuss Distance Metric Learning Using Proxies', 'paperID': '0b1157e308289bd09e798c207b38dfdeb8335c46', 'arxivId': '1703.07464', 'publication_year': 2017, 'abstract': None}
{'title': 'Joint Detection and Identification Feature Learning for Person Search', 'paperID': 'fb4b700ba023c08e64c13f8030f40dcc901ac518', 'arxivId': '1604.01850', 'publication_year': 2016, 'abstract': None}
{'title': 'Deep Metric Learning via Lifted Structured Feature Embedding', 'paperID': '884750937bb97e82c41316d80e5d104e0c0e4795', 'arxivId': '1511.06452', 'publication_year': 2015, 'abstract': None}
{'title': 'SIREN: Shaping Representations for Detecting Out-of-Distribution Objects', 'paperID': 'e90ec61e867579bc8bff26e686a59f70129e612c', 'arxivId': None, 'publication_year': 2022, 'abstract': None}
{'title': 'STEP: Out-of-Distribution Detection in the Presence of Limited In-Distribution Labeled Data', 'paperID': 'c442d155c47981599ff9b13275058c55feb72c2e', 'arxivId': None, 'publication_year': 2021, 'abstract': None}
{'title': 'How to Exploit Hyperspherical Embeddings for Out-of-Distribution Detection?', 'paperID': 'ef81bbfae3c77c177e3a5fd007c8b66a2ee7322b', 'arxivId': '2203.04450', 'publication_year': '2022', 'abstract': 'Out-of-distribution (OOD) detection is a critical task for reliable machine learning. Recent advances in representation learning give rise to distance-based OOD detection, where testing samples are detected as OOD if they are relatively far away from the centroids or prototypes of in-distribution (ID) classes. However, prior methods directly take off-the-shelf contrastive losses that suffice for classifying ID samples, but are not optimally designed when test inputs contain OOD samples. In this work, we propose CIDER, a novel representation learning framework that exploits hyperspherical embeddings for OOD detection. CIDER jointly optimizes two losses to promote strong ID-OOD separability: a dispersion loss that promotes large angular distances among different class prototypes, and a compactness loss that encourages samples to be close to their class prototypes. We analyze and establish the unexplored relationship between OOD detection performance and the embedding properties in the hyperspherical space, and demonstrate the importance of dispersion and compactness. CIDER establishes superior performance, outperforming the latest rival by 19.36% in FPR95. Code is available at https://github.com/deeplearning-wisc/cider.'}
{'title': 'Domain-Indexing Variational Bayes: Interpretable Domain Index for Domain Adaptation', 'paperID': 'ef018596c581fa37e83e9544b6412beeb15e31fa', 'arxivId': '2302.02561', 'publication_year': 2023, 'abstract': None}
{'title': 'Model Agnostic Sample Reweighting for Out-of-Distribution Learning', 'paperID': 'cf12611abee206c9efe466781fe8998b06aba19d', 'arxivId': '2301.09819', 'publication_year': 2023, 'abstract': None}
{'title': 'Domain-invariant Feature Exploration for Domain Generalization', 'paperID': '8d13ac2a2e427489ba6645567c6a02eef28eefa3', 'arxivId': '2207.12020', 'publication_year': 2022, 'abstract': None}
{'title': 'TACTiS: Transformer-Attentional Copulas for Time Series', 'paperID': 'c6d7e13e064e9b7e972d03751045ae1fbbed26af', 'arxivId': '2202.03528', 'publication_year': 2022, 'abstract': None}
{'title': 'Provable Domain Generalization via Invariant-Feature Subspace Recovery', 'paperID': '7e8e9f5ddefb025154ebbcc37b5c86302a8aea9d', 'arxivId': '2201.12919', 'publication_year': 2022, 'abstract': None}
{'title': 'Towards Principled Disentanglement for Domain Generalization', 'paperID': '763aee6af4ce9bfa6eb3dae148536c52780f736a', 'arxivId': '2111.13839', 'publication_year': 2021, 'abstract': None}
{'title': 'Improving Model Generalization by Agreement of Learned Representations from Data Augmentation', 'paperID': '9d7a6d0d92ec1ae3d84d7eaaa8c7bad13452de6b', 'arxivId': '2110.10536', 'publication_year': 2021, 'abstract': None}
{'title': 'Fishr: Invariant Gradient Variances for Out-of-distribution Generalization', 'paperID': '6bf04318d6e57463f7823b9770c5a6c19a7b47e9', 'arxivId': '2109.02934', 'publication_year': 2021, 'abstract': None}
{'title': 'Learning to Diversify for Single Domain Generalization', 'paperID': '1109f18a41ad21635ae30952be89f56f52295f39', 'arxivId': '2108.11726', 'publication_year': 2021, 'abstract': None}
{'title': 'AdaRNN: Adaptive Learning and Forecasting of Time Series', 'paperID': '6ef770d11e3e5918646b2f5a97c0bcc8bc9b9256', 'arxivId': '2108.04443', 'publication_year': 2021, 'abstract': None}
{'title': 'Delving Deep into the Generalization of Vision Transformers under Distribution Shifts', 'paperID': '53a16a2bd25c40401c7507ac8d70d61bbfb2e286', 'arxivId': '2106.07617', 'publication_year': 2021, 'abstract': None}
{'title': 'Adversarially Adaptive Normalization for Single Domain Generalization', 'paperID': '648c13c77a94d46b2dbd75c8073cca4b8870bd9f', 'arxivId': '2106.01899', 'publication_year': 2021, 'abstract': None}
{'title': 'Latent Independent Excitation for Generalizable Sensor-based Cross-Person Activity Recognition', 'paperID': '266a35c51001be877cc970323ba8c65c7ac60811', 'arxivId': None, 'publication_year': 2021, 'abstract': None}
{'title': 'Progressive Domain Expansion Network for Single Domain Generalization', 'paperID': '6ab82d3abe6c1b09ca9695f901ed927a0171a875', 'arxivId': '2103.16050', 'publication_year': 2021, 'abstract': None}
{'title': 'Robust Domain-Free Domain Generalization with Class-Aware Alignment', 'paperID': '8d82973ef80e92cd64345feb3756ae361b49618c', 'arxivId': '2102.08897', 'publication_year': 2021, 'abstract': None}
{'title': 'Domain adversarial neural networks for domain generalization: when it works and how to improve', 'paperID': '539e1fc503f525d3ef5b8a1976da04577279107a', 'arxivId': '2102.03924', 'publication_year': 2021, 'abstract': None}
{'title': 'MiniRocket: A Very Fast (Almost) Deterministic Transform for Time Series Classification', 'paperID': 'bbae866c5edd477c1c39921436c47fd43d1f6e5c', 'arxivId': '2012.08791', 'publication_year': 2020, 'abstract': None}
{'title': 'Learning explanations that are hard to vary', 'paperID': '6972010d883e9746ecdf8147168caeccef6dcdb3', 'arxivId': '2009.00329', 'publication_year': 2020, 'abstract': None}
{'title': 'Continuously Indexed Domain Adaptation', 'paperID': '03479dd8970c96058998956b7eadbac485a2a170', 'arxivId': '2007.01807', 'publication_year': 2020, 'abstract': None}
{'title': 'Multi-Source Deep Domain Adaptation with Weak Supervision for Time-Series Sensor Data', 'paperID': '2d96c2f8c11ff95bd3fb5d9ba797beb63f01ab07', 'arxivId': '2005.10996', 'publication_year': 2020, 'abstract': None}
{'title': 'Neural Controlled Differential Equations for Irregular Time Series', 'paperID': '31603b3339f4da5bdc6b7de4231bd1ddfb32a50a', 'arxivId': '2005.08926', 'publication_year': 2020, 'abstract': None}
{'title': 'MatchboxNet: 1D Time-Channel Separable Convolutional Neural Network Architecture for Speech Commands Recognition', 'paperID': '48eda0f2a611bc488987870f628dac82ae8dcfaa', 'arxivId': '2004.08531', 'publication_year': 2020, 'abstract': None}
{'title': 'Shallow RNN: Accurate Time-series Classification on Resource Constrained Devices', 'paperID': '0d48655970e797e135e9dc8069edbb6a922da019', 'arxivId': None, 'publication_year': 2019, 'abstract': None}
{'title': 'PyTorch: An Imperative Style, High-Performance Deep Learning Library', 'paperID': '3c8a456509e6c0805354bd40a35e3f2dbf8069b1', 'arxivId': '1912.01703', 'publication_year': 2019, 'abstract': None}
{'title': 'Domain Generalization Using a Mixture of Multiple Latent Domains', 'paperID': '41a4aa801da162ca777c14243e8e3a14e9bc2d45', 'arxivId': '1911.07661', 'publication_year': 2019, 'abstract': None}
{'title': 'Enhancing the Locality and Breaking the Memory Bottleneck of Transformer on Time Series Forecasting', 'paperID': '36e30516683032634975c53e60f3737b6e35ff80', 'arxivId': '1907.00235', 'publication_year': 2019, 'abstract': None}
{'title': 'Domain Agnostic Learning with Disentangled Representations', 'paperID': 'f8d1cae82cdd4c6f4dcfefe5b2d1c0f0e68742fc', 'arxivId': '1904.12347', 'publication_year': 2019, 'abstract': None}
{'title': 'Introducing WESAD, a Multimodal Dataset for Wearable Stress and Affect Detection', 'paperID': 'f7d4957127bb35b0d3cb1042a676ea60e259463d', 'arxivId': None, 'publication_year': 2018, 'abstract': None}
{'title': 'Deep learning for time series classification: a review', 'paperID': '1c2efb418f79b5d29913e014a1dfd78865221c39', 'arxivId': '1809.04356', 'publication_year': 2018, 'abstract': None}
{'title': 'Deep Clustering for Unsupervised Learning of Visual Features', 'paperID': '1d033b30f38642e4b6dd146bb8b464bfb58aad96', 'arxivId': '1807.05520', 'publication_year': 2018, 'abstract': None}
{'title': 'Speech Commands: A Dataset for Limited-Vocabulary Speech Recognition', 'paperID': 'da6e404d8911b0e5785019a79dc8607e0b313dc4', 'arxivId': '1804.03209', 'publication_year': 2018, 'abstract': None}
{'title': 'Latent Factors Limiting the Performance of sEMG-Interfaces', 'paperID': '1855fc5254f6c40c49df7fc15409e8278cabad3c', 'arxivId': None, 'publication_year': 2018, 'abstract': None}
{'title': 'Deep Learning for Sensor-based Activity Recognition: A Survey', 'paperID': '60a1e0a81a562f2efd56fe2c1d012b8cf5f47e1c', 'arxivId': '1707.03502', 'publication_year': 2017, 'abstract': None}
{'title': 'Attention is All you Need', 'paperID': '204e3073870fae3d05bcbc2f6a8e263d9b72e776', 'arxivId': '1706.03762', 'publication_year': 2017, 'abstract': None}
{'title': 'Variational Recurrent Adversarial Deep Domain Adaptation', 'paperID': '9c4f30fe94ce07a89eb9b1789b338064d5c44811', 'arxivId': None, 'publication_year': 2016, 'abstract': None}
{'title': 'Deep CORAL: Correlation Alignment for Deep Domain Adaptation', 'paperID': '12d0cf8ae5ffe1b89345e1dcead22be592d844b2', 'arxivId': '1607.01719', 'publication_year': 2016, 'abstract': None}
{'title': 'Recognizing Daily and Sports Activities in Two Open Source Machine Learning Environments Using Body-Worn Sensor Units', 'paperID': '67216c49d031134a6554d050ab53440014263c20', 'arxivId': None, 'publication_year': 2014, 'abstract': None}
{'title': 'Highly Comparative Feature-Based Time-Series Classification', 'paperID': '22a13f42511192cc5dbf7b4b1b8d72bcb15f1b75', 'arxivId': '1401.3531', 'publication_year': 2014, 'abstract': None}
{'title': 'Human Activity Recognition on Smartphones Using a Multiclass Hardware-Friendly Support Vector Machine', 'paperID': '4f605b3bb3ce574f4053f19264434baa522305b7', 'arxivId': None, 'publication_year': 2012, 'abstract': None}
{'title': 'USC-HAD: a daily activity dataset for ubiquitous activity recognition using wearable sensors', 'paperID': '7854760393966e63011c14eb81a29b1e5fb379cf', 'arxivId': None, 'publication_year': 2012, 'abstract': None}
{'title': 'Introducing a New Benchmarked Dataset for Activity Monitoring', 'paperID': 'f4dacd1dae1615a6c89cffb5e06254aa9f3af1ef', 'arxivId': None, 'publication_year': 2012, 'abstract': None}
{'title': 'The Infinite Gaussian Mixture Model', 'paperID': '5079ea296646fbbb0c1ceb8bbadf86c698c842ef', 'arxivId': None, 'publication_year': 1999, 'abstract': None}
{'title': 'Rule Discovery from Time Series', 'paperID': '4f12b08ad975c0def6da20d32536291becd48479', 'arxivId': None, 'publication_year': 1998, 'abstract': None}
{'title': 'CrossMatch: Cross-Classifier Consistency Regularization for Open-Set Single Domain Generalization', 'paperID': 'c1e10c15172b94d057f2bcdbcd6f3ddc766d8c62', 'arxivId': None, 'publication_year': 2022, 'abstract': None}
{'title': 'Conditional Contrastive Domain Generalization for Fault Diagnosis', 'paperID': 'e57b96b6be9666de5d87f314117ab15ccf902689', 'arxivId': None, 'publication_year': 2022, 'abstract': None}
{'title': 'Visual Representation Learning over Latent Domains', 'paperID': 'e0071927a83f29ab191c603f3a3bf9b6b1b35e96', 'arxivId': None, 'publication_year': 2022, 'abstract': None}
{'title': 'Recurrent neural networks for time series classification', 'paperID': '530d2b07898a610a3c7de19c01b71dc4b5a6dd5d', 'arxivId': None, 'publication_year': 2003, 'abstract': None}
{'title': 'Out-of-distribution Representation Learning for Time Series Classification', 'paperID': '95d1e89b4ed74c1d2924aacf1b0ae21ffd2a1cff', 'arxivId': '2209.07027', 'publication_year': '2022', 'abstract': 'Time series classification is an important problem in real world. Due to its non-stationary property that the distribution changes over time, it remains challenging to build models for generalization to unseen distributions. In this paper, we propose to view the time series classification problem from the distribution perspective. We argue that the temporal complexity attributes to the unknown latent distributions within. To this end, we propose DIVERSIFY to learn generalized representations for time series classification. DIVERSIFY takes an iterative process: it first obtains the worst-case distribution scenario via adversarial training, then matches the distributions of the obtained sub-domains. We also present some theoretical insights. We conduct experiments on gesture recognition, speech commands recognition, wearable stress and affect detection, and sensor-based human activity recognition with a total of seven datasets in different settings. Results demonstrate that DIVERSIFY significantly outperforms other baselines and effectively characterizes the latent distributions by qualitative and quantitative analysis. Code is available at: https://github.com/microsoft/robustlearn.'}
{'title': 'Functional Indirection Neural Estimator for Better Out-of-distribution Generalization', 'paperID': '92394181881a9ff4063d9aedb3e4fd4ada466edb', 'arxivId': '2210.12739', 'publication_year': 2022, 'abstract': None}
{'title': 'Chain of Thought Prompting Elicits Reasoning in Large Language Models', 'paperID': '1b6e810ce0afd0dd093f789d2b2742d047e316d5', 'arxivId': '2201.11903', 'publication_year': 2022, 'abstract': None}
{'title': 'Dynamic Inference with Neural Interpreters', 'paperID': '8ccaf0c0fbd5e4079f36fa720cf23890be10dd66', 'arxivId': '2110.06399', 'publication_year': 2021, 'abstract': None}
{'title': 'Abstraction and analogy‐making in artificial intelligence', 'paperID': '8c479e81ddaf55aba9044449b5be7b7bf2046b7e', 'arxivId': '2102.10717', 'publication_year': 2021, 'abstract': None}
{'title': 'Switch Transformers: Scaling to Trillion Parameter Models with Simple and Efficient Sparsity', 'paperID': 'fdacf2a732f55befdc410ea927091cad3b791f13', 'arxivId': '2101.03961', 'publication_year': 2021, 'abstract': None}
{'title': 'Emergent Symbols through Binding in External Memory', 'paperID': '8eaa6a82e1f94c1552e5c284061e25fee36ec427', 'arxivId': '2012.14601', 'publication_year': 2020, 'abstract': None}
{'title': 'An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale', 'paperID': '268d347e8a55b5eb82fb5e7d2f800e33c75ab18a', 'arxivId': '2010.11929', 'publication_year': 2020, 'abstract': None}
{'title': 'Learning Representations that Support Extrapolation', 'paperID': '024a3f0ce83528914690a6bb010ba715643669d4', 'arxivId': '2007.05059', 'publication_year': 2020, 'abstract': None}
{'title': '5分で分かる!? 有名論文ナナメ読み：Jacob Devlin et al. : BERT : Pre-training of Deep Bidirectional Transformers for Language Understanding', 'paperID': '43f2ad297941db230c089ba353efc3f281ab678c', 'arxivId': None, 'publication_year': 2020, 'abstract': None}
{'title': 'Measuring Compositional Generalization: A Comprehensive Method on Realistic Data', 'paperID': '5cdab78acc4f3aab429a0dd41c3ec7e605d42e7b', 'arxivId': '1912.09713', 'publication_year': 2019, 'abstract': None}
{'title': 'Comparing methods for comparing networks', 'paperID': 'd2dc5081236a5e64260666e916f41c53879fc24b', 'arxivId': None, 'publication_year': 2019, 'abstract': None}
{'title': 'FewRel 2.0: Towards More Challenging Few-Shot Relation Classification', 'paperID': '2873f78efd7adcb118a70f8ea3ca7fa1501e320a', 'arxivId': '1910.07124', 'publication_year': 2019, 'abstract': None}
{'title': 'Learning by Abstraction: The Neural State Machine', 'paperID': '136c05cb8dd359fb8e0dc7947172a9ecb74ccbec', 'arxivId': '1907.03950', 'publication_year': 2019, 'abstract': None}
{'title': 'Matching the Blanks: Distributional Similarity for Relation Learning', 'paperID': '4af09143735210777281b66997ec12994dbb43d4', 'arxivId': '1906.03158', 'publication_year': 2019, 'abstract': None}
{'title': 'An Explicitly Relational Neural Network Architecture', 'paperID': '3880fa12f4a19e839f812819eda42a631278535f', 'arxivId': '1905.10307', 'publication_year': 2019, 'abstract': None}
{'title': 'RAVEN: A Dataset for Relational and Analogical Visual REasoNing', 'paperID': 'd0bfd3cb732471a0843a39d2d047caf60a844466', 'arxivId': '1903.02741', 'publication_year': 2019, 'abstract': None}
{'title': 'Transformer-XL: Attentive Language Models beyond a Fixed-Length Context', 'paperID': 'c4744a7c2bb298e4a52289a1e085c71cc3d37bc6', 'arxivId': '1901.02860', 'publication_year': 2019, 'abstract': None}
{'title': 'Music Transformer: Generating Music with Long-Term Structure', 'paperID': 'fb507ada871d1e8c29e376dbf7b7879689aa89f9', 'arxivId': '1809.04281', 'publication_year': 2018, 'abstract': None}
{'title': 'Generalisation in humans and deep neural networks', 'paperID': '54fc23348ed840cb5f1fe2b41c80bfdcfc03631f', 'arxivId': '1808.08750', 'publication_year': 2018, 'abstract': None}
{'title': 'Cut Based Method for Comparing Complex Networks', 'paperID': '046cd4c35f607a9ebfa2c41f02643eeded933245', 'arxivId': None, 'publication_year': 2018, 'abstract': None}
{'title': 'Self-Attention with Relative Position Representations', 'paperID': 'c8efcc854d97dfc2a42b83316a2109f9d166e43f', 'arxivId': '1803.02155', 'publication_year': 2018, 'abstract': None}
{'title': 'Compositional Attention Networks for Machine Reasoning', 'paperID': '289fb3709475f5c87df8d97f129af54029d27fee', 'arxivId': '1803.03067', 'publication_year': 2018, 'abstract': None}
{'title': 'Learning Independent Causal Mechanisms', 'paperID': 'd93b0b37ee0e87a0e096ef803667b0798f465528', 'arxivId': '1712.00961', 'publication_year': 2017, 'abstract': None}
{'title': 'Few-Shot Learning with Graph Neural Networks', 'paperID': '572a1f77306e160c3893299c18f3ed862fb5f6d9', 'arxivId': '1711.04043', 'publication_year': 2017, 'abstract': None}
{'title': 'What can the brain teach us about building artificial intelligence?', 'paperID': '5f0625c30014c12f333eb518268647673d18f9f1', 'arxivId': '1909.01561', 'publication_year': 2016, 'abstract': None}
{'title': 'Group Equivariant Convolutional Networks', 'paperID': 'fafcaf5ca3fab8dc4fad15c2391c0fdb4a7dc005', 'arxivId': '1602.07576', 'publication_year': 2016, 'abstract': None}
{'title': 'Neural Module Networks', 'paperID': '21c99706bb26e9012bfb4d8d48009a3d45af59b2', 'arxivId': '1511.02799', 'publication_year': 2015, 'abstract': None}
{'title': 'Neural Turing Machines', 'paperID': 'c3823aacea60bc1f2cabb9283144690a3d015db5', 'arxivId': '1410.5401', 'publication_year': 2014, 'abstract': None}
{'title': 'Convergent Sequences of Dense Graphs I: Subgraph Frequencies, Metric Properties and Testing', 'paperID': 'be033f227bc5aeed0702d2beb944b1068b274cfa', 'arxivId': 'math/0702004', 'publication_year': 2007, 'abstract': None}
{'title': 'Structure-Mapping: A Theoretical Framework for Analogy', 'paperID': 'c0373426c8e5579dcff60cc0bd930277822edc7d', 'arxivId': None, 'publication_year': 1983, 'abstract': None}
{'title': 'Features of Similarity', 'paperID': 'f718309706172d6fb1e89f583927274f9a4cdf4f', 'arxivId': None, 'publication_year': 1977, 'abstract': None}
{'title': 'Deep Learning with Python', 'paperID': '3087b58cbfc6eb4a3076a180e21d6b872293f9a8', 'arxivId': None, 'publication_year': 2017, 'abstract': None}
{'title': 'The analogical mind : perspectives from cognitive science', 'paperID': 'a2fb9bc2e3ec45fd1d7f20280c9c8503aa3de9c3', 'arxivId': None, 'publication_year': 2001, 'abstract': None}
{'title': 'The Correlation Theory of Brain Function', 'paperID': 'e62f7643f616aaad65ffd47155a53bfa325e455d', 'arxivId': None, 'publication_year': 1994, 'abstract': None}
{'title': 'Improving Out-of-distribution Generalization with Indirection Representations', 'paperID': 'c1f1d55ee54b6ea0b6052180e1aa88c2efd62481', 'arxivId': None, 'publication_year': None, 'abstract': 'We propose a generic module named Indirection Layer (InLay), which leverages indirection and data internal relationships to effectively construct symbolic indirect representations to improve out-of-distribution generalization capabilities of various neural architectures. InLay receives data input in the form of a sequence of objects, treats it as a complete weighted graph whose vertices are the objects and edge weights are scalars representing relationships between vertices. The input is ﬁrst mapped via indirection to a symbolic graph with data-independent and trainable vertices. This symbolic graph is then propagated, resulting in new vertex features whose indirection will be used for prediction steps afterward. Theoretically, we show that the distances between indirection representations are bounded by the distances between corresponding graphs, implying that unseen samples with very different surface statistics can still be close in the representation space to the seen samples if they share similar internal relationships. We demonstrate that InLay is consistently effective in improving out-of-distribution generalization throughout a comprehensive suite of experiments, including IQ problems, distorted image classiﬁcation, and few-shot domain adaptation NLP classiﬁcation. We also conduct ablation studies to verify different design choices of InLay.'}
{'title': 'Watermarking for Out-of-distribution Detection', 'paperID': '41e68a78f5bd266b1ae54d521ebd0be0e9314cd8', 'arxivId': '2210.15198', 'publication_year': 2022, 'abstract': None}
{'title': 'Is Out-of-Distribution Detection Learnable?', 'paperID': 'a5927a417272327d424a76b2d260f6c1a73bc71e', 'arxivId': '2210.14707', 'publication_year': 2022, 'abstract': None}
{'title': 'Harnessing Out-Of-Distribution Examples via Augmenting Content and Style', 'paperID': '10b2dc04a91b6e1cb3f24003a988fc07b57df09f', 'arxivId': '2207.03162', 'publication_year': 2022, 'abstract': None}
{'title': 'Minimax Regret Optimization for Robust Machine Learning under Distribution Shift', 'paperID': '4fe3f3e113334998114211f2bb9ff1659100fc14', 'arxivId': '2202.05436', 'publication_year': 2022, 'abstract': None}
{'title': 'Generalized Out-of-Distribution Detection: A Survey', 'paperID': '7b2180d7fa0d65e8756401cb077bf3dea3f9b575', 'arxivId': '2110.11334', 'publication_year': 2021, 'abstract': None}
{'title': 'Mixture Outlier Exposure: Towards Out-of-Distribution Detection in Fine-grained Environments', 'paperID': '7bdc1a737a8864b80c7abd5cca71c6514de25345', 'arxivId': '2106.03917', 'publication_year': 2021, 'abstract': None}
{'title': 'ImageNet-21K Pretraining for the Masses', 'paperID': '0d5406775fab3e71848908327fb5504df5f60f92', 'arxivId': '2104.10972', 'publication_year': 2021, 'abstract': None}
{'title': 'ATOM: Robustifying Out-of-Distribution Detection Using Outlier Mining', 'paperID': '275675ea82a4b35c42bea2943649cabe6f6e43ab', 'arxivId': '2006.15207', 'publication_year': 2020, 'abstract': None}
{'title': 'Principled Learning Method for Wasserstein distributionally robust optimization with local perturbations', 'paperID': '0c4b0409cb2ac16ad4e744d37bc5ca52cee1c1b4', 'arxivId': '2006.03333', 'publication_year': 2020, 'abstract': None}
{'title': 'What Can Be Transferred: Unsupervised Domain Adaptation for Endoscopic Lesions Segmentation', 'paperID': '897e77a4721e542990981aad9d65580cc0937f57', 'arxivId': '2004.11500', 'publication_year': 2020, 'abstract': None}
{'title': 'Anomalous Instance Detection in Deep Learning: A Survey', 'paperID': '86c12bb6fb6fb2956d1147bd1b15a788b6d07f6e', 'arxivId': '2003.06979', 'publication_year': 2020, 'abstract': None}
{'title': 'Relative Flatness and Generalization', 'paperID': 'd8c0aabe41ec6036a2404cb2bfaea2a7d6424ae3', 'arxivId': '2001.00939', 'publication_year': 2020, 'abstract': None}
{'title': 'Distributionally Robust Optimization: A Review', 'paperID': '2a7c45c63959d3c5652f90d5bc3e97b39ea42f32', 'arxivId': '1908.05659', 'publication_year': 2019, 'abstract': None}
{'title': 'Fairness Without Demographics in Repeated Loss Minimization', 'paperID': '16f0c508aa54e26aa18e3b0f3c91b0c143c6a605', 'arxivId': '1806.08010', 'publication_year': 2018, 'abstract': None}
{'title': 'Certifying Some Distributional Robustness with Principled Adversarial Training', 'paperID': '818c52f4ba56cb8cf152ad614f2f4803057a5cfe', 'arxivId': '1710.10571', 'publication_year': 2017, 'abstract': None}
{'title': 'SGDR: Stochastic Gradient Descent with Warm Restarts', 'paperID': 'b022f2a277a4bf5f42382e86e4380b96340b9e86', 'arxivId': '1608.03983', 'publication_year': 2016, 'abstract': None}
{'title': 'The relationship between Precision-Recall and ROC curves', 'paperID': '73f76a40ed20aa3c6a8e27e4db4a8c102e7b4c6d', 'arxivId': None, 'publication_year': 2006, 'abstract': None}
{'title': 'Scaling Out-of-Distribution Detection for Real-World Settings', 'paperID': '0e4b0d177e550d365f456375781cd0e4f7a04979', 'arxivId': '1911.11132', 'publication_year': 2022, 'abstract': None}
{'title': 'Out-of-distribution Detection with Implicit Outlier Transformation', 'paperID': 'a64a192b01c57e18dafd1a8e826056cd3e97cedd', 'arxivId': '2303.05033', 'publication_year': '2023', 'abstract': 'Outlier exposure (OE) is powerful in out-of-distribution (OOD) detection, enhancing detection capability via model fine-tuning with surrogate OOD data. However, surrogate data typically deviate from test OOD data. Thus, the performance of OE, when facing unseen OOD data, can be weakened. To address this issue, we propose a novel OE-based approach that makes the model perform well for unseen OOD situations, even for unseen OOD cases. It leads to a min-max learning scheme -- searching to synthesize OOD data that leads to worst judgments and learning from such OOD data for uniform performance in OOD detection. In our realization, these worst OOD data are synthesized by transforming original surrogate ones. Specifically, the associated transform functions are learned implicitly based on our novel insight that model perturbation leads to data transformation. Our methodology offers an efficient way of synthesizing OOD data, which can further benefit the detection model, besides the surrogate OOD data. We conduct extensive experiments under various OOD detection setups, demonstrating the effectiveness of our method against its advanced counterparts.'}
{'title': 'Improving Out-of-Distribution Robustness via Selective Augmentation', 'paperID': '3ced5335b973fa9d4e537376c02c2df22dd5631c', 'arxivId': '2201.00299', 'publication_year': 2022, 'abstract': None}
{'title': 'A Fine-Grained Analysis on Distribution Shift', 'paperID': '0e845ef0a3ae71bd32a6954fafe0702d0f0f033f', 'arxivId': '2110.11328', 'publication_year': 2021, 'abstract': None}
{'title': 'Invariance Principle Meets Information Bottleneck for Out-of-Distribution Generalization', 'paperID': '4390d210bfd4cd7b646f13f287f44f9620a4f214', 'arxivId': '2106.06607', 'publication_year': 2021, 'abstract': None}
{'title': 'OoD-Bench: Quantifying and Understanding Two Dimensions of Out-of-Distribution Generalization', 'paperID': '04c9b1b0f83e5608e1f0c3ee0d331e74752f1fc1', 'arxivId': '2106.03721', 'publication_year': 2021, 'abstract': None}
{'title': 'Towards Causal Representation Learning', 'paperID': '8f566001453bc6be0a935bf69ffd90d9db3af32b', 'arxivId': '2102.11107', 'publication_year': 2021, 'abstract': None}
{'title': 'The Pitfalls of Simplicity Bias in Neural Networks', 'paperID': '0b40141779fafcedc28d83bd678807ddb5980df3', 'arxivId': '2006.07710', 'publication_year': 2020, 'abstract': None}
{'title': 'Distributionally Robust Neural Networks', 'paperID': '5d0e2635a1ebe2c9347529975bc876d4286c9ab7', 'arxivId': None, 'publication_year': 2020, 'abstract': None}
{'title': 'Weakly-Supervised Disentanglement Without Compromises', 'paperID': '3538c520244b508945476f0814d2ba1e8f22307e', 'arxivId': '2002.02886', 'publication_year': 2020, 'abstract': None}
{'title': 'Improve Unsupervised Domain Adaptation with Mixup Training', 'paperID': '976cb563bd7edfba984fbb6795026b31a4df3237', 'arxivId': '2001.00677', 'publication_year': 2020, 'abstract': None}
{'title': 'Generalizing to unseen domains via distribution matching', 'paperID': 'a1aaccbb59dda09352e6409f2628f152d79c00dd', 'arxivId': '1911.00804', 'publication_year': 2019, 'abstract': None}
{'title': 'Randaugment: Practical automated data augmentation with a reduced search space', 'paperID': '87f6a7c014ce206ac5b57299c07e10667d194b39', 'arxivId': '1909.13719', 'publication_year': 2019, 'abstract': None}
{'title': 'Domain Generalization via Multidomain Discriminant Analysis', 'paperID': 'f855730cac5cc3d004d7d0a70c5cd0cfe9090af3', 'arxivId': '1907.11216', 'publication_year': 2019, 'abstract': None}
{'title': 'Nuanced Metrics for Measuring Unintended Bias with Real Data for Text Classification', 'paperID': 'b611a8095630557229dc5fb6b07c272f1cd614da', 'arxivId': '1903.04561', 'publication_year': 2019, 'abstract': None}
{'title': 'Support and Invertibility in Domain-Invariant Representations', 'paperID': '2f0b9e8e1aed4d4c112164d04f10ddbeb27da55f', 'arxivId': '1903.03448', 'publication_year': 2019, 'abstract': None}
{'title': 'Quantifying the effects of data augmentation and stain color normalization in convolutional neural networks for computational pathology', 'paperID': '35ee6606ec99b5bf282a0c5f400edbd16a6e22d9', 'arxivId': '1902.06543', 'publication_year': 2019, 'abstract': None}
{'title': 'From Detection of Individual Metastases to Classification of Lymph Node Status at the Patient Level: The CAMELYON17 Challenge', 'paperID': '1b27b9cfe0ce17950b6ea72f9ef8cf5a7459bccd', 'arxivId': None, 'publication_year': 2019, 'abstract': None}
{'title': 'On Learning Invariant Representation for Domain Adaptation', 'paperID': '3645848a932a8182533e5b054ca67d1072f360f9', 'arxivId': '1901.09453', 'publication_year': 2019, 'abstract': None}
{'title': 'Measuring and Mitigating Unintended Bias in Text Classification', 'paperID': '44fc8d79fb8e0f8c6c6f680179b5803a789c6227', 'arxivId': None, 'publication_year': 2018, 'abstract': None}
{'title': 'Reducing Gender Bias in Abusive Language Detection', 'paperID': '8ad3bc604adc58c828c30e55e9adef0a81bf7e81', 'arxivId': '1808.07231', 'publication_year': 2018, 'abstract': None}
{'title': 'Domain Generalization via Conditional Invariant Representations', 'paperID': '4c45944b2faeb6e19d80dfb9e536934167cb2a82', 'arxivId': '1807.08479', 'publication_year': 2018, 'abstract': None}
{'title': 'Machine Learning Methods for Histopathological Image Analysis', 'paperID': '7e355a8f42becb6648efc4cf0c129a7f560789be', 'arxivId': '1709.00786', 'publication_year': 2017, 'abstract': None}
{'title': 'Unpaired Image-to-Image Translation Using Cycle-Consistent Adversarial Networks', 'paperID': 'c43d954cf8133e6254499f3d68e45218067e4941', 'arxivId': '1703.10593', 'publication_year': 2017, 'abstract': None}
{'title': 'beta-VAE: Learning Basic Visual Concepts with a Constrained Variational Framework', 'paperID': 'a90226c41b79f8b06007609f39f82757073641e2', 'arxivId': None, 'publication_year': 2016, 'abstract': None}
{'title': 'Scatter Component Analysis: A Unified Framework for Domain Adaptation and Domain Generalization', 'paperID': '8a29808865a0daf55e80a626a555c21f31c479f4', 'arxivId': '1510.04373', 'publication_year': 2015, 'abstract': None}
{'title': 'Domain Generalization for Object Recognition with Multi-task Autoencoders', 'paperID': '1357de2a653b704066d2a2b0b2dfe12875bf8eb8', 'arxivId': '1508.07680', 'publication_year': 2015, 'abstract': None}
{'title': 'A Kernel Two-Sample Test', 'paperID': '225f78ae8a44723c136646044fd5c5d7f1d3d15a', 'arxivId': None, 'publication_year': 2012, 'abstract': None}
{'title': 'The Caltech-UCSD Birds-200-2011 Dataset', 'paperID': 'c069629a51f6c1c301eb20ed77bc6b586c24ce32', 'arxivId': None, 'publication_year': 2011, 'abstract': None}
{'title': 'Learning methods for generic object recognition with invariance to pose and lighting', 'paperID': 'f354310098e09c1e1dc88758fca36767fd9d084d', 'arxivId': None, 'publication_year': 2004, 'abstract': None}
{'title': 'Invariance Principle Meets Out-of-Distribution Generalization on Graphs', 'paperID': '7c15ee1018a87708815c359d920820d8742dd3c8', 'arxivId': None, 'publication_year': 2022, 'abstract': None}
{'title': 'Counterfactual Invariance to Spurious Correlations in Text Classification', 'paperID': '6c3155e37db216929b3a3c7a3ecf6b1124cba56c', 'arxivId': None, 'publication_year': 2021, 'abstract': None}
{'title': 'Modeling the Data-Generating Process is Necessary for Out-of-Distribution Generalization', 'paperID': '810f0c7a6f8e0e684cb0be4a7bd1675fc8a0bbb7', 'arxivId': '2206.07837', 'publication_year': '2022', 'abstract': 'Recent empirical studies on domain generalization (DG) have shown that DG algorithms that perform well on some distribution shifts fail on others, and no state-of-the-art DG algorithm performs consistently well on all shifts. Moreover, real-world data often has multiple distribution shifts over different attributes; hence we introduce multi-attribute distribution shift datasets and find that the accuracy of existing DG algorithms falls even further. To explain these results, we provide a formal characterization of generalization under multi-attribute shifts using a canonical causal graph. Based on the relationship between spurious attributes and the classification label, we obtain realizations of the canonical causal graph that characterize common distribution shifts and show that each shift entails different independence constraints over observed variables. As a result, we prove that any algorithm based on a single, fixed constraint cannot work well across all shifts, providing theoretical evidence for mixed empirical results on DG algorithms. Based on this insight, we develop Causally Adaptive Constraint Minimization (CACM), an algorithm that uses knowledge about the data-generating process to adaptively identify and apply the correct independence constraints for regularization. Results on fully synthetic, MNIST, small NORB, and Waterbirds datasets, covering binary and multi-valued attributes and labels, show that adaptive dataset-dependent constraints lead to the highest accuracy on unseen domains whereas incorrect constraints fail to do so. Our results demonstrate the importance of modeling the causal relationships inherent in the data-generating process.'}
{'title': 'Scaling Autoregressive Models for Content-Rich Text-to-Image Generation', 'paperID': '1243e13254bb4ea1f71b4be8a3e4e54ffd02d2fe', 'arxivId': '2206.10789', 'publication_year': 2022, 'abstract': None}
{'title': 'Photorealistic Text-to-Image Diffusion Models with Deep Language Understanding', 'paperID': '9695824d7a01fad57ba9c01d7d76a519d78d65e7', 'arxivId': '2205.11487', 'publication_year': 2022, 'abstract': None}
{'title': 'OPT: Open Pre-trained Transformer Language Models', 'paperID': '13a0d8bb38f739990c8cd65a44061c6534f17221', 'arxivId': '2205.01068', 'publication_year': 2022, 'abstract': None}
{'title': 'Hierarchical Text-Conditional Image Generation with CLIP Latents', 'paperID': 'c57293882b2561e1ba03017902df9fc2f289dea2', 'arxivId': '2204.06125', 'publication_year': 2022, 'abstract': None}
{'title': 'Locating and Editing Factual Associations in GPT', 'paperID': '996445d847f06e99b0bd259345408a0cf1bce87e', 'arxivId': '2202.05262', 'publication_year': 2022, 'abstract': None}
{'title': 'Editing a classifier by rewriting its prediction rules', 'paperID': 'ec4f3b701c6d97fc73d5afdede41a6510092320f', 'arxivId': '2112.01008', 'publication_year': 2021, 'abstract': None}
{'title': 'DICE: Leveraging Sparsification for Out-of-Distribution Detection', 'paperID': '1a250108e2a4d6c0d472b56bf2cbb2e07d2eedbb', 'arxivId': '2111.09805', 'publication_year': 2021, 'abstract': None}
{'title': 'Revisiting the Calibration of Modern Neural Networks', 'paperID': 'e757488d2e8684e3da7b14fbb000b7e4a0bab001', 'arxivId': '2106.07998', 'publication_year': 2021, 'abstract': None}
{'title': 'A Near-Optimal Algorithm for Debiasing Trained Machine Learning Models', 'paperID': '7b9d49b4c18a160512cbe9fc9fa5d8c40cd6b84e', 'arxivId': '2106.12887', 'publication_year': 2021, 'abstract': None}
{'title': 'Sparsity in Deep Learning: Pruning and growth for efficient inference and training in neural networks', 'paperID': '9d6acac70b2d1fdb861a08b00766ef263109cd7f', 'arxivId': '2102.00554', 'publication_year': 2021, 'abstract': None}
{'title': 'Language Models are Few-Shot Learners', 'paperID': '6b85b63579a916f705a8e10a49bd8d849d91b1fc', 'arxivId': '2005.14165', 'publication_year': 2020, 'abstract': None}
{'title': 'Scaling Laws for Neural Language Models', 'paperID': 'e6c561d02500b2596a230b341a8eb8b921ca5bf2', 'arxivId': '2001.08361', 'publication_year': 2020, 'abstract': None}
{'title': 'Plug and Play Language Models: A Simple Approach to Controlled Text Generation', 'paperID': 'e04a80263d252a3d8a382ba37a249b9345620570', 'arxivId': '1912.02164', 'publication_year': 2019, 'abstract': None}
{'title': 'Autoregressive Models', 'paperID': '6efc9b997e57203e7e5405751c2ef7ee75c5e578', 'arxivId': None, 'publication_year': 2019, 'abstract': None}
{'title': 'Explanations can be manipulated and geometry is to blame', 'paperID': 'a0f0a94927c0013fa924ee43c8ddbace1d71e3fb', 'arxivId': '1906.07983', 'publication_year': 2019, 'abstract': None}
{'title': 'Learning Sparse Networks Using Targeted Dropout', 'paperID': '13de3c06ef6dac1c296ada45df2be590f843edb7', 'arxivId': '1905.13678', 'publication_year': 2019, 'abstract': None}
{'title': 'How Can We Be So Dense? The Benefits of Using Highly Sparse Representations', 'paperID': '3055e31b007c93fb9291b3ecd5b3c5f94fe9225f', 'arxivId': '1903.11257', 'publication_year': 2019, 'abstract': None}
{'title': 'Certified Adversarial Robustness via Randomized Smoothing', 'paperID': 'f7f73185e3975bb62a3c42b2ba6bd4db57fee8ed', 'arxivId': '1902.02918', 'publication_year': 2019, 'abstract': None}
{'title': 'Classification with Fairness Constraints: A Meta-Algorithm with Provable Guarantees', 'paperID': '95e920c2ba4ed19e462d42b2802536a5b35b796b', 'arxivId': '1806.06055', 'publication_year': 2018, 'abstract': None}
{'title': 'Measuring the Intrinsic Dimension of Objective Landscapes', 'paperID': 'd55d1d035e91220335edff0fe8f5d249d8c4a00b', 'arxivId': '1804.08838', 'publication_year': 2018, 'abstract': None}
{'title': 'Stochastic Activation Pruning for Robust Adversarial Defense', 'paperID': '2f201c77e7ccdf1f37115e16accac3486a65c03d', 'arxivId': '1803.01442', 'publication_year': 2018, 'abstract': None}
{'title': 'The cost of fairness in binary classification', 'paperID': '9d55b5fc3f3b92324f4a9c46d5b66d11895ba565', 'arxivId': None, 'publication_year': 2018, 'abstract': None}
{'title': 'MobileNetV2: Inverted Residuals and Linear Bottlenecks', 'paperID': 'dd9cfe7124c734f5a6fc90227d541d3dbcd72ba4', 'arxivId': '1801.04381', 'publication_year': 2018, 'abstract': None}
{'title': 'Algorithmic Decision Making and the Cost of Fairness', 'paperID': '57797e2432b06dfbb7debd6f13d0aab45d374426', 'arxivId': '1701.08230', 'publication_year': 2017, 'abstract': None}
{'title': 'Extremely Simple Activation Shaping for Out-of-Distribution Detection', 'paperID': 'cf49af82a5f1ba5f2beba9f290e684b7b51b64e6', 'arxivId': '2209.09858', 'publication_year': '2022', 'abstract': "The separation between training and deployment of machine learning models implies that not all scenarios encountered in deployment can be anticipated during training, and therefore relying solely on advancements in training has its limits. Out-of-distribution (OOD) detection is an important area that stress-tests a model's ability to handle unseen situations: Do models know when they don't know? Existing OOD detection methods either incur extra training steps, additional data or make nontrivial modifications to the trained network. In contrast, in this work, we propose an extremely simple, post-hoc, on-the-fly activation shaping method, ASH, where a large portion (e.g. 90%) of a sample's activation at a late layer is removed, and the rest (e.g. 10%) simplified or lightly adjusted. The shaping is applied at inference time, and does not require any statistics calculated from training data. Experiments show that such a simple treatment enhances in-distribution and out-of-distribution distinction so as to allow state-of-the-art OOD detection on ImageNet, and does not noticeably deteriorate the in-distribution accuracy. Video, animation and code can be found at: https://andrijazz.github.io/ash"}
{'title': 'The Tilted Variational Autoencoder: Improving Out-of-Distribution Detection', 'paperID': '20ca62aae323c8778a978300c682ac8e1d160e74', 'arxivId': None, 'publication_year': None, 'abstract': None}
{'title': 'Towards Calibrated Hyper-Sphere Representation via Distribution Overlap Coefficient for Long-tailed Learning', 'paperID': 'd57a90a2abafc55fcdf7dda2a84ac2fc05aa4d9a', 'arxivId': '2208.10043', 'publication_year': 2022, 'abstract': None}
{'title': 'Open-Sampling: Exploring Out-of-Distribution data for Re-balancing Long-tailed datasets', 'paperID': 'b2eb73e269622329ac98e9938bb1402314281c9b', 'arxivId': '2206.08802', 'publication_year': 2022, 'abstract': None}
{'title': 'Contrastive Learning with Boosted Memorization', 'paperID': '10060c83e48b86eab95386da928de3dfd4201ac8', 'arxivId': '2205.12693', 'publication_year': 2022, 'abstract': None}
{'title': 'Flamingo: a Visual Language Model for Few-Shot Learning', 'paperID': '26218bdcc3945c7edae7aa2adbfba4cd820a2df3', 'arxivId': '2204.14198', 'publication_year': 2022, 'abstract': None}
{'title': 'Chaos is a Ladder: A New Theoretical Understanding of Contrastive Learning via Augmentation Overlap', 'paperID': '13beab6bad06631d177e274e4d70b95c4b103423', 'arxivId': '2203.13457', 'publication_year': 2022, 'abstract': None}
{'title': 'Targeted Supervised Contrastive Learning for Long-Tailed Recognition', 'paperID': '2121c6910b5f187fdaecf65981ed76a6a668a559', 'arxivId': '2111.13998', 'publication_year': 2021, 'abstract': None}
{'title': 'Mosaicking to Distill: Knowledge Distillation from Out-of-Domain Data', 'paperID': '16aa9ddb681554daf075eb13ba1fe37aff5f151d', 'arxivId': '2110.15094', 'publication_year': 2021, 'abstract': None}
{'title': 'ABC: Auxiliary Balanced Classifier for Class-imbalanced Semi-supervised Learning', 'paperID': '6b1b8cbace3bcbfe9fd9bd48fae47bc6473abd79', 'arxivId': '2110.10368', 'publication_year': 2021, 'abstract': None}
{'title': 'FlexMatch: Boosting Semi-Supervised Learning with Curriculum Pseudo Labeling', 'paperID': '4b842ba29f6d244b9f456056a2d7efab9e4903a5', 'arxivId': '2110.08263', 'publication_year': 2021, 'abstract': None}
{'title': 'Self-supervised Learning is More Robust to Dataset Imbalance', 'paperID': 'a01ac66f5f66a2b23152f631b920972e4407275c', 'arxivId': '2110.05025', 'publication_year': 2021, 'abstract': None}
{'title': 'Open-set Label Noise Can Improve Robustness Against Inherent Label Noise', 'paperID': '39ccbe81127e44bf3275b94d8b2311367d5c9548', 'arxivId': '2106.10891', 'publication_year': 2021, 'abstract': None}
{'title': 'Self-Damaging Contrastive Learning', 'paperID': '98be8ae73dc5b9666c298b09ae0ffe9a361197a9', 'arxivId': '2106.02990', 'publication_year': 2021, 'abstract': None}
{'title': 'Iterative human and automated identification of wildlife images', 'paperID': '33c18b096ca4493a2c052b49c77468e2bc3f17c1', 'arxivId': '2105.02320', 'publication_year': 2021, 'abstract': None}
{'title': 'Relational Subsets Knowledge Distillation for Long-tailed Retinal Diseases Recognition', 'paperID': 'aff22383d605f9e3961364f850b93db6d986b843', 'arxivId': '2104.11057', 'publication_year': 2021, 'abstract': None}
{'title': 'Understanding deep learning (still) requires rethinking generalization', 'paperID': '2f65c6ac06bfcd992d4dd75f0099a072f5c3cc8c', 'arxivId': None, 'publication_year': 2021, 'abstract': None}
{'title': 'Learning Invariant Representations and Risks for Semi-supervised Domain Adaptation', 'paperID': '758fb62a9ce0cabfce71b0020a662522ca8ceabf', 'arxivId': '2010.04647', 'publication_year': 2020, 'abstract': None}
{'title': 'Distribution Aligning Refinery of Pseudo-label for Imbalanced Semi-supervised Learning', 'paperID': '3bab355a4660edcc3f6e10df5e260dcf92f630d0', 'arxivId': '2007.08844', 'publication_year': 2020, 'abstract': None}
{'title': 'Rethinking the Value of Labels for Improving Class-Imbalanced Learning', 'paperID': '5099d47408251626a4adc6a0f5e93678d8188732', 'arxivId': '2006.07529', 'publication_year': 2020, 'abstract': None}
{'title': 'Bootstrap Your Own Latent: A New Approach to Self-Supervised Learning', 'paperID': '38f93092ece8eee9771e61c1edaf11b1293cae1b', 'arxivId': '2006.07733', 'publication_year': 2020, 'abstract': None}
{'title': 'Rethinking Class-Balanced Methods for Long-Tailed Visual Recognition From a Domain Adaptation Perspective', 'paperID': '297dbda128756e2816130a8de057f96760e4b89c', 'arxivId': '2003.10780', 'publication_year': 2020, 'abstract': None}
{'title': 'FixMatch: Simplifying Semi-Supervised Learning with Consistency and Confidence', 'paperID': '299847adf3ee558a760475ffa364facac3ebbb16', 'arxivId': '2001.07685', 'publication_year': 2020, 'abstract': None}
{'title': 'What Do Compressed Deep Neural Networks Forget', 'paperID': '37d87f24841987ae64e871088efb6c1df6d405d4', 'arxivId': '1911.05248', 'publication_year': 2019, 'abstract': None}
{'title': 'Decoupling Representation and Classifier for Long-Tailed Recognition', 'paperID': 'dcc4c760c3f1cb17f953c487190b735030c33b78', 'arxivId': '1910.09217', 'publication_year': 2019, 'abstract': None}
{'title': 'Open Compound Domain Adaptation', 'paperID': '01cc664615c8b48c3341cab4452a60191fb1451d', 'arxivId': '1909.03403', 'publication_year': 2019, 'abstract': None}
{'title': 'Learning Imbalanced Datasets with Label-Distribution-Aware Margin Loss', 'paperID': 'bcfba69c2fadf2efea83be12fda2601f8d4681af', 'arxivId': '1906.07413', 'publication_year': 2019, 'abstract': None}
{'title': 'Contrastive Multiview Coding', 'paperID': '97f4d09175705be4677d675fa27e55defac44800', 'arxivId': '1906.05849', 'publication_year': 2019, 'abstract': None}
{'title': 'Large-Scale Long-Tailed Recognition in an Open World', 'paperID': '73c07e0a998576bb9d9409e5eed713788c0be037', 'arxivId': '1904.05160', 'publication_year': 2019, 'abstract': None}
{'title': 'Class-Balanced Loss Based on Effective Number of Samples', 'paperID': '54036f43acc6c9b49b334270c7237217685f52fb', 'arxivId': '1901.05555', 'publication_year': 2019, 'abstract': None}
{'title': 'Unsupervised Domain Adaptation for Semantic Segmentation via Class-Balanced Self-training', 'paperID': '9b15362b9a025071aa170f7ed81a761bc057c859', 'arxivId': None, 'publication_year': 2018, 'abstract': None}
{'title': 'Deep Active Learning over the Long Tail', 'paperID': '41ed3608eae64fd181ca8b5e6d0eb63b210b588b', 'arxivId': '1711.00941', 'publication_year': 2017, 'abstract': None}
{'title': 'Relay Backpropagation for Effective Learning of Deep Convolutional Neural Networks', 'paperID': '1f0bafe95728885034f5371420db2790e990971d', 'arxivId': '1512.05830', 'publication_year': 2015, 'abstract': None}
{'title': 'Learning Transferable Features with Deep Adaptation Networks', 'paperID': '7340f090f8a0df5b109682e9f6d57e4b8ca1a2f7', 'arxivId': '1502.02791', 'publication_year': 2015, 'abstract': None}
{'title': 'Cost-sensitive boosting for classification of imbalanced data', 'paperID': 'b1e4660c82951ba19a861afc8be5cf56cc46aaa8', 'arxivId': None, 'publication_year': 2007, 'abstract': None}
{'title': 'Measuring and Predicting Importance of Objects in Our Visual World', 'paperID': 'fb885a2bcab4d361e6fbcd426ea617f0cab1ef63', 'arxivId': None, 'publication_year': 2007, 'abstract': None}
{'title': 'The Foundations of Cost-Sensitive Learning', 'paperID': '7fed3e00be2bb09510f5f7cad7ac106e6c94a359', 'arxivId': None, 'publication_year': 2001, 'abstract': None}
{'title': 'Improving Contrastive Learning on Imbalanced Data via Open-World Sampling', 'paperID': '23feca8b7435f46c317c90172bb01eb1ed942fae', 'arxivId': None, 'publication_year': 2021, 'abstract': None}
{'title': 'Exploring Balanced Feature Spaces for Representation Learning', 'paperID': 'b65bc8bd4e8900c38eb09bc1cbccea2499a86627', 'arxivId': None, 'publication_year': 2021, 'abstract': None}
{'title': 'On the Effectiveness of Out-of-Distribution Data in Self-Supervised Long-Tail Learning.', 'paperID': '48790c048f0b982e290e932eb320e0e1f544b641', 'arxivId': '2306.04934', 'publication_year': '2023', 'abstract': "Though Self-supervised learning (SSL) has been widely studied as a promising technique for representation learning, it doesn't generalize well on long-tailed datasets due to the majority classes dominating the feature space. Recent work shows that the long-tailed learning performance could be boosted by sampling extra in-domain (ID) data for self-supervised training, however, large-scale ID data which can rebalance the minority classes are expensive to collect. In this paper, we propose an alternative but easy-to-use and effective solution, Contrastive with Out-of-distribution (OOD) data for Long-Tail learning (COLT), which can effectively exploit OOD data to dynamically re-balance the feature space. We empirically identify the counter-intuitive usefulness of OOD samples in SSL long-tailed learning and principally design a novel SSL method. Concretely, we first localize the `head' and `tail' samples by assigning a tailness score to each OOD sample based on its neighborhoods in the feature space. Then, we propose an online OOD sampling strategy to dynamically re-balance the feature space. Finally, we enforce the model to be capable of distinguishing ID and OOD samples by a distribution-level supervised contrastive loss. Extensive experiments are conducted on various datasets and several state-of-the-art SSL frameworks to verify the effectiveness of the proposed method. The results show that our method significantly improves the performance of SSL on long-tailed datasets by a large margin, and even outperforms previous work which uses external ID data. Our code is available at https://github.com/JianhongBai/COLT."}
{'title': 'Predicting is not Understanding: Recognizing and Addressing Underspecification in Machine Learning', 'paperID': '517f2d4a0d2e4ee8c452ce53c455a4c3e7662a7b', 'arxivId': '2207.02598', 'publication_year': 2022, 'abstract': None}
{'title': 'Last Layer Re-Training is Sufficient for Robustness to Spurious Correlations', 'paperID': '14a3aae8060338e3fbefc2af694890b019874d4f', 'arxivId': '2204.02937', 'publication_year': 2022, 'abstract': None}
{'title': 'Agree to Disagree: Diversity through Disagreement for Better Transferability', 'paperID': '962466ca8a3bf432a2d45b656ab5dbcc9caf5b16', 'arxivId': '2202.04414', 'publication_year': 2022, 'abstract': None}
{'title': 'Extending the WILDS Benchmark for Unsupervised Adaptation', 'paperID': 'ab2a8ca21309859ed027928dc38e6915be0e6776', 'arxivId': '2112.05090', 'publication_year': 2021, 'abstract': None}
{'title': 'Which Shortcut Cues Will DNNs Choose? A Study from the Parameter-Space Perspective', 'paperID': '535131d7218e26360c09cd8f9a2e7198ec0e3e6f', 'arxivId': '2110.03095', 'publication_year': 2021, 'abstract': None}
{'title': 'Just Train Twice: Improving Group Robustness without Training Group Information', 'paperID': '216d093cb2ad81bf55c21dbce2217f2b9032e67b', 'arxivId': '2107.09044', 'publication_year': 2021, 'abstract': None}
{'title': 'Evading the Simplicity Bias: Training a Diverse Set of Models Discovers Solutions with Superior OOD Generalization', 'paperID': 'd071797499892940876a50f518d9c74d8c4e4018', 'arxivId': '2105.05612', 'publication_year': 2021, 'abstract': None}
{'title': 'Learning Neural Network Subspaces', 'paperID': '0edbe195120c78777959dc8bff25d4c61305c9c8', 'arxivId': '2102.10472', 'publication_year': 2021, 'abstract': None}
{'title': 'DICE: Diversity in Deep Ensembles via Conditional Redundancy Adversarial Estimation', 'paperID': 'a3ec0076139420a34d2079a029b0836b890e5d3c', 'arxivId': '2101.05544', 'publication_year': 2021, 'abstract': None}
{'title': 'Ridge Rider: Finding Diverse Solutions by Following Eigenvectors of the Hessian', 'paperID': 'b405764900fd2ec3979b16633056e0e6434973a8', 'arxivId': '2011.06505', 'publication_year': 2020, 'abstract': None}
{'title': 'Underspecification Presents Challenges for Credibility in Modern Machine Learning', 'paperID': '71a85e735a3686bef8cce3725ae5ba82e2cabb1b', 'arxivId': '2011.03395', 'publication_year': 2020, 'abstract': None}
{'title': 'One Solution is Not All You Need: Few-Shot Extrapolation via Structured MaxEnt RL', 'paperID': 'e4a46c64aafbef0406e9cfa90dd9c43e3e07598c', 'arxivId': '2010.14484', 'publication_year': 2020, 'abstract': None}
{'title': 'Learning from Failure: Training Debiased Classifier from Biased Classifier', 'paperID': '5ce0ce49c082313d042fb864471af39ad04d26e5', 'arxivId': '2007.02561', 'publication_year': 2020, 'abstract': None}
{'title': 'DIBS: Diversity inducing Information Bottleneck in Model Ensembles', 'paperID': '99fbd94538d9568a04196e055d286ffae32cf58f', 'arxivId': '2003.04514', 'publication_year': 2020, 'abstract': None}
{'title': 'Causality for Machine Learning', 'paperID': 'b5461f9c5d65e87561e00848921ee797902dae14', 'arxivId': '1911.10500', 'publication_year': 2019, 'abstract': None}
{'title': 'Hidden stratification causes clinically meaningful failures in machine learning for medical imaging', 'paperID': '4ce2f55585f3156e332721b8ab4f449389dc2a3c', 'arxivId': '1909.12475', 'publication_year': 2019, 'abstract': None}
{'title': 'Learning Neural Causal Models from Unknown Interventions', 'paperID': '207033829813aadc2f2dca8f93279352d39de759', 'arxivId': '1910.01075', 'publication_year': 2019, 'abstract': None}
{'title': 'A study in Rashomon curves and volumes: A new perspective on generalization and model simplicity in machine learning', 'paperID': 'df074eebeeaac85f87b48b0c1351c92f8442c1fb', 'arxivId': None, 'publication_year': 2019, 'abstract': None}
{'title': 'Dynamics-Aware Unsupervised Discovery of Skills', 'paperID': 'ffb3886a253ff927bcc46b78e00409893865a68e', 'arxivId': '1907.01657', 'publication_year': 2019, 'abstract': None}
{'title': 'Improving Adversarial Robustness via Promoting Ensemble Diversity', 'paperID': '676e40050453ddeb1387f8314478c0ac3681a8c6', 'arxivId': '1901.08846', 'publication_year': 2019, 'abstract': None}
{'title': 'Implicit Bias of Gradient Descent on Linear Convolutional Networks', 'paperID': '67a97032fd3ad81cda45e1e5d4a1a7d851494525', 'arxivId': '1806.00468', 'publication_year': 2018, 'abstract': None}
{'title': 'Annotation Artifacts in Natural Language Inference Data', 'paperID': '2997b26ffb8c291ce478bd8a6e47979d5a55c466', 'arxivId': '1803.02324', 'publication_year': 2018, 'abstract': None}
{'title': 'Diversity is All You Need: Learning Skills without a Reward Function', 'paperID': '5b01eaef54a653ba03ddd5a978690380fbc19bfc', 'arxivId': '1802.06070', 'publication_year': 2018, 'abstract': None}
{'title': 'Disentangling by Factorising', 'paperID': '04541599accc47d8174f63345ce9c987ef21685b', 'arxivId': '1802.05983', 'publication_year': 2018, 'abstract': None}
{'title': 'Isolating Sources of Disentanglement in Variational Autoencoders', 'paperID': '540b399c768ab254be3df3c5b0cfd195cbd08f3a', 'arxivId': None, 'publication_year': 2018, 'abstract': None}
{'title': "All Models are Wrong, but Many are Useful: Learning a Variable's Importance by Studying an Entire Class of Prediction Models Simultaneously", 'paperID': '12a6492b48ab5c475615f7ba381b3dcd205041d6', 'arxivId': '1801.01489', 'publication_year': 2018, 'abstract': None}
{'title': 'Improving Exploration in Evolution Strategies for Deep Reinforcement Learning via a Population of Novelty-Seeking Agents', 'paperID': '2064020586d5832b55f80a7dffea1fd90a5d94dd', 'arxivId': '1712.06560', 'publication_year': 2017, 'abstract': None}
{'title': 'A Closer Look at Memorization in Deep Networks', 'paperID': '5ddd38a5df945e4afee68d96ed51fd6ca1f7d4cf', 'arxivId': '1706.05394', 'publication_year': 2017, 'abstract': None}
{'title': 'Causal Effect Inference with Deep Latent-Variable Models', 'paperID': 'a32a61a6bf23d13a7088f1c77e694ab13bb6c58e', 'arxivId': None, 'publication_year': 2017, 'abstract': None}
{'title': 'Quality and Diversity Optimization: A Unifying Modular Framework', 'paperID': '1252ce88d42db2810de848e10f0a2d85f9bfdf7b', 'arxivId': '1708.09251', 'publication_year': 2017, 'abstract': None}
{'title': 'Correlation Alignment for Unsupervised Domain Adaptation', 'paperID': 'd4a196e67e9e47a9797670b7e4ae59f2330baca0', 'arxivId': '1612.01939', 'publication_year': 2016, 'abstract': None}
{'title': 'Grad-CAM: Visual Explanations from Deep Networks via Gradient-Based Localization', 'paperID': 'e7eef2ac4136ec93bd306d2c9c353a13729a4553', 'arxivId': '1610.02391', 'publication_year': 2016, 'abstract': None}
{'title': 'InfoGAN: Interpretable Representation Learning by Information Maximizing Generative Adversarial Nets', 'paperID': 'eb7ee0bc355652654990bcf9f92f124688fde493', 'arxivId': '1606.03657', 'publication_year': 2016, 'abstract': None}
{'title': 'Illuminating search spaces by mapping elites', 'paperID': '45373921f06a6efebefa6189d2dd80362ab0836e', 'arxivId': '1504.04909', 'publication_year': 2015, 'abstract': None}
{'title': 'Deep Domain Confusion: Maximizing for Domain Invariance', 'paperID': '1c734a14c2325cb76783ca0431862c7f04a69268', 'arxivId': '1412.3474', 'publication_year': 2014, 'abstract': None}
{'title': 'Theory of Disagreement-Based Active Learning', 'paperID': '1e3154b10b872c100b86181ac2931c8e26f67912', 'arxivId': None, 'publication_year': 2014, 'abstract': None}
{'title': 'Microsoft COCO: Common Objects in Context', 'paperID': '71b7178df5d2b112d07e45038cb5637208659ff7', 'arxivId': '1405.0312', 'publication_year': 2014, 'abstract': None}
{'title': 'The MNIST Database of Handwritten Digit Images for Machine Learning Research [Best of the Web]', 'paperID': '46f74231b9afeb0c290d6d550043c55045284e5f', 'arxivId': None, 'publication_year': 2012, 'abstract': None}
{'title': 'Bayesian Active Learning for Classification and Preference Learning', 'paperID': '7486e148260329785fb347ac6725bd4123d8dad6', 'arxivId': '1112.5745', 'publication_year': 2011, 'abstract': None}
{'title': 'Neural network with ensembles', 'paperID': '88843f4372f7c0b8c820a164b64060983df12049', 'arxivId': None, 'publication_year': 2010, 'abstract': None}
{'title': 'Ensemble Methods in Machine Learning', 'paperID': 'a0456c27cdd58f197032c1c8b4f304f09d4c9bc5', 'arxivId': None, 'publication_year': 2000, 'abstract': None}
{'title': 'Active Learning with Statistical Models', 'paperID': '1150f9289c6151506e3f7cf0e6ebbcfd49f1dace', 'arxivId': 'cs/9603104', 'publication_year': 1996, 'abstract': None}
{'title': 'Information Theory and Statistical Mechanics', 'paperID': '08b67692bc037eada8d3d7ce76cc70994e7c8116', 'arxivId': None, 'publication_year': 1957, 'abstract': None}
{'title': 'Einops: Clear and Reliable Tensor Manipulations with Einstein-like Notation', 'paperID': '8a85ef6a7ebcd8735b868bf9c4a77e6a3c195caa', 'arxivId': None, 'publication_year': 2022, 'abstract': None}
{'title': 'ChestX-ray: Hospital-Scale Chest X-ray Database and Benchmarks on Weakly Supervised Classification and Localization of Common Thorax Diseases', 'paperID': '05e882679d61f4c64a68ebe21826251a39f87e98', 'arxivId': None, 'publication_year': 2019, 'abstract': None}
{'title': 'Causality pairwise inference datasets. Replication Data for: "Learning Functional Causal Models with Generative Neural Networks"', 'paperID': 'ef0d827d5512de73d877048cf63b61c016cb81f1', 'arxivId': None, 'publication_year': 2017, 'abstract': None}
{'title': 'Pseudo-Label : The Simple and Efficient Semi-Supervised Learning Method for Deep Neural Networks', 'paperID': '798d9840d2439a0e5d47bcf5d164aa46d5e7dc26', 'arxivId': None, 'publication_year': 2013, 'abstract': None}
{'title': 'Novelty Search and the Problem with Objectives', 'paperID': '1325bbd04a3e5a7e8137cf2edf9cbca7fc6fd55d', 'arxivId': None, 'publication_year': 2011, 'abstract': None}
{'title': 'Causality: Models, Reasoning and Inference', 'paperID': '62064218665ad89f0cb2a44f5b19f7703d9c7e71', 'arxivId': None, 'publication_year': 2000, 'abstract': None}
{'title': 'Neural Network Ensembles, Cross Validation, and Active Learning', 'paperID': '910688d01c01856dd20715907af44157de8d3d1d', 'arxivId': None, 'publication_year': 1994, 'abstract': None}
{'title': 'A Treatise on Probability', 'paperID': 'ae3abde9f9df2cddd6d9c896e91a93fca5034480', 'arxivId': None, 'publication_year': 1922, 'abstract': None}
{'title': 'Diversify and Disambiguate: Out-of-Distribution Robustness via Disagreement', 'paperID': '35af40853f48030c5050c1c3191f6e227ceb264b', 'arxivId': None, 'publication_year': None, 'abstract': 'Real-world machine learning problems often exhibit shifts between the source and target distributions, in which source data does not fully convey the desired behavior on target inputs. Different functions that achieve near-perfect source accuracy can make differing predictions on test inputs, and such ambiguity makes robustness to distribution shifts challenging. We propose DivDis, a simple two-stage framework for identifying and resolving ambiguity in data. DivDis first learns a diverse set of hypotheses that achieve low source loss but make differing predictions on target inputs. We then disambiguate by selecting one of the discovered functions using additional information, for example, a small number of target labels. Our experimental evaluation shows improved performance in subpopulation shift and domain generalization settings, demonstrating that DivDis can scalably adapt to distribution shifts in image and text classification benchmarks.'}
{'title': 'Domain Generalization without Excess Empirical Risk', 'paperID': 'dc659ff4b6f654d8c4ba355fb247d80726d623df', 'arxivId': '2308.15856', 'publication_year': 2023, 'abstract': None}
{'title': 'ID and OOD Performance Are Sometimes Inversely Correlated on Real-world Datasets', 'paperID': '5f09037109dceda8803baa527e8d1ed4095bee8f', 'arxivId': '2209.00613', 'publication_year': 2022, 'abstract': None}
{'title': 'Bayesian Invariant Risk Minimization', 'paperID': '50447645baad0ad9f3a6c314a42abfe8ee6455fb', 'arxivId': None, 'publication_year': 2022, 'abstract': None}
{'title': 'Rich Feature Construction for the Optimization-Generalization Dilemma', 'paperID': '5651cf8db4ffdc728aa89cf780a5573c37ecf805', 'arxivId': '2203.15516', 'publication_year': 2022, 'abstract': None}
{'title': 'Correct-N-Contrast: A Contrastive Approach for Improving Robustness to Spurious Correlations', 'paperID': '1420c75750c06c5eee473118389a6901847ad18b', 'arxivId': '2203.01517', 'publication_year': 2022, 'abstract': None}
{'title': 'Understanding and Improving Graph Injection Attack by Promoting Unnoticeability', 'paperID': '1b24fbc2189aca1d17f66eac7c8b09397eaf336f', 'arxivId': '2202.08057', 'publication_year': 2022, 'abstract': None}
{'title': 'Domain-Adjusted Regression or: ERM May Already Learn Features Sufficient for Out-of-Distribution Generalization', 'paperID': '241f8a90da2a9ec13ca44be5b602585bde4f92b7', 'arxivId': '2202.06856', 'publication_year': 2022, 'abstract': None}
{'title': 'Learning Causally Invariant Representations for Out-of-Distribution Generalization on Graphs', 'paperID': 'aa39c5a3080de756ad00648548e8f4faa2cfbf54', 'arxivId': '2202.05441', 'publication_year': 2022, 'abstract': None}
{'title': 'Understanding Why Generalized Reweighting Does Not Improve Over ERM', 'paperID': '0399be055f69e07a360dd4537c6f6304ff8c6ddc', 'arxivId': '2201.12293', 'publication_year': 2022, 'abstract': None}
{'title': 'Pareto Domain Adaptation', 'paperID': 'b7fe3952a4d0abaa027f188ff39f2be3f1825e94', 'arxivId': '2112.04137', 'publication_year': 2021, 'abstract': None}
{'title': 'On Characterizing the Trade-off in Invariant Representation Learning', 'paperID': '2f6b5a30f3ef66402ccdf19564ae0eebd0029fc0', 'arxivId': '2109.03386', 'publication_year': 2021, 'abstract': None}
{'title': 'CausalAdv: Adversarial Robustness through the Lens of Causality', 'paperID': '3076cfc34ed4cbcea88da074a0faa841cbf82036', 'arxivId': '2106.06196', 'publication_year': 2021, 'abstract': None}
{'title': 'Calibrating and Improving Graph Contrastive Learning', 'paperID': '34cce045b2106decb208e25197619628859fa3c0', 'arxivId': '2101.11525', 'publication_year': 2021, 'abstract': None}
{'title': 'Fundamental Limits and Tradeoffs in Invariant Representation Learning', 'paperID': '531beffcfca278108d8f89e1f9f5ed474907aa2d', 'arxivId': '2012.10713', 'publication_year': 2020, 'abstract': None}
{'title': 'Empirical or Invariant Risk Minimization? A Sample Complexity Perspective', 'paperID': 'fbf50ed8e09b3268770029af30b01d31973f77d0', 'arxivId': '2010.16412', 'publication_year': 2020, 'abstract': None}
{'title': 'AI for radiographic COVID-19 detection selects shortcuts over signal', 'paperID': '6e62a903dac8e643160bd1337d6cb8b09bf2f062', 'arxivId': None, 'publication_year': 2020, 'abstract': None}
{'title': 'Distributionally Robust Losses for Latent Covariate Mixtures', 'paperID': '8352a4ec9a0cf24b7556945743c418f84f9ed9fb', 'arxivId': '2007.13982', 'publication_year': 2020, 'abstract': None}
{'title': 'Multi-Task Learning with User Preferences: Gradient Descent with Controlled Ascent in Pareto Optimization', 'paperID': '90e8767589109ff1bcd01ba847a497da6027a9cf', 'arxivId': None, 'publication_year': 2020, 'abstract': None}
{'title': 'Efficient Continuous Pareto Exploration in Multi-Task Learning', 'paperID': '77e71aed1d8827ea65367933503ce24d6fbfb4ae', 'arxivId': '2006.16434', 'publication_year': 2020, 'abstract': None}
{'title': 'Random Hypervolume Scalarizations for Provable Multi-Objective Black Box Optimization', 'paperID': 'e14c3c0b4b2efb73cf47c54c45a2f23e45f6a7d1', 'arxivId': '2006.04655', 'publication_year': 2020, 'abstract': None}
{'title': 'Feature Purification: How Adversarial Training Performs Robust Deep Learning', 'paperID': '23c84238f9b15d7fd87a95d3b16882a21b953d8a', 'arxivId': '2005.10190', 'publication_year': 2020, 'abstract': None}
{'title': 'The iWildCam 2020 Competition Dataset', 'paperID': '431717afcb02e83a1c77c08639199436d702dc4b', 'arxivId': '2004.10340', 'publication_year': 2020, 'abstract': None}
{'title': 'Pareto Multi-Task Learning', 'paperID': '0702f398468c23c96e3313e6efc798c964fba289', 'arxivId': '1912.12854', 'publication_year': 2019, 'abstract': None}
{'title': 'Domain Generalization via Model-Agnostic Learning of Semantic Features', 'paperID': '9f93e2de4c24acd3ffb10efae1c849a63830148d', 'arxivId': '1910.13580', 'publication_year': 2019, 'abstract': None}
{'title': 'DistilBERT, a distilled version of BERT: smaller, faster, cheaper and lighter', 'paperID': 'a54b56af24bb4873ed0163b77df63b92bd018ddc', 'arxivId': '1910.01108', 'publication_year': 2019, 'abstract': None}
{'title': 'The stochastic multi-gradient algorithm for multi-objective optimization and its application to supervised machine learning', 'paperID': '6672941010dddfbe3228102e30de02f848930f36', 'arxivId': '1907.04472', 'publication_year': 2019, 'abstract': None}
{'title': 'On Learning Invariant Representations for Domain Adaptation', 'paperID': 'acb9017f0d55ab0e8c8863b0b5dbdb373e4aee7b', 'arxivId': None, 'publication_year': 2019, 'abstract': None}
{'title': 'Fine-Grained Analysis of Optimization and Generalization for Overparameterized Two-Layer Neural Networks', 'paperID': '14558cb69319eed0d5bfc5648aafcd09d882f443', 'arxivId': '1901.08584', 'publication_year': 2019, 'abstract': None}
{'title': 'Learning and Generalization in Overparameterized Neural Networks, Going Beyond Two Layers', 'paperID': '611fe6e34df07ea1b2104899e49642b4531b53e9', 'arxivId': '1811.04918', 'publication_year': 2018, 'abstract': None}
{'title': 'Multi-Task Learning as Multi-Objective Optimization', 'paperID': '2b0d7e51efd004fe3847f54863540c79312f3546', 'arxivId': '1810.04650', 'publication_year': 2018, 'abstract': None}
{'title': 'A Simple Stochastic Variance Reduced Algorithm with Fast Convergence Rates', 'paperID': '42f25f9513a86546a22626d6e1ea3b446c8fc994', 'arxivId': '1806.11027', 'publication_year': 2018, 'abstract': None}
{'title': 'Neural Tangent Kernel: Convergence and Generalization in Neural Networks', 'paperID': '7a84a692327534fd227fa1e07fcb3816b633c591', 'arxivId': '1806.07572', 'publication_year': 2018, 'abstract': None}
{'title': 'Elements of Causal Inference: Foundations and Learning Algorithms', 'paperID': 'e02ae07b45a2241f7ee1180b446ed7ba208c51e8', 'arxivId': None, 'publication_year': 2017, 'abstract': None}
{'title': 'Empirical Analysis of the Hessian of Over-Parametrized Neural Networks', 'paperID': '0528ec31d633d1588a711c41b6adf624442df21f', 'arxivId': '1706.04454', 'publication_year': 2017, 'abstract': None}
{'title': 'Revisiting Distributionally Robust Supervised Learning in Classification', 'paperID': '07b5093aace8e485e7d23b83edb6351618138127', 'arxivId': '1611.02041', 'publication_year': 2016, 'abstract': None}
{'title': 'Invariant Models for Causal Transfer Learning', 'paperID': '1a60d4122ef0ac6972ef9b4a3752ac1657de482c', 'arxivId': None, 'publication_year': 2015, 'abstract': None}
{'title': 'Causal inference by using invariant prediction: identification and confidence intervals', 'paperID': 'a2bf2e83df0c8b3257a8a809cb96c3ea58ec04b3', 'arxivId': '1501.01332', 'publication_year': 2015, 'abstract': None}
{'title': 'Stochastic Optimization with Importance Sampling for Regularized Loss Minimization', 'paperID': '8221da402eb27e415d08d7a5b43517cc0fa2f9f1', 'arxivId': '1401.2753', 'publication_year': 2014, 'abstract': None}
{'title': 'On the importance of initialization and momentum in deep learning', 'paperID': 'aa7bfd2304201afbb19971ebde87b17e40242e91', 'arxivId': None, 'publication_year': 2013, 'abstract': None}
{'title': 'Multiple-gradient descent algorithm (MGDA) for multiobjective optimization', 'paperID': 'b7ef79008d87bce38144b6f1a06e36870e1c2449', 'arxivId': None, 'publication_year': 2012, 'abstract': None}
{'title': 'Nonlinear multiobjective optimization', 'paperID': '844bc70828afab2d5be286934148a62c7a9e51df', 'arxivId': None, 'publication_year': 1998, 'abstract': None}
{'title': 'Causality', 'paperID': 'a0117b72a4f68d0a134e24f674ca7fd0b42663b7', 'arxivId': None, 'publication_year': 1938, 'abstract': None}
{'title': 'Sparse Invariant Risk Minimization', 'paperID': '191bb2e05e943903a05f6862e171f873a681793d', 'arxivId': None, 'publication_year': 2022, 'abstract': None}
{'title': 'ZIN: When and How to Learn Invariance by Environment Inference?', 'paperID': '5a064b89834622e238033a67e0da1f241db1dfe2', 'arxivId': None, 'publication_year': 2022, 'abstract': None}
{'title': "Amortized Nesterov's Momentum: A Robust Momentum and Its Application to Deep Learning", 'paperID': '249348e7da5b91ab09202f401831750cd0eb0a3b', 'arxivId': None, 'publication_year': 2020, 'abstract': None}
{'title': 'Learning Representations Using Causal Invariance', 'paperID': 'acb6f28bbfb2d91832a5e11e734012cd95974976', 'arxivId': None, 'publication_year': 2020, 'abstract': None}
{'title': 'RXRX1: AN IMAGE SET FOR CELLULAR MORPHOLOGICAL VARIATION ACROSS MANY EXPERIMENTAL BATCHES', 'paperID': '046de0df4562625a14998f96601a28475a05e4bb', 'arxivId': None, 'publication_year': 2019, 'abstract': None}
{'title': 'Understanding Machine Learning From Theory to Algorithms 1st Edition Shwartz Solutions Manual', 'paperID': '9dc62fe526f67674512d749ad1880f8eaa5ca3de', 'arxivId': None, 'publication_year': 2015, 'abstract': None}
{'title': 'Gradient-based learning applied to document recognition', 'paperID': '162d958ff885f1462aeda91cd72582323fd6a1f4', 'arxivId': None, 'publication_year': 1998, 'abstract': None}
{'title': 'Pareto Invariant Risk Minimization: Towards Mitigating the Optimization Dilemma in Out-of-Distribution Generalization', 'paperID': '9a7a51cf95e5cb796847ec6d32c0b9ed95f1eec2', 'arxivId': '2206.07766', 'publication_year': '2022', 'abstract': 'Recently, there has been a growing surge of interest in enabling machine learning systems to generalize well to Out-of-Distribution (OOD) data. Most efforts are devoted to advancing optimization objectives that regularize models to capture the underlying invariance; however, there often are compromises in the optimization process of these OOD objectives: i) Many OOD objectives have to be relaxed as penalty terms of Empirical Risk Minimization (ERM) for the ease of optimization, while the relaxed forms can weaken the robustness of the original objective; ii) The penalty terms also require careful tuning of the penalty weights due to the intrinsic conflicts between ERM and OOD objectives. Consequently, these compromises could easily lead to suboptimal performance of either the ERM or OOD objective. To address these issues, we introduce a multi-objective optimization (MOO) perspective to understand the OOD optimization process, and propose a new optimization scheme called PAreto Invariant Risk Minimization (PAIR). PAIR improves the robustness of OOD objectives by cooperatively optimizing with other OOD objectives, thereby bridging the gaps caused by the relaxations. Then PAIR approaches a Pareto optimal solution that trades off the ERM and OOD objectives properly. Extensive experiments on challenging benchmarks, WILDS, show that PAIR alleviates the compromises and yields top OOD performances.'}
{'title': 'Plex: Towards Reliability using Pretrained Large Model Extensions', 'paperID': '9da634823416e96417530f0a2197b9a4936eee3e', 'arxivId': '2207.07411', 'publication_year': 2022, 'abstract': None}
{'title': 'TRUE: Re-evaluating Factual Consistency Evaluation', 'paperID': 'c69f9a5185b4c29525bedb2dcc79d20b42c14cc6', 'arxivId': '2204.04991', 'publication_year': 2022, 'abstract': None}
{'title': 'LaMDA: Language Models for Dialog Applications', 'paperID': 'b3848d32f7294ec708627897833c4097eb4d8778', 'arxivId': '2201.08239', 'publication_year': 2022, 'abstract': None}
{'title': 'PnPOOD : Out-Of-Distribution Detection for Text Classification via Plug andPlay Data Augmentation', 'paperID': '1706a87cf650750df326891b09da53899e85354e', 'arxivId': '2111.00506', 'publication_year': 2021, 'abstract': None}
{'title': 'Learning Compact Metrics for MT', 'paperID': 'dfd104dd0ff28b1bde2fbd4c4d6d3ccb4761f639', 'arxivId': '2110.06341', 'publication_year': 2021, 'abstract': None}
{'title': 'Types of Out-of-Distribution Texts and How to Detect Them', 'paperID': '8331f4363d65235a8344e6a0c9b21fa3ab4c1d5e', 'arxivId': '2109.06827', 'publication_year': 2021, 'abstract': None}
{'title': 'Shifts: A Dataset of Real Distributional Shift Across Multiple Large-Scale Tasks', 'paperID': '3397f25209666d30a8b797932e3197cc826fba18', 'arxivId': '2107.07455', 'publication_year': 2021, 'abstract': None}
{'title': 'Uncertainty Estimation in Autoregressive Structured Prediction', 'paperID': '0921322cf6ea34d1852f13cb67eeac9d1f863518', 'arxivId': None, 'publication_year': 2021, 'abstract': None}
{'title': 'Contrastive Out-of-Distribution Detection for Pretrained Transformers', 'paperID': 'a9b04a3e0cf5766df9b3af8c442f2d85ac5e2c7e', 'arxivId': '2104.08812', 'publication_year': 2021, 'abstract': None}
{'title': 'Deep Deterministic Uncertainty: A New Simple Baseline', 'paperID': '6e84d6788bdd1f99a0ed322cf35ae7b2fb81aa66', 'arxivId': '2102.11582', 'publication_year': 2021, 'abstract': None}
{'title': 'A Unifying Review of Deep and Shallow Anomaly Detection', 'paperID': '30b99ae0682d42a2010be401dd1d8f7baca9bb5f', 'arxivId': '2009.11732', 'publication_year': 2020, 'abstract': None}
{'title': 'COMET: A Neural Framework for MT Evaluation', 'paperID': '9e67b9758520e49016ab66bafb974d2e1ed762d1', 'arxivId': '2009.09025', 'publication_year': 2020, 'abstract': None}
{'title': 'ParaCrawl: Web-Scale Acquisition of Parallel Corpora', 'paperID': '14fc61fdc8f2205ff96ff6dc9c4c881e4063db8c', 'arxivId': None, 'publication_year': 2020, 'abstract': None}
{'title': 'Wat zei je? Detecting Out-of-Distribution Translations with Variational Transformers', 'paperID': '49b477049668505ecc5d74be1f9117437e63d14e', 'arxivId': '2006.08344', 'publication_year': 2020, 'abstract': None}
{'title': 'Simple and Principled Uncertainty Estimation with Deterministic Deep Learning via Distance Awareness', 'paperID': '298f67a9719e74192296fa2428776c46161a256a', 'arxivId': '2006.10108', 'publication_year': 2020, 'abstract': None}
{'title': 'On Faithfulness and Factuality in Abstractive Summarization', 'paperID': 'dbeeca8466e0c177ec67c60d529899232415ca87', 'arxivId': '2005.00661', 'publication_year': 2020, 'abstract': None}
{'title': 'Pretrained Transformers Improve Out-of-Distribution Robustness', 'paperID': '97f08c1ae8ca5ddf5948c66bfbbc0546ac154807', 'arxivId': '2004.06100', 'publication_year': 2020, 'abstract': None}
{'title': 'Automatic Machine Translation Evaluation in Many Languages via Zero-Shot Paraphrasing', 'paperID': '01508f386eb2ca5181fde7bb6da4920e250d7498', 'arxivId': '2004.14564', 'publication_year': 2020, 'abstract': None}
{'title': 'PEGASUS: Pre-training with Extracted Gap-sentences for Abstractive Summarization', 'paperID': 'f4061bd225b3be5b3f5b18eb1a229ce991efefeb', 'arxivId': '1912.08777', 'publication_year': 2019, 'abstract': None}
{'title': 'SAMSum Corpus: A Human-annotated Dialogue Dataset for Abstractive Summarization', 'paperID': 'f9700e31a1d0ae34d4571ab056dfb268c1543349', 'arxivId': '1911.12237', 'publication_year': 2019, 'abstract': None}
{'title': 'Unsupervised Cross-lingual Representation Learning at Scale', 'paperID': '6fec3e579c7cd4f13bdabbee2b6ac2e8ff5941c6', 'arxivId': '1911.02116', 'publication_year': 2019, 'abstract': None}
{'title': 'BART: Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension', 'paperID': '395de0bd3837fdf4b4b5e5f04835bcc69c279481', 'arxivId': '1910.13461', 'publication_year': 2019, 'abstract': None}
{'title': 'Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer', 'paperID': '3cfb319689f06bf04c2e28399361f414ca32c4b3', 'arxivId': '1910.10683', 'publication_year': 2019, 'abstract': None}
{'title': 'Assessing The Factual Accuracy of Generated Text', 'paperID': '8d89f85b5f8a1d65b4e93a7ebb793618641c3ece', 'arxivId': '1905.13322', 'publication_year': 2019, 'abstract': None}
{'title': 'The Curious Case of Neural Text Degeneration', 'paperID': 'cf4aa38ae31b43fd07abe13b4ffdb265babb7be1', 'arxivId': '1904.09751', 'publication_year': 2019, 'abstract': None}
{'title': 'Abstractive Summarization of Reddit Posts with Multi-level Memory Networks', 'paperID': 'a01fb557abc65ec5c37c28ca18298f27aa0dba72', 'arxivId': '1811.00783', 'publication_year': 2018, 'abstract': None}
{'title': 'MTNT: A Testbed for Machine Translation of Noisy Text', 'paperID': 'ce89ee7aaeeea2c9d474707690f3ea9d948776a3', 'arxivId': '1809.00388', 'publication_year': 2018, 'abstract': None}
{'title': 'Don’t Give Me the Details, Just the Summary! Topic-Aware Convolutional Neural Networks for Extreme Summarization', 'paperID': '305b2cf37e5dece81e95c92883d5a6e28ac93b22', 'arxivId': '1808.08745', 'publication_year': 2018, 'abstract': None}
{'title': 'Newsroom: A Dataset of 1.3 Million Summaries with Diverse Extractive Strategies', 'paperID': '4e346eb1628df6a12c1a121f862fb3a16c6fec60', 'arxivId': '1804.11283', 'publication_year': 2018, 'abstract': None}
{'title': 'Adafactor: Adaptive Learning Rates with Sublinear Memory Cost', 'paperID': '54a13bcc9613dcaa76fb25fbe96572f376cfcca9', 'arxivId': '1804.04235', 'publication_year': 2018, 'abstract': None}
{'title': 'Generating Wikipedia by Summarizing Long Sequences', 'paperID': '8691706ad0cf5e83969658b2e6bfffdc379440c9', 'arxivId': '1801.10198', 'publication_year': 2018, 'abstract': None}
{'title': 'Selective Classification for Deep Neural Networks', 'paperID': '2ed7cc027367295b1a7d7cd49406acfa5c580138', 'arxivId': '1705.08500', 'publication_year': 2017, 'abstract': None}
{'title': 'Get To The Point: Summarization with Pointer-Generator Networks', 'paperID': '668db48c6a79826456341680ee1175dfc4cced71', 'arxivId': '1704.04368', 'publication_year': 2017, 'abstract': None}
{'title': "Google's Neural Machine Translation System: Bridging the Gap between Human and Machine Translation", 'paperID': 'c6850869aa5e78a107c378d2e8bfa39633158c0c', 'arxivId': '1609.08144', 'publication_year': 2016, 'abstract': None}
{'title': 'Findings of the 2015 Workshop on Statistical Machine Translation', 'paperID': 'feb420a4ac7c5719d51480053cd3e8669d5f2062', 'arxivId': None, 'publication_year': 2015, 'abstract': None}
{'title': 'Teaching Machines to Read and Comprehend', 'paperID': 'd1505c6123c102e53eb19dff312cb25cea840b72', 'arxivId': '1506.03340', 'publication_year': 2015, 'abstract': None}
{'title': 'Parallel Data, Tools and Interfaces in OPUS', 'paperID': '25ca4a36df2955b345634b5f8a6b6bb66a774b3c', 'arxivId': None, 'publication_year': 2012, 'abstract': None}
{'title': 'Classification with a Reject Option using a Hinge Loss', 'paperID': '595aed9aa694565348794782a3ebf8344ced529a', 'arxivId': None, 'publication_year': 2008, 'abstract': None}
{'title': 'An optimum character recognition system using decision functions', 'paperID': '32d8a10c47096fefe17a68f3166059f172ad094e', 'arxivId': None, 'publication_year': 1957, 'abstract': None}
{'title': 'Towards Collaborative Neural-Symbolic Graph Semantic Parsing via Uncertainty', 'paperID': '3e60cba99b4e8a45f2e3ba3df462ac949a720833', 'arxivId': None, 'publication_year': 2022, 'abstract': None}
{'title': 'Detecting Compositionally Out-of-Distribution Examples in Semantic Parsing', 'paperID': '0b1470014bdbaa80ba63da0491d9db6c7d4febcc', 'arxivId': None, 'publication_year': 2021, 'abstract': None}
{'title': 'ForumSum: A Multi-Speaker Conversation Summarization Dataset', 'paperID': '22e7424448e17e3357e03db73ddf7ce2c39b48f6', 'arxivId': None, 'publication_year': 2021, 'abstract': None}
{'title': 'Results of the WMT21 Metrics Shared Task: Evaluating Metrics with Expert-based Human Evaluations on TED and News Domain', 'paperID': '63aa5073ce839c26b3d505200e5ef78d875f91c0', 'arxivId': None, 'publication_year': 2021, 'abstract': None}
{'title': 'Anomalous Example Detection in Deep Learning: A Survey', 'paperID': '37eb32915b7767685ec3c9e9728ca9a50a379b8d', 'arxivId': None, 'publication_year': 2020, 'abstract': None}
{'title': 'The OPUS Resource Repository: An Open Package for Creating Parallel Corpora and Machine Translation Services', 'paperID': '25890fe723d290ac5d535212b64382e22f8a66f6', 'arxivId': None, 'publication_year': 2019, 'abstract': None}
{'title': 'Language Models are Unsupervised Multitask Learners', 'paperID': '9405cc0d6169988371b2755e573cc28650d14dfe', 'arxivId': None, 'publication_year': 2019, 'abstract': None}
{'title': 'Out-of-Distribution Detection and Selective Generation for Conditional Language Models', 'paperID': '94b6f6822f364cf7b1a3a9984667c009e2ec6a65', 'arxivId': '2209.15558', 'publication_year': '2022', 'abstract': 'Machine learning algorithms typically assume independent and identically distributed samples in training and at test time. Much work has shown that high-performing ML classifiers can degrade significantly and provide overly-confident, wrong classification predictions, particularly for out-of-distribution (OOD) inputs. Conditional language models (CLMs) are predominantly trained to classify the next token in an output sequence, and may suffer even worse degradation on OOD inputs as the prediction is done auto-regressively over many steps. Furthermore, the space of potential low-quality outputs is larger as arbitrary text can be generated and it is important to know when to trust the generated output. We present a highly accurate and lightweight OOD detection method for CLMs, and demonstrate its effectiveness on abstractive summarization and translation. We also show how our method can be used under the common and realistic setting of distribution shift for selective generation (analogous to selective prediction for classification) of high-quality outputs, while automatically abstaining from low-quality ones, enabling safer deployment of generative language models.'}
{'title': 'Achieving Verified Robustness to Symbol Substitutions via Interval Bound Propagation', 'paperID': '07398e448180ad75c44d30f23a65289d40ff6f52', 'arxivId': '1909.01492', 'publication_year': 2019, 'abstract': None}
{'title': 'Certified Robustness to Adversarial Word Substitutions', 'paperID': '4690190d6c110f7525f7250e1acf4a4eab42519f', 'arxivId': '1909.00986', 'publication_year': 2019, 'abstract': None}
{'title': 'Probing Neural Network Comprehension of Natural Language Arguments', 'paperID': 'f3b89e9a2b8ce1b6058e6984c3556bc2dded0938', 'arxivId': '1907.07355', 'publication_year': 2019, 'abstract': None}
{'title': 'Adversarial attacks against Fact Extraction and VERification', 'paperID': '46f055fff654f936e40aeac1a3abb082beab0edc', 'arxivId': '1903.05543', 'publication_year': 2019, 'abstract': None}
{'title': 'Semidefinite relaxations for certifying robustness to adversarial examples', 'paperID': '7ad8c18994108a630c4564400f6137bf4d8b7818', 'arxivId': '1811.01057', 'publication_year': 2018, 'abstract': None}
{'title': 'Excessive Invariance Causes Adversarial Vulnerability', 'paperID': '67b72e427187b1113c787f9265926322e3d123e8', 'arxivId': '1811.00401', 'publication_year': 2018, 'abstract': None}
{'title': 'On the Effectiveness of Interval Bound Propagation for Training Verifiably Robust Models', 'paperID': '43a4a354b67ab6d5531355a368094815d2d2593d', 'arxivId': '1810.12715', 'publication_year': 2018, 'abstract': None}
{'title': 'Adversarial Over-Sensitivity and Over-Stability Strategies for Dialogue Models', 'paperID': '3de72d2b1ead0b9c7af5804252024128312b9cfe', 'arxivId': '1809.02079', 'publication_year': 2018, 'abstract': None}
{'title': 'Adversarially Regularising Neural NLI Models to Integrate Logical Background Knowledge', 'paperID': 'fac1c95993e86f92c7adeec7f72e06503e4190d5', 'arxivId': '1808.08609', 'publication_year': 2018, 'abstract': None}
{'title': 'Differentiable Abstract Interpretation for Provably Robust Neural Networks', 'paperID': '75339d34bdac0d21a41461228ec6088eecdf857a', 'arxivId': None, 'publication_year': 2018, 'abstract': None}
{'title': 'Training verified learners with learned verifiers', 'paperID': '54afe5cde4d4140e728dde299d4d66b2c0eda6da', 'arxivId': '1805.10265', 'publication_year': 2018, 'abstract': None}
{'title': 'Hypothesis Only Baselines in Natural Language Inference', 'paperID': '8c6427cc1f4e1bbe5d6da34a4511842361f4fbb6', 'arxivId': '1805.01042', 'publication_year': 2018, 'abstract': None}
{'title': 'Formal Security Analysis of Neural Networks using Symbolic Intervals', 'paperID': '2410923ed90b099e3f5565b63e789f10bf70ec4c', 'arxivId': '1804.10829', 'publication_year': 2018, 'abstract': None}
{'title': 'Anchors: High-Precision Model-Agnostic Explanations', 'paperID': '1d8f4f76ac6534627ef8a1c24b9937d8ab2a5c5f', 'arxivId': None, 'publication_year': 2018, 'abstract': None}
{'title': 'Towards Fast Computation of Certified Robustness for ReLU Networks', 'paperID': '9db631435f7f79646a4e0a1841fbeb3340e44261', 'arxivId': '1804.09699', 'publication_year': 2018, 'abstract': None}
{'title': 'Generating Natural Language Adversarial Examples', 'paperID': 'c68fbc1f4aa72d30974f8a3071054e3b227137fd', 'arxivId': '1804.07998', 'publication_year': 2018, 'abstract': None}
{'title': 'Pathologies of Neural Models Make Interpretations Difficult', 'paperID': '74e9053d6f44f4507bd40bbea999ee65f0cbefb2', 'arxivId': '1804.07781', 'publication_year': 2018, 'abstract': None}
{'title': 'Adversarial Example Generation with Syntactically Controlled Paraphrase Networks', 'paperID': '2b110fce160468eb179b6c43ea27e098757a56dd', 'arxivId': '1804.06059', 'publication_year': 2018, 'abstract': None}
{'title': 'A Dual Approach to Scalable Verification of Deep Networks', 'paperID': '8d35663a80199b173d8cbd12dbf2300a9f86a021', 'arxivId': '1803.06567', 'publication_year': 2018, 'abstract': None}
{'title': 'Adversarial Risk and the Dangers of Evaluating Against Weak Attacks', 'paperID': 'f4b434c3ab979ecdd71bbed894b34de77590c6dd', 'arxivId': '1802.05666', 'publication_year': 2018, 'abstract': None}
{'title': 'Certified Defenses against Adversarial Examples', 'paperID': '966e3c7a65ec75a6359b55c0cecaf3896d318432', 'arxivId': '1801.09344', 'publication_year': 2018, 'abstract': None}
{'title': 'HotFlip: White-Box Adversarial Examples for Text Classification', 'paperID': '514e7fb769950dbe96eb519c88ca17e04dc829f6', 'arxivId': None, 'publication_year': 2017, 'abstract': None}
{'title': 'Synthetic and Natural Noise Both Break Neural Machine Translation', 'paperID': '765bdcf27ebc1eb03a14f1e47aefa4dda1e03073', 'arxivId': '1711.02173', 'publication_year': 2017, 'abstract': None}
{'title': 'Towards Linguistically Generalizable NLP Systems: A Workshop and Shared Task', 'paperID': '8472e999f723a9ccaffc6089b7be1865d8a1b863', 'arxivId': '1711.01505', 'publication_year': 2017, 'abstract': None}
{'title': 'Provable defenses against adversarial examples via the convex outer adversarial polytope', 'paperID': '4b23012689e0f17912fb38d4984775e567cff8d6', 'arxivId': '1711.00851', 'publication_year': 2017, 'abstract': None}
{'title': 'Piecewise Linear Neural Network verification: A comparative study', 'paperID': '7b8fee37c685d6fd38455e2c06eef988fa86d522', 'arxivId': '1711.00455', 'publication_year': 2017, 'abstract': None}
{'title': 'Generating Natural Adversarial Examples', 'paperID': '3502b5ef1afb16f76bcae33db17179195bbcdaae', 'arxivId': '1710.11342', 'publication_year': 2017, 'abstract': None}
{'title': 'Maximum Resilience of Artificial Neural Networks', 'paperID': '9f92a0ccc8b039a83bd5ba5482facb5829c712aa', 'arxivId': '1705.01040', 'publication_year': 2017, 'abstract': None}
{'title': 'Robust Training under Linguistic Adversity', 'paperID': '73300838d524d062e8341b242765fb6efaf48f43', 'arxivId': None, 'publication_year': 2017, 'abstract': None}
{'title': 'Reluplex: An Efficient SMT Solver for Verifying Deep Neural Networks', 'paperID': 'b0dc598adda48acab590f95a5985fcc7abf2aca9', 'arxivId': '1702.01135', 'publication_year': 2017, 'abstract': None}
{'title': 'Adversarial examples in the physical world', 'paperID': 'b544ca32b66b4c9c69bcfa00d63ee4b799d8ab6b', 'arxivId': '1607.02533', 'publication_year': 2016, 'abstract': None}
{'title': 'A Decomposable Attention Model for Natural Language Inference', 'paperID': '2cd8e8f510c89c7c18268e8ad51c061e459ad321', 'arxivId': '1606.01933', 'publication_year': 2016, 'abstract': None}
{'title': '"Why Should I Trust You?": Explaining the Predictions of Any Classifier', 'paperID': 'e96506ee4baab43fa81cf1870cf7befb4a71fec7', 'arxivId': '1602.04938', 'publication_year': 2016, 'abstract': None}
{'title': 'Reasoning about Entailment with Neural Attention', 'paperID': '2846e83d405cbe3bf2f0f3b5f635dd8b3c680c45', 'arxivId': '1509.06664', 'publication_year': 2015, 'abstract': None}
{'title': 'A large annotated corpus for learning natural language inference', 'paperID': 'f04df4e20a18358ea2f689b4c129781628ef7fc1', 'arxivId': '1508.05326', 'publication_year': 2015, 'abstract': None}
{'title': 'The Third PASCAL Recognizing Textual Entailment Challenge', 'paperID': 'de794d50713ea5f91a7c9da3d72041e2f5ef8452', 'arxivId': None, 'publication_year': 2007, 'abstract': None}
{'title': 'Verification and validation of language processing systems: Is it evaluation?', 'paperID': '908119b1aee9774f3a2ed9ecaf42c441f038178c', 'arxivId': None, 'publication_year': 2001, 'abstract': None}
{'title': 'Towards Verified Robustness under Text Deletion Interventions', 'paperID': 'f9512b7c6129e0243726742cd833532482b2b11b', 'arxivId': None, 'publication_year': '2020', 'abstract': 'Neural networks are widely used in Natural Language Processing, yet despite their empirical successes, their behaviour is brittle: they are both over-sensitive to small input changes, and under-sensitive to deletions of large fractions of input text. This paper aims to tackle under-sensitivity in the context of natural language inference by ensuring that models do not become more confident in their predictions as arbitrary subsets of words from the input text are deleted. We develop a novel technique for formal verification of this specification for models based on the popular decomposable attention mechanism by employing the efficient yet effective interval bound propagation (IBP) approach. Using this method we can efficiently prove, given a model, whether a particular sample is free from the under-sensitivity problem. We compare different training methods to address under-sensitivity, and compare metrics to measure it. In our experiments on the SNLI and MNLI datasets, we observe that IBP training leads to a significantly improved verified accuracy. On the SNLI test set, we can verify 18.4% of samples, a substantial improvement over only 2.8% using standard training.'}
{'title': 'Best Practices for Scientific Research on Neural Architecture Search', 'paperID': '78dbb9334215194020437c2c2cfdfce478f30060', 'arxivId': '1909.02453', 'publication_year': 2019, 'abstract': None}
{'title': 'AutoDispNet: Improving Disparity Estimation With AutoML', 'paperID': '954d607ec77d2893e64105021f6b1010c3dd5e2e', 'arxivId': '1905.07443', 'publication_year': 2019, 'abstract': None}
{'title': 'Evaluating the Search Phase of Neural Architecture Search', 'paperID': '6eb3a62cd365e4f9792eedca43c90595e1a862ba', 'arxivId': '1902.08142', 'publication_year': 2019, 'abstract': None}
{'title': 'Random Search and Reproducibility for Neural Architecture Search', 'paperID': '35a59bd09974c7fc78cf681f77f7301e180fd23c', 'arxivId': '1902.07638', 'publication_year': 2019, 'abstract': None}
{'title': 'Probabilistic Neural Architecture Search', 'paperID': '6beadd6d5191e5546d1334d0a2f1d8bd1ab80e30', 'arxivId': '1902.05116', 'publication_year': 2019, 'abstract': None}
{'title': 'Aging Evolution for Image Classifier Architecture Search', 'paperID': '7bac3d11824fabe0dc3ac2fee9bfb667e82fba9c', 'arxivId': None, 'publication_year': 2019, 'abstract': None}
{'title': 'Auto-DeepLab: Hierarchical Neural Architecture Search for Semantic Image Segmentation', 'paperID': 'f4838839719cf96951ade45a221700341f57c4d7', 'arxivId': '1901.02985', 'publication_year': 2019, 'abstract': None}
{'title': 'Stable Bayesian optimization', 'paperID': '40fa2e2a58c0245a35fb363e6694d978ef51adb2', 'arxivId': None, 'publication_year': 2018, 'abstract': None}
{'title': 'ProxylessNAS: Direct Neural Architecture Search on Target Task and Hardware', 'paperID': 'f323407464c4cd492d3fc1afd7170eab08f44d9b', 'arxivId': '1812.00332', 'publication_year': 2018, 'abstract': None}
{'title': 'SNAS: Stochastic Neural Architecture Search', 'paperID': '3f0a2de309f21a957b4741dd68007eb08d9b12e3', 'arxivId': '1812.09926', 'publication_year': 2018, 'abstract': None}
{'title': 'Towards Automated Deep Learning: Efficient Joint Neural Architecture and Hyperparameter Search', 'paperID': 'b9e942942306d1d4b7a5640d8ed3c0cdcdc34078', 'arxivId': '1807.06906', 'publication_year': 2018, 'abstract': None}
{'title': 'BOHB: Robust and Efficient Hyperparameter Optimization at Scale', 'paperID': '93436a26d744e0417e21df10abdfce2cc74b1e58', 'arxivId': '1807.01774', 'publication_year': 2018, 'abstract': None}
{'title': 'Understanding and Simplifying One-Shot Architecture Search', 'paperID': '45b7b5514a65126d39a51d5a68da53e7aa244c1f', 'arxivId': None, 'publication_year': 2018, 'abstract': None}
{'title': 'DARTS: Differentiable Architecture Search', 'paperID': 'c1f457e31b611da727f9aef76c283a18157dfa83', 'arxivId': '1806.09055', 'publication_year': 2018, 'abstract': None}
{'title': 'Bilevel Programming for Hyperparameter Optimization and Meta-Learning', 'paperID': '15561ab20c298e113b0008b7a029486a422e7ca3', 'arxivId': '1806.04910', 'publication_year': 2018, 'abstract': None}
{'title': 'Path-Level Network Transformation for Efficient Architecture Search', 'paperID': 'dcc808993310a8a64fdd5efa9e46d0022ff12c27', 'arxivId': '1806.02639', 'publication_year': 2018, 'abstract': None}
{'title': 'Efficient Multi-Objective Neural Architecture Search via Lamarckian Evolution', 'paperID': '3662def6e3909868f92461694a586a626e725416', 'arxivId': '1804.09081', 'publication_year': 2018, 'abstract': None}
{'title': 'Hessian-based Analysis of Large Batch Training and Robustness to Adversaries', 'paperID': 'f322a04e51e50a5896a2d28da0beba12a0a49d1b', 'arxivId': '1802.08241', 'publication_year': 2018, 'abstract': None}
{'title': 'Efficient Neural Architecture Search via Parameter Sharing', 'paperID': 'fe9b8aac9fa3bfd9724db5a881a578e471e612d7', 'arxivId': '1802.03268', 'publication_year': 2018, 'abstract': None}
{'title': 'On Optimal Generalizability in Parametric Learning', 'paperID': 'c7ec956cb69ee85269067bdaa3c06a8aa63f04ac', 'arxivId': '1711.05323', 'publication_year': 2017, 'abstract': None}
{'title': 'Simple And Efficient Architecture Search for Convolutional Neural Networks', 'paperID': '0e0ee672ebd9ec0019c414d1c0524f3bb888dd6d', 'arxivId': '1711.04528', 'publication_year': 2017, 'abstract': None}
{'title': 'Hierarchical Representations for Efficient Architecture Search', 'paperID': '856451974cce2d353d5d8a5a72104984a252375c', 'arxivId': '1711.00436', 'publication_year': 2017, 'abstract': None}
{'title': 'Practical Block-Wise Neural Network Architecture Generation', 'paperID': '8a1ce657dd41a4f49990a4769000dc8049b83404', 'arxivId': None, 'publication_year': 2017, 'abstract': None}
{'title': 'Improved Regularization of Convolutional Neural Networks with Cutout', 'paperID': 'eb35fdc11a325f21a8ce0ca65058f7480a2fc91f', 'arxivId': '1708.04552', 'publication_year': 2017, 'abstract': None}
{'title': 'Learning Transferable Architectures for Scalable Image Recognition', 'paperID': 'd0611891b9e8a7c5731146097b6f201578f47b2f', 'arxivId': '1707.07012', 'publication_year': 2017, 'abstract': None}
{'title': 'Efficient Architecture Search by Network Transformation', 'paperID': '84e65a5bdb735d62eef4f72c2f01af354b2285ba', 'arxivId': None, 'publication_year': 2017, 'abstract': None}
{'title': 'Accelerating Neural Architecture Search using Performance Prediction', 'paperID': '2cad68ca9cea089324b67ed96b1175f7a655c521', 'arxivId': None, 'publication_year': 2017, 'abstract': None}
{'title': 'Forward and Reverse Gradient-Based Hyperparameter Optimization', 'paperID': 'ecc76c03d6a3ae4233097ef8bcc9d04d8b3c9bec', 'arxivId': '1703.01785', 'publication_year': 2017, 'abstract': None}
{'title': 'Large-Scale Evolution of Image Classifiers', 'paperID': 'f108b65fe0003e387e1cd7e50f537af0531818e4', 'arxivId': '1703.01041', 'publication_year': 2017, 'abstract': None}
{'title': 'Evolving Deep Neural Networks', 'paperID': '0359739027d44f2baa0ae7e99fca8e3400b8181f', 'arxivId': '1703.00548', 'publication_year': 2017, 'abstract': None}
{'title': 'Entropy-SGD: biasing gradient descent into wide valleys', 'paperID': 'b6583fe9c9dc52bb129aff4cefc60519349f3b4c', 'arxivId': '1611.01838', 'publication_year': 2016, 'abstract': None}
{'title': 'Designing Neural Network Architectures using Reinforcement Learning', 'paperID': '6cd5dfccd9f52538b19a415e00031d0ee4e5b181', 'arxivId': '1611.02167', 'publication_year': 2016, 'abstract': None}
{'title': 'Neural Architecture Search with Reinforcement Learning', 'paperID': '67d968c7450878190e45ac7886746de867bf673d', 'arxivId': '1611.01578', 'publication_year': 2016, 'abstract': None}
{'title': 'Hyperband: Bandit-Based Configuration Evaluation for Hyperparameter Optimization', 'paperID': '04fe6b11280c79b91c060934be66856877e532c6', 'arxivId': None, 'publication_year': 2016, 'abstract': None}
{'title': 'On Large-Batch Training for Deep Learning: Generalization Gap and Sharp Minima', 'paperID': '8ec5896b4490c6e127d1718ffc36a3439d84cb81', 'arxivId': '1609.04836', 'publication_year': 2016, 'abstract': None}
{'title': 'Convolutional Neural Fabrics', 'paperID': '197c8988ef21d0b58d363c21bafe1900c3089e3e', 'arxivId': '1606.02492', 'publication_year': 2016, 'abstract': None}
{'title': 'Hyperparameter optimization with approximate gradient', 'paperID': '66edb2a8d33db2d133d3a3c8c032a06a95c6cd3b', 'arxivId': '1602.02355', 'publication_year': 2016, 'abstract': None}
{'title': 'A Large Dataset to Train Convolutional Networks for Disparity, Optical Flow, and Scene Flow Estimation', 'paperID': '1ced31e02234bc3d1092ffb2c7442ffbd51cb309', 'arxivId': '1512.02134', 'publication_year': 2015, 'abstract': None}
{'title': 'FlowNet: Learning Optical Flow with Convolutional Networks', 'paperID': 'c2fb5b39428818d7ec8cc78e152e19c21b7db568', 'arxivId': '1504.06852', 'publication_year': 2015, 'abstract': None}
{'title': 'Gradient-based Hyperparameter Optimization through Reversible Learning', 'paperID': 'e2820bffe5b42cb7d88b7f65c12171c62ab4aae2', 'arxivId': '1502.03492', 'publication_year': 2015, 'abstract': None}
{'title': 'A Naturalistic Open Source Movie for Optical Flow Evaluation', 'paperID': '7d53f0c87c8ab0de6f3e74515e3ffaf3fab40c62', 'arxivId': None, 'publication_year': 2012, 'abstract': None}
{'title': 'Generic Methods for Optimization-Based Modeling', 'paperID': '5b0a44014c24f9b584904bf223530a3b9fa9853f', 'arxivId': None, 'publication_year': 2012, 'abstract': None}
{'title': 'An overview of bilevel optimization', 'paperID': '6609c558425c9e1848944049c6e302c69eeb2842', 'arxivId': None, 'publication_year': 2007, 'abstract': None}
{'title': 'Evolving Neural Networks through Augmenting Topologies', 'paperID': 'd03c916d49268d48fde3b76a68e64af7761835e7', 'arxivId': None, 'publication_year': 2002, 'abstract': None}
{'title': 'Gradient-Based Optimization of Hyperparameters', 'paperID': 'e5ca0f1d79a5245ee5ddf6af80c01829bcac7340', 'arxivId': None, 'publication_year': 2000, 'abstract': None}
{'title': 'New Branch-and-Bound Rules for Linear Bilevel Programming', 'paperID': '6b61cbbdce584fe8ee97184d8abb416daf96721a', 'arxivId': None, 'publication_year': 1989, 'abstract': None}
{'title': 'Flat Minima', 'paperID': 'f91154c0d159a3f2dd3638915db32c5914544273', 'arxivId': None, 'publication_year': 1997, 'abstract': None}
{'title': 'Understanding and Robustifying Differentiable Architecture Search', 'paperID': '3242bf8767179c13c7322ccfdbe18c66c1e25a99', 'arxivId': '1909.09656', 'publication_year': '2019', 'abstract': 'Differentiable Architecture Search (DARTS) has attracted a lot of attention due to its simplicity and small search costs achieved by a continuous relaxation and an approximation of the resulting bi-level optimization problem. However, DARTS does not work robustly for new problems: we identify a wide range of search spaces for which DARTS yields degenerate architectures with very poor test performance. We study this failure mode and show that, while DARTS successfully minimizes validation loss, the found solutions generalize poorly when they coincide with high validation loss curvature in the architecture space. We show that by adding one of various types of regularization we can robustify DARTS to find solutions with less curvature and better generalization properties. Based on these observations, we propose several simple variations of DARTS that perform substantially more robustly in practice. Our observations are robust across five search spaces on three image classification tasks and also hold for the very different domains of disparity estimation (a dense regression task) and language modelling.'}
{'title': 'Learning Representations by Maximizing Mutual Information in Variational Autoencoders', 'paperID': 'd55902d896a1a890e8f5cf1be4768c5bf0d74ec2', 'arxivId': '1912.13361', 'publication_year': 2019, 'abstract': None}
{'title': 'On Mutual Information Maximization for Representation Learning', 'paperID': '41fcef711faca9013fd0980a9f6ec1d23c9c76c8', 'arxivId': '1907.13625', 'publication_year': 2019, 'abstract': None}
{'title': 'Learning Representations by Maximizing Mutual Information Across Views', 'paperID': '9b09d296059909490096e34e9df2d95314787ad5', 'arxivId': '1906.00910', 'publication_year': 2019, 'abstract': None}
{'title': 'Data-Efficient Image Recognition with Contrastive Predictive Coding', 'paperID': '1cae417456711c4da184f5efcd1b7464a7a0661a', 'arxivId': '1905.09272', 'publication_year': 2019, 'abstract': None}
{'title': 'On Variational Bounds of Mutual Information', 'paperID': '4aea3547974399a32d7aa7c007b10bd665e93fab', 'arxivId': '1905.06922', 'publication_year': 2019, 'abstract': None}
{'title': 'Semantically Tied Paired Cycle Consistency for Zero-Shot Sketch-Based Image Retrieval', 'paperID': '96112f58cae6cbb85528ab1cb01550d106dc4ae8', 'arxivId': '1903.03372', 'publication_year': 2019, 'abstract': None}
{'title': 'Probabilistic symmetry and invariant neural networks', 'paperID': 'fa7af221e7773033fed816f0fe29209cb4ed4283', 'arxivId': '1901.06082', 'publication_year': 2019, 'abstract': None}
{'title': 'Formal Limitations on the Measurement of Mutual Information', 'paperID': '2b2cf76246466c266f9c9fe9bbfd43d918514e55', 'arxivId': '1811.04251', 'publication_year': 2018, 'abstract': None}
{'title': 'Generative Domain-Migration Hashing for Sketch-to-Image Retrieval', 'paperID': '77be85f6c3c465ef8e17d3ec6251794cf4ff5940', 'arxivId': None, 'publication_year': 2018, 'abstract': None}
{'title': 'Learning deep representations by mutual information estimation and maximization', 'paperID': 'af3825437b627db1a99f946f7aa773ba8b03befd', 'arxivId': '1808.06670', 'publication_year': 2018, 'abstract': None}
{'title': 'Invariant Information Clustering for Unsupervised Image Classification and Segmentation', 'paperID': '787c11692e202173367929af6a96f4ccdcdbd2e7', 'arxivId': '1807.06653', 'publication_year': 2018, 'abstract': None}
{'title': 'Understanding disentangling in β-VAE', 'paperID': '287547fc81364e64d196abb8d891ade3f6599a5a', 'arxivId': '1804.03599', 'publication_year': 2018, 'abstract': None}
{'title': 'MINE: Mutual Information Neural Estimation', 'paperID': 'bb17ff968ae1dbd772ac337f469d1ca915cb4c03', 'arxivId': None, 'publication_year': 2018, 'abstract': None}
{'title': 'Fixing a Broken ELBO', 'paperID': '8976e91ccae57a20c29f3c9d88bf45b19973c952', 'arxivId': None, 'publication_year': 2017, 'abstract': None}
{'title': 'Multi-view learning overview: Recent progress and new challenges', 'paperID': '9206cca6ced47353cf11f524c68d432d8496e171', 'arxivId': None, 'publication_year': 2017, 'abstract': None}
{'title': 'Emergence of Invariance and Disentanglement in Deep Representations', 'paperID': '4d7574c0c4aca70e5811a8e33906f0106d6b76e6', 'arxivId': None, 'publication_year': 2017, 'abstract': None}
{'title': 'VAE with a VampPrior', 'paperID': '5ea2cdab68c69d7aef5a004495783ae7628193f2', 'arxivId': '1705.07120', 'publication_year': 2017, 'abstract': None}
{'title': 'Deep Sketch Hashing: Fast Free-Hand Sketch-Based Image Retrieval', 'paperID': '69569f5d9fa03f410f5e83299e974ad683523cdc', 'arxivId': '1703.05605', 'publication_year': 2017, 'abstract': None}
{'title': 'Variational Lossy Autoencoder', 'paperID': '590c9a1ff422b03477f7830b20609f212c85aa13', 'arxivId': '1611.02731', 'publication_year': 2016, 'abstract': None}
{'title': 'PixelVAE: A Latent Variable Model for Natural Images', 'paperID': '42e9055ec712ec9c7f0a79d963ea034a72dc7fa8', 'arxivId': '1611.05013', 'publication_year': 2016, 'abstract': None}
{'title': 'Deep Variational Canonical Correlation Analysis', 'paperID': 'fa3e6f9361d75b9ccbad9baeec1e9025c2b0f6db', 'arxivId': '1610.03454', 'publication_year': 2016, 'abstract': None}
{'title': 'Sketch-based image retrieval via Siamese convolutional neural network', 'paperID': 'e8db8b3ae77c09e0b882560b06fbfb4b4690792e', 'arxivId': None, 'publication_year': 2016, 'abstract': None}
{'title': 'Improved Variational Inference with Inverse Autoregressive Flow', 'paperID': '6a97d2668187965743d1b825b306defccbabbb4c', 'arxivId': '1606.04934', 'publication_year': 2016, 'abstract': None}
{'title': 'A Relationship between the Average Precision and the Area Under the ROC Curve', 'paperID': '9aea99b194a3473829cef62d71ec466a09cb462e', 'arxivId': None, 'publication_year': 2015, 'abstract': None}
{'title': 'Variational Inference with Normalizing Flows', 'paperID': '0f899b92b7fb03b609fee887e4b6f3b633eaf30d', 'arxivId': '1505.05770', 'publication_year': 2015, 'abstract': None}
{'title': 'Deep learning and the information bottleneck principle', 'paperID': '415229903f91a1f3fc7404f5e5997fde025c221d', 'arxivId': '1503.02406', 'publication_year': 2015, 'abstract': None}
{'title': 'Sketch-a-Net that Beats Humans', 'paperID': 'e40f36cea9a7620165543d5c77a3b898dbd83b7f', 'arxivId': None, 'publication_year': 2015, 'abstract': None}
{'title': 'Improved Multimodal Deep Learning with Variation of Information', 'paperID': '64bfeb1ddd35838706e4fffc469234cc2f215631', 'arxivId': None, 'publication_year': 2014, 'abstract': None}
{'title': 'Multilingual Distributed Representations without Word Alignment', 'paperID': 'c20ed3a1600122e6cf03b8ed74d3d2920ad0a8c6', 'arxivId': '1312.6173', 'publication_year': 2013, 'abstract': None}
{'title': 'Iterative Quantization: A Procrustean Approach to Learning Binary Codes for Large-Scale Image Retrieval', 'paperID': 'b3f09ea2a8cc1d82c2b27d71dd8f7451d178beaf', 'arxivId': None, 'publication_year': 2013, 'abstract': None}
{'title': 'Deep Canonical Correlation Analysis', 'paperID': 'e2257e3f56ccb12875a57bc0a8cca1d9d7e93ec6', 'arxivId': None, 'publication_year': 2013, 'abstract': None}
{'title': 'Multimodal learning with deep Boltzmann machines', 'paperID': '5726c7b40fcc454b77d989656c085520bf6c15fa', 'arxivId': None, 'publication_year': 2012, 'abstract': None}
{'title': 'How do humans sketch objects?', 'paperID': '56ac97a7d53702a0941c7bdebe41c682d9831627', 'arxivId': None, 'publication_year': 2012, 'abstract': None}
{'title': 'Multimodal Deep Learning', 'paperID': '80e9e3fc3670482c1fee16b2542061b779f47c4f', 'arxivId': None, 'publication_year': 2011, 'abstract': None}
{'title': 'The MIR flickr retrieval evaluation', 'paperID': 'f79131806747fce087d0fe73d0867cc621547b2a', 'arxivId': None, 'publication_year': 2008, 'abstract': None}
{'title': 'Estimating Divergence Functionals and the Likelihood Ratio by Convex Risk Minimization', 'paperID': 'e0293e4a293ff1a0137c6fcfd3be3274c16b9959', 'arxivId': '0809.0853', 'publication_year': 2008, 'abstract': None}
{'title': 'The IM algorithm: a variational approach to Information Maximization', 'paperID': 'aae4efb3d412d585ea0dec03f933397c93caf989', 'arxivId': None, 'publication_year': 2003, 'abstract': None}
{'title': 'The information bottleneck method', 'paperID': 'c76c62c5ab6c076a80f925d277ef04dd36f6bf9c', 'arxivId': 'physics/0004057', 'publication_year': 2000, 'abstract': None}
{'title': 'Self-organization in a perceptual network', 'paperID': '16d70e8af45ca0ae2c1bb73f3be6628518d40b8f', 'arxivId': None, 'publication_year': 1988, 'abstract': None}
{'title': 'Deep Multi-view Information Bottleneck', 'paperID': '3121c41844faf48bbf61cb037d36045742f04091', 'arxivId': None, 'publication_year': 2019, 'abstract': None}
{'title': 'Deep Variational Information Bottleneck', 'paperID': 'a181fb5a42ad8fe2cc27b5542fa40384e9a8d72c', 'arxivId': '1612.00410', 'publication_year': 2017, 'abstract': None}
{'title': 'Deep Learning', 'paperID': '4f8d648c52edf74e41b0996128aa536e13cc7e82', 'arxivId': None, 'publication_year': 2016, 'abstract': None}
{'title': 'Learning Robust Representations via Multi-View Information Bottleneck', 'paperID': '4bf832104a47c380eb4413b20a9d5bf06649684f', 'arxivId': '2002.07017', 'publication_year': '2020', 'abstract': 'The information bottleneck method provides an information-theoretic view of representation learning. The original formulation, however, can only be applied in the supervised setting where task-specific labels are available at learning time. We extend this method to the unsupervised setting, by taking advantage of multi-view data, which provides two views of the same underlying entity. A theoretical analysis leads to the definition of a new multi-view model which produces state-of-the-art results on two standard multi-view datasets, Sketchy and MIR-Flickr. We also extend our theory to the single-view setting by taking advantage of standard data augmentation techniques, empirically showing better generalization capabilities when compared to traditional unsupervised approaches.'}
{'title': 'An Empirical Study on Learning Fairness Metrics for COMPAS Data with Human Supervision', 'paperID': '8d4e3ec650e8509f2ff001462f53064a3071c86a', 'arxivId': '1910.10255', 'publication_year': 2019, 'abstract': None}
{'title': 'Debiasing Embeddings for Reduced Gender Bias in Text Classification', 'paperID': 'f397df630e0708d411e76309b85f56440b853b86', 'arxivId': '1908.02810', 'publication_year': 2019, 'abstract': None}
{'title': 'Wasserstein Fair Classification', 'paperID': 'f7f5a101985e66c7440deb9286f7c4602294f29b', 'arxivId': '1907.12059', 'publication_year': 2019, 'abstract': None}
{'title': 'Metric Learning for Individual Fairness', 'paperID': '2c59645915e054d4434f2e2e007ce82a8c65b55a', 'arxivId': '1906.00250', 'publication_year': 2019, 'abstract': None}
{'title': 'Bias in Bios: A Case Study of Semantic Representation Bias in a High-Stakes Setting', 'paperID': 'c4afa2b3eda95a1194313394901e0e96e24cefaa', 'arxivId': '1901.09451', 'publication_year': 2019, 'abstract': None}
{'title': 'AI Fairness 360: An Extensible Toolkit for Detecting, Understanding, and Mitigating Unwanted Algorithmic Bias', 'paperID': 'c8541b1dc813f3a638d7acc79e5f972e77f3c5a7', 'arxivId': '1810.01943', 'publication_year': 2018, 'abstract': None}
{'title': 'Counterfactual Fairness in Text Classification through Robustness', 'paperID': '70e28eb8ee40cf5caa704ac7f87940c0818ba28e', 'arxivId': '1809.10610', 'publication_year': 2018, 'abstract': None}
{'title': 'The Measure and Mismeasure of Fairness: A Critical Review of Fair Machine Learning', 'paperID': 'acd6de3ac2a3d9449aae51b87fbb03f6f0020954', 'arxivId': None, 'publication_year': 2018, 'abstract': None}
{'title': 'Learning Adversarially Fair and Transferable Representations', 'paperID': 'c657b3fc93a24349117bf87296ea2b9b780706cc', 'arxivId': '1802.06309', 'publication_year': 2018, 'abstract': None}
{'title': 'On conditional parity as a notion of non-discrimination in machine learning', 'paperID': '567e1d6f83f792f5532a60a020c5f22ac39ecf99', 'arxivId': '1706.08519', 'publication_year': 2017, 'abstract': None}
{'title': 'Minimax Statistical Learning with Wasserstein distances', 'paperID': 'f7c0b4333f914546b144ba15ea38d0e8f29bb622', 'arxivId': None, 'publication_year': 2017, 'abstract': None}
{'title': 'Adversarial Machine Learning at Scale', 'paperID': 'e2a85a6766b982ff7c8980e57ca6342d22493827', 'arxivId': '1611.01236', 'publication_year': 2016, 'abstract': None}
{'title': 'Fair prediction with disparate impact: A study of bias in recidivism prediction instruments', 'paperID': '37f5d47019f467c74acff22a38ffd4b98bdcb5d4', 'arxivId': '1610.07524', 'publication_year': 2016, 'abstract': None}
{'title': 'Robust Wasserstein profile inference and applications to machine learning', 'paperID': '352056cf4cf7e44fb8ebf863c4b632b759a39344', 'arxivId': '1610.05627', 'publication_year': 2016, 'abstract': None}
{'title': 'Variance-based Regularization with Convex Objectives', 'paperID': '6e77765dd3250fc671c413b44554087bad43ad92', 'arxivId': '1610.02581', 'publication_year': 2016, 'abstract': None}
{'title': 'Inherent Trade-Offs in the Fair Determination of Risk Scores', 'paperID': 'ed6297433cfc580837e87592f550cc96296c7d0a', 'arxivId': '1609.05807', 'publication_year': 2016, 'abstract': None}
{'title': 'Semantics derived automatically from language corpora contain human-like biases', 'paperID': '5966d7c7f60898d610812e24c64d4d57855ad86a', 'arxivId': '1608.07187', 'publication_year': 2016, 'abstract': None}
{'title': 'Man is to Computer Programmer as Woman is to Homemaker? Debiasing Word Embeddings', 'paperID': 'ccf6a69a7f33bcf052aa7def176d3b9de495beb7', 'arxivId': '1607.06520', 'publication_year': 2016, 'abstract': None}
{'title': 'Quantifying Distributional Model Risk Via Optimal Transport', 'paperID': 'f701b58e41d928cdcd8d733b638fd65a73623b72', 'arxivId': '1604.01446', 'publication_year': 2016, 'abstract': None}
{'title': 'Quantifying uncertainty in sample average approximation', 'paperID': '8a344f58fbb83871bf3e46b110557b645bdee862', 'arxivId': None, 'publication_year': 2015, 'abstract': None}
{'title': 'The Limitations of Deep Learning in Adversarial Settings', 'paperID': '819167ace2f0caae7745d2f25a803979be5fbfae', 'arxivId': '1511.07528', 'publication_year': 2015, 'abstract': None}
{'title': 'Censoring Representations with an Adversary', 'paperID': '86c37cd1109ce5b465116695b7705444a45185cf', 'arxivId': '1511.05897', 'publication_year': 2015, 'abstract': None}
{'title': 'Distributionally Robust Logistic Regression', 'paperID': '51dcc0c6c8ea27f0a5a3071fb8c4b32004cd55d8', 'arxivId': '1509.09259', 'publication_year': 2015, 'abstract': None}
{'title': 'Distributional Smoothing with Virtual Adversarial Training', 'paperID': 'd450b0f12ae0437048e4047a630c31d902002d0c', 'arxivId': '1507.00677', 'publication_year': 2015, 'abstract': None}
{'title': 'Data-driven distributionally robust optimization using the Wasserstein metric: performance guarantees and tractable reformulations', 'paperID': '948dfbb55a93aa9585056a4b4dd3cd6553b236a9', 'arxivId': '1505.05116', 'publication_year': 2015, 'abstract': None}
{'title': 'GloVe: Global Vectors for Word Representation', 'paperID': 'f37e1b62a767a307c046404ca96bc140b3e68cb5', 'arxivId': None, 'publication_year': 2014, 'abstract': None}
{'title': 'Fairness through awareness', 'paperID': 'adaa0523a5c9d5f92aa2009a51226391d8e62380', 'arxivId': '1104.3913', 'publication_year': 2011, 'abstract': None}
{'title': 'Distributionally Robust Optimization and Its Tractable Approximations', 'paperID': '43ed402570125c14cb2cbd1d158a55a1cebd0248', 'arxivId': None, 'publication_year': 2010, 'abstract': None}
{'title': 'A Robust Optimization Perspective on Stochastic Programming', 'paperID': '42810f584d17fc7c355bec2d35caf5fc1b13f0a7', 'arxivId': None, 'publication_year': 2007, 'abstract': None}
{'title': 'Mining and summarizing customer reviews', 'paperID': 'cdcf7cb29f37ac0546961ea8a076075b9cc1f992', 'arxivId': None, 'publication_year': 2004, 'abstract': None}
{'title': "Big Data's Disparate Impact", 'paperID': '1d174f0e3c391368d0f3384a144a6c7487f2a143', 'arxivId': None, 'publication_year': 2016, 'abstract': None}
{'title': 'Training individually fair ML models with sensitive subspace robustness', 'paperID': 'b1e6716d068ee0d98aa213ad496ec189c10f9250', 'arxivId': '1907.00020', 'publication_year': '2019', 'abstract': 'We propose an approach to training machine learning models that are fair in the sense that their performance is invariant under certain perturbations to the features. For example, the performance of a resume screening system should be invariant under changes to the name of the applicant. We formalize this intuitive notion of fairness by connecting it to the original notion of individual fairness put forth by Dwork et al and show that the proposed approach achieves this notion of fairness. We also demonstrate the effectiveness of the approach on two machine learning tasks that are susceptible to gender and racial biases.'}
{'title': 'An Empirical Evaluation on Robustness and Uncertainty of Regularization Methods', 'paperID': '2ce8e6bf9687a479f4aa8858e0e4a75e4885c143', 'arxivId': '2003.03879', 'publication_year': 2020, 'abstract': None}
{'title': "A Discussion of 'Adversarial Examples Are Not Bugs, They Are Features': Adversarial Example Researchers Need to Expand What is Meant by 'Robustness'", 'paperID': 'cccc4fa0dba2eb11cecb382f0ffea8289263af84', 'arxivId': None, 'publication_year': 2019, 'abstract': None}
{'title': 'A Fourier Perspective on Model Robustness in Computer Vision', 'paperID': '934d7bffdba0b560a80a518b99a791a16b3e198c', 'arxivId': '1906.08988', 'publication_year': 2019, 'abstract': None}
{'title': 'Improving Robustness Without Sacrificing Accuracy with Patch Gaussian Augmentation', 'paperID': 'c703618d1f97a2d2184a09bbd73520034a19ef56', 'arxivId': '1906.02611', 'publication_year': 2019, 'abstract': None}
{'title': 'Adversarial Training Can Hurt Generalization', 'paperID': 'c3d846a3c51dc6423381257b95a4b821e778dce0', 'arxivId': '1906.06032', 'publication_year': 2019, 'abstract': None}
{'title': 'Unsupervised Data Augmentation', 'paperID': '3562fefb64cd63ac1a6a0adbaa83ae73dd674243', 'arxivId': None, 'publication_year': 2019, 'abstract': None}
{'title': 'Making Convolutional Networks Shift-Invariant Again', 'paperID': '8c92054c26fb4c6dd7435bc99fbb8af3323eae1b', 'arxivId': '1904.11486', 'publication_year': 2019, 'abstract': None}
{'title': 'Using Videos to Evaluate Image Model Robustness', 'paperID': '9b2dba32fa1837216602259a707637ca54c6575c', 'arxivId': '1904.10076', 'publication_year': 2019, 'abstract': None}
{'title': 'Data Augmentation Using Random Image Cropping and Patching for Deep CNNs', 'paperID': '1f5066018662b7c7d13a57611e6f118b2871d39f', 'arxivId': '1811.09030', 'publication_year': 2018, 'abstract': None}
{'title': 'MixUp as Locally Linear Out-Of-Manifold Regularization', 'paperID': 'd3eef9744324abc397c82b112b026aad3ec56708', 'arxivId': '1809.02499', 'publication_year': 2018, 'abstract': None}
{'title': 'Evaluating and Understanding the Robustness of Adversarial Logit Pairing', 'paperID': '6effa092456e30e7e54954fd28b755e0a75b52b8', 'arxivId': '1807.10272', 'publication_year': 2018, 'abstract': None}
{'title': 'Motivating the Rules of the Game for Adversarial Example Research', 'paperID': '18063ed998c99bfef92fad8418610b97f863d878', 'arxivId': '1807.06732', 'publication_year': 2018, 'abstract': None}
{'title': 'Why do deep convolutional networks generalize so poorly to small image transformations?', 'paperID': '6f4afaa1ec7528c59aba86def531df6c524229b2', 'arxivId': '1805.12177', 'publication_year': 2018, 'abstract': None}
{'title': 'AutoAugment: Learning Augmentation Policies from Data', 'paperID': 'f723eb3e7159f07b97464c8d947d15e78612abe4', 'arxivId': '1805.09501', 'publication_year': 2018, 'abstract': None}
{'title': 'Detecting and Correcting for Label Shift with Black Box Predictors', 'paperID': '80ef8b8a1284790e0d8f7cbf9727c9e0b2a89332', 'arxivId': '1802.03916', 'publication_year': 2018, 'abstract': None}
{'title': 'Between-Class Learning for Image Classification', 'paperID': 'e41bbabd84bfbce6ef66825c1a2d7eb869bd1202', 'arxivId': '1711.10284', 'publication_year': 2017, 'abstract': None}
{'title': 'Random Erasing Data Augmentation', 'paperID': '2788a2461ed0067e2f7aaa63c449a24a237ec341', 'arxivId': '1708.04896', 'publication_year': 2017, 'abstract': None}
{'title': 'Accurate, Large Minibatch SGD: Training ImageNet in 1 Hour', 'paperID': '0d57ba12a6d958e178d83be4c84513f7e42b24e5', 'arxivId': '1706.02677', 'publication_year': 2017, 'abstract': None}
{'title': 'Examining the Impact of Blur on Recognition by Convolutional Networks', 'paperID': 'a93ddecb919b50f6072ae6447430786e002d4857', 'arxivId': '1611.05760', 'publication_year': 2016, 'abstract': None}
{'title': 'Aggregated Residual Transformations for Deep Neural Networks', 'paperID': 'f6e0856b4a9199fa968ac00da612a9407b5cb85c', 'arxivId': '1611.05431', 'publication_year': 2016, 'abstract': None}
{'title': 'Improving the Robustness of Deep Neural Networks via Stability Training', 'paperID': 'a573ecb0960d0d2c115c0ad3fc971aa6cdb578eb', 'arxivId': '1604.04326', 'publication_year': 2016, 'abstract': None}
{'title': 'Weight Normalization: A Simple Reparameterization to Accelerate Training of Deep Neural Networks', 'paperID': '3d2c6941a9b4608ba52b328369a3352db2092ae0', 'arxivId': '1602.07868', 'publication_year': 2016, 'abstract': None}
{'title': 'Posterior calibration and exploratory analysis for natural language processing models', 'paperID': '1aad4230be997ec83acd6b7c41d581eb8dd033ca', 'arxivId': '1508.05154', 'publication_year': 2015, 'abstract': None}
{'title': 'Striving for Simplicity: The All Convolutional Net', 'paperID': '0f84a81f431b18a78bd97f59ed4b9d8eda390970', 'arxivId': '1412.6806', 'publication_year': 2014, 'abstract': None}
{'title': 'Learning with Pseudo-Ensembles', 'paperID': '03cd6f2297637a322bdd4519b8cee331ef42984b', 'arxivId': '1412.4864', 'publication_year': 2014, 'abstract': None}
{'title': 'Unbiased look at dataset bias', 'paperID': '0302bb2d5476540cfb21467473f5eca843caf90b', 'arxivId': None, 'publication_year': 2011, 'abstract': None}
{'title': 'Testing Robustness Against Unforeseen Adversaries', 'paperID': '1c5b068ce6dff86bf152312b99f3360456a00faf', 'arxivId': None, 'publication_year': 2019, 'abstract': None}
{'title': 'AugMix: A Simple Data Processing Method to Improve Robustness and Uncertainty', 'paperID': '02b1607af35b48f0bd716367caf6a7428b969369', 'arxivId': '1912.02781', 'publication_year': '2019', 'abstract': 'Modern deep neural networks can achieve high accuracy when the training distribution and test distribution are identically distributed, but this assumption is frequently violated in practice. When the train and test distributions are mismatched, accuracy can plummet. Currently there are few techniques that improve robustness to unforeseen data shifts encountered during deployment. In this work, we propose a technique to improve the robustness and uncertainty estimates of image classifiers. We propose AugMix, a data processing technique that is simple to implement, adds limited computational overhead, and helps models withstand unforeseen corruptions. AugMix significantly improves robustness and uncertainty measures on challenging image classification benchmarks, closing the gap between previous methods and the best possible performance in some cases by more than half.'}
{'title': 'Classical Electrodynamics', 'paperID': 'e4a81b32bdc0adbf599bb8e98e53ec1adfa91878', 'arxivId': None, 'publication_year': 2020, 'abstract': None}
{'title': 'UniformFace: Learning Deep Equidistributed Representation for Face Recognition', 'paperID': '3e4a49b86c9c34e27e00a0f250b3d82f269cf153', 'arxivId': None, 'publication_year': 2019, 'abstract': None}
{'title': 'You Only Propagate Once: Accelerating Adversarial Training via Maximal Principle', 'paperID': 'd33deae7f654b07ac8a5c437a4fa018c29e6af17', 'arxivId': '1905.00877', 'publication_year': 2019, 'abstract': None}
{'title': 'Adversarial Training for Free!', 'paperID': 'c92be891c5f8f0f60b6de206364f9a744612d1e8', 'arxivId': '1904.12843', 'publication_year': 2019, 'abstract': None}
{'title': 'Adversarial Defense by Restricting the Hidden Space of Deep Neural Networks', 'paperID': '144a8fb6e9d573f7ffb0768846f94d7859811d44', 'arxivId': '1904.00887', 'publication_year': 2019, 'abstract': None}
{'title': 'On Evaluating Adversarial Robustness', 'paperID': 'be94fe9f2414639cd3f6cef0fdeafd4a10d1b2e5', 'arxivId': '1902.06705', 'publication_year': 2019, 'abstract': None}
{'title': 'Adversarial Examples Are a Natural Consequence of Test Error in Noise', 'paperID': '988a378f640eb7fb681f977d6cb1e0c830c07b4c', 'arxivId': '1901.10513', 'publication_year': 2019, 'abstract': None}
{'title': 'Feature Denoising for Improving Adversarial Robustness', 'paperID': '41071dbbbcbb27af3fec70de045f19c28535f5b7', 'arxivId': '1812.03411', 'publication_year': 2018, 'abstract': None}
{'title': 'Training for Faster Adversarial Robustness Verification via Inducing ReLU Stability', 'paperID': 'de49430578bb3f8de3e610423255662c45f17610', 'arxivId': '1809.03008', 'publication_year': 2018, 'abstract': None}
{'title': 'Scaling provable adversarial defenses', 'paperID': '20f85256555ad612148e52f9363e52f9d661728b', 'arxivId': '1805.12514', 'publication_year': 2018, 'abstract': None}
{'title': 'Learning towards Minimum Hyperspherical Energy', 'paperID': '13b2bc8101a2a7a0c95412c48f40ef95e798e9fb', 'arxivId': '1805.09298', 'publication_year': 2018, 'abstract': None}
{'title': 'Black-box Adversarial Attacks with Limited Queries and Information', 'paperID': 'b3f83e8416010e9c3a705a0b6390d268e5ddf5c0', 'arxivId': '1804.08598', 'publication_year': 2018, 'abstract': None}
{'title': 'SoK: Security and Privacy in Machine Learning', 'paperID': '29524f145db94cab2336da99f157e869d805dead', 'arxivId': None, 'publication_year': 2018, 'abstract': None}
{'title': 'Adversarial Attacks and Defences Competition', 'paperID': 'ca5642f522cd2cd44948c7e9f337c91e5f26fdcf', 'arxivId': '1804.00097', 'publication_year': 2018, 'abstract': None}
{'title': 'Improving Transferability of Adversarial Examples With Input Diversity', 'paperID': 'f78a911f516625d6b7b76a9a33c1eb14613341c4', 'arxivId': '1803.06978', 'publication_year': 2018, 'abstract': None}
{'title': 'Rethinking Feature Distribution for Loss Functions in Image Classification', 'paperID': 'b6b24dfaf4c9e498ca9b9ee9f82d8d0c5bdb77e9', 'arxivId': '1803.02988', 'publication_year': 2018, 'abstract': None}
{'title': 'Max-Mahalanobis Linear Discriminant Analysis Networks', 'paperID': '40addc9c5d6ab5668fe347806e94546e80e66595', 'arxivId': '1802.09308', 'publication_year': 2018, 'abstract': None}
{'title': 'Adversarial vulnerability for any classifier', 'paperID': '7005fe514458b538b7516b41af5f5e1971154070', 'arxivId': '1802.08686', 'publication_year': 2018, 'abstract': None}
{'title': 'Face Recognition via Centralized Coordinate Learning', 'paperID': 'f60070d3a4d333aa1436e4c372b1feb5b316a7ba', 'arxivId': '1801.05678', 'publication_year': 2018, 'abstract': None}
{'title': 'A Rotation and a Translation Suffice: Fooling CNNs with Simple Transformations', 'paperID': 'afa0d49c1399c752d6f4665d75ecec640c000468', 'arxivId': '1712.02779', 'publication_year': 2017, 'abstract': None}
{'title': 'Soft-Margin Softmax for Deep Classification', 'paperID': 'f220ef68612e68a5708001f2b596d742b941e773', 'arxivId': None, 'publication_year': 2017, 'abstract': None}
{'title': 'Boosting Adversarial Attacks with Momentum', 'paperID': '8e37a3b227b68953f8067215828dc8b8714cb21b', 'arxivId': None, 'publication_year': 2017, 'abstract': None}
{'title': 'EAD: Elastic-Net Attacks to Deep Neural Networks via Adversarial Examples', 'paperID': '160a03c2890f3ef5436c25ef9b1758faa13807a0', 'arxivId': '1709.04114', 'publication_year': 2017, 'abstract': None}
{'title': 'ZOO: Zeroth Order Optimization Based Black-box Attacks to Deep Neural Networks without Training Substitute Models', 'paperID': '9ab7319dbe80549ba80e3320d0546d741a7a5791', 'arxivId': '1708.03999', 'publication_year': 2017, 'abstract': None}
{'title': 'One-shot Face Recognition by Promoting Underrepresented Classes', 'paperID': '6cacda04a541d251e8221d70ac61fda88fb61a70', 'arxivId': '1707.05574', 'publication_year': 2017, 'abstract': None}
{'title': 'Formal Guarantees on the Robustness of a Classifier against Adversarial Manipulation', 'paperID': '255d2c2af6d7abbbebfc03dab51cd8574ad3558e', 'arxivId': '1705.08475', 'publication_year': 2017, 'abstract': None}
{'title': 'SoK: Science, Security and the Elusive Goal of Security as a Scientific Pursuit', 'paperID': '5fb1988aca0d8797daaf97dbfd56f54f7b84d230', 'arxivId': None, 'publication_year': 2017, 'abstract': None}
{'title': 'Adversarial Examples Are Not Easily Detected: Bypassing Ten Detection Methods', 'paperID': '99cb08c76c120599abd1d1637e32aaf577f38d39', 'arxivId': '1705.07263', 'publication_year': 2017, 'abstract': None}
{'title': 'Ensemble Adversarial Training: Attacks and Defenses', 'paperID': '136dee73f203df2f4831994bf4f0c0a4ad2e764e', 'arxivId': '1705.07204', 'publication_year': 2017, 'abstract': None}
{'title': 'NormFace: L2 Hypersphere Embedding for Face Verification', 'paperID': '21063765fc3dc7884dc2a28c68e6c7174ab70af2', 'arxivId': '1704.06369', 'publication_year': 2017, 'abstract': None}
{'title': 'A Discriminative Feature Learning Approach for Deep Face Recognition', 'paperID': '4cfd770ccecae1c0b4248bc800d7fd35c817bbbd', 'arxivId': None, 'publication_year': 2016, 'abstract': None}
{'title': 'Guaranteed Bounds on the Kullback–Leibler Divergence of Univariate Mixtures', 'paperID': '1f4f8206c1d459f60324f06967173b906a12ef6a', 'arxivId': None, 'publication_year': 2016, 'abstract': None}
{'title': 'Robustness of classifiers: from adversarial to random noise', 'paperID': '637c25f7e8f37226f829cd9264d4eeea50f75e7b', 'arxivId': '1608.08967', 'publication_year': 2016, 'abstract': None}
{'title': 'Large-Margin Softmax Loss for Convolutional Neural Networks', 'paperID': '6fd9e3cb0cf23c8ef4aa7065d9be407c45250bff', 'arxivId': '1612.02295', 'publication_year': 2016, 'abstract': None}
{'title': 'FaceNet: A unified embedding for face recognition and clustering', 'paperID': '5aa26299435bdf7db874ef1640a6c3b5a4a2c394', 'arxivId': '1503.03832', 'publication_year': 2015, 'abstract': None}
{'title': 'Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift', 'paperID': '4d376d6978dad0374edfa6709c9556b42d3594d3', 'arxivId': '1502.03167', 'publication_year': 2015, 'abstract': None}
{'title': 'Deep Learning Face Representation by Joint Identification-Verification', 'paperID': '91bdaf3f1226e4065c4296d5c362906ceadfc631', 'arxivId': '1406.4773', 'publication_year': 2014, 'abstract': None}
{'title': 'Evasion Attacks against Machine Learning at Test Time', 'paperID': '033c08ca48aaed2d5ab0a17d668d410538678ed8', 'arxivId': '1708.06131', 'publication_year': 2013, 'abstract': None}
{'title': 'Dimensionality Reduction by Learning an Invariant Mapping', 'paperID': '46f30e94dd3d5902141c5fbe58d0bc9189545c76', 'arxivId': None, 'publication_year': 2006, 'abstract': None}
{'title': 'Smooth minimization of non-smooth functions', 'paperID': '8e6c6086ea725737aa6081a57ea68d43a24ca3b9', 'arxivId': None, 'publication_year': 2005, 'abstract': None}
{'title': 'Classical Electrodynamics, 3rd ed.', 'paperID': '7114418f520880dd202108f20fe8e6ce70db68bd', 'arxivId': None, 'publication_year': 1999, 'abstract': None}
{'title': 'On monotonicity of the hypersphere volume and area', 'paperID': '7fb1364bc382c67901f3e3eb12901874570788ca', 'arxivId': None, 'publication_year': 2007, 'abstract': None}
{'title': 'On the momentum term in gradient descent learning algorithms', 'paperID': '735d4220d5579cc6afe956d9f6ea501a96ae99e2', 'arxivId': None, 'publication_year': 1999, 'abstract': None}
{'title': 'Rethinking Softmax Cross-Entropy Loss for Adversarial Robustness', 'paperID': 'c68cd22de315a14587120e98bb02fdcf51edec46', 'arxivId': '1905.10626', 'publication_year': '2019', 'abstract': 'Previous work shows that adversarially robust generalization requires larger sample complexity, and the same dataset, e.g., CIFAR-10, which enables good standard accuracy may not suffice to train robust models. Since collecting new training data could be costly, we focus on better utilizing the given data by inducing the regions with high sample density in the feature space, which could lead to locally sufficient samples for robust learning. We first formally show that the softmax cross-entropy (SCE) loss and its variants convey inappropriate supervisory signals, which encourage the learned feature points to spread over the space sparsely in training. This inspires us to propose the Max-Mahalanobis center (MMC) loss to explicitly induce dense feature regions in order to benefit robustness. Namely, the MMC loss encourages the model to concentrate on learning ordered and compact representations, which gather around the preset optimal centers for different classes. We empirically demonstrate that applying the MMC loss can significantly improve robustness even under strong adaptive attacks, while keeping state-of-the-art accuracy on clean inputs with little extra computation compared to the SCE loss.'}
{'title': 'A Bayesian Approach to Robust Reinforcement Learning', 'paperID': '03367b0458e08105475dba32dbacee1fe0b7f311', 'arxivId': '1905.08188', 'publication_year': 2019, 'abstract': None}
{'title': 'Challenges of Real-World Reinforcement Learning', 'paperID': '896e5529de1da1e4494033404721b70339bb9557', 'arxivId': '1904.12901', 'publication_year': 2019, 'abstract': None}
{'title': 'Soft Actor-Critic Algorithms and Applications', 'paperID': '12c0751b4f51ed833172a713b7e32390032ead93', 'arxivId': '1812.05905', 'publication_year': 2018, 'abstract': None}
{'title': 'Relative Entropy Regularized Policy Iteration', 'paperID': '655cfe96e20675183dc8c2acbab659bce54fd6f5', 'arxivId': '1812.02256', 'publication_year': 2018, 'abstract': None}
{'title': 'Learning dexterous in-hand manipulation', 'paperID': 'd37a34c204a8beefcaef4dddddb7a90c16e973d4', 'arxivId': '1808.00177', 'publication_year': 2018, 'abstract': None}
{'title': 'Learning Dexterous In-Hand Manipulation.', 'paperID': 'b47512c1444374add267ed7232b689037972da01', 'arxivId': None, 'publication_year': 2018, 'abstract': None}
{'title': 'QT-Opt: Scalable Deep Reinforcement Learning for Vision-Based Robotic Manipulation', 'paperID': 'eb37e7b76d26b75463df22b2a3aa32b6a765c672', 'arxivId': '1806.10293', 'publication_year': 2018, 'abstract': None}
{'title': 'Soft-Robust Actor-Critic Policy-Gradient', 'paperID': '0c284ef8a3366b4912d59b6af7e70cbb0d070f80', 'arxivId': '1803.04848', 'publication_year': 2018, 'abstract': None}
{'title': 'Learning by Playing - Solving Sparse Reward Tasks from Scratch', 'paperID': 'cab81775baae7ba2d056ebbc60437f2e03358ca3', 'arxivId': '1802.10567', 'publication_year': 2018, 'abstract': None}
{'title': 'Unicorn: Continual Learning with a Universal, Off-policy Agent', 'paperID': 'd72e69eacd4afeac33f71d07c484686084e55b9a', 'arxivId': '1802.08294', 'publication_year': 2018, 'abstract': None}
{'title': 'Maximum a Posteriori Policy Optimisation', 'paperID': 'a8ef08940341381390d9a5672546354d0ce51328', 'arxivId': '1806.06920', 'publication_year': 2018, 'abstract': None}
{'title': 'Learning Robust Options', 'paperID': '4e43d0365e4e922123de54c5e9a430bbced4a817', 'arxivId': '1802.03236', 'publication_year': 2018, 'abstract': None}
{'title': 'DeepMind Control Suite', 'paperID': 'a9a3ed69c94a3e1c08ef1f833d9199f57736238b', 'arxivId': '1801.00690', 'publication_year': 2018, 'abstract': None}
{'title': 'Mutual Alignment Transfer Learning', 'paperID': 'b7473703c1e56b1e48b9d69eb055d95dd8ba9e83', 'arxivId': '1707.07907', 'publication_year': 2017, 'abstract': None}
{'title': 'Distral: Robust multitask reinforcement learning', 'paperID': 'cf90552b5d2e992e93ab838fd615e1c36618e31c', 'arxivId': '1707.04175', 'publication_year': 2017, 'abstract': None}
{'title': 'Equivalence Between Policy Gradients and Soft Q-Learning', 'paperID': 'd0352057e2b99f65f8b5244a0b912026c86d7b21', 'arxivId': '1704.06440', 'publication_year': 2017, 'abstract': None}
{'title': 'Bridging the Gap Between Value and Policy Based Reinforcement Learning', 'paperID': '96a067e188f1c89db9faea1fea2314a15ae51bbc', 'arxivId': '1702.08892', 'publication_year': 2017, 'abstract': None}
{'title': 'Transfer from Simulation to Real World through Learning Deep Inverse Dynamics Model', 'paperID': '3ed67ded2b4d3614b38798b3f17a8e69803d0980', 'arxivId': '1610.03518', 'publication_year': 2016, 'abstract': None}
{'title': 'Learning modular neural network policies for multi-task and multi-robot transfer', 'paperID': '8fab7d7dfd233fd5d19bc2641b4c1ca74fc7bc6a', 'arxivId': '1609.07088', 'publication_year': 2016, 'abstract': None}
{'title': 'A Deep Hierarchical Approach to Lifelong Learning in Minecraft', 'paperID': '3c3861c607fb79f3fbf79552018724617fc8ba1b', 'arxivId': '1604.07255', 'publication_year': 2016, 'abstract': None}
{'title': 'Benchmarking Deep Reinforcement Learning for Continuous Control', 'paperID': '1464776f20e2bccb6182f183b5ff2e15b0ae5e56', 'arxivId': '1604.06778', 'publication_year': 2016, 'abstract': None}
{'title': 'Planning with Information-Processing Constraints and Model Uncertainty in Markov Decision Processes', 'paperID': '3a472aeb7312383822da385f03141f2decb3d124', 'arxivId': '1604.02080', 'publication_year': 2016, 'abstract': None}
{'title': 'Taming the Noise in Reinforcement Learning via Soft Updates', 'paperID': '4a026fd65af4ba3575e64174de56fee093fa3330', 'arxivId': '1512.08562', 'publication_year': 2015, 'abstract': None}
{'title': 'Policy Distillation', 'paperID': '1c4927af526d5c28f7c2cfa492ece192d80a61d4', 'arxivId': '1511.06295', 'publication_year': 2015, 'abstract': None}
{'title': 'Learning Continuous Control Policies by Stochastic Value Gradients', 'paperID': '6640f4e4beae786f301928d82a9f8eb037aa6935', 'arxivId': '1510.09142', 'publication_year': 2015, 'abstract': None}
{'title': 'Human-level control through deep reinforcement learning', 'paperID': 'e0e9a94c4a6ba219e768b4e59f72c18f0a22e23d', 'arxivId': None, 'publication_year': 2015, 'abstract': None}
{'title': 'Scaling Up Robust MDPs using Function Approximation', 'paperID': '199a292bb72d57cae4a4455249f438a4f9ac96b8', 'arxivId': None, 'publication_year': 2014, 'abstract': None}
{'title': 'Stochastic Backpropagation and Approximate Inference in Deep Generative Models', 'paperID': '484ad17c926292fbe0d5211540832a8c8a8e958b', 'arxivId': None, 'publication_year': 2014, 'abstract': None}
{'title': 'Robust Markov Decision Processes', 'paperID': '9eae0c6ca4a52fc5e6b6f9eb111ab6fdbecdf9a6', 'arxivId': None, 'publication_year': 2013, 'abstract': None}
{'title': 'Policy Gradients with Variance Related Risk Criteria', 'paperID': 'e27fb84fccd3d9724df8ce35fe14149da5de3251', 'arxivId': '1206.6404', 'publication_year': 2012, 'abstract': None}
{'title': 'Path integral control and bounded rationality', 'paperID': 'a86e7b223be9005d30ad806803c09fedfc804624', 'arxivId': None, 'publication_year': 2011, 'abstract': None}
{'title': 'Robust Control of Markov Decision Processes with Uncertain Transition Matrices', 'paperID': '6db16608fccddef51202af84112b34cfebfbe20a', 'arxivId': None, 'publication_year': 2005, 'abstract': None}
{'title': 'Robust Dynamic Programming', 'paperID': 'ab4a1c4dfe23b3a1e3d077df467452cc68f64de8', 'arxivId': None, 'publication_year': 2005, 'abstract': None}
{'title': 'Between MDPs and Semi-MDPs: A Framework for Temporal Abstraction in Reinforcement Learning', 'paperID': '0e7638dc16a5e5e9e46c91272bfb9c3dd242ef6d', 'arxivId': None, 'publication_year': 1999, 'abstract': None}
{'title': 'Sample-efficient Reinforcement Learning via Difference Models', 'paperID': '87bd79e8444d6604dc2b2d8342f3e80cdf3468b1', 'arxivId': None, 'publication_year': 2018, 'abstract': None}
{'title': 'Machine Learning Applications for Data Center Optimization', 'paperID': '6e7891253247b01b346e92fb81c2ba589ca8e428', 'arxivId': None, 'publication_year': 2014, 'abstract': None}
{'title': 'Trading Value and Information in MDPs', 'paperID': '1d75b5275f24c422b6f73dd77750b402d997d060', 'arxivId': None, 'publication_year': 2012, 'abstract': None}
{'title': 'Reinforcement Learning: An Introduction', 'paperID': '97efafdb4a3942ab3efba53ded7413199f79c054', 'arxivId': None, 'publication_year': 2005, 'abstract': None}
{'title': 'Meta learning', 'paperID': '427ce4ce5f64295f39c8714de6ff09fb3bb7d187', 'arxivId': None, 'publication_year': 2003, 'abstract': None}
{'title': 'Robust Reinforcement Learning for Continuous Control with Model Misspecification', 'paperID': '6946ae0c23257586c12d01675e05167d74cb89fa', 'arxivId': '1906.07516', 'publication_year': '2019', 'abstract': 'We provide a framework for incorporating robustness -- to perturbations in the transition dynamics which we refer to as model misspecification -- into continuous control Reinforcement Learning (RL) algorithms. We specifically focus on incorporating robustness into a state-of-the-art continuous control RL algorithm called Maximum a-posteriori Policy Optimization (MPO). We achieve this by learning a policy that optimizes for a worst case expected return objective and derive a corresponding robust entropy-regularized Bellman contraction operator. In addition, we introduce a less conservative, soft-robust, entropy-regularized objective with a corresponding Bellman operator. We show that both, robust and soft-robust policies, outperform their non-robust counterparts in nine Mujoco domains with environment perturbations. In addition, we show improved robust performance on a high-dimensional, simulated, dexterous robotic hand. Finally, we present multiple investigative experiments that provide a deeper insight into the robustness framework. This includes an adaptation to another continuous control RL algorithm as well as learning the uncertainty set from offline data. Performance videos can be found online at this https URL.'}
{'title': 'How Does Disagreement Benefit Co-teaching?', 'paperID': '5d99d520410efec67a515e3bcc20ce8868e13b6d', 'arxivId': None, 'publication_year': 2019, 'abstract': None}
{'title': 'How does Disagreement Help Generalization against Label Corruption?', 'paperID': '568675640f381fbc13998015c2854298877b7aa0', 'arxivId': '1901.04215', 'publication_year': 2019, 'abstract': None}
{'title': 'Learning with Bad Training Data via Iterative Trimmed Loss Minimization', 'paperID': '66169adc068ef55f17ce1b1b51efb8778673ecfc', 'arxivId': None, 'publication_year': 2018, 'abstract': None}
{'title': 'An Empirical Study of Example Forgetting during Deep Neural Network Learning', 'paperID': 'a2b5d224895d96bfe2e384e2dcf1ebd136ac3782', 'arxivId': '1812.05159', 'publication_year': 2018, 'abstract': None}
{'title': 'Controlling Over-generalization and its Effect on Adversarial Examples Generation and Detection', 'paperID': '6c4f5c95004cdfde3b58d543b8cb25d6b91ebed6', 'arxivId': '1808.08282', 'publication_year': 2018, 'abstract': None}
{'title': 'The Devil of Face Recognition is in the Noise', 'paperID': '4f686309f5a34d5a5c687539b71bac0bafd8476f', 'arxivId': '1807.11649', 'publication_year': 2018, 'abstract': None}
{'title': 'Dimensionality-Driven Learning with Noisy Labels', 'paperID': '622727f595542afa3caf8802927d880818ddb17a', 'arxivId': '1806.02612', 'publication_year': 2018, 'abstract': None}
{'title': 'Insights on representational similarity in neural networks with canonical correlation', 'paperID': 'e5a95a679774e069e1e36d96f92bac6b93027118', 'arxivId': '1806.05759', 'publication_year': 2018, 'abstract': None}
{'title': 'Co-teaching: Robust training of deep neural networks with extremely noisy labels', 'paperID': 'e061d23b68e7d4aac5aece4794c044c80e638dca', 'arxivId': '1804.06872', 'publication_year': 2018, 'abstract': None}
{'title': 'Iterative Learning with Open-set Noisy Labels', 'paperID': '0abea3322379506b017784309d9bee2e375e3e5d', 'arxivId': '1804.00092', 'publication_year': 2018, 'abstract': None}
{'title': 'Using Trusted Data to Train Deep Networks on Labels Corrupted by Severe Noise', 'paperID': '780d18205252a4d3fc1ab4b4a2db55a370d0105e', 'arxivId': '1802.05300', 'publication_year': 2018, 'abstract': None}
{'title': 'Realistic Evaluation of Deep Semi-Supervised Learning Algorithms', 'paperID': '2b1a3d7e6045dc6b544a548b372c1f8492b85967', 'arxivId': '1804.09170', 'publication_year': 2018, 'abstract': None}
{'title': 'MentorNet: Learning Data-Driven Curriculum for Very Deep Neural Networks on Corrupted Labels', 'paperID': '306a2e8ca31fdcc148618d37074785c290f96375', 'arxivId': '1712.05055', 'publication_year': 2017, 'abstract': None}
{'title': 'WebVision Database: Visual Learning and Understanding from Web Data', 'paperID': '5de5848dc3fc35e40420ffec70a407e4770e3a8d', 'arxivId': '1708.02862', 'publication_year': 2017, 'abstract': None}
{'title': 'A Downsampled Variant of ImageNet as an Alternative to the CIFAR datasets', 'paperID': 'e644a409b4a4c6eaedffe27efbc5c76280b34c61', 'arxivId': '1707.08819', 'publication_year': 2017, 'abstract': None}
{'title': 'Deep Learning is Robust to Massive Label Noise', 'paperID': '96f4d4fc345698b9b44f034c0d63b704772c8386', 'arxivId': '1705.10694', 'publication_year': 2017, 'abstract': None}
{'title': "Deep Nets Don't Learn via Memorization", 'paperID': '0ebb83e5c28719c7b5cb5bc482e62f835fb0d116', 'arxivId': None, 'publication_year': 2017, 'abstract': None}
{'title': 'Training deep neural-networks using a noise adaptation layer', 'paperID': 'bc550ee45f4194f86c52152c10d302965c3563ca', 'arxivId': None, 'publication_year': 2016, 'abstract': None}
{'title': 'Temporal Ensembling for Semi-Supervised Learning', 'paperID': 'd2e4587744a89bad95fea69e08842cad6c8ff0dd', 'arxivId': '1610.02242', 'publication_year': 2016, 'abstract': None}
{'title': 'Making Deep Neural Networks Robust to Label Noise: A Loss Correction Approach', 'paperID': '91d331d2bdd5fc86400c40c497bcb4c741c652be', 'arxivId': '1609.03683', 'publication_year': 2016, 'abstract': None}
{'title': 'Inception-v4, Inception-ResNet and the Impact of Residual Connections on Learning', 'paperID': 'b5c26ab8767d046cb6e32d959fdf726aee89bb62', 'arxivId': '1602.07261', 'publication_year': 2016, 'abstract': None}
{'title': 'Training Deep Neural Networks on Noisy Labels with Bootstrapping', 'paperID': '77e3c48aa10535276e7f570a3af594ba63de7d65', 'arxivId': '1412.6596', 'publication_year': 2014, 'abstract': None}
{'title': 'Training Convolutional Networks with Noisy Labels', 'paperID': 'ad84f49b2cd1b85a6d7df2304144a093f5b610a8', 'arxivId': '1406.2080', 'publication_year': 2014, 'abstract': None}
{'title': 'Robust training with ensemble consensus', 'paperID': 'd5fc1374bfb839a65e928c8554ec09421739c2b7', 'arxivId': '1910.09792', 'publication_year': '2019', 'abstract': 'Since deep neural networks are over-parametrized, they may memorize noisy examples. We address such memorizing issue under the existence of annotation noise. From the fact that deep neural networks cannot generalize neighborhoods of the features acquired via memorization, we find that noisy examples do not consistently incur small losses on the network in the presence of perturbation. Based on this, we propose a novel training method called Learning with Ensemble Consensus (LEC) whose goal is to prevent overfitting noisy examples by eliminating them identified via consensus of an ensemble of perturbed networks. One of the proposed LECs, LTEC outperforms the current state-of-the-art methods on MNIST, CIFAR-10, and CIFAR-100 despite its efficient memory.'}
{'title': 'Gradient Descent Maximizes the Margin of Homogeneous Neural Networks', 'paperID': '3f46ac38812f9f0f99ff1edddd85d71a84da4497', 'arxivId': '1906.05890', 'publication_year': 2019, 'abstract': None}
{'title': 'Deterministic PAC-Bayesian generalization bounds for deep networks via generalizing noise-resilience', 'paperID': '0204871837acb118871e8d1bb59407da73142333', 'arxivId': '1905.13344', 'publication_year': 2019, 'abstract': None}
{'title': 'Size-free generalization bounds for convolutional neural networks', 'paperID': 'ec7c8b82009fee95ee807da79045c83373378fef', 'arxivId': None, 'publication_year': 2019, 'abstract': None}
{'title': 'A Hessian Based Complexity Measure for Deep Networks', 'paperID': 'b2162301e7c2fc90f5eb62471b4f23ece8da1b8d', 'arxivId': '1905.11639', 'publication_year': 2019, 'abstract': None}
{'title': 'Lexicographic and Depth-Sensitive Margins in Homogeneous and Non-Homogeneous Deep Models', 'paperID': '6b81ffcb4b461f7f657cfb4d9b076cdc595b1077', 'arxivId': '1905.07325', 'publication_year': 2019, 'abstract': None}
{'title': 'Data-dependent Sample Complexity of Deep Neural Networks via Lipschitz Augmentation', 'paperID': '816db3b923a870f02391759c214a024a8d2c548c', 'arxivId': '1905.03684', 'publication_year': 2019, 'abstract': None}
{'title': 'VC Classes are Adversarially Robustly Learnable, but Only Improperly', 'paperID': 'fa2bfdf70e43b84a632b679a8f35999816245919', 'arxivId': '1902.04217', 'publication_year': 2019, 'abstract': None}
{'title': 'Adversarial Risk Bounds for Binary Classification via Function Transformation', 'paperID': '2236e2263cab1a9e4ba71fdb7cedc7092bfb6c2f', 'arxivId': '1810.09519', 'publication_year': 2018, 'abstract': None}
{'title': 'Regularization Matters: Generalization and Optimization of Neural Nets v.s. their Induced Kernel', 'paperID': '9c985db0a4a255a06e0fbf2ce147ea741720f9f0', 'arxivId': '1810.05369', 'publication_year': 2018, 'abstract': None}
{'title': 'Rademacher Complexity for Adversarially Robust Generalization', 'paperID': '1438fab07a94351eaabcbe92983fbefaa208b2f3', 'arxivId': '1810.11914', 'publication_year': 2018, 'abstract': None}
{'title': 'Generalizable Adversarial Training via Spectral Normalization', 'paperID': '3a606480406886742572a956e221e986c65d94c1', 'arxivId': '1811.07457', 'publication_year': 2018, 'abstract': None}
{'title': 'Predicting the Generalization Gap in Deep Networks with Margin Distributions', 'paperID': 'e3c6d32182992310b802ec0a2c261358e72487ae', 'arxivId': '1810.00113', 'publication_year': 2018, 'abstract': None}
{'title': 'Just Interpolate: Kernel "Ridgeless" Regression Can Generalize', 'paperID': '47149cbfee9dac6c092462bbe13cf18cf9cc9314', 'arxivId': '1808.00387', 'publication_year': 2018, 'abstract': None}
{'title': 'Manifold Mixup: Encouraging Meaningful On-Manifold Interpolation as a Regularizer', 'paperID': 'cd34714b819ca75bba63fea36aff54d66f458d1b', 'arxivId': None, 'publication_year': 2018, 'abstract': None}
{'title': 'Risk and parameter convergence of logistic regression', 'paperID': '4a5a17d7849b91a3af583c7b99403844e1a5cdb1', 'arxivId': '1803.07300', 'publication_year': 2018, 'abstract': None}
{'title': 'Large Margin Deep Networks for Classification', 'paperID': '06f35a25c12d33a93578711eccf7cceab4e66d54', 'arxivId': '1803.05598', 'publication_year': 2018, 'abstract': None}
{'title': 'Sensitivity and Generalization in Neural Networks: an Empirical Study', 'paperID': 'e837dfa120e8ce3cd587bde7b0787ef43fa7832d', 'arxivId': '1802.08760', 'publication_year': 2018, 'abstract': None}
{'title': 'Stronger generalization bounds for deep nets via a compression approach', 'paperID': 'a9022d8ffb5e417458fba9a280f90c1b08cb6c73', 'arxivId': '1802.05296', 'publication_year': 2018, 'abstract': None}
{'title': 'To understand deep learning we need to understand kernel learning', 'paperID': '033f7570be9877c5a4bcbb71f6aec8f95cee3608', 'arxivId': '1802.01396', 'publication_year': 2018, 'abstract': None}
{'title': 'Algorithmic Regularization in Over-parameterized Matrix Sensing and Neural Networks with Quadratic Activations', 'paperID': '8b4b861583f698e89c8cd9e198aad86809a71de7', 'arxivId': None, 'publication_year': 2017, 'abstract': None}
{'title': 'Size-Independent Sample Complexity of Neural Networks', 'paperID': '018a844cd7a496aed84f166e4b02ff547c3b5d16', 'arxivId': '1712.06541', 'publication_year': 2017, 'abstract': None}
{'title': 'The Implicit Bias of Gradient Descent on Separable Data', 'paperID': '11adc8bd35bd897502f9b5452ab7ac668ec9b0fb', 'arxivId': '1710.10345', 'publication_year': 2017, 'abstract': None}
{'title': 'Robust Large Margin Deep Neural Networks', 'paperID': 'f657e68dde470641ba1a6cd7ab755e6359a32840', 'arxivId': None, 'publication_year': 2017, 'abstract': None}
{'title': 'A PAC-Bayesian Approach to Spectrally-Normalized Margin Bounds for Neural Networks', 'paperID': '4fc3ee440c2b0f66255a9e6966cee871ee0cc6da', 'arxivId': '1707.09564', 'publication_year': 2017, 'abstract': None}
{'title': 'Exploring Generalization in Deep Learning', 'paperID': 'd53fb3feeeab07a0d70bf466dd473ec6052ecc07', 'arxivId': '1706.08947', 'publication_year': 2017, 'abstract': None}
{'title': 'Spectrally-normalized margin bounds for neural networks', 'paperID': '9753967a3af8e1db1e2da52a9bb3255bd1ce5c51', 'arxivId': '1706.08498', 'publication_year': 2017, 'abstract': None}
{'title': 'Train faster, generalize better: Stability of stochastic gradient descent', 'paperID': '0f7c85357c366b314b5b55c400869a62fd23372c', 'arxivId': '1509.01240', 'publication_year': 2015, 'abstract': None}
{'title': 'Norm-Based Capacity Control in Neural Networks', 'paperID': '02480b5d060eb4cb2228ac7e824fda22b29c3e9e', 'arxivId': '1503.00036', 'publication_year': 2015, 'abstract': None}
{'title': 'Optimistic Rates for Learning with a Smooth Loss', 'paperID': '34ad20cf5f0043b47de601e0f77e6fb4a7d824c6', 'arxivId': '1009.3896', 'publication_year': 2010, 'abstract': None}
{'title': 'On the Complexity of Linear Prediction: Risk Bounds, Margin Bounds, and Regularization', 'paperID': 'ae6e206c8c2994e04c3fdc5bd97d81fdd0f27493', 'arxivId': None, 'publication_year': 2008, 'abstract': None}
{'title': 'Kernel methods in machine learning', 'paperID': 'd37fc9e9c4fedc32865b08661e7fb950df1f8fbe', 'arxivId': 'math/0701907', 'publication_year': 2007, 'abstract': None}
{'title': 'Boosting as a Regularized Path to a Maximum Margin Classifier', 'paperID': 'f5616db9e1e377ef580bbe5c05b6e969b16dc222', 'arxivId': None, 'publication_year': 2004, 'abstract': None}
{'title': 'Rademacher and Gaussian Complexities: Risk Bounds and Structural Results', 'paperID': '009f35c0e453f2435efd8d8ef8086b76b294967a', 'arxivId': None, 'publication_year': 2003, 'abstract': None}
{'title': 'Concentration Inequalities and Empirical Processes Theory Applied to the Analysis of Learning Algorithms', 'paperID': 'a5c8ca9177054499e43898ac73d1c1b6e2a45928', 'arxivId': None, 'publication_year': 2002, 'abstract': None}
{'title': 'Empirical margin distributions and bounding the generalization error of combined classifiers', 'paperID': '6388150296152c8173fae995e30c80a86d7cf1f7', 'arxivId': 'math/0405343', 'publication_year': 2002, 'abstract': None}
{'title': 'A training algorithm for optimal margin classifiers', 'paperID': '2599131a4bc2fa957338732a37c744cfe3e17b24', 'arxivId': None, 'publication_year': 1992, 'abstract': None}
{'title': 'The Sizes of Compact Subsets of Hilbert Space and Continuity of Gaussian Processes', 'paperID': 'dace63396b81af8f3b34112d8ab744380ab024e7', 'arxivId': None, 'publication_year': 1967, 'abstract': None}
{'title': 'Improved Sample Complexities for Deep Neural Networks and Robust Classification via an All-Layer Margin', 'paperID': 'f324002c4d22abf7ed5f24699151719f29625d08', 'arxivId': None, 'publication_year': '2020', 'abstract': 'For linear classifiers, the relationship between (normalized) output margin and generalization is captured in a clear and simple bound – a large output margin implies good generalization. Unfortunately, for deep models, this relationship is less clear: existing analyses of the output margin give complicated bounds which sometimes depend exponentially on depth. In this work, we propose to instead analyze a new notion of margin, which we call the “all-layer margin.” Our analysis reveals that the all-layer margin has a clear and direct relationship with generalization for deep models. We present three concrete applications of the all-layer margin: 1) by analyzing the all-layer margin, we obtain tighter generalization bounds for neural nets which depend on Jacobian and hidden layer norms and remove the exponential dependency on depth 2) our neural net results easily translate to the adversarially robust setting, giving the first direct analysis of robust test error for deep networks, and 3) we present a theoretically inspired training algorithm for increasing the all-layer margin and demonstrate that our algorithm improves test performance over strong baselines in practice.'}
{'title': 'Robust Subspace Recovery with Adversarial Outliers', 'paperID': '10965afaf73892bc989c9242442ec01cf22eb365', 'arxivId': '1904.03275', 'publication_year': 2019, 'abstract': None}
{'title': 'q-Space Novelty Detection with Variational Autoencoders', 'paperID': '68e7f5bcb2e2c628b15a96bfa72b612bd992a8e6', 'arxivId': '1806.02997', 'publication_year': 2018, 'abstract': None}
{'title': 'Deep Anomaly Detection Using Geometric Transformations', 'paperID': '5db790198b9acf4e5efe350acdd814238fcacaa7', 'arxivId': '1805.10917', 'publication_year': 2018, 'abstract': None}
{'title': 'An Overview of Robust Subspace Recovery', 'paperID': 'ddbc185ed132f09673ef048aab0a10a25ee6d27e', 'arxivId': '1803.01013', 'publication_year': 2018, 'abstract': None}
{'title': 'Static and Dynamic Robust PCA and Matrix Completion: A Review', 'paperID': 'f35ef556eff448479dad4f139eb747c5e2911384', 'arxivId': '1803.00651', 'publication_year': 2018, 'abstract': None}
{'title': 'Deep Autoencoding Gaussian Mixture Model for Unsupervised Anomaly Detection', 'paperID': 'dbc7401e3e75c40d3c720e7db3c906d48bd742d7', 'arxivId': None, 'publication_year': 2018, 'abstract': None}
{'title': 'Novelty Detection with GAN', 'paperID': '98af3dc5af084967adcfeda40b58b0012f98e1e9', 'arxivId': '1802.10560', 'publication_year': 2018, 'abstract': None}
{'title': 'Efficient GAN-Based Anomaly Detection', 'paperID': 'b3acb6f183b5f4b651f53c0eec5cb5c805224ac1', 'arxivId': '1802.06222', 'publication_year': 2018, 'abstract': None}
{'title': 'Clustering and Unsupervised Anomaly Detection with l2 Normalized Deep Auto-Encoder Representations', 'paperID': '388645c44061f6e88fff0ecdad2f622936207d67', 'arxivId': '1802.00187', 'publication_year': 2018, 'abstract': None}
{'title': 'Robust PCA for Anomaly Detection in Cyber Networks', 'paperID': 'bd32166541a656a4420c5c1ffc5701d09eedf2aa', 'arxivId': '1801.01571', 'publication_year': 2018, 'abstract': None}
{'title': 'Future Frame Prediction for Anomaly Detection - A New Baseline', 'paperID': '8a6acba7fb2aad1299fcf35701417e063d410ed4', 'arxivId': '1712.09867', 'publication_year': 2017, 'abstract': None}
{'title': 'OLE: Orthogonal Low-rank Embedding, A Plug and Play Geometric Loss for Deep Learning', 'paperID': 'd66d93fafe61e878b8da5a8d0ecee442d44b5be0', 'arxivId': '1712.01727', 'publication_year': 2017, 'abstract': None}
{'title': 'Deep Clustering with Convolutional Autoencoders', 'paperID': '1003462fd2d360542ea712430b13cf0c43fc7f9d', 'arxivId': None, 'publication_year': 2017, 'abstract': None}
{'title': 'Deep Subspace Clustering Networks', 'paperID': 'da0ae07cafd76210fed537e4a776cb52b3c50174', 'arxivId': '1709.02508', 'publication_year': 2017, 'abstract': None}
{'title': 'Anomaly Detection with Robust Deep Autoencoders', 'paperID': '2b75ba7f75170b73d913c515cc0deefef6c88f5f', 'arxivId': None, 'publication_year': 2017, 'abstract': None}
{'title': 'Wasserstein Generative Adversarial Networks', 'paperID': 'acd87843a451d18b4dc6474ddce1ae946429eaf1', 'arxivId': None, 'publication_year': 2017, 'abstract': None}
{'title': 'A Well-Tempered Landscape for Non-convex Robust Subspace Recovery', 'paperID': '65f233478263b77b48dc435d73bf3647f4ae4027', 'arxivId': '1706.03896', 'publication_year': 2017, 'abstract': None}
{'title': 'Robust, Deep and Inductive Anomaly Detection', 'paperID': '1d4ec24a6da3be62dc5d7efbae2a101c63f187e8', 'arxivId': '1704.06743', 'publication_year': 2017, 'abstract': None}
{'title': 'Improved Training of Wasserstein GANs', 'paperID': 'edf73ab12595c6709f646f542a0d2b33eb20a3f4', 'arxivId': '1704.00028', 'publication_year': 2017, 'abstract': None}
{'title': 'Wasserstein GAN', 'paperID': '2f85b7376769473d2bed56f855f115e23d727094', 'arxivId': '1701.07875', 'publication_year': 2017, 'abstract': None}
{'title': 'A Comparative Evaluation of Unsupervised Anomaly Detection Algorithms for Multivariate Data', 'paperID': '355692eb86b06a0a23af45c106cfb02c95bf380e', 'arxivId': None, 'publication_year': 2016, 'abstract': None}
{'title': 'Learning Discriminative Reconstructions for Unsupervised Outlier Removal', 'paperID': '1c06870e1ecc63e120e45a2283ca4b72c153e867', 'arxivId': None, 'publication_year': 2015, 'abstract': None}
{'title': 'Deep Learning', 'paperID': 'a4cec122a08216fe8a3bc19b22e78fbaea096256', 'arxivId': None, 'publication_year': 2015, 'abstract': None}
{'title': 'Fast, Robust and Non-convex Subspace Recovery', 'paperID': 'd47312e1019450097adaf50347120fc6db6c5323', 'arxivId': '1406.6145', 'publication_year': 2014, 'abstract': None}
{'title': 'Enhancing one-class support vector machines for unsupervised anomaly detection', 'paperID': 'eea4ca46542125e02cd7b6de60f28c3710b3f7a3', 'arxivId': None, 'publication_year': 2013, 'abstract': None}
{'title': 'Isolation-Based Anomaly Detection', 'paperID': 'dcd9f5d61bc9a70c40be84a8d78fbee822ffcd9e', 'arxivId': None, 'publication_year': 2012, 'abstract': None}
{'title': 'Robust Computation of Linear Models by Convex Relaxation', 'paperID': '9c7da2c47c66afe9a723af75908f0b5c45832e61', 'arxivId': '1202.4044', 'publication_year': 2012, 'abstract': None}
{'title': 'A novel M-estimator for robust PCA', 'paperID': '67d77348984b1793ebc65be0684a50bae90bb39e', 'arxivId': '1112.4863', 'publication_year': 2011, 'abstract': None}
{'title': 'Mining of Massive Datasets: Large-Scale File Systems and Map-Reduce', 'paperID': '437a48a476268ec4bfa40b7446a3ff95291a4fe0', 'arxivId': None, 'publication_year': 2011, 'abstract': None}
{'title': 'Scikit-learn: Machine Learning in Python', 'paperID': '168f28ac3c8c7ea63bf7ed25f2288e8b67e2fe74', 'arxivId': '1201.0490', 'publication_year': 2011, 'abstract': None}
{'title': 'lp\\documentclass[12pt]{minimal} \\usepackage{amsmath} \\usepackage{wasysym} \\usepackage{amsfonts} \\usepackage{amssymb} \\usepackage{amsbsy} \\usepackage{mathrsfs} \\usepackage{upgreek} \\setlength{\\oddsidemargin}{-69pt} \\begin{document}$${l_p}$$\\end{document}-Recovery of the Most Significant Subspace Amon', 'paperID': '73fa4d95d635d6b914c967e41b5dd3321751672a', 'arxivId': '1012.4116', 'publication_year': 2010, 'abstract': None}
{'title': 'Two proposals for robust PCA using semidefinite programming', 'paperID': '07f87b91ddabb7f71f43f20ab1b7d572904fe801', 'arxivId': '1012.1086', 'publication_year': 2010, 'abstract': None}
{'title': 'Robust PCA via Outlier Pursuit', 'paperID': '01625cba9f8a783994377d4f35aa765242faab4f', 'arxivId': '1010.4237', 'publication_year': 2010, 'abstract': None}
{'title': 'Median K-Flats for hybrid linear modeling with many outliers', 'paperID': 'a56d20496e084f99823493eebf28a88a60f92e17', 'arxivId': '0909.3123', 'publication_year': 2009, 'abstract': None}
{'title': 'Anomaly detection: A survey', 'paperID': '71d1ac92ad36b62a04f32ed75a10ad3259a7218d', 'arxivId': None, 'publication_year': 2009, 'abstract': None}
{'title': 'Robust Principal Component Analysis: Exact Recovery of Corrupted Low-Rank Matrices', 'paperID': '13fb2d7aef8b6352e99c3ccd268fc139c34cf657', 'arxivId': '0905.0233', 'publication_year': 2009, 'abstract': None}
{'title': 'R1-PCA: rotational invariant L1-norm principal component analysis for robust subspace factorization', 'paperID': '0439f9ea8dabf18581322f33aa25424851251d21', 'arxivId': None, 'publication_year': 2006, 'abstract': None}
{'title': 'Learning Generative Visual Models from Few Training Examples: An Incremental Bayesian Approach Tested on 101 Object Categories', 'paperID': 'ed9db7b20e019cdb1c7db8b7921221ee2d9f36e2', 'arxivId': None, 'publication_year': 2004, 'abstract': None}
{'title': 'Quantifying curvelike structures of measures by using L2 Jones quantities', 'paperID': '0f2cd9d0e82d4868f7c9c0fb06fcedd7237a1ac7', 'arxivId': None, 'publication_year': 2003, 'abstract': None}
{'title': 'A Framework for Robust Subspace Learning', 'paperID': '3f5dfbd571ef719a2c5dc1ed63ca6a3702f7861e', 'arxivId': None, 'publication_year': 2003, 'abstract': None}
{'title': 'LOF: identifying density-based local outliers', 'paperID': 'a7c828184693a453a6c2867dee233ed054b2012e', 'arxivId': None, 'publication_year': 2000, 'abstract': None}
{'title': 'Support Vector Method for Novelty Detection', 'paperID': 'bf206bad6a74d27b40c8ea77ee54e98e492fb7f9', 'arxivId': None, 'publication_year': 1999, 'abstract': None}
{'title': 'NewsWeeder: Learning to Filter Netnews', 'paperID': '38b3a4447a47a6a6ed1869f3da03352c487f8fe3', 'arxivId': None, 'publication_year': 1995, 'abstract': None}
{'title': 'Rectifiable sets and the Traveling Salesman Problem', 'paperID': 'da6fa08473e1e7dd84abfb0533e5d17d7aa7d422', 'arxivId': None, 'publication_year': 1990, 'abstract': None}
{'title': 'Outlier Detection for Text Data', 'paperID': '15e46987e753a7f01f3d0f3b23e5a948366f94e8', 'arxivId': None, 'publication_year': 2017, 'abstract': None}
{'title': 'Variational Autoencoder based Anomaly Detection using Reconstruction Probability', 'paperID': '061146b1d7938d7a8dae70e3531a00fceb3c78e8', 'arxivId': None, 'publication_year': 2015, 'abstract': None}
{'title': 'A Novel Anomaly Detection Scheme Based on Principal Component Classifier', 'paperID': 'dcb207ce848b358aeb2e4698c9ea1ad273ce98db', 'arxivId': None, 'publication_year': 2003, 'abstract': None}
{'title': 'Some problems in orthogonal distance and non-orthogonal distance regression', 'paperID': '68f52ec7b398998f21034cf19972fc54dc057cad', 'arxivId': None, 'publication_year': 2001, 'abstract': None}
{'title': 'Reuters-21578 Text Categorization Test Collection, Distribution 1.0', 'paperID': '5833aa3ab163bf57a969b74ff3c3a66babe19fa1', 'arxivId': None, 'publication_year': 1997, 'abstract': None}
{'title': 'Analysis of and on uniformly rectifiable sets', 'paperID': '1f6921bd11f8a37e56049e68fc584417bb10c7ba', 'arxivId': None, 'publication_year': 1993, 'abstract': None}
{'title': 'Robust Subspace Recovery Layer for Unsupervised Anomaly Detection', 'paperID': '3a2ef5c27e7140f819a4c99444b7d4fd533dca59', 'arxivId': '1904.00152', 'publication_year': '2019', 'abstract': 'We propose a neural network for unsupervised anomaly detection with a novel robust subspace recovery layer (RSR layer). This layer seeks to extract the underlying subspace from a latent representation of the given data and removes outliers that lie away from this subspace. It is used within an autoencoder. The encoder maps the data into a latent space, from which the RSR layer extracts the subspace. The decoder then smoothly maps back the underlying subspace to a "manifold" close to the original inliers. Inliers and outliers are distinguished according to the distances between the original and mapped positions (small for inliers and large for outliers). Extensive numerical experiments with both image and document datasets demonstrate state-of-the-art precision and recall.'}
{'title': 'Efficiently Breaking the Curse of Horizon: Double Reinforcement Learning in Infinite-Horizon Processes', 'paperID': '035c298e77b21968425eb44598c0516b1efbe4be', 'arxivId': None, 'publication_year': 2019, 'abstract': None}
{'title': 'Double Reinforcement Learning for Efficient Off-Policy Evaluation in Markov Decision Processes', 'paperID': '25a7b8c2e110a1bcd5c42ab5de55a0c08b0b8846', 'arxivId': '1908.08526', 'publication_year': 2019, 'abstract': None}
{'title': 'Optimal Off-Policy Evaluation for Reinforcement Learning with Marginalized Importance Sampling', 'paperID': '4708b886a622a821f64d1be30638b78a7dbeb64e', 'arxivId': '1906.03393', 'publication_year': 2019, 'abstract': None}
{'title': 'DualDICE: Behavior-Agnostic Estimation of Discounted Stationary Distribution Corrections', 'paperID': '875280d96b2f138902061ae6409249ee4ded0da3', 'arxivId': '1906.04733', 'publication_year': 2019, 'abstract': None}
{'title': 'A Kernel Loss for Solving the Bellman Equation', 'paperID': '197cd4b7cd242243b5e8fc48ee08828882c930a1', 'arxivId': '1905.10506', 'publication_year': 2019, 'abstract': None}
{'title': 'Off-Policy Policy Gradient with Stationary Distribution Correction', 'paperID': '922c32ccc83b9054df2bbef7e81e20e8edca1605', 'arxivId': '1904.08473', 'publication_year': 2019, 'abstract': None}
{'title': 'Off-Policy Deep Reinforcement Learning by Bootstrapping the Covariate Shift', 'paperID': 'dc4ec37102afb166b96abc268ae3dc15e230d776', 'arxivId': '1901.09455', 'publication_year': 2019, 'abstract': None}
{'title': 'Breaking the Curse of Horizon: Infinite-Horizon Off-Policy Estimation', 'paperID': 'e81ea45d8bec329fdb11fd84990852f620895d6f', 'arxivId': '1810.12429', 'publication_year': 2018, 'abstract': None}
{'title': 'Importance Sampling Policy Evaluation with an Estimated Behavior Policy', 'paperID': 'dbba10eb7fb37626ea554cf7f64ef514ddd642be', 'arxivId': '1806.01347', 'publication_year': 2018, 'abstract': None}
{'title': 'Representation Balancing MDPs for Off-Policy Policy Evaluation', 'paperID': '4382b7abb3bda846cb999ce60f6858ecb56acd4e', 'arxivId': '1805.09044', 'publication_year': 2018, 'abstract': None}
{'title': 'More Robust Doubly Robust Off-policy Evaluation', 'paperID': 'd7b32bf240bb3b2f2a98d87ea21b669226e0f9d8', 'arxivId': '1802.03493', 'publication_year': 2018, 'abstract': None}
{'title': 'SBEED: Convergent Reinforcement Learning with Nonlinear Function Approximation', 'paperID': '1bd66197d692581f4ac507107184ca9110b61d7d', 'arxivId': None, 'publication_year': 2017, 'abstract': None}
{'title': 'Smoothed Dual Embedding Control', 'paperID': '5fd8f4d7bcea08e15229a6d0b6ba1bc11d44f348', 'arxivId': '1712.10285', 'publication_year': 2017, 'abstract': None}
{'title': 'Using Options and Covariance Testing for Long Horizon Off-Policy Policy Evaluation', 'paperID': '00d6c4aa261fb3fb4e8e76997bce91f9336f250f', 'arxivId': None, 'publication_year': 2017, 'abstract': None}
{'title': 'Consistent On-Line Off-Policy Evaluation', 'paperID': 'ba847beb3ed679ff56d0414c04748de88ed46af9', 'arxivId': '1702.07121', 'publication_year': 2017, 'abstract': None}
{'title': 'Predictive Off-Policy Policy Evaluation for Nonstationary Decision Problems, with Applications to Digital Marketing', 'paperID': '1f81de57298677c98736d8b6f6736a279c75cc35', 'arxivId': None, 'publication_year': 2017, 'abstract': None}
{'title': 'Stochastic Primal-Dual Methods and Sample Complexity of Reinforcement Learning', 'paperID': '2c2bed7759d817b023732b6e9b5d11911ea49dd5', 'arxivId': '1612.02516', 'publication_year': 2016, 'abstract': None}
{'title': 'Optimal and Adaptive Off-policy Evaluation in Contextual Bandits', 'paperID': '117f12f75cfe4d5705d7beabbe961b2ced0d7025', 'arxivId': '1612.01205', 'publication_year': 2016, 'abstract': None}
{'title': 'Learning from Conditional Distributions via Dual Kernel Embeddings', 'paperID': 'd402ec2bd0ab0e5399b71f75076d589df914a4e3', 'arxivId': '1607.04579', 'publication_year': 2016, 'abstract': None}
{'title': 'Data-Efficient Off-Policy Policy Evaluation for Reinforcement Learning', 'paperID': 'ec8a2f6cfe72309f5f1608d22ec28778d3ee976a', 'arxivId': '1604.00923', 'publication_year': 2016, 'abstract': None}
{'title': 'Doubly Robust Off-policy Value Evaluation for Reinforcement Learning', 'paperID': '2fdb536da39a014c598ea67b0db88431fcd852a8', 'arxivId': '1511.03722', 'publication_year': 2015, 'abstract': None}
{'title': 'Finite-Sample Analysis of Proximal Gradient TD Algorithms', 'paperID': 'fc71c22a316ee4d8cbf27fabf5b4c0c9041c43cc', 'arxivId': '2006.14364', 'publication_year': 2015, 'abstract': None}
{'title': 'Toward Minimax Off-policy Value Estimation', 'paperID': '15b15083809a1a951d63821a21cbbc12af8dddef', 'arxivId': None, 'publication_year': 2015, 'abstract': None}
{'title': 'Batch mode reinforcement learning based on the synthesis of artificial trajectories', 'paperID': '139a945f22e53a6c2eab19105f3ab0c7a67f68bd', 'arxivId': None, 'publication_year': 2013, 'abstract': None}
{'title': 'Counterfactual reasoning and learning systems: the example of computational advertising', 'paperID': 'b006aefa9c8be8c33138c4c5352f4d2d44378be9', 'arxivId': '1209.2355', 'publication_year': 2012, 'abstract': None}
{'title': 'Doubly Robust Policy Evaluation and Learning', 'paperID': '5ccf7658018981bf492d0c8d66277d22ebaac815', 'arxivId': '1103.4601', 'publication_year': 2011, 'abstract': None}
{'title': 'Unbiased offline evaluation of contextual-bandit-based news article recommendation algorithms', 'paperID': 'd6554953543050bba991c58dc637f10fc2474e6e', 'arxivId': '1003.5956', 'publication_year': 2010, 'abstract': None}
{'title': 'Learning from Logged Implicit Exploration Data', 'paperID': '28886248acf75e7b1cca167669161d9d214ed662', 'arxivId': '1003.0120', 'publication_year': 2010, 'abstract': None}
{'title': 'Stochastic Simulation: Algorithms and Analysis', 'paperID': '7e348097aba114157dfbd649bca0c59b981deb59', 'arxivId': None, 'publication_year': 2007, 'abstract': None}
{'title': 'Markov Decision Processes', 'paperID': 'b2db5541059288472ca246acdca6ead949326864', 'arxivId': None, 'publication_year': 2004, 'abstract': None}
{'title': 'The Linear Programming Approach to Approximate Dynamic Programming', 'paperID': '8a14ac38f66996913c4d7f3a3141294a602fd8f3', 'arxivId': None, 'publication_year': 2003, 'abstract': None}
{'title': 'Monte Carlo Strategies in Scientific Computing', 'paperID': '47ba51a5913a6f2be8ab874a5f2d246735c89614', 'arxivId': None, 'publication_year': 2002, 'abstract': None}
{'title': 'Marginal Mean Models for Dynamic Regimes', 'paperID': '2edf95e2c4323783731c388b33ba79bb72faa5d8', 'arxivId': None, 'publication_year': 2001, 'abstract': None}
{'title': 'Dynamic Programming and Optimal Control', 'paperID': 'a82db864e472b5aa6313596ef9919f64e3363b1f', 'arxivId': None, 'publication_year': 1995, 'abstract': None}
{'title': 'Markov Decision Processes: Discrete Stochastic Dynamic Programming', 'paperID': '8090121ad488b4af27bc59bf91b62e9c6a6f49c6', 'arxivId': None, 'publication_year': 1994, 'abstract': None}
{'title': 'Optimal and Adaptive Off-policy Evaluation in Contextual Bandits', 'paperID': '4217bf521e0ffb4b2a36673478caa29c223a2b84', 'arxivId': None, 'publication_year': 2017, 'abstract': None}
{'title': 'Doubly Robust Off-policy Evaluation for Reinforcement Learning', 'paperID': 'e5309d90535f7f798ef8482e2450f78900a53651', 'arxivId': None, 'publication_year': 2015, 'abstract': None}
{'title': 'Monte Carlo strategies in scientific computing', 'paperID': 'b907404e5676c338f25592e582abd91a4b2ef2c2', 'arxivId': None, 'publication_year': 2001, 'abstract': None}
{'title': 'A linear programming approach', 'paperID': '142ec0ed30a36cd247cc14c2f303eaf5eb63df53', 'arxivId': None, 'publication_year': 1977, 'abstract': None}
{'title': 'Doubly Robust Bias Reduction in Infinite Horizon Off-Policy Estimation', 'paperID': 'c2c5d4650beb72a0e00a4c384064f4ab2ddef1dc', 'arxivId': '1910.07186', 'publication_year': '2019', 'abstract': 'Infinite horizon off-policy policy evaluation is a highly challenging task due to the excessively large variance of typical importance sampling (IS) estimators. Recently, Liu et al. (2018a) proposed an approach that significantly reduces the variance of infinite-horizon off-policy evaluation by estimating the stationary density ratio, but at the cost of introducing potentially high biases due to the error in density ratio estimation. In this paper, we develop a bias-reduced augmentation of their method, which can take advantage of a learned value function to obtain higher accuracy. Our method is doubly robust in that the bias vanishes when either the density ratio or the value function estimation is perfect. In general, when either of them is accurate, the bias can also be reduced. Both theoretical and empirical results show that our method yields significant advantages over previous methods.'}
{'title': 'Towards Query-Efficient Black-Box Adversary with Zeroth-Order Natural Gradient Descent', 'paperID': 'aa647f298e43192a479d5c70b4378a58ca1e2333', 'arxivId': '2002.07891', 'publication_year': 2020, 'abstract': None}
{'title': 'On the Design of Black-Box Adversarial Examples by Leveraging Gradient-Free Optimization and Operator Splitting Method', 'paperID': 'f91d9aec51826e85050029ca15f0ba391534c83e', 'arxivId': '1907.11684', 'publication_year': 2019, 'abstract': None}
{'title': 'Fault Sneaking Attack: a Stealthy Framework for Misleading Deep Neural Networks', 'paperID': '549180d76bc15ec3fcb9fa0e34d06bf7173faa6b', 'arxivId': '1905.12032', 'publication_year': 2019, 'abstract': None}
{'title': 'BadNets: Evaluating Backdooring Attacks on Deep Neural Networks', 'paperID': 'bd4336b6015d4d680a27c25a0ed296df5692ddf1', 'arxivId': None, 'publication_year': 2019, 'abstract': None}
{'title': 'Neural Cleanse: Identifying and Mitigating Backdoor Attacks in Neural Networks', 'paperID': '42658c812d60d26a0bdad91b4d81e8620b994bf6', 'arxivId': None, 'publication_year': 2019, 'abstract': None}
{'title': 'Robustness via Curvature Regularization, and Vice Versa', 'paperID': '5ae786deaa875613e85ed2df0dbeec4301109f74', 'arxivId': '1811.09716', 'publication_year': 2018, 'abstract': None}
{'title': 'Detecting Backdoor Attacks on Deep Neural Networks by Activation Clustering', 'paperID': '633ccadcde3bfca87f91bfe5ef4aa297fb2da2f4', 'arxivId': '1811.03728', 'publication_year': 2018, 'abstract': None}
{'title': 'Defending DNN Adversarial Attacks with Pruning and Logits Augmentation', 'paperID': '77030ffbd1119bf98614459bc087a8a59ce5697d', 'arxivId': None, 'publication_year': 2018, 'abstract': None}
{'title': 'Spectral Signatures in Backdoor Attacks', 'paperID': '71f212b84e8f784bb2c17bf9e2415b0b780f2e73', 'arxivId': '1811.00636', 'publication_year': 2018, 'abstract': None}
{'title': 'Towards Robust Deep Neural Networks', 'paperID': '67c6a88a877b195e99b655197dc75f54ca2fca1a', 'arxivId': '1810.11726', 'publication_year': 2018, 'abstract': None}
{'title': 'Limitations of adversarial robustness: strong No Free Lunch Theorem', 'paperID': '1d8d6c71a9dd22c8e5f82e42afb8fec3c31e1fc8', 'arxivId': '1810.04065', 'publication_year': 2018, 'abstract': None}
{'title': 'Interpreting Adversarial Robustness: A View from Decision Surface in Input Space', 'paperID': '28fdcbe150096451521240371fc5978c4f124afe', 'arxivId': '1810.00144', 'publication_year': 2018, 'abstract': None}
{'title': 'Identifying Generalization Properties in Neural Networks', 'paperID': '5a40a8d27d37948dae9ab62337dc6ec492caa611', 'arxivId': '1809.07402', 'publication_year': 2018, 'abstract': None}
{'title': 'Defensive dropout for hardening deep neural networks under adversarial attacks', 'paperID': '98ebd263571748a30eb99d9b9d58bc0519be09ea', 'arxivId': '1809.05165', 'publication_year': 2018, 'abstract': None}
{'title': 'Structured Adversarial Attack: Towards General Implementation and Better Interpretability', 'paperID': '5bc67a8a47c796053d5ed77aaecd3cbbd4c5d4c1', 'arxivId': '1808.01664', 'publication_year': 2018, 'abstract': None}
{'title': 'Is Robustness the Cost of Accuracy? - A Comprehensive Study on the Robustness of 18 Deep Image Classification Models', 'paperID': '821fd5bed14d6d06c25fbf44123fd7be382f7b4e', 'arxivId': '1808.01688', 'publication_year': 2018, 'abstract': None}
{'title': 'Using Mode Connectivity for Loss Landscape Analysis', 'paperID': '289f58af35a5a7509cd8addeb450d45a2dc86bad', 'arxivId': '1806.06977', 'publication_year': 2018, 'abstract': None}
{'title': 'Empirical Study of the Topology and Geometry of Deep Networks', 'paperID': 'e5b4a134836f376fc368fb8cdb194c8ca2a8828e', 'arxivId': None, 'publication_year': 2018, 'abstract': None}
{'title': 'Adversarial examples from computational constraints', 'paperID': 'ba4883eafede39be6494a80c8b999abc46fa6b5e', 'arxivId': '1805.10204', 'publication_year': 2018, 'abstract': None}
{'title': 'An ADMM-Based Universal Framework for Adversarial Attacks on Deep Neural Networks', 'paperID': 'ab2f8be8cd0474b3ab2c77b1bfeee25f25cad076', 'arxivId': '1804.03193', 'publication_year': 2018, 'abstract': None}
{'title': 'Manipulating Machine Learning: Poisoning Attacks and Countermeasures for Regression Learning', 'paperID': 'efd7b7aafeb83b8a8d6fd90a35d6fb6a62f5f695', 'arxivId': '1804.00308', 'publication_year': 2018, 'abstract': None}
{'title': 'Poison Frogs! Targeted Clean-Label Poisoning Attacks on Neural Networks', 'paperID': 'c6d4ef1a98b1b9e5875b79efd3ef2a73403a0884', 'arxivId': '1804.00792', 'publication_year': 2018, 'abstract': None}
{'title': 'Essentially No Barriers in Neural Network Energy Landscape', 'paperID': '2c90d366126a3ccd3c43e47891730650003059da', 'arxivId': '1803.00885', 'publication_year': 2018, 'abstract': None}
{'title': 'Loss Surfaces, Mode Connectivity, and Fast Ensembling of DNNs', 'paperID': 'f6195d8dc6aad8231e97b563246f2585842bc68b', 'arxivId': '1802.10026', 'publication_year': 2018, 'abstract': None}
{'title': 'Wild Patterns: Ten Years After the Rise of Adversarial Machine Learning', 'paperID': '2c20e7220269b28fb1935a83d0e7f2db330aa691', 'arxivId': '1712.03141', 'publication_year': 2017, 'abstract': None}
{'title': 'Fault injection attack on deep neural network', 'paperID': '900d130f25f453948fedf7df5faf4ab710fb5e94', 'arxivId': None, 'publication_year': 2017, 'abstract': None}
{'title': 'The Robustness of Deep Networks: A Geometrical Perspective', 'paperID': '8f1dc314680ab0e2b780c093546395b499bb2b67', 'arxivId': None, 'publication_year': 2017, 'abstract': None}
{'title': 'Towards Understanding Generalization of Deep Learning: Perspective of Loss Landscapes', 'paperID': '33472f3b55747e8aa36f4db57070de1e0e321218', 'arxivId': '1706.10239', 'publication_year': 2017, 'abstract': None}
{'title': 'Drammer: Deterministic Rowhammer Attacks on Mobile Platforms', 'paperID': '2612541a89857949bc512b6fb2ad7f0c153cb97c', 'arxivId': None, 'publication_year': 2016, 'abstract': None}
{'title': 'Pruning Filters for Efficient ConvNets', 'paperID': 'c2a1cb1612ba21e067a5c3ba478a8d73b796b77a', 'arxivId': '1608.08710', 'publication_year': 2016, 'abstract': None}
{'title': 'Transferability in Machine Learning: from Phenomena to Black-Box Attacks using Adversarial Samples', 'paperID': '78aa018ee7d52360e15d103390ea1cdb3a0beb41', 'arxivId': '1605.07277', 'publication_year': 2016, 'abstract': None}
{'title': 'Practical Black-Box Attacks against Machine Learning', 'paperID': '53b047e503f4c24602f376a774d653f7ed56c024', 'arxivId': '1602.02697', 'publication_year': 2016, 'abstract': None}
{'title': 'The Bernstein polynomial basis: A centennial retrospective', 'paperID': '0ad3053eb32ecc5a13d9a6aa868b5c86c5663372', 'arxivId': None, 'publication_year': 2012, 'abstract': None}
{'title': 'Poisoning Attacks against Support Vector Machines', 'paperID': '990a02f20529f5ce3b382f1d54648afaab391179', 'arxivId': '1206.6389', 'publication_year': 2012, 'abstract': None}
{'title': 'Computer Graphics: Theory and Practice', 'paperID': '3866fe85f6d7d1f38e6d6d4f112b51e03ab0c68b', 'arxivId': None, 'publication_year': 2012, 'abstract': None}
{'title': 'Fault Injection Attacks on Cryptographic Devices: Theory, Practice, and Countermeasures', 'paperID': 'cead00c7b3384653ce8013139a5d4543d96fcd07', 'arxivId': None, 'publication_year': 2012, 'abstract': None}
{'title': 'Trojaning Attack on Neural Networks', 'paperID': '08f7ac64b420210aa46fcbbdb0f206215f2e0644', 'arxivId': None, 'publication_year': 2018, 'abstract': None}
{'title': 'Training Deep and Recurrent Networks with Hessian-Free Optimization', 'paperID': 'f2a0fbba89f0d18ea0abd29639d4e43babe59cf3', 'arxivId': None, 'publication_year': 2012, 'abstract': None}
{'title': 'Bridging Mode Connectivity in Loss Landscapes and Adversarial Robustness', 'paperID': 'dc0def651f7ff53d7b3d764924b5c2c28024cdd7', 'arxivId': '2005.00060', 'publication_year': '2020', 'abstract': 'Mode connectivity provides novel geometric insights on analyzing loss landscapes and enables building high-accuracy pathways between well-trained neural networks. In this work, we propose to employ mode connectivity in loss landscapes to study the adversarial robustness of deep neural networks, and provide novel methods for improving this robustness. Our experiments cover various types of adversarial attacks applied to different network architectures and datasets. When network models are tampered with backdoor or error-injection attacks, our results demonstrate that the path connection learned using limited amount of bonafide data can effectively mitigate adversarial effects while maintaining the original accuracy on clean data. Therefore, mode connectivity provides users with the power to repair backdoored or error-injected models. We also use mode connectivity to investigate the loss landscapes of regular and robust models against evasion attacks. Experiments show that there exists a barrier in adversarial robustness loss on the path connecting regular and adversarially-trained models. A high correlation is observed between the adversarial robustness loss and the largest eigenvalue of the input Hessian matrix, for which theoretical justifications are provided. Our results suggest that mode connectivity offers a holistic tool and practical means for evaluating and improving adversarial robustness.'}
{'title': 'Robustness to Modification with Shared Words in Paraphrase Identification', 'paperID': '46f2c91124681b9a2653249efc058453c476dd75', 'arxivId': None, 'publication_year': 2019, 'abstract': None}
{'title': 'Adversarial Examples with Difficult Common Words for Paraphrase Identification', 'paperID': '8974985efa379dd03be434c6a2958e6563b0b6ab', 'arxivId': '1909.02560', 'publication_year': 2019, 'abstract': None}
{'title': 'VL-BERT: Pre-training of Generic Visual-Linguistic Representations', 'paperID': '2527626c11a84f15709e943fbfa2356e19930e3b', 'arxivId': '1908.08530', 'publication_year': 2019, 'abstract': None}
{'title': 'VisualBERT: A Simple and Performant Baseline for Vision and Language', 'paperID': '5aec474c31a2f4b74703c6f786c0a8ff85c450da', 'arxivId': '1908.03557', 'publication_year': 2019, 'abstract': None}
{'title': 'RoBERTa: A Robustly Optimized BERT Pretraining Approach', 'paperID': '077f8329a7b6fa3b7c877a57b81eb6c18b5f87de', 'arxivId': '1907.11692', 'publication_year': 2019, 'abstract': None}
{'title': 'Art: Abstraction Refinement-Guided Training for Provably Correct Neural Networks', 'paperID': '3608b958ced869c674877e3cba03f7b04befa775', 'arxivId': '1907.10662', 'publication_year': 2019, 'abstract': None}
{'title': 'Verification of RNN-Based Neural Agent-Environment Systems', 'paperID': 'd8d4cb8e8893b3ddb940134083582566d45da22e', 'arxivId': None, 'publication_year': 2019, 'abstract': None}
{'title': 'On the Robustness of Self-Attentive Models', 'paperID': 'b66a943dd745c0868d03144d60b7cd2aeb3c2ba7', 'arxivId': None, 'publication_year': 2019, 'abstract': None}
{'title': 'XLNet: Generalized Autoregressive Pretraining for Language Understanding', 'paperID': 'e0c6abdbdecf04ffac65c440da77fb9d66bb474c', 'arxivId': '1906.08237', 'publication_year': 2019, 'abstract': None}
{'title': 'Correctness Verification of Neural Networks', 'paperID': 'dd9d4111e218628954047be0f315fa61be108806', 'arxivId': '1906.01030', 'publication_year': 2019, 'abstract': None}
{'title': 'POPQORN: Quantifying Robustness of Recurrent Neural Networks', 'paperID': 'cb60351c4e2f9f244bcbed2eb44cdce86a029b4b', 'arxivId': '1905.07387', 'publication_year': 2019, 'abstract': None}
{'title': 'Semi-Supervised Graph Classification: A Hierarchical Graph Perspective', 'paperID': 'ef1ca41cc6ed1b34cfe3d34a6150912cfc5aed3b', 'arxivId': '1904.05003', 'publication_year': 2019, 'abstract': None}
{'title': 'Verifying Aircraft Collision Avoidance Neural Networks Through Linear Approximations of Safe Regions', 'paperID': '210fcca62c05e84d660330fbe1c2648ab0984154', 'arxivId': '1903.00762', 'publication_year': 2019, 'abstract': None}
{'title': 'A Convex Relaxation Barrier to Tight Robustness Verification of Neural Networks', 'paperID': '5473175211aff4a8a099c44d1a57802d1b7ecf9e', 'arxivId': '1902.08722', 'publication_year': 2019, 'abstract': None}
{'title': 'Verification of Non-Linear Specifications for Neural Networks', 'paperID': 'ad640ea420d49a969a995632aed22c21251891df', 'arxivId': '1902.09592', 'publication_year': 2019, 'abstract': None}
{'title': 'An abstract domain for certifying neural networks', 'paperID': 'f20de741e2d4ece239261de010d6d9beca3b26b9', 'arxivId': None, 'publication_year': 2019, 'abstract': None}
{'title': 'Verification of Recurrent Neural Networks Through Rule Extraction', 'paperID': '44d7b5a66faeaccd7d3e2c36a3b51f4f13f73f4e', 'arxivId': '1811.06029', 'publication_year': 2018, 'abstract': None}
{'title': 'Efficient Neural Network Robustness Certification with General Activation Functions', 'paperID': '2a7d19594e07e9f5f40eb39f19b0e5ffa6aa5df9', 'arxivId': '1811.00866', 'publication_year': 2018, 'abstract': None}
{'title': 'RecurJac: An Efficient Recursive Algorithm for Bounding Jacobian Matrix of Neural Networks and Its Applications', 'paperID': 'f7f1b5437b9c97d67fae59142b242ce079d7cb08', 'arxivId': '1810.11783', 'publication_year': 2018, 'abstract': None}
{'title': 'Efficient Formal Safety Analysis of Neural Networks', 'paperID': '98cc371f4e3a39b5c69b4e8980a5990f9011f223', 'arxivId': '1809.08098', 'publication_year': 2018, 'abstract': None}
{'title': 'Self-Attentive Sequential Recommendation', 'paperID': '97faeefa771e8cc8e55159e2bd03e6f5eef249a8', 'arxivId': '1808.09781', 'publication_year': 2018, 'abstract': None}
{'title': 'AI2: Safety and Robustness Certification of Neural Networks with Abstract Interpretation', 'paperID': 'd21fde0f55ee0285c66334d37b8920c867959784', 'arxivId': None, 'publication_year': 2018, 'abstract': None}
{'title': 'A Symbolic Approach to Explaining Bayesian Network Classifiers', 'paperID': 'a8cb3df07c340f47fc0f225282e46757a93ca0d0', 'arxivId': '1805.03364', 'publication_year': 2018, 'abstract': None}
{'title': 'Syllable-Based Sequence-to-Sequence Speech Recognition with the Transformer in Mandarin Chinese', 'paperID': '53dcd6068586d50169877d145df550ff3f568221', 'arxivId': '1804.10752', 'publication_year': 2018, 'abstract': None}
{'title': 'Output Range Analysis for Deep Feedforward Neural Networks', 'paperID': 'd2df6969b185a4017048f996d0e7cd1859c24e67', 'arxivId': None, 'publication_year': 2018, 'abstract': None}
{'title': 'Seq2Sick: Evaluating the Robustness of Sequence-to-Sequence Models with Adversarial Examples', 'paperID': 'fdfbabfd7b3712a4c2cb864ca0ca5c201dfee5a1', 'arxivId': '1803.01128', 'publication_year': 2018, 'abstract': None}
{'title': 'Image Transformer', 'paperID': '1db9bd18681b96473f3c82b21edc9240b44dc329', 'arxivId': '1802.05751', 'publication_year': 2018, 'abstract': None}
{'title': 'Black-Box Generation of Adversarial Text Sequences to Evade Deep Learning Classifiers', 'paperID': 'fa12574c228542151ccd7d4e3f42cc4896cd274a', 'arxivId': '1801.04354', 'publication_year': 2018, 'abstract': None}
{'title': 'Evaluating Robustness of Neural Networks with Mixed Integer Programming', 'paperID': '9de69a46e6c619255eeffbfbb6c7b7163690eb48', 'arxivId': None, 'publication_year': 2017, 'abstract': None}
{'title': 'A Unified View of Piecewise Linear Neural Network Verification', 'paperID': '91f4ebdfb4618e9a7bbcefc8b64e2f7d6e176545', 'arxivId': None, 'publication_year': 2017, 'abstract': None}
{'title': 'Formal Verification of Piece-Wise Linear Feed-Forward Neural Networks', 'paperID': '333416708c80d0c163ca275d1b190b1f2576fa5f', 'arxivId': '1705.01320', 'publication_year': 2017, 'abstract': None}
{'title': 'Crafting adversarial input sequences for recurrent neural networks', 'paperID': '1439e05971a053c2368e6dee6d484b43c833d43c', 'arxivId': '1604.08275', 'publication_year': 2016, 'abstract': None}
{'title': 'Character-level Convolutional Networks for Text Classification', 'paperID': '51a55df1f023571a7e07e338ee45a3e3d66ef73e', 'arxivId': '1509.01626', 'publication_year': 2015, 'abstract': None}
{'title': 'Recursive Deep Models for Semantic Compositionality Over a Sentiment Treebank', 'paperID': '687bac2d3320083eb4530bf18bb8f8f721477600', 'arxivId': None, 'publication_year': 2013, 'abstract': None}
{'title': 'Efficient Neural Network Verification with Exactness Characterization', 'paperID': '42371cfea5154e77a5057cafde7dc00a6446ea16', 'arxivId': None, 'publication_year': 2019, 'abstract': None}
{'title': 'Fast and Effective Robustness Certification', 'paperID': 'bb92676f9ec13783ac664c268191f20944718f95', 'arxivId': None, 'publication_year': 2018, 'abstract': None}
{'title': 'Robustness Verification for Transformers', 'paperID': '6189bf5f4c851ad0217a782509f8818aca4c7ff4', 'arxivId': '2002.06622', 'publication_year': '2020', 'abstract': 'Robustness verification that aims to formally certify the prediction behavior of neural networks has become an important tool for understanding the behavior of a given model and for obtaining safety guarantees. However, previous methods are usually limited to relatively simple neural networks. In this paper, we consider the robustness verification problem for Transformers. Transformers have complex self-attention layers that pose many challenges for verification, including cross-nonlinearity and cross-position dependency, which have not been discussed in previous work. We resolve these challenges and develop the first verification algorithm for Transformers. The certified robustness bounds computed by our method are significantly tighter than those by naive Interval Bound Propagation. These bounds also shed light on interpreting Transformers as they consistently reflect the importance of words in sentiment analysis.'}
{'title': 'Differential Privacy Has Disparate Impact on Model Accuracy', 'paperID': '3b1941105317edaef6ac5995089d6d916e5fb483', 'arxivId': '1905.12101', 'publication_year': 2019, 'abstract': None}
{'title': 'Preserving Differential Privacy in Adversarial Learning with Provable Robustness', 'paperID': 'b5c93d5438fcd0f21b5cb0b962e392545671e71c', 'arxivId': '1903.09822', 'publication_year': 2019, 'abstract': None}
{'title': 'Kitsune: An Ensemble of Autoencoders for Online Network Intrusion Detection', 'paperID': 'fa11df1157486731afe86af7d6d9254a82d4dbd6', 'arxivId': '1802.09089', 'publication_year': 2018, 'abstract': None}
{'title': 'The Secret Sharer: Evaluating and Testing Unintended Memorization in Neural Networks', 'paperID': '520ec00dc35475e0554dbb72f27bd2eeb6f4191d', 'arxivId': '1802.08232', 'publication_year': 2018, 'abstract': None}
{'title': 'The Secret Sharer: Measuring Unintended Neural Network Memorization & Extracting Secrets', 'paperID': 'f9313ada269360c9faa74385d966122e5a20e69a', 'arxivId': None, 'publication_year': 2018, 'abstract': None}
{'title': 'Certified Robustness to Adversarial Examples with Differential Privacy', 'paperID': '3e86a51d1f2051ab8f448b66c6dcc17924d17cfa', 'arxivId': '1802.03471', 'publication_year': 2018, 'abstract': None}
{'title': 'DeepLog: Anomaly Detection and Diagnosis from System Logs through Deep Learning', 'paperID': 'fefeded74334e5eafa47c5df6de2837fe3b7502d', 'arxivId': None, 'publication_year': 2017, 'abstract': None}
{'title': 'Machine Learning Models that Remember Too Much', 'paperID': '18cfd4b9e35fb12fbebedb0fdc3f7811090372bf', 'arxivId': '1709.07886', 'publication_year': 2017, 'abstract': None}
{'title': 'AutoPerf: A Generalized Zero-Positive Learning System to Detect Software Performance Anomalies', 'paperID': 'fb6409e86fbd27f65b6fbbf7a448a1be958bd206', 'arxivId': None, 'publication_year': 2017, 'abstract': None}
{'title': 'AutoCon: Regression Testing for Detecting Cache Contention Anomalies Using Autoencoder', 'paperID': '64ed3a3af683ddf2619173dda156e741c1fb277f', 'arxivId': None, 'publication_year': 2017, 'abstract': None}
{'title': 'Privacy Risk in Machine Learning: Analyzing the Connection to Overfitting', 'paperID': 'c8f216f663660ff3bc195ecd3a8ad61f0ed1d9d7', 'arxivId': None, 'publication_year': 2017, 'abstract': None}
{'title': 'BadNets: Identifying Vulnerabilities in the Machine Learning Model Supply Chain', 'paperID': '573fd2ce97c70bb29097e8efb28a27af791225ca', 'arxivId': '1708.06733', 'publication_year': 2017, 'abstract': None}
{'title': 'Deep Learning with Differential Privacy', 'paperID': 'e9a986c8ff6c2f381d026fe014f6aaa865f34da7', 'arxivId': '1607.00133', 'publication_year': 2016, 'abstract': None}
{'title': 'On the evaluation of unsupervised outlier detection: measures, datasets, and an empirical study', 'paperID': '04c159a99bd8083b2b609d9b39611a57a4114553', 'arxivId': None, 'publication_year': 2016, 'abstract': None}
{'title': 'Differentially Private Analysis of Outliers', 'paperID': 'e3ab07e76fd97a6014332a8a0ffa09af02696a8e', 'arxivId': '1507.06763', 'publication_year': 2015, 'abstract': None}
{'title': 'Preserving Statistical Validity in Adaptive Data Analysis', 'paperID': '8963b5c1a754741d6599b95e47818fe3b79a6a51', 'arxivId': '1411.2664', 'publication_year': 2014, 'abstract': None}
{'title': 'The Algorithmic Foundations of Differential Privacy', 'paperID': '0023582fde36430c7e3ae81611a14e558c8f4bae', 'arxivId': None, 'publication_year': 2014, 'abstract': None}
{'title': 'Ensembles for unsupervised outlier detection: challenges and research questions a position paper', 'paperID': '36445111c9f9eb6763fedab5294aca792519f925', 'arxivId': None, 'publication_year': 2014, 'abstract': None}
{'title': 'Semi-Supervised Novelty Detection Using SVM Entire Solution Path', 'paperID': 'e6f273cbb59d882c7690413dba22dbcbd7c9b64e', 'arxivId': None, 'publication_year': 2013, 'abstract': None}
{'title': 'A survey on unsupervised outlier detection in high‐dimensional numerical data', 'paperID': 'b65fc8f5e7329f0476bc7280f0ef6b91a8c8484b', 'arxivId': None, 'publication_year': 2012, 'abstract': None}
{'title': 'Boosting and Differential Privacy', 'paperID': 'f8558a09553fc35415b271019be9f7d44354073e', 'arxivId': None, 'publication_year': 2010, 'abstract': None}
{'title': 'Mining Invariants from Console Logs for System Problem Detection', 'paperID': '852094207ef6083d807a5215028e46e50685acbb', 'arxivId': None, 'publication_year': 2010, 'abstract': None}
{'title': 'Semi-Supervised Novelty Detection', 'paperID': 'd612d7c21d4130a457968273d79c2c2f6946953d', 'arxivId': None, 'publication_year': 2010, 'abstract': None}
{'title': 'Detecting large-scale system problems by mining console logs', 'paperID': 'c1e25bb0c3d0c3a8c3b2bf8e9735a9aadc175b45', 'arxivId': None, 'publication_year': 2009, 'abstract': None}
{'title': 'Cluster-based outlier detection', 'paperID': '9cc44c3c3b57cbb95b356bde75985e12ae3ced67', 'arxivId': None, 'publication_year': 2009, 'abstract': None}
{'title': 'Differential Privacy: A Survey of Results', 'paperID': '70fda5147aedd42c64143a464117b5ffde18a2e4', 'arxivId': None, 'publication_year': 2008, 'abstract': None}
{'title': 'What Can We Learn Privately?', 'paperID': '8c23ea0ed7badd70a8e26dcea73f2d673cc0c74d', 'arxivId': '0803.0924', 'publication_year': 2008, 'abstract': None}
{'title': 'Kernel PCA for novelty detection', 'paperID': '27222787908c3a1c6fb6c4b5cb5ef8b2542f1b3c', 'arxivId': None, 'publication_year': 2007, 'abstract': None}
{'title': 'Differential Privacy', 'paperID': '2618dbd8bc6bc401fbc202342c00cd2ffefcbe4f', 'arxivId': None, 'publication_year': 2006, 'abstract': None}
{'title': 'Novelty detection: a review - part 1: statistical approaches', 'paperID': '59bb8d6c3eec8f925710db4d2488e2a23167d3e8', 'arxivId': None, 'publication_year': 2003, 'abstract': None}
{'title': 'Novelty detection: a review - part 2: : neural network based approaches', 'paperID': 'ba10c37a6a24276f5e67a22a71d0d511c01cf5e1', 'arxivId': None, 'publication_year': 2003, 'abstract': None}
{'title': 'Stability and Generalization', 'paperID': '53f2bf254c530c4412a8892896422511bc2cee45', 'arxivId': None, 'publication_year': 2002, 'abstract': None}
{'title': 'Outlier detection for high dimensional data', 'paperID': '96bc069f7734c062cd9a15ba686ef3a444bfb914', 'arxivId': None, 'publication_year': 2001, 'abstract': None}
{'title': 'Metrics', 'paperID': '9f9829038c1374f34143e77dd42ea469e8c145ac', 'arxivId': None, 'publication_year': 2005, 'abstract': None}
{'title': 'A Survey of Outlier Detection Methodologies', 'paperID': '7e2fd9c6205613c4858b36ebb4e1b655d915c099', 'arxivId': None, 'publication_year': 2004, 'abstract': None}
{'title': 'Robust anomaly detection and backdoor attack detection via differential privacy', 'paperID': '7ad9822c1de2b61708b803e8a0a548718cefdeb5', 'arxivId': '1911.07116', 'publication_year': '2019', 'abstract': 'Outlier detection and novelty detection are two important topics for anomaly detection. Suppose the majority of a dataset are drawn from a certain distribution, outlier detection and novelty detection both aim to detect data samples that do not fit the distribution. Outliers refer to data samples within this dataset, while novelties refer to new samples. In the meantime, backdoor poisoning attacks for machine learning models are achieved through injecting poisoning samples into the training dataset, which could be regarded as "outliers" that are intentionally added by attackers. Differential privacy has been proposed to avoid leaking any individual\'s information, when aggregated analysis is performed on a given dataset. It is typically achieved by adding random noise, either directly to the input dataset, or to intermediate results of the aggregation mechanism. In this paper, we demonstrate that applying differential privacy can improve the utility of outlier detection and novelty detection, with an extension to detect poisoning samples in backdoor attacks. We first present a theoretical analysis on how differential privacy helps with the detection, and then conduct extensive experiments to validate the effectiveness of differential privacy in improving outlier detection, novelty detection, and backdoor attack detection.'}
{'title': 'Verification of Neural Network Control Policy Under Persistent Adversarial Perturbation', 'paperID': '00d2739b1b3b4d2fa8ffc090c68225a5e3dd96ef', 'arxivId': '1908.06353', 'publication_year': 2019, 'abstract': None}
{'title': 'Adversarial Policies: Attacking Deep Reinforcement Learning', 'paperID': '6ff50528f3d7c72772f8c0e3f8398f9dd8e06575', 'arxivId': '1905.10615', 'publication_year': 2019, 'abstract': None}
{'title': 'Rigorous Agent Evaluation: An Adversarial Approach to Uncover Catastrophic Failures', 'paperID': '553e6c8a79a24abc554782bfe2c5a0ecb31bbb61', 'arxivId': '1812.01647', 'publication_year': 2018, 'abstract': None}
{'title': 'Deep Reinforcement Learning in a Handful of Trials using Probabilistic Dynamics Models', 'paperID': '56136aa0b2c347cbcf3d50821f310c4253155026', 'arxivId': '1805.12114', 'publication_year': 2018, 'abstract': None}
{'title': 'Distributed Distributional Deterministic Policy Gradients', 'paperID': 'd355e339298fc2ab920688c1709d4ba6476a2bc6', 'arxivId': '1804.08617', 'publication_year': 2018, 'abstract': None}
{'title': 'Model-Ensemble Trust-Region Policy Optimization', 'paperID': '27dfecb6bb0308c7484e13dcaefd5eeebba677d3', 'arxivId': '1802.10592', 'publication_year': 2018, 'abstract': None}
{'title': 'Audio Adversarial Examples: Targeted Attacks on Speech-to-Text', 'paperID': '6a5704ac5fdacb7121a0c02a9be4de2bdc5a40fc', 'arxivId': '1801.01944', 'publication_year': 2018, 'abstract': None}
{'title': 'Recurrent Environment Simulators', 'paperID': 'bb430ec2f25e4a1513073a2a4098cbb942c2e3e0', 'arxivId': '1704.02254', 'publication_year': 2017, 'abstract': None}
{'title': 'Tactics of Adversarial Attack on Deep Reinforcement Learning Agents', 'paperID': '236b40f3144b95cd84779484c8269092122920aa', 'arxivId': '1703.06748', 'publication_year': 2017, 'abstract': None}
{'title': 'One-shot learning of manipulation skills with online dynamics adaptation and neural network priors', 'paperID': '62e11a7ad4096521b8ba1a30c1994648197330d1', 'arxivId': '1509.06841', 'publication_year': 2015, 'abstract': None}
{'title': 'Continuous control with deep reinforcement learning', 'paperID': '024006d4c2a89f7acacc6e4438d156525b60a98f', 'arxivId': '1509.02971', 'publication_year': 2015, 'abstract': None}
{'title': 'A comparison of direct and model-based reinforcement learning', 'paperID': '936a67aad36a9d9a7799237f0499d2f588d6e8ba', 'arxivId': None, 'publication_year': 1997, 'abstract': None}
{'title': 'Toward Evaluating Robustness of Deep Reinforcement Learning with Continuous Control', 'paperID': '6113062a0d646080aa8ec726908fba9406f4eebb', 'arxivId': None, 'publication_year': '2020', 'abstract': 'Deep reinforcement learning has achieved great success in many previously difficult reinforcement learning tasks, yet recent studies show that deep RL agents are also unavoidably susceptible to adversarial perturbations, similar to deep neural networks in classification tasks. Prior works mostly focus on model-free adversarial attacks and agents with discrete actions. In this work, we study the problem of continuous control agents in deep RL with adversarial attacks and propose the first two-step algorithm based on learned model dynamics. Extensive experiments on various MuJoCo domains (Cartpole, Fish, Walker, Humanoid) demonstrate that our proposed framework is much more effective and efficient than model-free based attacks baselines in degrading agent performance as well as driving agents to unsafe states.'}
{'title': 'Adaptive Generation of Unrestricted Adversarial Inputs', 'paperID': '8a67aa574b0c6ee161ecc286506d79f44c43b74d', 'arxivId': None, 'publication_year': 2019, 'abstract': None}
{'title': 'Towards Stable and Efficient Training of Verifiably Robust Neural Networks', 'paperID': 'ff22e140a0423f1cf0595d213f36402668084014', 'arxivId': '1906.06316', 'publication_year': 2019, 'abstract': None}
{'title': 'Provably Robust Deep Learning via Adversarially Trained Smoothed Classifiers', 'paperID': '5812dae376cc07b955244a8e1ce11c3e4b9775ac', 'arxivId': '1906.04584', 'publication_year': 2019, 'abstract': None}
{'title': 'Functional Adversarial Attacks', 'paperID': 'fb38fc75f58cf8e171d59b868b1afbddbb9a28eb', 'arxivId': '1906.00001', 'publication_year': 2019, 'abstract': None}
{'title': 'Generating Realistic Unrestricted Adversarial Inputs using Dual-Objective GAN Training', 'paperID': '1e8a10b781e17234267200880a4dc99c41b0e29c', 'arxivId': '1905.02463', 'publication_year': 2019, 'abstract': None}
{'title': 'Wasserstein Adversarial Examples via Projected Sinkhorn Iterations', 'paperID': '7c0a73771778fa8362c3e3abe7734dc9b1de3c76', 'arxivId': '1902.07906', 'publication_year': 2019, 'abstract': None}
{'title': 'Universal Adversarial Training', 'paperID': '263f845e25c1df3dffbadbee4f17a03fd0cea5dc', 'arxivId': '1811.11304', 'publication_year': 2018, 'abstract': None}
{'title': 'Unrestricted Adversarial Examples', 'paperID': '052252e5d5523e9b6488f0f6022bf3621f44e0be', 'arxivId': '1809.08352', 'publication_year': 2018, 'abstract': None}
{'title': 'Second-Order Adversarial Attack and Certifiable Robustness', 'paperID': '750fd4f2a6139387b4f6245d3fd1013a8c8cf702', 'arxivId': None, 'publication_year': 2018, 'abstract': None}
{'title': 'Maximal Jacobian-based Saliency Map Attack', 'paperID': '769da7360c0c9c199645d9523ec576ad576ea4b3', 'arxivId': '1808.07945', 'publication_year': 2018, 'abstract': None}
{'title': 'Constructing Unrestricted Adversarial Examples with Generative Models', 'paperID': '5023544ad6fa49b35526a62f22207e43c4db870d', 'arxivId': '1805.07894', 'publication_year': 2018, 'abstract': None}
{'title': 'Semantic Adversarial Examples', 'paperID': '48d88124dd89d988386ae452516dbba6c4a96e85', 'arxivId': '1804.00499', 'publication_year': 2018, 'abstract': None}
{'title': 'Exploring the Landscape of Spatial Robustness', 'paperID': '0314e777333a63aca5735ea136c74e113aa8801d', 'arxivId': None, 'publication_year': 2017, 'abstract': None}
{'title': 'Breaking  Certified  Defenses:  Semantic  Adversarial  Examples  With  Spoofed  Robustness  Certificates', 'paperID': '6e635f131c37d481f5b8778c5823a35201876150', 'arxivId': '2003.08937', 'publication_year': '2020', 'abstract': 'Defenses against adversarial attacks can be classified into certified and non-certified. Certifiable defenses make networks robust within a certain $\\ell_p$-bounded radius, so that it is impossible for the adversary to make adversarial examples in the certificate bound. We present an attack that maintains the imperceptibility property of adversarial examples while being outside of the certified radius. Furthermore, the proposed "Shadow Attack" can fool certifiably robust networks by producing an imperceptible adversarial example that gets misclassified and produces a strong ``spoofed\'\' certificate.'}
{'title': 'Can sleep protect memories from catastrophic forgetting?', 'paperID': 'aa2343a94a6ae7cc4e6434801abf03c9feb6bb5f', 'arxivId': None, 'publication_year': 2019, 'abstract': None}
{'title': 'Adversarial Examples: Attacks and Defenses for Deep Learning', 'paperID': '03a507a0876c7e1a26608358b1a9dd39f1eb08e0', 'arxivId': '1712.07107', 'publication_year': 2017, 'abstract': None}
{'title': 'Decision-Based Adversarial Attacks: Reliable Attacks Against Black-Box Machine Learning Models', 'paperID': '1b225474e7a5794f98cdfbde8b12ccbc56799409', 'arxivId': '1712.04248', 'publication_year': 2017, 'abstract': None}
{'title': 'Synthesizing Robust Adversarial Examples', 'paperID': '8dce99e33c6fceb3e79023f5894fdbe733c91e92', 'arxivId': None, 'publication_year': 2017, 'abstract': None}
{'title': 'Foolbox v0.8.0: A Python toolbox to benchmark the robustness of machine learning models', 'paperID': '6114cdf58aa606ceaa998ed883c01c692207d473', 'arxivId': '1707.04131', 'publication_year': 2017, 'abstract': None}
{'title': 'Differential roles of sleep spindles and sleep slow oscillations in memory consolidation', 'paperID': 'a8c6ad02756387456422d4bd1727c0932e8c9b04', 'arxivId': None, 'publication_year': 2017, 'abstract': None}
{'title': 'On classification of distorted images with deep convolutional neural networks', 'paperID': 'eb4d7688cd03f3863a175149f5fa293140f9df30', 'arxivId': '1701.01924', 'publication_year': 2017, 'abstract': None}
{'title': 'Defensive Distillation is Not Robust to Adversarial Examples', 'paperID': '975b6ec05f04662a967af8c7504b7f552a0ee0bd', 'arxivId': '1607.04311', 'publication_year': 2016, 'abstract': None}
{'title': 'Understanding how image quality affects deep neural networks', 'paperID': '2e67d919815a073d1dbc6db3153697578257a28d', 'arxivId': '1604.04004', 'publication_year': 2016, 'abstract': None}
{'title': 'Mastering the game of Go with deep neural networks and tree search', 'paperID': '846aedd869a00c09b40f1f1f35673cb22bc87490', 'arxivId': None, 'publication_year': 2016, 'abstract': None}
{'title': 'Distillation as a Defense to Adversarial Perturbations Against Deep Neural Networks', 'paperID': '6adf016e7531c91100d3cf4a74f5d4c87b26b528', 'arxivId': '1511.04508', 'publication_year': 2015, 'abstract': None}
{'title': 'Learning with a Strong Adversary', 'paperID': '1534867c76db0315c7f50ebc14099940dd860a93', 'arxivId': '1511.03034', 'publication_year': 2015, 'abstract': None}
{'title': 'Fast-classifying, high-accuracy spiking deep networks through weight and threshold balancing', 'paperID': '1cb3a0ff57de3199fe7029db7a1b8bac310fa5f8', 'arxivId': None, 'publication_year': 2015, 'abstract': None}
{'title': "About sleep's role in memory.", 'paperID': 'c201cff713db94cd98fcd1fb1aea2b00e0299307', 'arxivId': None, 'publication_year': 2013, 'abstract': None}
{'title': 'Sleep-dependent memory triage: evolving generalization through selective processing', 'paperID': 'fd3c816a35e8cc14330eeaf5e471c24827a36331', 'arxivId': None, 'publication_year': 2013, 'abstract': None}
{'title': 'Overlapping memory replay during sleep builds cognitive schemata', 'paperID': '3a8cc04d591c9e1c69f8bc9df9bdc5d23cd13ae5', 'arxivId': None, 'publication_year': 2011, 'abstract': None}
{'title': 'A brief nap is beneficial for human route-learning: The role of navigation experience and EEG spectral power.', 'paperID': '83897de64130d56de390eaf2c17e157946284f47', 'arxivId': None, 'publication_year': 2010, 'abstract': None}
{'title': 'The role of sleep in false memory formation', 'paperID': '86c6461f6dfb3e990f0ecf76bbdac58c271be6ba', 'arxivId': None, 'publication_year': 2009, 'abstract': None}
{'title': 'Sleep function and synaptic homeostasis.', 'paperID': 'f15be3dfc68f65090e9a81def42ccfc066bcf558', 'arxivId': None, 'publication_year': 2006, 'abstract': None}
{'title': 'Sleep-dependent memory consolidation', 'paperID': 'bc45769a57087ffceab785bc624b99acf0aa5c7a', 'arxivId': None, 'publication_year': 2005, 'abstract': None}
{'title': 'Competitive Hebbian learning through spike-timing-dependent synaptic plasticity', 'paperID': '77c53d8d539f2b48f7b71d4e2f8041a43b0e1800', 'arxivId': None, 'publication_year': 2000, 'abstract': None}
{'title': 'Reactivation of hippocampal ensemble memories during sleep.', 'paperID': 'c0ac11ca3fd3a63bde616e76d70a44aa859ba3c0', 'arxivId': None, 'publication_year': 1994, 'abstract': None}
{'title': 'Foolbox: A Python toolbox to benchmark the robustness of machine learning models', 'paperID': '59d9318f07331ec15e54fe2a4218bc4a5c247a38', 'arxivId': None, 'publication_year': 2017, 'abstract': None}
{'title': 'Spiking Neural Networks', 'paperID': '0186ae43e8889d5bbc19e3f331d91eedec0ff586', 'arxivId': None, 'publication_year': 2003, 'abstract': None}
{'title': 'Model neurons: From Hodgkin-Huxley to hopfield', 'paperID': '6f8bbdee59216c5506d06558b0629972fcff290c', 'arxivId': None, 'publication_year': 1990, 'abstract': None}
{'title': 'Biologically inspired sleep algorithm for increased generalization and adversarial robustness in deep neural networks', 'paperID': '161446f6c04f0451bf77cfc8550a2e654e056571', 'arxivId': None, 'publication_year': '2020', 'abstract': "Current artificial neural networks (ANNs) can perform and excel at a variety of tasks ranging from image classification to spam detection through training on large datasets of labeled data. While the trained network usually performs well on similar testing data, certain inputs that differ even slightly from the training data may trigger unpredictable behavior. Due to this limitation, it is possible to generate inputs with very small designed perturbations that can result in misclassification. These adversarial attacks present a security risk to deployed ANNs and indicate a divergence between how ANNs and humans perform classification. Humans are robust at behaving in the presence of noise and are capable of correctly classifying objects that are occluded, blurred, or otherwise distorted. It has been hypothesized that sleep promotes generalization and improves robustness against noise in animals and humans. In this work, we utilize a biologically inspired sleep phase in ANNs and demonstrate the benefit of sleep on defending against adversarial attacks as well as increasing ANN classification robustness. We compare the sleep algorithm's performance on various robustness tasks with two previously proposed adversarial defenses, defensive distillation and fine-tuning. We report an increase in robustness after sleep to adversarial attacks as well as to general image distortions for three datasets: MNIST, CUB200, and a toy dataset. Overall, these results demonstrate the potential for biologically inspired solutions to solve existing problems in ANNs and guide the development of more robust, human-like ANNs."}
{'title': 'Marginalized Average Attentional Network for Weakly-Supervised Learning', 'paperID': '6c97556edbc192896cc55395f8f21fe0ff148580', 'arxivId': '1905.08586', 'publication_year': 2019, 'abstract': None}
{'title': 'Robust Inference via Generative Classifiers for Handling Noisy Labels', 'paperID': 'c307baff85987544b0b85821f4a5c02b889994e9', 'arxivId': '1901.11300', 'publication_year': 2019, 'abstract': None}
{'title': 'Masking: A New Perspective of Noisy Supervision', 'paperID': '77a1dcdb52b5b76ae17fb4f181840797e58f7fed', 'arxivId': '1805.08193', 'publication_year': 2018, 'abstract': None}
{'title': 'Generalized Cross Entropy Loss for Training Deep Neural Networks with Noisy Labels', 'paperID': '1e1855ca80e8ac3de0e169871f320416902e9ad1', 'arxivId': '1805.07836', 'publication_year': 2018, 'abstract': None}
{'title': 'Joint Optimization Framework for Learning with Noisy Labels', 'paperID': 'c4c4bc0367ec099f1e00a7700332cd0bf393aa55', 'arxivId': '1803.11364', 'publication_year': 2018, 'abstract': None}
{'title': 'Learning From Noisy Singly-labeled Data', 'paperID': 'a4a8e91995ae8c8b203dd857bdc0915facddeebe', 'arxivId': '1712.04577', 'publication_year': 2017, 'abstract': None}
{'title': 'Robust Web Image Annotation via Exploring Multi-Facet and Structural Knowledge', 'paperID': '492874f957e11a535c46c242ea0e595c0f068785', 'arxivId': None, 'publication_year': 2017, 'abstract': None}
{'title': 'Virtual Adversarial Training for Semi-Supervised Text Classification', 'paperID': '93d8d45fe8101545ae6d9fab3dbb38f904ff7b4e', 'arxivId': None, 'publication_year': 2016, 'abstract': None}
{'title': 'Learning with Symmetric Label Noise: The Importance of Being Unhinged', 'paperID': 'dd05ce86cacf50e3aee70d633040241923deb120', 'arxivId': '1505.07634', 'publication_year': 2015, 'abstract': None}
{'title': 'Self-Paced Curriculum Learning', 'paperID': '21d255246cd7ddba24a651fd716950f893ea8eb2', 'arxivId': None, 'publication_year': 2015, 'abstract': None}
{'title': 'Self-Paced Learning with Diversity', 'paperID': '44606e1209a47d1fcf88b90e306db9e4b84fa2c5', 'arxivId': None, 'publication_year': 2014, 'abstract': None}
{'title': 'Training Convolutional Networks with Noisy Labels', 'paperID': '9f59d0a003558066d2ff4fc1c77f461b4d233663', 'arxivId': None, 'publication_year': 2014, 'abstract': None}
{'title': 'Crowdsourcing Annotations for Visual Object Detection', 'paperID': 'cf9daa503798c3d4e04131bc7bf01544666265d1', 'arxivId': None, 'publication_year': 2012, 'abstract': None}
{'title': 'Self-Paced Learning for Latent Variable Models', 'paperID': 'a049555721f17ed79a97fd492c8fc9a3f8f8aa17', 'arxivId': None, 'publication_year': 2010, 'abstract': None}
{'title': 'Curriculum learning', 'paperID': '8de174ab5419b9d3127695405efd079808e956e8', 'arxivId': None, 'publication_year': 2009, 'abstract': None}
{'title': 'On the Design of Loss Functions for Classification: theory, robustness to outliers, and SavageBoost', 'paperID': 'f5fb14e99bab28ec06d9a4f77875a37ceb73c489', 'arxivId': None, 'publication_year': 2008, 'abstract': None}
{'title': 'Robust Truncated Hinge Loss Support Vector Machines', 'paperID': '5a43cc163f4e570b28617ad8a40872ad9189349c', 'arxivId': None, 'publication_year': 2007, 'abstract': None}
{'title': 'Convexity, Classification, and Risk Bounds', 'paperID': '1c1ea4eaf2c5ec2fb55debcbfa2bc8c07a821435', 'arxivId': None, 'publication_year': 2006, 'abstract': None}
{'title': 'L1 and L2 regularization for multiclass hinge loss models', 'paperID': 'e82c817c75061797f2ec111610ae4ce8d8c20794', 'arxivId': None, 'publication_year': 2011, 'abstract': None}
{'title': 'Curriculum Loss: Robust Learning and Generalization  against Label Corruption', 'paperID': '509f652d67a793a614633d4a5c236592d80b6522', 'arxivId': '1905.10045', 'publication_year': '2019', 'abstract': 'Deep neural networks (DNNs) have great expressive power, which can even memorize samples with wrong labels. It is vitally important to reiterate robustness and generalization in DNNs against label corruption. To this end, this paper studies the 0-1 loss, which has a monotonic relationship with an empirical adversary (reweighted) risk~\\citep{hu2016does}. Although the 0-1 loss has some robust properties, it is difficult to optimize. To efficiently optimize the 0-1 loss while keeping its robust properties, we propose a very simple and efficient loss, i.e. curriculum loss (CL). Our CL is a tighter upper bound of the 0-1 loss compared with conventional summation based surrogate losses. Moreover, CL can adaptively select samples for model training. As a result, our loss can be deemed as a novel perspective of curriculum sample selection strategy, which bridges a connection between curriculum learning and robust learning. Experimental results on benchmark datasets validate the robustness of the proposed loss.'}
{'title': 'AdvIT: Adversarial Frames Identifier Based on Temporal Consistency in Videos', 'paperID': '86fcf7c9166b5151c7e84ece7ea137bf2bd6b740', 'arxivId': None, 'publication_year': 2019, 'abstract': None}
{'title': 'A Provable Defense for Deep Residual Networks', 'paperID': '5677b0ca32651b80aa3a210d691bfc93bf9fcc82', 'arxivId': '1903.12519', 'publication_year': 2019, 'abstract': None}
{'title': 'The Limitations of Adversarial Training and the Blind-Spot Attack', 'paperID': 'e749e8c947550485eddf864f8efeb870b894e4ce', 'arxivId': '1901.04684', 'publication_year': 2019, 'abstract': None}
{'title': 'Verification of deep probabilistic models', 'paperID': '7c6123cd7052c9c8bb2ed5e11818b2ba7f06e79c', 'arxivId': '1812.02795', 'publication_year': 2018, 'abstract': None}
{'title': 'MixTrain: Scalable Training of Formally Robust Neural Networks', 'paperID': '63b4347cd65c00efae69726996752a2b1c869fa5', 'arxivId': None, 'publication_year': 2018, 'abstract': None}
{'title': 'MeshAdv: Adversarial Meshes for Visual Recognition', 'paperID': '1a83564d61aebde360c0be4834cf6eb4c472c1bd', 'arxivId': None, 'publication_year': 2018, 'abstract': None}
{'title': 'Certified Adversarial Robustness with Additive Noise', 'paperID': '2fff1d71c751ad8bdaaa96b625d2b65eb2fb5eaa', 'arxivId': '1809.03113', 'publication_year': 2018, 'abstract': None}
{'title': 'Characterizing Adversarial Examples Based on Spatial Consistency Information for Semantic Segmentation', 'paperID': '74dbcc09a3456ddacf5cece640b84045ebdf6be1', 'arxivId': '1810.05162', 'publication_year': 2018, 'abstract': None}
{'title': 'Distributionally Adversarial Attack', 'paperID': 'f749b2576c062a4fd16bb668d76d1e1084ad704e', 'arxivId': '1808.05537', 'publication_year': 2018, 'abstract': None}
{'title': 'Robust Physical-World Attacks on Deep Learning Visual Classification', 'paperID': 'f0c5991dbb130fa6b5de011cf7a04f6ed815ef68', 'arxivId': None, 'publication_year': 2018, 'abstract': None}
{'title': 'Defense-GAN: Protecting Classifiers Against Adversarial Attacks Using Generative Models', 'paperID': 'f7bb1636ced9036b3d0edafc7d82ad43164d41a3', 'arxivId': '1805.06605', 'publication_year': 2018, 'abstract': None}
{'title': 'Thermometer Encoding: One Hot Way To Resist Adversarial Examples', 'paperID': '8b9127bee0f7d109da2672ba06d0f39a5a60335a', 'arxivId': None, 'publication_year': 2018, 'abstract': None}
{'title': 'Characterizing Adversarial Subspaces Using Local Intrinsic Dimensionality', 'paperID': 'a18ada04d93981178234d9c8907fb99ea92fddcb', 'arxivId': '1801.02613', 'publication_year': 2018, 'abstract': None}
{'title': 'Generating Adversarial Examples with Adversarial Networks', 'paperID': 'd5577abcc1fbf57d66017e3b5b2211a82022842c', 'arxivId': '1801.02610', 'publication_year': 2018, 'abstract': None}
{'title': 'Spatially Transformed Adversarial Examples', 'paperID': 'd3c071dbbb4520ed5875f7e064a9da87240534db', 'arxivId': '1801.02612', 'publication_year': 2018, 'abstract': None}
{'title': 'Attacking Visual Language Grounding with Adversarial Examples: A Case Study on Neural Image Captioning', 'paperID': '77685c77a1fa39890006fe13f43738aac49a2c51', 'arxivId': None, 'publication_year': 2017, 'abstract': None}
{'title': 'Towards Robust Neural Networks via Random Self-ensemble', 'paperID': '1cf361d02f5ad84567e48754f1a8f895653bc701', 'arxivId': '1712.00673', 'publication_year': 2017, 'abstract': None}
{'title': 'PixelDefend: Leveraging Generative Models to Understand and Defend against Adversarial Examples', 'paperID': 'e83291498a3bc6b0efe8f9571e9c9ca1811707bd', 'arxivId': '1710.10766', 'publication_year': 2017, 'abstract': None}
{'title': 'Adversarial Example Defenses: Ensembles of Weak Defenses are not Strong', 'paperID': '6f61d15a31d6d051aeee3bf6d1482d332e68ebfe', 'arxivId': '1706.04701', 'publication_year': 2017, 'abstract': None}
{'title': 'Countering Adversarial Images using Input Transformations', 'paperID': 'e225dd59ef4954db21479cdcbee497624b2d6d0f', 'arxivId': '1711.00117', 'publication_year': 2018, 'abstract': None}
{'title': 'Transfer of Adversarial Robustness Between Perturbation Types', 'paperID': '25f99278a54417a2dcb64c549416e138373082d6', 'arxivId': '1905.01034', 'publication_year': 2019, 'abstract': None}
{'title': 'Adversarial Training and Robustness for Multiple Perturbations', 'paperID': 'daf8cd0f2c159d022477914bfacee9ff6da70c8b', 'arxivId': '1904.13000', 'publication_year': 2019, 'abstract': None}
{'title': 'Scaling up the Randomized Gradient-Free Adversarial Attack Reveals Overestimation of Robustness Using Established Attacks', 'paperID': '530859552c04fa4dae8f77882d7590e2df1a557e', 'arxivId': '1903.11359', 'publication_year': 2019, 'abstract': None}
{'title': 'Logit Pairing Methods Can Fool Gradient-Based Attacks', 'paperID': '9eda74b1219572287e489f84134bb935f139c4e7', 'arxivId': '1810.12042', 'publication_year': 2018, 'abstract': None}
{'title': 'Provable Robustness of ReLU networks via Maximization of Linear Regions', 'paperID': 'ecba2826cd7a51d4d8b9820591ff0fa6b41d66a6', 'arxivId': '1810.07481', 'publication_year': 2018, 'abstract': None}
{'title': 'A randomized gradient-free attack on ReLU networks', 'paperID': '12b6a7eb4014338fba3edef956be32775d271c78', 'arxivId': '1811.11493', 'publication_year': 2018, 'abstract': None}
{'title': 'Towards the first adversarially robust neural network model on MNIST', 'paperID': 'fd7789de401811fd8692466b8d49230e7184655f', 'arxivId': '1805.09190', 'publication_year': 2018, 'abstract': None}
{'title': 'Adversarial Patch', 'paperID': 'e3b17a245dce9a2189a8a4f7538631b69c93812e', 'arxivId': '1712.09665', 'publication_year': 2017, 'abstract': None}
{'title': 'Attacking the Madry Defense Model with L1-based Adversarial Examples', 'paperID': '6afc5e895d2fa5a816cb47311dfc1768c8bf86c9', 'arxivId': '1710.10733', 'publication_year': 2017, 'abstract': None}
{'title': 'Measuring Neural Net Robustness with Constraints', 'paperID': '73f56fd3fdcbff8131b8a70ebcc05264cecc3d99', 'arxivId': '1605.07262', 'publication_year': 2016, 'abstract': None}
{'title': 'Towards Deep Neural Network Architectures Robust to Adversarial Examples', 'paperID': '4f9f7434f06cbe31e54a0bb118975340b9e0a4c9', 'arxivId': '1412.5068', 'publication_year': 2014, 'abstract': None}
{'title': 'Man vs. computer: Benchmarking machine learning algorithms for traffic sign recognition', 'paperID': 'c56e758ba18066a8cdc333f15dfdb7ea6af4d283', 'arxivId': None, 'publication_year': 2012, 'abstract': None}
{'title': 'Provable robustness against all adversarial $l_p$-perturbations for $p\\geq 1$', 'paperID': 'df26b25512f5e8ff8f2242f9b0aa40e7572f2f43', 'arxivId': '1905.11213', 'publication_year': '2019', 'abstract': 'In recent years several adversarial attacks and defenses have been proposed. Often seemingly robust models turn out to be non-robust when more sophisticated attacks are used. One way out of this dilemma are provable robustness guarantees. While provably robust models for specific $l_p$-perturbation models have been developed, we show that they do not come with any guarantee against other $l_q$-perturbations. We propose a new regularization scheme, MMR-Universal, for ReLU networks which enforces robustness wrt $l_1$- and $l_\\infty$-perturbations and show how that leads to the first provably robust models wrt any $l_p$-norm for $p\\geq 1$.'}
{'title': 'Adversarial Robustness through Local Linearization', 'paperID': 'd6dcbf0bb628658df27abd297c03147115e476e4', 'arxivId': '1907.02610', 'publication_year': 2019, 'abstract': None}
{'title': 'Convergence of Adversarial Training in Overparametrized Neural Networks', 'paperID': '1822e737dfbc933c95ab44f1dd123756120dfaa4', 'arxivId': '1906.07916', 'publication_year': 2019, 'abstract': None}
{'title': 'Adversarially Robust Generalization Just Requires More Unlabeled Data', 'paperID': '63c022ae3b385d1d49c119142bfabb5cdb5ec90b', 'arxivId': '1906.00555', 'publication_year': 2019, 'abstract': None}
{'title': 'Max-Margin Adversarial (MMA) Training: Direct Input Space Margin Maximization through Adversarial Training', 'paperID': '93314b89c218c02cc1a32cad7071215693599907', 'arxivId': '1812.02637', 'publication_year': 2018, 'abstract': None}
{'title': 'Query-Efficient Hard-label Black-box Attack: An Optimization-based Approach', 'paperID': 'b862efa06baea0b032214675eb3c3645d5d69d46', 'arxivId': '1807.04457', 'publication_year': 2018, 'abstract': None}
{'title': 'Mitigating adversarial effects through randomization', 'paperID': '9a089c56eec68df722b2a5a52727143aacdc2532', 'arxivId': '1711.01991', 'publication_year': 2017, 'abstract': None}
{'title': 'Towards the Science of Security and Privacy in Machine Learning', 'paperID': 'ebab687cd1be7d25392c11f89fce6a63bef7219d', 'arxivId': '1611.03814', 'publication_year': 2016, 'abstract': None}
{'title': 'Empirical Bernstein Bounds and Sample-Variance Penalization', 'paperID': '6e71a24fc0bba4a712b89dd9ff87a452230c2c4b', 'arxivId': '0907.3740', 'publication_year': 2009, 'abstract': None}
{'title': 'MACER: Attack-free and Scalable Robust Training via Maximizing Certified Radius', 'paperID': '4136cbc5f7f1fa34b91bf7bd335b173afaaf68d6', 'arxivId': '2001.02378', 'publication_year': '2020', 'abstract': 'Adversarial training is one of the most popular ways to learn robust models but is usually attack-dependent and time costly. In this paper, we propose the MACER algorithm, which learns robust models without using adversarial training but performs better than all existing provable l2-defenses. Recent work shows that randomized smoothing can be used to provide certified l2 radius to smoothed classifiers, and our algorithm trains provably robust smoothed classifiers via MAximizing the CErtified Radius (MACER). The attack-free characteristic makes MACER faster to train and easier to optimize. In our experiments, we show that our method can be applied to modern deep neural networks on a wide range of datasets, including Cifar-10, ImageNet, MNIST, and SVHN. For all tasks, MACER spends less training time than state-of-the-art adversarial training algorithms, and the learned models achieve larger average certified radius.'}
{'title': 'Discretization Based Solutions for Secure Machine Learning Against Adversarial Attacks', 'paperID': 'b4dc59552f815283f371e6aa024a4ee7dd2d101d', 'arxivId': '1902.03151', 'publication_year': 2019, 'abstract': None}
{'title': 'Training Deep Neural Networks with 8-bit Floating Point Numbers', 'paperID': '9a1093af92d315def21b90918faf08665157051a', 'arxivId': '1812.08011', 'publication_year': 2018, 'abstract': None}
{'title': 'Defend Deep Neural Networks Against Adversarial Examples via Fixed andDynamic Quantized Activation Functions', 'paperID': '99ce59c65f1bdf1ae2592e5d4f939b42c084e193', 'arxivId': '1807.06714', 'publication_year': 2018, 'abstract': None}
{'title': 'A Scalable Multi- TeraOPS Deep Learning Processor Core for AI Trainina and Inference', 'paperID': '921cb84f4b7ea75a2632c7e7ceadb213b4d7d8fd', 'arxivId': None, 'publication_year': 2018, 'abstract': None}
{'title': 'Improving the Adversarial Robustness and Interpretability of Deep Neural Networks by Regularizing their Input Gradients', 'paperID': 'ac8e45a0451ac578f17f631fc2663ee4b98b83a9', 'arxivId': '1711.09404', 'publication_year': 2017, 'abstract': None}
{'title': 'Attacking Binarized Neural Networks', 'paperID': '64520a1f652ebd04565354fbb8a6281606c9724d', 'arxivId': '1711.00449', 'publication_year': 2017, 'abstract': None}
{'title': 'Ensemble Methods as a Defense to Adversarial Perturbations Against Deep Neural Networks', 'paperID': 'eccd39db20a0caae8dbcf7f64d04280e62cabf65', 'arxivId': '1709.03423', 'publication_year': 2017, 'abstract': None}
{'title': 'Technical Report on the CleverHans v2.1.0 Adversarial Examples Library', 'paperID': 'd86c9623d56e469aec73a76758a829891b0b2a09', 'arxivId': '1610.00768', 'publication_year': 2016, 'abstract': None}
{'title': 'Quantized Neural Networks: Training Neural Networks with Low Precision Weights and Activations', 'paperID': 'd2e4147eecae6f914e9e1e9aece8fdd2eaed809f', 'arxivId': '1609.07061', 'publication_year': 2016, 'abstract': None}
{'title': 'DoReFa-Net: Training Low Bitwidth Convolutional Neural Networks with Low Bitwidth Gradients', 'paperID': '8b053389eb8c18c61b84d7e59a95cb7e13f205b7', 'arxivId': '1606.06160', 'publication_year': 2016, 'abstract': None}
{'title': 'BinaryConnect: Training Deep Neural Networks with binary weights during propagations', 'paperID': 'a5733ff08daff727af834345b9cfff1d0aa109ec', 'arxivId': '1511.00363', 'publication_year': 2015, 'abstract': None}
{'title': 'AxNN: Energy-efficient neuromorphic systems using approximate computing', 'paperID': '9c0e19677f302f04a276469fddc849bd7616ab46', 'arxivId': None, 'publication_year': 2014, 'abstract': None}
{'title': 'Bagging predictors', 'paperID': 'd1ee87290fa827f1217b8fa2bccb3485da1a300e', 'arxivId': None, 'publication_year': 2004, 'abstract': None}
{'title': 'EMPIR: Ensembles of Mixed Precision Deep Networks for Increased Robustness Against Adversarial Attacks', 'paperID': '2a88cc8cc9562b4addec03ba16b35cb4d3baaa43', 'arxivId': '2004.10162', 'publication_year': '2020', 'abstract': 'Ensuring robustness of Deep Neural Networks (DNNs) is crucial to their adoption in safety-critical applications such as self-driving cars, drones, and healthcare. Notably, DNNs are vulnerable to adversarial attacks in which small input perturbations can produce catastrophic misclassifications. In this work, we propose EMPIR, ensembles of quantized DNN models with different numerical precisions, as a new approach to increase robustness against adversarial attacks. EMPIR is based on the observation that quantized neural networks often demonstrate much higher robustness to adversarial attacks than full precision networks, but at the cost of a substantial loss in accuracy on the original (unperturbed) inputs. EMPIR overcomes this limitation to achieve the “best of both worlds”, i.e., the higher unperturbed accuracies of the full precision models combined with the higher robustness of the low precision models, by composing them in an ensemble. Further, as low precision DNN models have significantly lower computational and storage requirements than full precision models, EMPIR models only incur modest compute and memory overheads compared to a single full-precision model (<25% in our evaluations). We evaluate EMPIR across a suite of 3 different DNN tasks (MNIST, CIFAR-10 and ImageNet) and under 4 different adversarial attacks. Our results indicate that EMPIR boosts the average adversarial accuracies by 43.6%, 15.3% and 11.9% for the DNN models trained on the MNIST, CIFAR-10 and ImageNet datasets respectively, when compared to single full-precision models, without sacrificing accuracy on the unperturbed inputs.'}
{'title': 'On the Convergence and Robustness of Adversarial Training', 'paperID': 'dcfb420412d76600eb124625f62fb28499af1e8c', 'arxivId': '2112.08304', 'publication_year': 2021, 'abstract': None}
{'title': 'Skip Connections Matter: On the Transferability of Adversarial Examples Generated with ResNets', 'paperID': '2fb43a4c5cab8215d510fc585ca81fb5ee8a3abb', 'arxivId': '2002.05990', 'publication_year': 2020, 'abstract': None}
{'title': 'Dirichlet Latent Variable Hierarchical Recurrent Encoder-Decoder in Dialogue Generation', 'paperID': 'b2125f338e736497bb01168b922a6ab63cc27d75', 'arxivId': None, 'publication_year': 2019, 'abstract': None}
{'title': 'Hilbert-Based Generative Defense for Adversarial Examples', 'paperID': '1067c814c5d517cd50af176f3c919493fa799c0f', 'arxivId': None, 'publication_year': 2019, 'abstract': None}
{'title': 'Understanding Adversarial Attacks on Deep Learning Based Medical Image Analysis Systems', 'paperID': '2172552b917ef3757b0af47d17fce18586d56cba', 'arxivId': '1907.10456', 'publication_year': 2019, 'abstract': None}
{'title': 'Black-box Adversarial Attacks on Video Recognition Models', 'paperID': '6be44364db3a46ab5fcf8172910650b210cc5c39', 'arxivId': '1904.05181', 'publication_year': 2019, 'abstract': None}
{'title': 'Adversarial attacks on medical machine learning', 'paperID': 'ac644a74a0ebc8cfbe1b0af8120004909828d283', 'arxivId': None, 'publication_year': 2019, 'abstract': None}
{'title': 'Adversarial Robustness May Be at Odds With Simplicity', 'paperID': '7bc43b9f701823c04c7ee3ed780a34b041ee4b07', 'arxivId': '1901.00532', 'publication_year': 2019, 'abstract': None}
{'title': 'On the Sensitivity of Adversarial Robustness to Input Data Distributions', 'paperID': '508dad538d5c63eb6c07fd10794510357a951a58', 'arxivId': '1902.08336', 'publication_year': 2018, 'abstract': None}
{'title': 'Security analysis and enhancement of model compressed deep learning systems under adversarial attacks', 'paperID': '92be0550fa3801d7a4bd71ea205373c22f5848a9', 'arxivId': '1802.05193', 'publication_year': 2018, 'abstract': None}
{'title': 'Defense Against Adversarial Attacks Using High-Level Representation Guided Denoiser', 'paperID': 'ca9c1224636b0a7dd37340a4691c34a9914b5af8', 'arxivId': '1712.02976', 'publication_year': 2017, 'abstract': None}
{'title': 'MagNet: A Two-Pronged Defense against Adversarial Examples', 'paperID': '63a010c69f00e65c946a68b546bbd42cbed03564', 'arxivId': '1705.09064', 'publication_year': 2017, 'abstract': None}
{'title': 'Feature Squeezing: Detecting Adversarial Examples in Deep Neural Networks', 'paperID': '9fec45e1ff97ffb0e0cf9f039e39b46043430301', 'arxivId': '1704.01155', 'publication_year': 2017, 'abstract': None}
{'title': 'Detecting Adversarial Samples from Artifacts', 'paperID': '405b6ff2ea2ec9a7c7d6b18ac951dc778892ffcf', 'arxivId': '1703.00410', 'publication_year': 2017, 'abstract': None}
{'title': 'Residual Convolutional CTC Networks for Automatic Speech Recognition', 'paperID': 'da1231a3a7536010ddb6ef5e163a785d03974af1', 'arxivId': '1702.07793', 'publication_year': 2017, 'abstract': None}
{'title': 'On the (Statistical) Detection of Adversarial Examples', 'paperID': '0a77313fa10a864e14f538c73d417d7b4d6f320e', 'arxivId': '1702.06280', 'publication_year': 2017, 'abstract': None}
{'title': 'DeepDriving: Learning Affordance for Direct Perception in Autonomous Driving', 'paperID': 'd6b93b766dff2066cebbc897c9ec7fbc44848ad7', 'arxivId': '1505.00256', 'publication_year': 2015, 'abstract': None}
{'title': 'Compression to the Rescue : Defending from Adversarial Attacks Across Modalities Extended Abstract', 'paperID': 'e5693e6b6d7551a82b64cd4ca0e2071c3dfef4c9', 'arxivId': None, 'publication_year': 2018, 'abstract': None}
{'title': 'Improving Adversarial Robustness Requires Revisiting Misclassified Examples', 'paperID': '764eff31d9596033859895d9513b838d2c57a6fb', 'arxivId': None, 'publication_year': '2020', 'abstract': 'Deep neural networks (DNNs) are vulnerable to adversarial examples crafted by imperceptible perturbations. A range of defense techniques have been proposed to improve DNN robustness to adversarial examples, among which adversarial training has been demonstrated to be the most effective. Adversarial training is often formulated as a min-max optimization problem, with the inner maximization for generating adversarial examples. However, there exists a simple, yet easily overlooked fact that adversarial examples are only defined on correctly classified (natural) examples, but inevitably, some (natural) examples will be misclassified during training. In this paper, we investigate the distinctive influence of misclassified and correctly classified examples on the final robustness of adversarial training. Specifically, we find that misclassified examples indeed have a significant impact on the final robustness. More surprisingly, we find that different maximization techniques on misclassified examples may have a negligible influence on the final robustness, while different minimization techniques are crucial. Motivated by the above discovery, we propose a new defense algorithm called {\\em Misclassification Aware adveRsarial Training} (MART), which explicitly differentiates the misclassified and correctly classified examples during the training. We also propose a semi-supervised extension of MART, which can leverage the unlabeled data to further improve the robustness. Experimental results show that MART and its variant could significantly improve the state-of-the-art adversarial robustness.'}
{'title': 'Robust Learning with Jacobian Regularization', 'paperID': 'cdfee4355cae3299b06f3f98718df9bb64a899bf', 'arxivId': '1908.02729', 'publication_year': 2019, 'abstract': None}
{'title': 'Defense Against Adversarial Attacks Using Feature Scattering-based Adversarial Training', 'paperID': '2c1006c856fefdbd6cd710e840e57153f2d6cd04', 'arxivId': '1907.10764', 'publication_year': 2019, 'abstract': None}
{'title': 'On the Connection Between Adversarial Robustness and Saliency Map Interpretability', 'paperID': '81bcbae2f547c6915dc14e7b0c3ff9ea6cff7d4f', 'arxivId': '1905.04172', 'publication_year': 2019, 'abstract': None}
{'title': 'Diagnosing and Enhancing VAE Models', 'paperID': 'f6a201eed70e8b48e2f60d97c98cfc8fe3b7b175', 'arxivId': '1903.05789', 'publication_year': 2019, 'abstract': None}
{'title': 'PROVEN: Certifying Robustness of Neural Networks with a Probabilistic Approach', 'paperID': '0c1a245a67a5136d85de77d3ba38a900ab0579ab', 'arxivId': '1812.08329', 'publication_year': 2018, 'abstract': None}
{'title': 'Improving DNN Robustness to Adversarial Attacks using Jacobian Regularization', 'paperID': 'ba6bc847a6ece8448ff492d0639a93d736427903', 'arxivId': '1803.08680', 'publication_year': 2018, 'abstract': None}
{'title': 'First-Order Adversarial Vulnerability of Neural Networks and Input Dimension', 'paperID': '5e3e36049ed4156f01b0133d56352af8f5020b4a', 'arxivId': None, 'publication_year': 2018, 'abstract': None}
{'title': 'StarGAN: Unified Generative Adversarial Networks for Multi-domain Image-to-Image Translation', 'paperID': '302207c149bdf7beb6e46e4d4afbd2fa9ac02c64', 'arxivId': '1711.09020', 'publication_year': 2017, 'abstract': None}
{'title': 'End to End Learning for Self-Driving Cars', 'paperID': '0e3cc46583217ec81e87045a4f9ae3478a008227', 'arxivId': '1604.07316', 'publication_year': 2016, 'abstract': None}
{'title': 'Autoencoding beyond pixels using a learned similarity metric', 'paperID': 'e8b8a7778ace2a02f8db6fe321a54520c6b283ca', 'arxivId': '1512.09300', 'publication_year': 2015, 'abstract': None}
{'title': 'Double backpropagation increasing generalization performance', 'paperID': 'dc048a657951340b312504450a09a07b630152d7', 'arxivId': None, 'publication_year': 1991, 'abstract': None}
{'title': 'Jacobian Adversarially Regularized Networks for Robustness', 'paperID': '000829516229b87cafff052fe310604c85236671', 'arxivId': '1912.10185', 'publication_year': '2019', 'abstract': "Adversarial examples are crafted with imperceptible perturbations with the intent to fool neural networks. Against such attacks, adversarial training and its variants stand as the strongest defense to date. Previous studies have pointed out that robust models that have undergone adversarial training tend to produce more salient and interpretable Jacobian matrices than their non-robust counterparts. A natural question is whether a model trained with an objective to produce salient Jacobian can result in better robustness. This paper answers this question with affirmative empirical results. We propose Jacobian Adversarially Regularized Networks (JARN) as a method to optimize the saliency of a classifier's Jacobian by adversarially regularizing the model's Jacobian to resemble natural training images. Image classifiers trained with JARN show improved robust accuracy compared to standard models on the MNIST, SVHN and CIFAR-10 datasets, uncovering a new angle to boost robustness without using adversarial training examples."}
{'title': 'Learning without Forgetting', 'paperID': '8f3b80ddc0dd62e6c3369fabb1715990c29e9b9a', 'arxivId': '1606.09282', 'publication_year': 2016, 'abstract': None}
{'title': 'Distilling the Knowledge in a Neural Network', 'paperID': '0c908739fbff75f03469d13d4a1a07de3414ee19', 'arxivId': '1503.02531', 'publication_year': 2015, 'abstract': None}
{'title': 'How transferable are features in deep neural networks?', 'paperID': '081651b38ff7533550a3adfc1c00da333a8fe86c', 'arxivId': '1411.1792', 'publication_year': 2014, 'abstract': None}
{'title': 'Adversarially robust transfer learning', 'paperID': '0d94293388417458eae73632e33840a772375900', 'arxivId': '1905.08232', 'publication_year': '2019', 'abstract': 'Transfer learning, in which a network is trained on one task and re-purposed on another, is often used to produce neural network classifiers when data is scarce or full-scale training is too costly. When the goal is to produce a model that is not only accurate but also adversarially robust, data scarcity and computational limitations become even more cumbersome. We consider robust transfer learning, in which we transfer not only performance but also robustness from a source model to a target domain. We start by observing that robust networks contain robust feature extractors. By training classifiers on top of these feature extractors, we produce new models that inherit the robustness of their parent networks. We then consider the case of fine tuning a network by re-training end-to-end in the target domain. When using lifelong learning strategies, this process preserves the robustness of the source network while achieving high accuracy. By using such strategies, it is possible to produce accurate and robust models with little data, and without the cost of adversarial training. Additionally, we can improve the generalization of adversarially trained models, while maintaining their robustness.'}
{'title': 'The Functional Neural Process', 'paperID': '77d76c5fb1d7467518744c7f14e4de3ac39e589e', 'arxivId': '1906.08324', 'publication_year': 2019, 'abstract': None}
{'title': 'Correlated Variational Auto-Encoders', 'paperID': '813995ec740921c88360fccee4a49befbb1e51c3', 'arxivId': '1905.05335', 'publication_year': 2019, 'abstract': None}
{'title': 'Entropic GANs meet VAEs: A Statistical Approach to Compute Sample Likelihoods in GANs', 'paperID': 'e8d2ad861e4d107ae2c0d1b7bb053d06022dfe1c', 'arxivId': '1810.04147', 'publication_year': 2018, 'abstract': None}
{'title': 'Sliced-Wasserstein Autoencoder: An Embarrassingly Simple Generative Model', 'paperID': '8ea9093542075bd8cc4928a4c671a95f363c61ef', 'arxivId': '1804.01947', 'publication_year': 2018, 'abstract': None}
{'title': 'Optimal Transport on Discrete Domains', 'paperID': '89317846e89556ef183433fbded801088b110a86', 'arxivId': '1801.07745', 'publication_year': 2018, 'abstract': None}
{'title': 'Information geometry connecting Wasserstein distance and Kullback–Leibler divergence via the entropy-relaxed transportation problem', 'paperID': '23b8ae10566785d4befacedf26631e80afa1af9f', 'arxivId': '1709.10219', 'publication_year': 2017, 'abstract': None}
{'title': 'From optimal transport to generative modeling: the VEGAN cookbook', 'paperID': '0a2605ca2c38fe45ac87b1d196a322857d8cb912', 'arxivId': '1705.07642', 'publication_year': 2017, 'abstract': None}
{'title': 'Adversarial Examples for Generative Models', 'paperID': '8e5d0c73eb29e3da8d6d3a0c8560b23680122bb2', 'arxivId': '1702.06832', 'publication_year': 2017, 'abstract': None}
{'title': 'Adversarial Variational Bayes: Unifying Variational Autoencoders and Generative Adversarial Networks', 'paperID': '29831b8830e278c8c28e45c8e9c41c619c89f86a', 'arxivId': '1701.04722', 'publication_year': 2017, 'abstract': None}
{'title': 'Adversarially Learned Inference', 'paperID': 'fcf43325529c8b1cc26aeb52fd5d7e532abb0a40', 'arxivId': '1606.00704', 'publication_year': 2016, 'abstract': None}
{'title': 'Adversarial Feature Learning', 'paperID': '1db6e3078597386ac4222ba6c3f4f61b61f53539', 'arxivId': '1605.09782', 'publication_year': 2016, 'abstract': None}
{'title': 'Adversarial Autoencoders', 'paperID': 'c8c04ed972d38e2326a53d322a6f2d7e0f8218c1', 'arxivId': '1511.05644', 'publication_year': 2015, 'abstract': None}
{'title': 'Sinkhorn Distances: Lightspeed Computation of Optimal Transportation Distances', 'paperID': '267754c911d6e8adadae50c1e7f3ab5be4244e52', 'arxivId': '1306.0895', 'publication_year': 2013, 'abstract': None}
{'title': 'Deep Learning of Representations: Looking Forward', 'paperID': '72d32c986b47d6b880dad0c3f155fe23d2939038', 'arxivId': '1305.0445', 'publication_year': 2013, 'abstract': None}
{'title': 'An Introduction to Conditional Random Fields', 'paperID': 'c7870b78c57e0bd2e9fb6907c0702e28eb87e239', 'arxivId': '1011.4088', 'publication_year': 2010, 'abstract': None}
{'title': 'Conditional Random Fields: Probabilistic Models for Segmenting and Labeling Sequence Data', 'paperID': 'f4ba954b0412773d047dc41231c733de0c1f4926', 'arxivId': None, 'publication_year': 2001, 'abstract': None}
{'title': 'Adversarially Robust Representations with Smooth Encoders', 'paperID': '5ecd39a7797978bf0fd5682f93eddb195ad4a1ea', 'arxivId': None, 'publication_year': '2020', 'abstract': 'This paper studies the undesired phenomena of over-sensitivity of representations learned by deep networks to semantically-irrelevant changes in data. We identify a cause for this shortcoming in the classical Variational Auto-encoder (VAE) objective, the evidence lower bound (ELBO). We show that the ELBO fails to control the behaviour of the encoder out of the support of the empirical data distribution and this behaviour of the VAE can lead to extreme errors in the learned representation. This is a key hurdle in the effective use of representations for data-efficient learning and transfer. To address this problem, we propose to augment the data with specifications that enforce insensitivity of the representation with respect to families of transformations. To incorporate these specifications, we propose a regularization method that is based on a selection mechanism that creates a fictive data point by explicitly perturbing an observed true data point. For certain choices of parameters, our formulation naturally leads to the minimization of the entropy regularized Wasserstein distance between representations. We illustrate our approach on standard datasets and experimentally show that significant improvements in the downstream adversarial accuracy can be achieved by learning robust representations completely in an unsupervised manner, without a reference to a particular downstream task and without a costly supervised adversarial training procedure.'}
{'title': 'SNODE: Spectral Discretization of Neural ODEs for System Identification', 'paperID': '79a13802beabf29155cc8b554a140fa215d77722', 'arxivId': '1906.07038', 'publication_year': 2019, 'abstract': None}
{'title': 'Accelerating Neural ODEs with Spectral Elements', 'paperID': '5f073839a55f387af71d789f1f7924e08bcd7df5', 'arxivId': None, 'publication_year': 2019, 'abstract': None}
{'title': 'Neural SDE: Stabilizing Neural ODE Networks with Stochastic Noise', 'paperID': '98fc7a351bbb07fb3a304508e1a5ffcab03babba', 'arxivId': '1906.02355', 'publication_year': 2019, 'abstract': None}
{'title': 'Augmented Neural ODEs', 'paperID': '31156009c49a88b5f0fb37437512eec570310d24', 'arxivId': '1904.01681', 'publication_year': 2019, 'abstract': None}
{'title': 'ResNets Ensemble via the Feynman-Kac Formalism to Improve Natural and Robust Accuracies', 'paperID': 'b51cdc040f98831b47e0848ee1f382e2e4d3ff57', 'arxivId': None, 'publication_year': 2018, 'abstract': None}
{'title': 'FFJORD: Free-form Continuous Dynamics for Scalable Reversible Generative Models', 'paperID': '8afa6dd9f9ac46462a1fb70a757c4ae1cd45bbf6', 'arxivId': '1810.01367', 'publication_year': 2018, 'abstract': None}
{'title': 'Adversarial Defense via Data Dependent Activation Function and Total Variation Minimization', 'paperID': 'ef0a6e167c95927dac6d61d96e2d08da413868ac', 'arxivId': '1809.08516', 'publication_year': 2018, 'abstract': None}
{'title': 'Analyzing Inverse Problems with Invertible Neural Networks', 'paperID': '25e433197844c239742f67fbb4171e913e0b9fe2', 'arxivId': '1808.04730', 'publication_year': 2018, 'abstract': None}
{'title': 'Neural Ordinary Differential Equations', 'paperID': '449310e3538b08b43227d660227dfd2875c3c3c1', 'arxivId': '1806.07366', 'publication_year': 2018, 'abstract': None}
{'title': 'Adversarial Examples that Fool both Human and Computer Vision', 'paperID': 'ce1ff1a833f38e411c0ecdbf84426cfea8842646', 'arxivId': None, 'publication_year': 2018, 'abstract': None}
{'title': 'Deep Defense: Training DNNs with Improved Adversarial Robustness', 'paperID': 'ee95231783167baa4785a642e8ef563a572c5d63', 'arxivId': '1803.00404', 'publication_year': 2018, 'abstract': None}
{'title': 'Deep Neural Nets with Interpolating Function as Output Activation', 'paperID': '9e09ef5f2e0519c7a7df01e6e1a7d9306441e179', 'arxivId': None, 'publication_year': 2018, 'abstract': None}
{'title': 'Adversarial Examples that Fool both Computer Vision and Time-Limited Humans', 'paperID': 'be4a4f7f65d397a4e07dc83b95da6b414e0634e2', 'arxivId': '1802.08195', 'publication_year': 2018, 'abstract': None}
{'title': 'Beyond Finite Layer Neural Networks: Bridging Deep Architectures and Numerical Differential Equations', 'paperID': '1cb7ea5de0f8f4d90e4369db4a161ca8594026dc', 'arxivId': '1710.10121', 'publication_year': 2017, 'abstract': None}
{'title': 'A Proposal on Machine Learning via Dynamical Systems', 'paperID': 'e3f8c8253767b6fe0891025cdf772cd286337921', 'arxivId': None, 'publication_year': 2017, 'abstract': None}
{'title': 'PolyNet: A Pursuit of Structural Diversity in Very Deep Networks', 'paperID': 'aad34665649953fa4bbacdc6eff4edb5408df6b3', 'arxivId': '1611.05725', 'publication_year': 2016, 'abstract': None}
{'title': 'FractalNet: Ultra-Deep Neural Networks without Residuals', 'paperID': 'd0156126edbfc524c8d108bdc0cf811cfe3129aa', 'arxivId': '1605.07648', 'publication_year': 2016, 'abstract': None}
{'title': 'Shapes and Diffeomorphisms', 'paperID': '163047737ca73fdb3e5147eaee64329abe04ed1d', 'arxivId': None, 'publication_year': 2010, 'abstract': None}
{'title': 'The Mathematical Theory of Optimal Processes', 'paperID': '4f2703652205bb4e146aee4dd48c78ed68b83ff3', 'arxivId': None, 'publication_year': 1965, 'abstract': None}
{'title': 'Theory Of Ordinary Differential Equations', 'paperID': '7b3a7733077e8f632d42bd0718943671b006e461', 'arxivId': None, 'publication_year': 2016, 'abstract': None}
{'title': 'THE GRONWALL INEQUALITY', 'paperID': 'cebeb3afc6d68217bc9f3f143a3aedf3622980b6', 'arxivId': None, 'publication_year': 2005, 'abstract': None}
{'title': 'On Robustness of Neural Ordinary Differential Equations', 'paperID': '00d4f1c5f11ecbbc1a033e6675934703f09016f8', 'arxivId': '1910.05513', 'publication_year': '2019', 'abstract': 'Neural ordinary differential equations (ODEs) have been attracting increasing attention in various research domains recently. There have been some works studying optimization issues and approximation capabilities of neural ODEs, but their robustness is still yet unclear. In this work, we fill this important gap by exploring robustness properties of neural ODEs both empirically and theoretically. We first present an empirical study on the robustness of the neural ODE-based networks (ODENets) by exposing them to inputs with various types of perturbations and subsequently investigating the changes of the corresponding outputs. In contrast to conventional convolutional neural networks (CNNs), we find that the ODENets are more robust against both random Gaussian perturbations and adversarial attack examples. We then provide an insightful understanding of this phenomenon by exploiting a certain desirable property of the flow of a continuous-time ODE, namely that integral curves are non-intersecting. Our work suggests that, due to their intrinsic robustness, it is promising to use neural ODEs as a basic block for building robust deep network models. To further enhance the robustness of vanilla neural ODEs, we propose the time-invariant steady neural ODE (TisODE), which regularizes the flow on perturbed data via the time-invariant property and the imposition of a steady-state constraint. We show that the TisODE method outperforms vanilla neural ODEs and also can work in conjunction with other state-of-the-art architectural methods to build more robust deep networks.'}
{'title': 'Nesterov Accelerated Gradient and Scale Invariance for Adversarial Attacks', 'paperID': '76199eeda71c903cc4b53691655e35f71909d8b2', 'arxivId': '1908.06281', 'publication_year': 2019, 'abstract': None}
{'title': 'Interpreting Adversarially Trained Convolutional Neural Networks', 'paperID': '5fbb606b313e4b8e57496db027025fb549543401', 'arxivId': '1905.09797', 'publication_year': 2019, 'abstract': None}
{'title': 'NATTACK: Learning the Distributions of Adversarial Examples for an Improved Black-Box Attack on Deep Neural Networks', 'paperID': '717425092f2e7a2a00c98e8e1778036e9b5a8b4e', 'arxivId': '1905.00441', 'publication_year': 2019, 'abstract': None}
{'title': 'A Direct Approach to Robust Deep Learning Using Adversarial Networks', 'paperID': '04ee17ea05341aadc8643a21d21746cb67993a9d', 'arxivId': '1905.09591', 'publication_year': 2019, 'abstract': None}
{'title': 'AT-GAN: A Generative Attack Model for Adversarial Transferring on Generative Adversarial Nets', 'paperID': '43e78439c6e37918133da064f2eed872b3b99ac5', 'arxivId': None, 'publication_year': 2019, 'abstract': None}
{'title': 'Improving the Generalization of Adversarial Training with Domain Adaptation', 'paperID': '428c2e5992d6ed3186c087cba0fdba2ab6a468b2', 'arxivId': '1810.00740', 'publication_year': 2018, 'abstract': None}
{'title': 'SmoothGrad: removing noise by adding noise', 'paperID': 'f538dca4def5167a32fbc12107b69a05f0c9d832', 'arxivId': '1706.03825', 'publication_year': 2017, 'abstract': None}
{'title': 'Delving into Transferable Adversarial Examples and Black-box Attacks', 'paperID': '99e5a8c10cf92749d4a7c2949691c3a6046e499a', 'arxivId': '1611.02770', 'publication_year': 2016, 'abstract': None}
{'title': 'Computer Vision: Algorithms and Applications', 'paperID': '4282a344671189e17c9c9e00e329fe2d0fa71769', 'arxivId': None, 'publication_year': 2010, 'abstract': None}
{'title': 'Robust Local Features for Improving the Generalization of Adversarial Training', 'paperID': '7c83832f00579685ce454d0f2d61758db2b635d6', 'arxivId': '1909.10147', 'publication_year': '2019', 'abstract': 'Adversarial training has been demonstrated as one of the most effective methods for training robust models to defend against adversarial examples. However, adversarially trained models often lack adversarially robust generalization on unseen testing data. Recent works show that adversarially trained models are more biased towards global structure features. Instead, in this work, we would like to investigate the relationship between the generalization of adversarial training and the robust local features, as the robust local features generalize well for unseen shape variation. To learn the robust local features, we develop a Random Block Shuffle (RBS) transformation to break up the global structure features on normal adversarial examples. We continue to propose a new approach called Robust Local Features for Adversarial Training (RLFAT), which first learns the robust local features by adversarial training on the RBS-transformed adversarial examples, and then transfers the robust local features into the training of normal adversarial examples. To demonstrate the generality of our argument, we implement RLFAT in currently state-of-the-art adversarial training frameworks. Extensive experiments on STL-10, CIFAR-10 and CIFAR-100 show that RLFAT significantly improves both the adversarially robust generalization and the standard generalization of adversarial training. Additionally, we demonstrate that our models capture more local features of the object on the images, aligning better with human perception.'}
{'title': 'Data-Free Quantization Through Weight Equalization and Bias Correction', 'paperID': 'd77123b54dcc8014949584ab624e97298617bcad', 'arxivId': '1906.04721', 'publication_year': 2019, 'abstract': None}
{'title': 'Defensive Quantization: When Efficiency Meets Robustness', 'paperID': 'ed1f55fb7ba0e3196913027840c4e23155e2e80c', 'arxivId': '1904.08444', 'publication_year': 2019, 'abstract': None}
{'title': 'Low-bit Quantization of Neural Networks for Efficient Inference', 'paperID': '47a1edfb88f5b4a7ba1e9f6aed327f67f942f6d6', 'arxivId': '1902.06822', 'publication_year': 2019, 'abstract': None}
{'title': 'Same, Same But Different - Recovering Neural Network Quantization Error Through Weight Factorization', 'paperID': '63521e29aacc8c07bcb8476389f9b0cc247802bd', 'arxivId': '1902.01917', 'publication_year': 2019, 'abstract': None}
{'title': 'Improving Neural Network Quantization without Retraining using Outlier Channel Splitting', 'paperID': '2735dd87f42f60dd8f50def5ae51bbbf95318235', 'arxivId': '1901.09504', 'publication_year': 2019, 'abstract': None}
{'title': 'Sparse DNNs with Improved Adversarial Robustness', 'paperID': '2aa2fe58f441fbecc183965bf79f4ef7fb2dd4a7', 'arxivId': '1810.09619', 'publication_year': 2018, 'abstract': None}
{'title': 'Post training 4-bit quantization of convolutional networks for rapid-deployment', 'paperID': 'f789425a7af1d012675118d7d10cd50afad09074', 'arxivId': None, 'publication_year': 2018, 'abstract': None}
{'title': 'Relaxed Quantization for Discretized Neural Networks', 'paperID': '16e6514ebf46ffdb5d11ba347fe366673fc0549c', 'arxivId': '1810.01875', 'publication_year': 2018, 'abstract': None}
{'title': 'Quantizing deep convolutional networks for efficient inference: A whitepaper', 'paperID': '3d8b62c060f8444907e7c975c6ae590373b51ed4', 'arxivId': '1806.08342', 'publication_year': 2018, 'abstract': None}
{'title': 'The Singular Values of Convolutional Layers', 'paperID': 'fb2edf25484c9e9e5f94b719c55dc1faf7591bfa', 'arxivId': '1805.10408', 'publication_year': 2018, 'abstract': None}
{'title': 'Inapproximability of Matrix p→q Norms', 'paperID': '665eff85f159c290e059056ac099a0a6e1f54725', 'arxivId': '1802.07425', 'publication_year': 2018, 'abstract': None}
{'title': 'Variational Network Quantization', 'paperID': 'f93ae1a0b9e40b138da8c25855b6c68af4ee201a', 'arxivId': None, 'publication_year': 2018, 'abstract': None}
{'title': 'BinaryRelax: A Relaxation Approach For Training Deep Neural Networks With Quantized Weights', 'paperID': 'b7ebb7aa28c275c329500e5597c2c399ac7e037a', 'arxivId': '1801.06313', 'publication_year': 2018, 'abstract': None}
{'title': 'Quantization and Training of Neural Networks for Efficient Integer-Arithmetic-Only Inference', 'paperID': '59d0d7ccec2db66cad20cac5721ce54a8a058294', 'arxivId': '1712.05877', 'publication_year': 2017, 'abstract': None}
{'title': 'Learning Discrete Weights Using the Local Reparameterization Trick', 'paperID': '15698db8c6b08891c8ab8b75a2738cad04c7b25b', 'arxivId': '1710.07739', 'publication_year': 2017, 'abstract': None}
{'title': 'Parseval Networks: Improving Robustness to Adversarial Examples', 'paperID': '013efe3ff541e518c51f08d1b62a62e0c57c0b14', 'arxivId': '1704.08847', 'publication_year': 2017, 'abstract': None}
{'title': 'Ristretto: Hardware-Oriented Approximation of Convolutional Neural Networks', 'paperID': '57713f4b3b9fbe6ceddfa8c26b4e1b99ad50a9b7', 'arxivId': '1605.06402', 'publication_year': 2016, 'abstract': None}
{'title': 'XNOR-Net: ImageNet Classification Using Binary Convolutional Neural Networks', 'paperID': 'b649a98ce77ece8cd7638bb74ab77d22d9be77e7', 'arxivId': '1603.05279', 'publication_year': 2016, 'abstract': None}
{'title': 'Automatic differentiation in machine learning: a survey', 'paperID': '643da4c4de1954daeac571a82367241db012a8bf', 'arxivId': '1502.05767', 'publication_year': 2015, 'abstract': None}
{'title': 'Deep Learning with Limited Numerical Precision', 'paperID': 'b7cf49e30355633af2db19f35189410c8515e91f', 'arxivId': '1502.02551', 'publication_year': 2015, 'abstract': None}
{'title': 'Estimating or Propagating Gradients Through Stochastic Neurons for Conditional Computation', 'paperID': '62c76ca0b2790c34e85ba1cce09d47be317c7235', 'arxivId': '1308.3432', 'publication_year': 2013, 'abstract': None}
{'title': 'Matrix P-norms are NP-hard to approximate if p ≠1,2,∞', 'paperID': '52a978e6de72fd3ee25b36170cd08cfe8005b7ba', 'arxivId': None, 'publication_year': 2009, 'abstract': None}
{'title': 'Matrix p-Norms Are NP-Hard to Approximate If p!=q1, 2, INFINITY', 'paperID': '61eabd7fa6c4d8fb14aa5ca5f8086238ef9f1e05', 'arxivId': '0908.1397', 'publication_year': 2009, 'abstract': None}
{'title': 'Probability Inequalities for Sums of Bounded Random Variables', 'paperID': '30ffd4a8e479d04b1dea5749eac4a466dccde64b', 'arxivId': None, 'publication_year': 1994, 'abstract': None}
{'title': 'Gradient $\\ell_1$ Regularization for Quantization Robustness', 'paperID': '036251ce21ef0750898bc4ddab42cb9f5d7bdded', 'arxivId': '2002.07520', 'publication_year': '2020', 'abstract': 'We analyze the effect of quantizing weights and activations of neural networks on their loss and derive a simple regularization scheme that improves robustness against post-training quantization. By training quantization-ready networks, our approach enables storing a single set of weights that can be quantized on-demand to different bit-widths as energy and memory requirements of the application change. Unlike quantization-aware training using the straight-through estimator that only targets a specific bit-width and requires access to training data and pipeline, our regularization-based method paves the way for "on the fly\'\' post-training quantization to various bit-widths. We show that by modeling quantization as a $\\ell_\\infty$-bounded perturbation, the first-order term in the loss expansion can be regularized using the $\\ell_1$-norm of gradients. We experimentally validate the effectiveness of our regularization scheme on different architectures on CIFAR-10 and ImageNet datasets.'}
{'title': 'Residual Dense Network for Image Restoration', 'paperID': '9a058fd787914ffbf90f607a5c62b271a8a87ea7', 'arxivId': '1812.10477', 'publication_year': 2018, 'abstract': None}
{'title': 'Dynamically Unfolding Recurrent Restorer: A Moving Endpoint Control Method for Image Restoration', 'paperID': 'f2ef09c15eeb7d197c8ec23fb85ce3bf4be6bd63', 'arxivId': '1805.07709', 'publication_year': 2018, 'abstract': None}
{'title': 'Fast, Trainable, Multiscale Denoising', 'paperID': 'e26e0c78e346c167e635e8f3b8b419e283542a70', 'arxivId': '1802.06130', 'publication_year': 2018, 'abstract': None}
{'title': 'Universal Denoising Networks : A Novel CNN Architecture for Image Denoising', 'paperID': '635fe55f70feffca01fec7e07e4968b98dba672f', 'arxivId': None, 'publication_year': 2017, 'abstract': None}
{'title': 'Beyond a Gaussian Denoiser: Residual Learning of Deep CNN for Image Denoising', 'paperID': '0c00a328fa7cd56ee60338c54e89bd48310db80b', 'arxivId': '1608.03981', 'publication_year': 2016, 'abstract': None}
{'title': 'Explaining nonlinear classification decisions with deep Taylor decomposition', 'paperID': 'dc00e2c47411d6d257c979963e4dd2f7d97d5d03', 'arxivId': '1512.02479', 'publication_year': 2015, 'abstract': None}
{'title': 'Trainable Nonlinear Reaction Diffusion: A Flexible Framework for Fast and Effective Image Restoration', 'paperID': 'eb04068416ade86de63cf9d9939e14d0bc9b96f9', 'arxivId': '1508.02848', 'publication_year': 2015, 'abstract': None}
{'title': 'Shrinkage Fields for Effective Image Restoration', 'paperID': '4513104e69cf6b01f3e70bb157ae107ed81624e0', 'arxivId': None, 'publication_year': 2014, 'abstract': None}
{'title': 'Deep Inside Convolutional Networks: Visualising Image Classification Models and Saliency Maps', 'paperID': 'dc6ac3437f0a6e64e4404b1b9d188394f8a3bf71', 'arxivId': '1312.6034', 'publication_year': 2013, 'abstract': None}
{'title': 'A Discriminative Approach for Wavelet Denoising', 'paperID': '33efd0cd7db2c9f44b2c2e150dafff14a96cd877', 'arxivId': None, 'publication_year': 2008, 'abstract': None}
{'title': 'Image Denoising Via Sparse and Redundant Representations Over Learned Dictionaries', 'paperID': 'e07416eabd4ba6c69fa473756bb04ae7161177be', 'arxivId': None, 'publication_year': 2006, 'abstract': None}
{'title': 'Image denoising with block-matching and 3D filtering', 'paperID': '742b3dce4a954001bb31bc7fa739c93fcbccd289', 'arxivId': None, 'publication_year': 2006, 'abstract': None}
{'title': 'Image quality assessment: from error visibility to structural similarity', 'paperID': 'eae2e0fa72e898c289365c0af16daf57a7a6cf40', 'arxivId': None, 'publication_year': 2004, 'abstract': None}
{'title': 'A database of human segmented natural images and its application to evaluating segmentation algorithms and measuring ecological statistics', 'paperID': '9a1ed876196ec9733acb1daa6d65e35ff0414291', 'arxivId': None, 'publication_year': 2001, 'abstract': None}
{'title': 'Bilateral filtering for gray and color images', 'paperID': 'bfeaf424a2ea6ca4702d545c6e959e2caeb68e9b', 'arxivId': None, 'publication_year': 1998, 'abstract': None}
{'title': 'Noise removal via Bayesian wavelet coring', 'paperID': '85a1725bfd3b4a2d3fe9a7272d66ebf03c016fed', 'arxivId': None, 'publication_year': 1996, 'abstract': None}
{'title': 'Adapting to Unknown Smoothness via Wavelet Shrinkage', 'paperID': '8cc9918add61ee5ef3b848aba9646169cc5e364e', 'arxivId': None, 'publication_year': 1995, 'abstract': None}
{'title': 'Extrapolation, Interpolation, and Smoothing of Stationary Time Series, with Engineering Applications', 'paperID': 'cb2ffb67def387b584a4bca8a6d40e1c7be44f72', 'arxivId': None, 'publication_year': 1949, 'abstract': None}
{'title': 'A Tour of Modern Image Filtering: New Insights and Methods, Both Practical and Theoretical', 'paperID': '5620050230ba1b45689cfc5e3efa064219a66a2e', 'arxivId': None, 'publication_year': 2013, 'abstract': None}
{'title': 'This article has been accepted for inclusion in a future issue of this journal. Content is final as presented, with the exception of pagination. IEEE TRANSACTIONS ON IMAGE PROCESSING 1 Optimal Denoising in Redundant Representations', 'paperID': '4e5c5fe6039aba0a86df0e8fc64c81563422a245', 'arxivId': None, 'publication_year': None, 'abstract': None}
{'title': 'Submitted to Ieee Transactions on Image Processing Adaptive Wavelet Thresholding for Image Denoising and Compression', 'paperID': '04f7769cf0908101af532b02428928baccb2c4d3', 'arxivId': None, 'publication_year': None, 'abstract': None}
{'title': 'Image Denoising Using Scale Mixtures of Gaussians in the Wavelet Domain', 'paperID': '85791491919e1f740f0e882366046acbe56fb14c', 'arxivId': None, 'publication_year': None, 'abstract': None}
{'title': 'Robust And Interpretable Blind Image Denoising Via Bias-Free Convolutional Neural Networks', 'paperID': '832baf7476fa4c98ad326ae9190d613d78e6eb13', 'arxivId': '1906.05478', 'publication_year': '2019', 'abstract': 'Deep convolutional networks often append additive constant ("bias") terms to their convolution operations, enabling a richer repertoire of functional mappings. Biases are also used to facilitate training, by subtracting mean response over batches of training images (a component of "batch normalization"). Recent state-of-the-art blind denoising methods (e.g., DnCNN) seem to require these terms for their success. Here, however, we show that these networks systematically overfit the noise levels for which they are trained: when deployed at noise levels outside the training range, performance degrades dramatically. In contrast, a bias-free architecture -- obtained by removing the constant terms in every layer of the network, including those used for batch normalization-- generalizes robustly across noise levels, while preserving state-of-the-art performance within the training range. Locally, the bias-free network acts linearly on the noisy image, enabling direct analysis of network behavior via standard linear-algebraic tools. These analyses provide interpretations of network functionality in terms of nonlinear adaptive filtering, and projection onto a union of low-dimensional subspaces, connecting the learning-based method to more traditional denoising methodology.'}
{'title': 'A Stratified Approach to Robustness for Randomly Smoothed Classifiers', 'paperID': '89750a16c0645ab8a8f7ba6f5848b7f98a4ea8eb', 'arxivId': None, 'publication_year': 2019, 'abstract': None}
{'title': 'Imperceptible, Robust, and Targeted Adversarial Examples for Automatic Speech Recognition', 'paperID': '361c7858fa8f55928dc6358bc25d18fe3316d735', 'arxivId': '1903.10346', 'publication_year': 2019, 'abstract': None}
{'title': 'Improving the Gaussian Mechanism for Differential Privacy: Analytical Calibration and Optimal Denoising', 'paperID': '7d45ac8d29160103cd0bba76aa99b0f60f23a1cd', 'arxivId': '1805.06530', 'publication_year': 2018, 'abstract': None}
{'title': 'Deep Speaker: an End-to-End Neural Speaker Embedding System', 'paperID': 'f8c61521ac186443aae4082616821a55780d32a9', 'arxivId': '1705.02304', 'publication_year': 2017, 'abstract': None}
{'title': 'CVXPY: A Python-Embedded Modeling Language for Convex Optimization', 'paperID': 'e177365c0dd642341469ba2f045405646c5dbb79', 'arxivId': '1603.00943', 'publication_year': 2016, 'abstract': None}
{'title': 'Librispeech: An ASR corpus based on public domain audio books', 'paperID': '34038d9424ce602d7ac917a4e582d977725d4393', 'arxivId': None, 'publication_year': 2015, 'abstract': None}
{'title': 'Between Pure and Approximate Differential Privacy', 'paperID': 'a7b7e17fbbc22664451ad0e01e8e012d934ac2c0', 'arxivId': '1501.06095', 'publication_year': 2015, 'abstract': None}
{'title': 'Beyond Differential Privacy: Composition Theorems and Relational Logic for f-divergences between Probabilistic Programs', 'paperID': '70e4a4d752a881fd0e8382489d5d22f449537567', 'arxivId': None, 'publication_year': 2013, 'abstract': None}
{'title': 'Missing data imputation for spectral audio signals', 'paperID': '55a4b14badcdcb4ae75e3729241fedbade728056', 'arxivId': None, 'publication_year': 2009, 'abstract': None}
{'title': 'Exploration-exploitation tradeoff using variance estimates in multi-armed bandits', 'paperID': '8d2820ac17ff3cedf59f173b16b98872848bf3ad', 'arxivId': None, 'publication_year': 2009, 'abstract': None}
{'title': 'On Divergences and Informations in Statistics and Information Theory', 'paperID': '91ab3ca9fe3add7ce48dc2f97bb9435db1a991b9', 'arxivId': None, 'publication_year': 2006, 'abstract': None}
{'title': 'Statistical models for natural sounds', 'paperID': 'e008ec108171c4eb88c65edf589ebee31e4359c8', 'arxivId': None, 'publication_year': 2010, 'abstract': None}
{'title': 'A General Class of Coefficients of Divergence of One Distribution from Another', 'paperID': '77ce3697fc01e0bebba1dfe81cedb712b0b604a0', 'arxivId': None, 'publication_year': 1966, 'abstract': None}
{'title': 'A Framework  for Robustness Certification  of Smoothed Classifiers Using  F-Divergences', 'paperID': 'e2d09159e54a53bb3b02e9265c0e63631d8d7d8a', 'arxivId': None, 'publication_year': '2020', 'abstract': 'Formal verification techniques that compute provable guarantees on properties of machine learning models, like robustness to norm-bounded adversarial perturbations, have yielded impressive results. Although most techniques developed so far requires knowledge of the architecture of the machine learning model and remains hard to scale to complex prediction pipelines, the method of randomized smoothing has been shown to overcome many of these obstacles. By requiring only black-box access to the underlying model, randomized smoothing scales to large architectures and is agnostic to the internals of the network. However, past work on randomized smoothing has focused on restricted classes of smoothing measures or perturbations (like Gaussian or discrete) and has only been able to prove robustness with respect to simple norm bounds. In this paper we introduce a general framework for proving robustness properties of smoothed machine learning models in the black-box setting. Specifically, we extend randomized smoothing procedures to handle arbitrary smoothing measures and prove robustness of the smoothed classifier by using $f$-divergences. Our methodology achieves state-of-the-art}certified robustness on MNIST, CIFAR-10 and ImageNet and also audio classification task, Librispeech, with respect to several classes of adversarial perturbations.'}
{'title': 'Learn to Grow: A Continual Structure Learning Framework for Overcoming Catastrophic Forgetting', 'paperID': '42a7f3e90aa4929d7f01b6124b87f82f7735aa88', 'arxivId': '1904.00310', 'publication_year': 2019, 'abstract': None}
{'title': 'Efficient Lifelong Learning with A-GEM', 'paperID': '4a954b3e72a61968ab235076bcc242aca3a05520', 'arxivId': '1812.00420', 'publication_year': 2018, 'abstract': None}
{'title': 'Learning to Learn without Forgetting By Maximizing Transfer and Minimizing Interference', 'paperID': '2b877889ac31b73d1ede70b00eb4c7118ef8eca2', 'arxivId': '1810.11910', 'publication_year': 2018, 'abstract': None}
{'title': 'Progress & Compress: A scalable framework for continual learning', 'paperID': 'ae7619604821adce52c28daa2aed14f5a191d975', 'arxivId': '1805.06370', 'publication_year': 2018, 'abstract': None}
{'title': 'Reinforced Continual Learning', 'paperID': '73d5c3cff5a777169dc62d0b351ddcfda503cd33', 'arxivId': '1805.12369', 'publication_year': 2018, 'abstract': None}
{'title': 'Unsupervised Representation Learning by Predicting Image Rotations', 'paperID': 'aab368284210c1bb917ec2d31b84588e3d2d7eb4', 'arxivId': '1803.07728', 'publication_year': 2018, 'abstract': None}
{'title': 'Piggyback: Adapting a Single Network to Multiple Tasks by Learning to Mask Weights', 'paperID': 'd5bb3faa48b83469da1a01ef267886e71f4a931a', 'arxivId': None, 'publication_year': 2018, 'abstract': None}
{'title': 'Overcoming catastrophic forgetting with hard attention to the task', 'paperID': '3aa673abd49f0837ed2fbf5cffcada9ba6f48693', 'arxivId': '1801.01423', 'publication_year': 2018, 'abstract': None}
{'title': 'Variational Continual Learning', 'paperID': 'd475f695dedd94e96771fdaa1e5c075fd01d11cf', 'arxivId': '1710.10628', 'publication_year': 2017, 'abstract': None}
{'title': 'Lifelong Learning with Dynamically Expandable Networks', 'paperID': 'ac7c04a668bdb0e3eff168e65cb85689b4f7ef57', 'arxivId': '1708.01547', 'publication_year': 2017, 'abstract': None}
{'title': 'Dynamic Multi-Task Learning with Convolutional Neural Network', 'paperID': 'ed04dc53d0091052feb3e7d6b7678fd7b218d416', 'arxivId': None, 'publication_year': 2017, 'abstract': None}
{'title': 'Gradient Episodic Memory for Continual Learning', 'paperID': '118fae4b4d07453561f1eded88654f812c7c61ec', 'arxivId': '1706.08840', 'publication_year': 2017, 'abstract': None}
{'title': 'Continual Learning with Deep Generative Replay', 'paperID': '59a922212153d3407e658109f36c11a34ee7d283', 'arxivId': '1705.08690', 'publication_year': 2017, 'abstract': None}
{'title': 'Overcoming Catastrophic Forgetting by Incremental Moment Matching', 'paperID': '0a9a3380090d994e867026388f64a85481cdb700', 'arxivId': '1703.08475', 'publication_year': 2017, 'abstract': None}
{'title': 'Overcoming catastrophic forgetting in neural networks', 'paperID': '2e55ba6c97ce5eb55abd959909403fe8da7e9fe9', 'arxivId': '1612.00796', 'publication_year': 2016, 'abstract': None}
{'title': 'Progressive Neural Networks', 'paperID': '53c9443e4e667170acc60ca1b31a0ec7151fe753', 'arxivId': '1606.04671', 'publication_year': 2016, 'abstract': None}
{'title': 'ELLA: An Efficient Lifelong Learning Algorithm', 'paperID': '8d49d34fff05285cb9a148261caff57775eb4453', 'arxivId': None, 'publication_year': 2013, 'abstract': None}
{'title': 'Learning Task Grouping and Overlap in Multi-task Learning', 'paperID': 'd3c04a424fff21d3d12ff8b0543734cf244d5f67', 'arxivId': '1206.6417', 'publication_year': 2012, 'abstract': None}
{'title': 'Online Incremental Feature Learning with Denoising Autoencoders', 'paperID': '005b668ef278941f584df96f2aca1ca88f056470', 'arxivId': None, 'publication_year': 2012, 'abstract': None}
{'title': 'A lifelong learning perspective for mobile robot control', 'paperID': '18e5ae17ea0c934dcad242b860e5f7a8ad6dd049', 'arxivId': None, 'publication_year': 1994, 'abstract': None}
{'title': 'Scalable and Order-robust Continual Learning with Additive Parameter Decomposition', 'paperID': 'bc4bcc5c62092349ad0ef82af958b16e0c3ec856', 'arxivId': '1902.09432', 'publication_year': '2019', 'abstract': 'While recent continual learning methods largely alleviate the catastrophic problem on toy-sized datasets, some issues remain to be tackled to apply them to real-world problem domains. First, a continual learning model should effectively handle catastrophic forgetting and be efficient to train even with a large number of tasks. Secondly, it needs to tackle the problem of order-sensitivity, where the performance of the tasks largely varies based on the order of the task arrival sequence, as it may cause serious problems where fairness plays a critical role (e.g. medical diagnosis). To tackle these practical challenges, we propose a novel continual learning method that is scalable as well as order-robust, which instead of learning a completely shared set of weights, represents the parameters for each task as a sum of task-shared and sparse task-adaptive parameters. With our Additive Parameter Decomposition (APD), the task-adaptive parameters for earlier tasks remain mostly unaffected, where we update them only to reflect the changes made to the task-shared parameters. This decomposition of parameters effectively prevents catastrophic forgetting and order-sensitivity, while being computation- and memory-efficient. Further, we can achieve even better scalability with APD using hierarchical knowledge consolidation, which clusters the task-adaptive parameters to obtain hierarchically shared parameters. We validate our network with APD, APD-Net, on multiple benchmark datasets against state-of-the-art continual learning methods, which it largely outperforms in accuracy, scalability, and order-robustness.'}
{'title': 'Tight Certificates of Adversarial Robustness for Randomly Smoothed Classifiers', 'paperID': '50c5763d2d35f2c4eaa5cebea310faf2cf0a10dc', 'arxivId': '1906.04948', 'publication_year': 2019, 'abstract': None}
{'title': 'Theoretical evidence for adversarial robustness through randomization: the case of the Exponential family', 'paperID': '4a416cb1cac9fb4fecad49af1ff07e2523c99cfe', 'arxivId': '1902.01148', 'publication_year': 2019, 'abstract': None}
{'title': 'Sorting out Lipschitz function approximation', 'paperID': 'f0ded4902d7f9c111e50047f8c9494effb7282d1', 'arxivId': '1811.05381', 'publication_year': 2018, 'abstract': None}
{'title': 'Adv-BNN: Improved Adversarial Defense through Robust Bayesian Neural Network', 'paperID': 'c1f76891bdfa07d9a61ad11a15de13b139b20d2a', 'arxivId': '1810.01279', 'publication_year': 2018, 'abstract': None}
{'title': 'Deep neural networks and mixed integer linear optimization', 'paperID': '33f68f93914704ba49b48b508e5bb93369f4e79f', 'arxivId': None, 'publication_year': 2018, 'abstract': None}
{'title': 'PeerNets: Exploiting Peer Wisdom Against Adversarial Attacks', 'paperID': 'bfb0d179916c000d54f27e7a9ea18b6269963e74', 'arxivId': '1806.00088', 'publication_year': 2018, 'abstract': None}
{'title': 'AttriGuard: A Practical Defense Against Attribute Inference Attacks via Adversarial Machine Learning', 'paperID': '291ac97d951026dfaa080bcbd46bdb9bde94ad4c', 'arxivId': '1805.04810', 'publication_year': 2018, 'abstract': None}
{'title': 'Regularisation of neural networks by enforcing Lipschitz continuity', 'paperID': '797e841a06e2f57163b86c24942b1e043fd3ca3e', 'arxivId': '1804.04368', 'publication_year': 2018, 'abstract': None}
{'title': 'On the Robustness of the CVPR 2018 White-Box Adversarial Example Defenses', 'paperID': '06b98537324dbf11c7de2040e519b4d110f5d622', 'arxivId': '1804.03286', 'publication_year': 2018, 'abstract': None}
{'title': 'Lipschitz-Margin Training: Scalable Certification of Perturbation Invariance for Deep Neural Networks', 'paperID': '0bd8c29a206c46dccca63c010a95734018c98d2e', 'arxivId': '1802.04034', 'publication_year': 2018, 'abstract': None}
{'title': 'Provably Minimally-Distorted Adversarial Examples', 'paperID': '59ea59d73eea51f80b60ba6ea47dac0197029336', 'arxivId': None, 'publication_year': 2017, 'abstract': None}
{'title': 'Output Range Analysis for Deep Neural Networks', 'paperID': 'c02596cee34919daeaab1beddd813f23d429973a', 'arxivId': '1709.09130', 'publication_year': 2017, 'abstract': None}
{'title': 'Mitigating Evasion Attacks to Deep Neural Networks via Region-based Classification', 'paperID': '69092affc3461a38eb05cf7982f104eb30b0492c', 'arxivId': '1709.05583', 'publication_year': 2017, 'abstract': None}
{'title': 'Cascade Adversarial Machine Learning Regularized with a Unified Embedding', 'paperID': '45a710be199c8eb43f465c88fc4b343267c35d38', 'arxivId': '1708.02582', 'publication_year': 2017, 'abstract': None}
{'title': 'An approach to reachability analysis for feed-forward ReLU neural networks', 'paperID': 'ee8bc379985788544e44cf63887cf75a03e08b64', 'arxivId': '1706.07351', 'publication_year': 2017, 'abstract': None}
{'title': 'On Detecting Adversarial Perturbations', 'paperID': '061fef7e31c2b6ae59e49b8cf3dfb9c449aebc0a', 'arxivId': '1702.04267', 'publication_year': 2017, 'abstract': None}
{'title': 'Safety Verification of Deep Neural Networks', 'paperID': 'd31655b3f82038c513eed0e4a84c8f1c89d5bfdb', 'arxivId': '1610.06940', 'publication_year': 2016, 'abstract': None}
{'title': 'Rank verification for exponential families', 'paperID': 'c770e4a0564e46e23f4684a76b885b995add053a', 'arxivId': '1610.03944', 'publication_year': 2016, 'abstract': None}
{'title': 'Simultaneous confidence intervals for multinomial proportions', 'paperID': 'd4180fc8e2a9d9f69f815e33b9f937197f649f96', 'arxivId': None, 'publication_year': 1999, 'abstract': None}
{'title': 'Simultaneous Confidence Intervals and Sample Size Determination for Multinomial Proportions', 'paperID': 'f10e974d32a8b20289bb6de74d96e90402b9ce2d', 'arxivId': None, 'publication_year': 1995, 'abstract': None}
{'title': 'On Simultaneous Confidence Intervals for Multinomial Proportions', 'paperID': 'd7b7e7b7771f8d0f666798a214b7437b63b6e3dd', 'arxivId': None, 'publication_year': 1965, 'abstract': None}
{'title': 'On the Problem of the Most Efficient Tests of Statistical Hypotheses', 'paperID': 'a05f5a5c9fe1d8a44f5960571cc6f4fbb75d0d36', 'arxivId': None, 'publication_year': 1933, 'abstract': None}
{'title': 'Certified Robustness for Top-k Predictions against Adversarial Perturbations via Randomized Smoothing', 'paperID': '947a4b2e31dcaeffa8d86bc8d6888665ec33c5f6', 'arxivId': '1912.09899', 'publication_year': '2019', 'abstract': 'It is well-known that classifiers are vulnerable to adversarial perturbations. To defend against adversarial perturbations, various certified robustness results have been derived. However, existing certified robustnesses are limited to top-1 predictions. In many real-world applications, top-$k$ predictions are more relevant. In this work, we aim to derive certified robustness for top-$k$ predictions. In particular, our certified robustness is based on randomized smoothing, which turns any classifier to a new classifier via adding noise to an input example. We adopt randomized smoothing because it is scalable to large-scale neural networks and applicable to any classifier. We derive a tight robustness in $\\ell_2$ norm for top-$k$ predictions when using randomized smoothing with Gaussian noise. We find that generalizing the certified robustness from top-1 to top-$k$ predictions faces significant technical challenges. We also empirically evaluate our method on CIFAR10 and ImageNet. For example, our method can obtain an ImageNet classifier with a certified top-5 accuracy of 62.8\\% when the $\\ell_2$-norms of the adversarial perturbations are less than 0.5 (=127/255). Our code is publicly available at: \\url{https://github.com/jjy1994/Certify_Topk}.'}
{'title': 'Dual Dynamic Inference: Enabling More Efficient, Adaptive, and Controllable Deep Inference', 'paperID': '53e36eb4ead1999146601db500d85faed219e8a9', 'arxivId': '1907.04523', 'publication_year': 2019, 'abstract': None}
{'title': 'Adversarial Robustness vs. Model Compression, or Both?', 'paperID': '1eff01027877843f1b492c4abecdbbc112497d29', 'arxivId': '1903.12561', 'publication_year': 2019, 'abstract': None}
{'title': 'Towards Understanding Adversarial Examples Systematically: Exploring Data Size, Task and Model Factors', 'paperID': 'ebde1d64f5a77f36258ac6c23f6285050968e3f9', 'arxivId': '1902.11019', 'publication_year': 2019, 'abstract': None}
{'title': 'Adversarially Trained Model Compression: When Robustness Meets Efficiency', 'paperID': '0b3de4589f96926621822dc07a9e3c25a5c338df', 'arxivId': None, 'publication_year': 2019, 'abstract': None}
{'title': 'Model Compression with Adversarial Robustness: A Unified Optimization Framework', 'paperID': '170dd6ea32861684e9fa4cc45816e5f6c2f44ea2', 'arxivId': '1902.03538', 'publication_year': 2019, 'abstract': None}
{'title': 'Survey on Multi-Output Learning', 'paperID': '4ae3fbba225eb647733e733c66836b0fc1abe4a0', 'arxivId': '1901.00248', 'publication_year': 2019, 'abstract': None}
{'title': 'EnergyNet: Energy-Efficient Dynamic Inference', 'paperID': '6aa8ca81c755843bb814f01b4f2a25fc8f3b781d', 'arxivId': None, 'publication_year': 2018, 'abstract': None}
{'title': 'Shallow-Deep Networks: Understanding and Mitigating Network Overthinking', 'paperID': 'a3143eaa68040d366848a9c324b29d3f56f97a5d', 'arxivId': None, 'publication_year': 2018, 'abstract': None}
{'title': 'Deep k-Means: Re-Training and Parameter Sharing with Harder Cluster Assignments for Compressing Deep Convolutions', 'paperID': 'e8b378731c5df7b09efdc6d14dc03a26e9f56a4b', 'arxivId': '1806.09228', 'publication_year': 2018, 'abstract': None}
{'title': 'Adversarial Learning of Portable Student Networks', 'paperID': 'f37a8472b00f4a00a91abb41e5ab764d5a5076a8', 'arxivId': None, 'publication_year': 2018, 'abstract': None}
{'title': 'SkipNet: Learning Dynamic Routing in Convolutional Networks', 'paperID': 'f37ea0b173dd0403a5028c12746082d31dff60bb', 'arxivId': '1711.09485', 'publication_year': 2017, 'abstract': None}
{'title': 'Anytime Neural Networks via Joint Optimization of Auxiliary Losses', 'paperID': '80b35b033bbb7585f97a458fd245e873fe5c75ed', 'arxivId': '1708.06832', 'publication_year': 2017, 'abstract': None}
{'title': 'On Compressing Deep Models by Low Rank and Sparse Decomposition', 'paperID': '9806871bdcf0a9f926f6b4aebd20ee4580d69f00', 'arxivId': None, 'publication_year': 2017, 'abstract': None}
{'title': 'Data-Driven Sparse Structure Selection for Deep Neural Networks', 'paperID': '2adb616a77fe28b49be2a2d66cccf2d7400e4a04', 'arxivId': '1707.01213', 'publication_year': 2017, 'abstract': None}
{'title': 'ShuffleNet: An Extremely Efficient Convolutional Neural Network for Mobile Devices', 'paperID': '9da734397acd7ff7c557960c62fb1b400b27bd89', 'arxivId': '1707.01083', 'publication_year': 2017, 'abstract': None}
{'title': 'Multi-Scale Dense Networks for Resource Efficient Image Classification', 'paperID': '125ccd810f43f1cba83c6681836d000f83d1886d', 'arxivId': None, 'publication_year': 2017, 'abstract': None}
{'title': 'Adversarial Transformation Networks: Learning to Generate Adversarial Examples', 'paperID': 'abf38db4775bec89c950013030d8eda56a89d32a', 'arxivId': '1703.09387', 'publication_year': 2017, 'abstract': None}
{'title': 'Spatially Adaptive Computation Time for Residual Networks', 'paperID': '7944d0b061610b1c67ad15efdf192681e60d0129', 'arxivId': '1612.02297', 'publication_year': 2016, 'abstract': None}
{'title': 'BranchyNet: Fast inference via early exiting from deep neural networks', 'paperID': '896de8418884f4aab1ae4a60027500c9e8baffc3', 'arxivId': '1709.01686', 'publication_year': 2016, 'abstract': None}
{'title': 'Learning Structured Sparsity in Deep Neural Networks', 'paperID': '7601b995303f953955004db7b9b8b206c0e02ff8', 'arxivId': '1608.03665', 'publication_year': 2016, 'abstract': None}
{'title': 'Quantized Convolutional Neural Networks for Mobile Devices', 'paperID': 'd3cb9bad655197b52932978dd8186b36c512bf92', 'arxivId': '1512.06473', 'publication_year': 2015, 'abstract': None}
{'title': 'Convolutional neural networks with low-rank regularization', 'paperID': 'd5b4721c8188269b120d3d06149a04435753e755', 'arxivId': '1511.06067', 'publication_year': 2015, 'abstract': None}
{'title': 'Learning both Weights and Connections for Efficient Neural Network', 'paperID': '1ff9a37d766e3a4f39757f5e1b235a42dacf18ff', 'arxivId': '1506.02626', 'publication_year': 2015, 'abstract': None}
{'title': 'Triple Wins: Boosting Accuracy, Robustness and Efficiency Together by Enabling Input-Adaptive Inference', 'paperID': '70a6f1820eec8152f4af826d9adf61f442a24743', 'arxivId': '2002.10025', 'publication_year': '2020', 'abstract': 'Deep networks were recently suggested to face the odds between accuracy (on clean natural images) and robustness (on adversarially perturbed images) (Tsipras et al., 2019). Such a dilemma is shown to be rooted in the inherently higher sample complexity (Schmidt et al., 2018) and/or model capacity (Nakkiran, 2019), for learning a high-accuracy and robust classifier. In view of that, give a classification task, growing the model capacity appears to help draw a win-win between accuracy and robustness, yet at the expense of model size and latency, therefore posing challenges for resource-constrained applications. Is it possible to co-design model accuracy, robustness and efficiency to achieve their triple wins? This paper studies multi-exit networks associated with input-adaptive efficient inference, showing their strong promise in achieving a “sweet point" in co-optimizing model accuracy, robustness, and efficiency. Our proposed solution, dubbed Robust Dynamic Inference Networks (RDI-Nets), allows for each input (either clean or adversarial) to adaptively choose one of the multiple output layers (early branches or the final one) to output its prediction. That multi-loss adaptivity adds new variations and flexibility to adversarial attacks and defenses, on which we present a systematical investigation. We show experimentally that by equipping existing backbones with such robust adaptive inference, the resulting RDI-Nets can achieve better accuracy and robustness, yet with over 30% computational savings, compared to the defended original models.'}
{'title': 'NOODL: Provable Online Dictionary Learning and Sparse Coding', 'paperID': '23e4f9ee3c7f6d201081cc895ddb5f33476b9058', 'arxivId': '1902.11261', 'publication_year': 2019, 'abstract': None}
{'title': 'Efficient Dictionary Learning with Gradient Descent', 'paperID': 'bbf8d32cfd460ddb89cba5d86d8dfb15e9979e17', 'arxivId': '1809.10313', 'publication_year': 2018, 'abstract': None}
{'title': 'Subgradient Descent Learns Orthogonal Dictionaries', 'paperID': '15411d45ac13f432c3505c3ce825dfa00d88f8a6', 'arxivId': '1810.10702', 'publication_year': 2018, 'abstract': None}
{'title': 'Structured Local Optima in Sparse Blind Deconvolution', 'paperID': 'a31df1ada97f656fc16516c75132b0cfe2b3ebc0', 'arxivId': '1806.00338', 'publication_year': 2018, 'abstract': None}
{'title': 'Global Geometry of Multichannel Sparse Blind Deconvolution on the Sphere', 'paperID': '68923afec7f5c04e2f399f3d31094bc27a82392b', 'arxivId': None, 'publication_year': 2018, 'abstract': None}
{'title': 'On Learning Sparsely Used Dictionaries from Incomplete Samples', 'paperID': '01218257f5871297755041551f25d77fed6b4c95', 'arxivId': '1804.09217', 'publication_year': 2018, 'abstract': None}
{'title': 'Alternating minimization for dictionary learning with random initialization', 'paperID': '0cfcb1908fee5395e159b9d5ab1f270009444cf9', 'arxivId': '1711.03634', 'publication_year': 2017, 'abstract': None}
{'title': 'Univariate and multivariate skewness and kurtosis for measuring nonnormality: Prevalence, influence and estimation', 'paperID': '67123f08ba8ffa75126cb68fd6860e5d34494815', 'arxivId': None, 'publication_year': 2017, 'abstract': None}
{'title': 'Fast and robust tensor decomposition with applications to dictionary learning', 'paperID': '078dfd1ae7a550b3f1d37de0887a4f1ce36aaa3f', 'arxivId': '1706.08672', 'publication_year': 2017, 'abstract': None}
{'title': 'Dictionary Learning for Massive Matrix Factorization', 'paperID': '0cef691880a3a2b15ea3d0740882921527d05c77', 'arxivId': '1605.00937', 'publication_year': 2016, 'abstract': None}
{'title': 'Complete dictionary recovery over the sphere', 'paperID': '1ef68840e963e6168a9d22785bc14cede6b54b2a', 'arxivId': '1504.06785', 'publication_year': 2015, 'abstract': None}
{'title': 'Sparse Modeling for Image and Vision Processing', 'paperID': 'a10a39d2811a804fcead1667c54c4465c3314484', 'arxivId': '1411.3230', 'publication_year': 2014, 'abstract': None}
{'title': 'Dictionary Learning and Tensor Decomposition via the Sum-of-Squares Method', 'paperID': '9868cfbc9860eb79a854be2550e1e9774ed53dc2', 'arxivId': '1407.1543', 'publication_year': 2014, 'abstract': None}
{'title': 'Exact Recovery of Sparsely-Used Dictionaries', 'paperID': '4e8d5da88bc2bb85bdc483b4cba316baed2b5999', 'arxivId': '1206.5882', 'publication_year': 2012, 'abstract': None}
{'title': 'Image Super-Resolution Via Sparse Representation', 'paperID': 'f99d0bd1f1288fe35d46f719125844bfbaf544e3', 'arxivId': None, 'publication_year': 2010, 'abstract': None}
{'title': 'Task-Driven Dictionary Learning', 'paperID': '59882b92d0183163e897a671b8c9298f89df5df3', 'arxivId': '1009.5358', 'publication_year': 2010, 'abstract': None}
{'title': 'Robust principal component analysis?', 'paperID': 'c8831d7d318b8d59f9b958d250a58f253f08bd8a', 'arxivId': '0912.3599', 'publication_year': 2009, 'abstract': None}
{'title': 'Natural Image Statistics - A Probabilistic Approach to Early Computational Vision', 'paperID': '3596cc61267bdae97bb1df9b01a8e9a1b8dca450', 'arxivId': None, 'publication_year': 2009, 'abstract': None}
{'title': 'Robust Face Recognition via Sparse Representation', 'paperID': 'd5eec41043d91964879c4c745c7165f823967f29', 'arxivId': None, 'publication_year': 2009, 'abstract': None}
{'title': 'Topology and data', 'paperID': 'a4b603ca6aaaa18968e08ac1b0ee093db8a99a6b', 'arxivId': None, 'publication_year': 2009, 'abstract': None}
{'title': 'Convex multi-task feature learning', 'paperID': '9e7b0395d7b34e9d34cca779afd0c10da6e135b5', 'arxivId': None, 'publication_year': 2008, 'abstract': None}
{'title': 'Generalized Power Method for Sparse Principal Component Analysis', 'paperID': 'c346bf16bcf34d432df0f30942b94cc6fdd4c3e2', 'arxivId': '0811.4724', 'publication_year': 2008, 'abstract': None}
{'title': 'Discriminative learned dictionaries for local image analysis', 'paperID': '0a072cbdee54b83c8df43a431065f009d2cd2e70', 'arxivId': None, 'publication_year': 2008, 'abstract': None}
{'title': 'Sparse Representation for Color Image Restoration', 'paperID': '92281d5002178003bd7060fc66677a3471cdaa4b', 'arxivId': None, 'publication_year': 2008, 'abstract': None}
{'title': 'Sparse Feature Learning for Deep Belief Networks', 'paperID': '41fef1a197fab9684a4608b725d3ae72e1ab4b39', 'arxivId': None, 'publication_year': 2007, 'abstract': None}
{'title': 'Guaranteed Minimum-Rank Solutions of Linear Matrix Equations via Nuclear Norm Minimization', 'paperID': '0c9bb579d8ad6ac987f7a16b66ddace671fc57c5', 'arxivId': '0706.4138', 'publication_year': 2007, 'abstract': None}
{'title': 'The Nonlinear Statistics of High-Contrast Patches in Natural Images', 'paperID': 'a11d6a90126d97d61d85098c8731c6f6d781e5ca', 'arxivId': None, 'publication_year': 2003, 'abstract': None}
{'title': 'Principal Component Analysis', 'paperID': '4387ec06ce5df65eb7c8221652cb9fd317c40bda', 'arxivId': None, 'publication_year': 2002, 'abstract': None}
{'title': 'Independent component analysis: algorithms and applications', 'paperID': '577d19a115f9ef6f002483fcf88adbb3b5479556', 'arxivId': None, 'publication_year': 2000, 'abstract': None}
{'title': 'Sparse coding with an overcomplete basis set: A strategy employed by V1?', 'paperID': '2805537bec87a6177037b18f9a3a9d3f1038867b', 'arxivId': None, 'publication_year': 1997, 'abstract': None}
{'title': 'A Fast Fixed-Point Algorithm for Independent Component Analysis', 'paperID': '0899a6b62251ebb4af1ed35f0c6f9d63bed8c8e9', 'arxivId': None, 'publication_year': 1997, 'abstract': None}
{'title': 'On the meaning and use of kurtosis.', 'paperID': '6f7ef8ed60553b37bdf335876ac4e0adf400d1a8', 'arxivId': None, 'publication_year': 1997, 'abstract': None}
{'title': 'Emergence of simple-cell receptive field properties by learning a sparse code for natural images', 'paperID': '8012c4a1e2ca663f1a04e80cbb19631a00cbab27', 'arxivId': None, 'publication_year': 1996, 'abstract': None}
{'title': 'Principal Components Analysis', 'paperID': 'b850d9d1529898ec4013deb1c976d081599c3a95', 'arxivId': None, 'publication_year': 1989, 'abstract': None}
{'title': 'Outlier-Robust PCA: The High-Dimensional Case', 'paperID': '70237128f7b4e4feda451457a9dc979446678776', 'arxivId': None, 'publication_year': 2013, 'abstract': None}
{'title': 'Projection-like Retractions on Matrix Manifolds', 'paperID': '6aa8b611d67af1d32bcb3b7af8ca82510f6b1949', 'arxivId': None, 'publication_year': 2012, 'abstract': None}
{'title': 'Understanding l4-based Dictionary Learning: Interpretation, Stability, and Robustness', 'paperID': 'f4ebde1ba8944f136a654b0bcd468afec23556f7', 'arxivId': None, 'publication_year': '2020', 'abstract': 'Recently $\\ell^4$-norm maximization has been proposed to solve the sparse dictionary learning (SDL) problem. The simple MSP (matching, stretching, and projection) algorithm proposed by \\cite{zhai2019a} has shown to be surprisingly efficient and effective. This paper aims to better understand this algorithm from its strong geometric and statistical connections with the classic PCA and ICA, as well as their associated fixed-point style algorithms. Such connections provide a unified way of viewing problems that pursue {\\em principal}, {\\em independent}, or {\\em sparse} components of high-dimensional data. Our studies reveal additional good properties of the $\\ell^4$-maximization: not only is the MSP algorithm for sparse coding insensitive to small noise, but also robust to outliers, and resilient to sparse corruptions. We provide preliminary statistical justification for such inherently nice properties. To corroborate the theoretical analysis, we also provide extensive and compelling experimental evidence with both synthetic data and real images.'}
{'title': 'Distributionally Robust Language Modeling', 'paperID': '77568c594470f9aa029f92774e2c12ab0451d9bb', 'arxivId': '1909.02060', 'publication_year': 2019, 'abstract': None}
{'title': 'Invariance-inducing regularization using worst-case transformations suffices to boost accuracy and spatial robustness', 'paperID': 'bd63a18ae679659b61a297e5ea8c5fee7f8b11b5', 'arxivId': '1906.11235', 'publication_year': 2019, 'abstract': None}
{'title': 'Right for the Wrong Reasons: Diagnosing Syntactic Heuristics in Natural Language Inference', 'paperID': '42ed4a9994e6121a9f325f5b901c5b3d7ce104f5', 'arxivId': '1902.01007', 'publication_year': 2019, 'abstract': None}
{'title': 'Gender Shades: Intersectional Accuracy Disparities in Commercial Gender Classification', 'paperID': '18858cc936947fc96b5c06bbe3c6c2faa5614540', 'arxivId': None, 'publication_year': 2018, 'abstract': None}
{'title': 'Anchor regression: Heterogeneous data meet causality', 'paperID': 'f8d8e52ec60a7da7609c79cb3a19635385e180aa', 'arxivId': '1801.06229', 'publication_year': 2018, 'abstract': None}
{'title': 'Conditional variance penalties and domain shift robustness', 'paperID': 'afdc57412a7dadf2a392a16276f05df757d5b98b', 'arxivId': None, 'publication_year': 2017, 'abstract': None}
{'title': 'Guarding Against Adversarial Domain Shifts with Counterfactual Regularization', 'paperID': '04fd269c96f11235fbbb985bb16dacedaa3098fd', 'arxivId': None, 'publication_year': 2017, 'abstract': None}
{'title': 'A systematic study of the class imbalance problem in convolutional neural networks', 'paperID': '9757ef31095227cb289af22b0a4010eda754d100', 'arxivId': '1710.05381', 'publication_year': 2017, 'abstract': None}
{'title': 'Incorporating Dialectal Variability for Socially Equitable Language Identification', 'paperID': 'd8a6999ab3b0395477e34e7e2fdb10e122e1cc56', 'arxivId': None, 'publication_year': 2017, 'abstract': None}
{'title': 'Train longer, generalize better: closing the generalization gap in large batch training of neural networks', 'paperID': '8501e330d78391f4e690886a8eb8fac867704ea6', 'arxivId': '1705.08741', 'publication_year': 2017, 'abstract': None}
{'title': 'A Broad-Coverage Challenge Corpus for Sentence Understanding through Inference', 'paperID': '5ded2b8c64491b4a67f6d39ce473d4b9347a672e', 'arxivId': '1704.05426', 'publication_year': 2017, 'abstract': None}
{'title': 'Virtual Adversarial Training: A Regularization Method for Supervised and Semi-Supervised Learning', 'paperID': '4b1c6f6521da545892f3f5dc39461584d4a27ec0', 'arxivId': '1704.03976', 'publication_year': 2017, 'abstract': None}
{'title': 'Gender and Dialect Bias in YouTube’s Automatic Captions', 'paperID': '901335712430a194b6e15d817685e5ecc72a15c1', 'arxivId': None, 'publication_year': 2017, 'abstract': None}
{'title': 'Equality of Opportunity in Supervised Learning', 'paperID': 'd42b11ce90c9c69a20ed015b73dc33e0e4100a7b', 'arxivId': '1610.02413', 'publication_year': 2016, 'abstract': None}
{'title': 'Demographic Dialectal Variation in Social Media: A Case Study of African-American English', 'paperID': '7a4f3a0cfc0cc2aafa4ed1a2924380e82d5e3e4c', 'arxivId': '1608.08868', 'publication_year': 2016, 'abstract': None}
{'title': 'Rethinking the Inception Architecture for Computer Vision', 'paperID': '23ffaa0fe06eae05817f527a47ac3291077f9e58', 'arxivId': '1512.00567', 'publication_year': 2015, 'abstract': None}
{'title': 'Unsupervised Domain Adaptation by Backpropagation', 'paperID': '2530cfc7764bda1330c48c0c8e2cd0e0c671d7e1', 'arxivId': '1409.7495', 'publication_year': 2014, 'abstract': None}
{'title': 'Magging: Maximin Aggregation for Inhomogeneous Large-Scale Data', 'paperID': '93f028b791bb7d0d4f0bccae89e7d7873a809572', 'arxivId': '1409.2638', 'publication_year': 2014, 'abstract': None}
{'title': 'Robust Learning under Uncertain Test Distributions: Relating Covariate Shift to Model Misspecification', 'paperID': '104f4de69582d2d2011d5c5135cf80b2233744f2', 'arxivId': None, 'publication_year': 2014, 'abstract': None}
{'title': 'Maximin effects in inhomogeneous large-scale data', 'paperID': '5d83a8514d419c3a2a62bc9754225968934288a0', 'arxivId': '1406.0596', 'publication_year': 2014, 'abstract': None}
{'title': 'Data-driven robust optimization', 'paperID': '50d7ecd6901d6759a6bd9da7f2fc8f346e073577', 'arxivId': '1401.0212', 'publication_year': 2013, 'abstract': None}
{'title': 'Tackling the widespread and critical impact of batch effects in high-throughput data', 'paperID': '52125dd0e436a5fe3ced11587aa4f37a01c51a87', 'arxivId': None, 'publication_year': 2010, 'abstract': None}
{'title': 'Convex Optimization Theory', 'paperID': 'e1932c4db44cc2ceab12a347c6067b139d040abb', 'arxivId': None, 'publication_year': 2009, 'abstract': None}
{'title': 'Improving predictive inference under covariate shift by weighting the log-likelihood function', 'paperID': '235723a15c86c369c99a42e7b666dfe156ad2cba', 'arxivId': None, 'publication_year': 2000, 'abstract': None}
{'title': 'Distributionally Robust Losses Against Mixture Covariate Shifts', 'paperID': '68d12857f76645a86417139eb6078db1ba76a7bf', 'arxivId': None, 'publication_year': 2019, 'abstract': None}
{'title': 'Certifiable Distributional Robustness with Principled Adversarial Training', 'paperID': 'a295f76c2afb7f79a970ccf086f16168d976bb93', 'arxivId': None, 'publication_year': 2017, 'abstract': None}
{'title': '“ Why Should I Trust You ? ” Explaining the Predictions of Any Classifier', 'paperID': '4c38051f439b5e7316dbd7fc42fb40249ce6835d', 'arxivId': None, 'publication_year': 2016, 'abstract': None}
{'title': 'ARMOURED: Adversarially Robust MOdels using Unlabeled data by REgularizing Diversity', 'paperID': '2bc747f61085bcd4c0cfa868ac6cfc92b0c1ce37', 'arxivId': None, 'publication_year': None, 'abstract': None}
{'title': 'Certify or Predict: Boosting Certified Robustness with Compositional Architectures', 'paperID': '48b7c4785693ba582f65b266756ba1946cef4bcb', 'arxivId': None, 'publication_year': None, 'abstract': None}
{'title': 'List-Decodable Mean Estimation in Nearly-PCA Time', 'paperID': '4c260343764c29db7d4039cfa14d88cf3169e11a', 'arxivId': '2011.09973', 'publication_year': 2020, 'abstract': None}
{'title': 'Optimal Robust Linear Regression in Nearly Linear Time', 'paperID': '1db7952118ebdc1d36ea20d9a2b74429a190994d', 'arxivId': '2007.08137', 'publication_year': 2020, 'abstract': None}
{'title': 'Robust Gaussian Covariance Estimation in Nearly-Matrix Multiplication Time', 'paperID': '18c20ed73e5a3424c91519664682130031a339af', 'arxivId': '2006.13312', 'publication_year': 2020, 'abstract': None}
{'title': 'Robust estimation via generalized quasi-gradients', 'paperID': '6a5126b6f980763e47d63c74526f11db5673cb45', 'arxivId': '2005.14073', 'publication_year': 2020, 'abstract': None}
{'title': 'List Decodable Mean Estimation in Nearly Linear Time', 'paperID': '5c7869bdcdcd0dd2ee45918792706e39ed1280dd', 'arxivId': '2005.09796', 'publication_year': 2020, 'abstract': None}
{'title': 'High-Dimensional Robust Mean Estimation via Gradient Descent', 'paperID': '9726d843000d55e24800bbc37d6392f821598c09', 'arxivId': '2005.01378', 'publication_year': 2020, 'abstract': None}
{'title': 'Recent Advances in Algorithmic High-Dimensional Robust Statistics', 'paperID': '0257850fef6a0c87eccb75942e05f3a8d051f2b1', 'arxivId': '1911.05911', 'publication_year': 2019, 'abstract': None}
{'title': 'Quantum Entropy Scoring for Fast Robust Mean Estimation and Improved Outlier Detection', 'paperID': 'e1d853d3c696e6ffc89bd02c3398aee29623687a', 'arxivId': '1906.11366', 'publication_year': 2019, 'abstract': None}
{'title': 'Faster Algorithms for High-Dimensional Robust Covariance Estimation', 'paperID': '6af68fe0e76d08966803959998dc34ee738d9391', 'arxivId': '1906.04661', 'publication_year': 2019, 'abstract': None}
{'title': 'Robust sub-Gaussian estimation of a mean vector in nearly linear time', 'paperID': 'aa7768d1bfe128a7c70deeadf351644b7aa9ab75', 'arxivId': '1906.03058', 'publication_year': 2019, 'abstract': None}
{'title': 'High-Dimensional Robust Mean Estimation in Nearly-Linear Time', 'paperID': '8599e1701c0598e27623419ef0b931c3e71dbac4', 'arxivId': '1811.09380', 'publication_year': 2018, 'abstract': None}
{'title': 'Robust moment estimation and improved clustering via sum of squares', 'paperID': 'c8662d9009dc0b4462a2d48c2ba1f6a51f09e70d', 'arxivId': None, 'publication_year': 2018, 'abstract': None}
{'title': 'Efficient Algorithms and Lower Bounds for Robust Linear Regression', 'paperID': '8904cdbe394593cdef96405b238fe5d3a4bdc03a', 'arxivId': '1806.00040', 'publication_year': 2018, 'abstract': None}
{'title': 'High Dimensional Robust Sparse Regression', 'paperID': 'ad901015a61585f967d87e6acb847be9d18d7df3', 'arxivId': '1805.11643', 'publication_year': 2018, 'abstract': None}
{'title': 'Efficient Algorithms for Outlier-Robust Regression', 'paperID': 'c49f1881dcb84113fe3cd8c9dbe539ad1111e2f0', 'arxivId': '1803.03241', 'publication_year': 2018, 'abstract': None}
{'title': 'Sever: A Robust Meta-Algorithm for Stochastic Optimization', 'paperID': 'f403d6c5c79d235c9d021e9e65ab691141e88a4c', 'arxivId': '1803.02815', 'publication_year': 2018, 'abstract': None}
{'title': 'Robust estimation via robust gradient estimation', 'paperID': 'e405c59d9e13c4d72050535f00cd3696ac004740', 'arxivId': '1802.06485', 'publication_year': 2018, 'abstract': None}
{'title': 'Mixture models, robustness, and sum of squares proofs', 'paperID': 'a4f12ff9e04ff40c320a40f67f2e9340479c8d54', 'arxivId': '1711.07454', 'publication_year': 2017, 'abstract': None}
{'title': 'List-decodable robust mean estimation and learning mixtures of spherical gaussians', 'paperID': 'bfbaf90374e4a33910435ab13c1d18f3b4835a4a', 'arxivId': '1711.07211', 'publication_year': 2017, 'abstract': None}
{'title': 'Computationally Efficient Robust Sparse Estimation in High Dimensions', 'paperID': '6b2ddc7eb3eff1adf2d69d9ef400dd5c4f6339ff', 'arxivId': None, 'publication_year': 2017, 'abstract': None}
{'title': 'Resilience: A Criterion for Learning in the Presence of Arbitrary Outliers', 'paperID': '925edae268cfdc7c6d75202da6963f2bf5770166', 'arxivId': '1703.04940', 'publication_year': 2017, 'abstract': None}
{'title': 'Being Robust (in High Dimensions) Can Be Practical', 'paperID': '2a6de51d86f13e9eb7efa85491682dad0ccd65e8', 'arxivId': '1703.00893', 'publication_year': 2017, 'abstract': None}
{'title': 'Testing Bayesian Networks', 'paperID': 'e7b392cb8c7b22cbd551fdd0be70eeb640b140f4', 'arxivId': '1612.03156', 'publication_year': 2016, 'abstract': None}
{'title': 'Statistical Query Lower Bounds for Robust Estimation of High-Dimensional Gaussians and Gaussian Mixtures', 'paperID': 'b501495a8467a93d559d6b3dda6184b0098b322f', 'arxivId': '1611.03473', 'publication_year': 2016, 'abstract': None}
{'title': 'Learning from untrusted data', 'paperID': '842ba35a690282acde75643bb1935a9b8b630b1e', 'arxivId': '1611.02315', 'publication_year': 2016, 'abstract': None}
{'title': 'Agnostic Estimation of Mean and Covariance', 'paperID': '45ec4a51a3c821039872dbbe0cb91087b92a106f', 'arxivId': '1604.06968', 'publication_year': 2016, 'abstract': None}
{'title': 'Robust Estimators in High Dimensions without the Computational Intractability', 'paperID': 'd5c26e47890f90d7b9ff64f9b395ff4210349b1b', 'arxivId': '1604.06443', 'publication_year': 2016, 'abstract': None}
{'title': 'Robust covariance and scatter matrix estimation under Huber’s contamination model', 'paperID': '026d83264f1590718a247c533fa912db34c7bc09', 'arxivId': '1506.00691', 'publication_year': 2015, 'abstract': None}
{'title': 'Structure learning of antiferromagnetic Ising models', 'paperID': '144987426b7d5bc9027f8d2dd9620ecb6966401f', 'arxivId': '1412.1443', 'publication_year': 2014, 'abstract': None}
{'title': 'Efficiently Learning Ising Models on Arbitrary Graphs', 'paperID': 'bd16fa2d0425e367385f00e6a924d37950361b82', 'arxivId': '1411.6156', 'publication_year': 2014, 'abstract': None}
{'title': 'Structure estimation for discrete graphical models: Generalized covariance matrices and their inverses', 'paperID': 'd32496881afebd48ab360b81c017d08466d5fcab', 'arxivId': '1212.0478', 'publication_year': 2012, 'abstract': None}
{'title': 'Learning Mixtures of Tree Graphical Models', 'paperID': 'e290d38eca3620965a2257aa12606b4a954e90d6', 'arxivId': None, 'publication_year': 2012, 'abstract': None}
{'title': 'Learning Bayesian networks: approaches and issues', 'paperID': '1e70c6c8128ddd94e59095c652e5513eb521d4ae', 'arxivId': None, 'publication_year': 2011, 'abstract': None}
{'title': 'Introduction to the non-asymptotic analysis of random matrices', 'paperID': '4406c54f40e0f73db2180704d454951649df32f2', 'arxivId': '1011.3027', 'publication_year': 2010, 'abstract': None}
{'title': 'Approximate centerpoints with proofs', 'paperID': '4c9abd36ab90c38432a21ff8957313648526ed1b', 'arxivId': None, 'publication_year': 2010, 'abstract': None}
{'title': 'Probabilistic Graphical Models: Principles and Techniques - Adaptive Computation and Machine Learning', 'paperID': 'c7baa5d9d6e244586eb90929526fa7d4589d8ed2', 'arxivId': None, 'publication_year': 2009, 'abstract': None}
{'title': 'Information-Theoretic Limits of Selecting Binary Graphical Models in High Dimensions', 'paperID': 'dce7e2c8b4187069aa7062b56bce77a2a26eeeda', 'arxivId': '0905.2639', 'publication_year': 2009, 'abstract': None}
{'title': 'Graphical Models, Exponential Families, and Variational Inference', 'paperID': 'd98d0d1900b13b87aa4ffd6b69c046beb63f0434', 'arxivId': None, 'publication_year': 2008, 'abstract': None}
{'title': 'Reconstruction of Markov Random Fields from Samples: Some Observations and Algorithms', 'paperID': 'b18c3b77cbe45cdb8869e44f3f8fa7289afa3858', 'arxivId': '0712.1402', 'publication_year': 2007, 'abstract': None}
{'title': 'Learning Bayesian networks', 'paperID': 'bc4d9febd19e30f376e4d26deeeb75047bde24d4', 'arxivId': None, 'publication_year': 2007, 'abstract': None}
{'title': 'High-Dimensional Graphical Model Selection Using ℓ1-Regularized Logistic Regression', 'paperID': 'a49a75990571ce0983bd045af8d2127bb6e3e9a8', 'arxivId': '0804.4202', 'publication_year': 2006, 'abstract': None}
{'title': 'Learning Factor Graphs in Polynomial Time and Sample Complexity', 'paperID': 'b52b4d46aa2ff7775ec36fc0f3d3fcc02ea237f1', 'arxivId': None, 'publication_year': 2006, 'abstract': None}
{'title': 'An optimal randomized algorithm for maximum Tukey depth', 'paperID': '27ae01b74d54035c28abff93b7e0dd0382139acf', 'arxivId': None, 'publication_year': 2004, 'abstract': None}
{'title': 'The Sample Complexity of Learning Fixed-Structure Bayesian Networks', 'paperID': 'd183977b599bd8b8dc711083d16717db55142ba6', 'arxivId': None, 'publication_year': 1997, 'abstract': None}
{'title': 'The Complexity and Approximability of Finding Maximum Feasible Subsystems of Linear Relations', 'paperID': '61a65e0d94160135b96cf7b484344449b53f621d', 'arxivId': None, 'publication_year': 1995, 'abstract': None}
{'title': 'Approximating center points with iterated radon points', 'paperID': 'db95a993109f14558f3410ab8f6c1a1a5534a5e3', 'arxivId': None, 'publication_year': 1993, 'abstract': None}
{'title': 'Approximating discrete probability distributions with dependence trees', 'paperID': '683fe3bbf2b2e628cf40d90e35fb39effc63b7e9', 'arxivId': None, 'publication_year': 1968, 'abstract': None}
{'title': 'High-Dimensional Graphical Model Selection Using ℓ1-Regularized Logistic Regression', 'paperID': 'f24d15247fe922982c7e3478db36c94825619395', 'arxivId': None, 'publication_year': 2007, 'abstract': None}
{'title': 'Bayesian Networks and Decision Graphs', 'paperID': '2aef78ad47756436deecf6b3578d65dc37a61753', 'arxivId': None, 'publication_year': 2001, 'abstract': None}
{'title': 'On robust estimation of the location parameter', 'paperID': 'c87d57da3b1f2b467ef4995d30df832ee2281107', 'arxivId': None, 'publication_year': 1980, 'abstract': None}
{'title': 'The Densest Hemisphere Problem', 'paperID': 'b83151fcd9264ce85feeeeb9707b3655ecbe6dc9', 'arxivId': None, 'publication_year': 1978, 'abstract': None}
{'title': 'Mathematics and the Picturing of Data', 'paperID': '746546336375a9129b856d44f0740e6609024212', 'arxivId': None, 'publication_year': 1975, 'abstract': None}
{'title': 'Robust Learning of Fixed-Structure Bayesian Networks in Nearly-Linear Time', 'paperID': '7427493f3233580b28c949baace2461a92f37706', 'arxivId': '2105.05555', 'publication_year': '2021', 'abstract': 'We study the problem of learning Bayesian networks where an ǫ-fraction of the samples are adversarially corrupted. We focus on the fully-observable case where the underlying graph structure is known. In this work, we present the first nearly-linear time algorithm for this problem with a dimension-independent error guarantee. Previous robust algorithms with comparable error guarantees are slower by at least a factor of (d/ǫ), where d is the number of variables in the Bayesian network and ǫ is the fraction of corrupted samples. Our algorithm and analysis are considerably simpler than those in previous work. 1 We achieve this by establishing a direct connection between robust learning of Bayesian networks and robust mean estimation. As a subroutine in our algorithm, we develop a robust mean estimation algorithm whose runtime is nearly-linear in the number of nonzeros in the input samples, which may be of independent interest.'}
{'title': 'Hierarchical Verification for Adversarial Robustness', 'paperID': '72647fbd50bd6ae42d253116bc62504bb136f8d7', 'arxivId': '2007.11826', 'publication_year': 2020, 'abstract': None}
{'title': 'Foundations of Data Science', 'paperID': 'dd45dc3767230b70197420e1523dc0f1d7930f80', 'arxivId': None, 'publication_year': 2020, 'abstract': None}
{'title': 'The Marabou Framework for Verification and Analysis of Deep Neural Networks', 'paperID': '3c742ebff7df12e3fd0194023975e2211e4ba67a', 'arxivId': None, 'publication_year': 2019, 'abstract': None}
{'title': 'Provable Certificates for Adversarial Examples: Fitting a Ball in the Union of Polytopes', 'paperID': '064ec3a5e121cf997c3b57b23867c756cd141c04', 'arxivId': '1903.08778', 'publication_year': 2019, 'abstract': None}
{'title': 'Decoupling Direction and Norm for Efficient Gradient-Based L2 Adversarial Attacks and Defenses', 'paperID': '5ca131d97019ff1e40a92fa1c9c4c5179632744a', 'arxivId': '1811.09600', 'publication_year': 2018, 'abstract': None}
{'title': 'Verifying Neural Networks with Mixed Integer Programming', 'paperID': 'edce5208900a2702eee5b2452781909a4c8aa77a', 'arxivId': '1711.07356', 'publication_year': 2017, 'abstract': None}
{'title': 'Efficient projections onto the l1-ball for learning in high dimensions', 'paperID': 'ed7c7c079c8c54d3b82e016cc52a7a2c3a61f237', 'arxivId': None, 'publication_year': 2008, 'abstract': None}
{'title': 'Abstract interpretation: a unified lattice model for static analysis of programs by construction or approximation of fixpoints', 'paperID': 'c77cd64f26228442ffff9219bfd870c83c8747c0', 'arxivId': None, 'publication_year': 1977, 'abstract': None}
{'title': 'Beyond the Single Neuron Convex Barrier for Neural Network Certification', 'paperID': '89803ae9052541794bf34673101d88c02c15b19f', 'arxivId': None, 'publication_year': 2019, 'abstract': None}
{'title': 'Certifying Geometric Robustness of Neural Networks', 'paperID': '641864f095a113c8a0e4f8e58647c4b22f5ef478', 'arxivId': None, 'publication_year': 2019, 'abstract': None}
{'title': 'Fast projection onto the simplex and the lll 1 ball', 'paperID': 'c1626528298f39c11834a66b34e21f645e46690c', 'arxivId': None, 'publication_year': 2014, 'abstract': None}
{'title': 'Fast Geometric Projections for Local Robustness Certification', 'paperID': '656cec38e5295b94a17cf82e9ee9dd7b38296b49', 'arxivId': '2002.04742', 'publication_year': '2020', 'abstract': 'Local robustness ensures that a model classifies all inputs within an $\\epsilon$-ball consistently, which precludes various forms of adversarial inputs. In this paper, we present a fast procedure for checking local robustness in feed-forward neural networks with piecewise linear activation functions. The key insight is that such networks partition the input space into a polyhedral complex such that the network is linear inside each polyhedral region; hence, a systematic search for decision boundaries within the regions around a given input is sufficient for assessing robustness. Crucially, we show how these regions can be analyzed using geometric projections instead of expensive constraint solving, thus admitting an efficient, highly-parallel GPU implementation at the price of incompleteness, which can be addressed by falling back on prior approaches. Empirically, we find that incompleteness is not often an issue, and that our method performs one to two orders of magnitude faster than existing robustness-certification techniques based on constraint solving.'}
{'title': 'Adversarial Training and Provable Defenses: Bridging the Gap', 'paperID': '71ea8f105803703893b5c2d01f0c9508643b6554', 'arxivId': None, 'publication_year': 2020, 'abstract': None}
{'title': 'On Adaptive Attacks to Adversarial Example Defenses', 'paperID': '58c143069444c7dff4be53531a47efefc40be497', 'arxivId': '2002.08347', 'publication_year': 2020, 'abstract': None}
{'title': 'Fast is better than free: Revisiting adversarial training', 'paperID': '6d4a87759917132913319960389f17fa1fe8b630', 'arxivId': '2001.03994', 'publication_year': 2020, 'abstract': None}
{'title': 'Playing it Safe: Adversarial Robustness with an Abstain Option', 'paperID': '9f862165c7b82eb4779484ff5ca2235a2fbaba91', 'arxivId': '1911.11253', 'publication_year': 2019, 'abstract': None}
{'title': 'Confidence-Calibrated Adversarial Training: Generalizing to Unseen Attacks', 'paperID': '604dc3c7ad3736e58d7fd8a5839f8d8ba63e63b6', 'arxivId': None, 'publication_year': 2019, 'abstract': None}
{'title': 'Mixup Inference: Better Exploiting Mixup to Defend Adversarial Attacks', 'paperID': '1c1003f06c6cf0f61dfe0fcc0346c23d3c681fae', 'arxivId': '1909.11515', 'publication_year': 2019, 'abstract': None}
{'title': 'Efficient and Accurate Estimation of Lipschitz Constants for Deep Neural Networks', 'paperID': '89fc3d8af739f3c41ff72a1bd0acf0571a8c533e', 'arxivId': '1906.04893', 'publication_year': 2019, 'abstract': None}
{'title': 'GAT: Generative Adversarial Training for Adversarial Example Detection and Robust Classification', 'paperID': '95239030dcb8d9213b77cf04b03f2e14a900e08b', 'arxivId': '1905.11475', 'publication_year': 2019, 'abstract': None}
{'title': 'Resisting Adversarial Attacks by k-Winners-Take-All', 'paperID': '449b8ee671510b7ba749074e053815a3a655b0be', 'arxivId': None, 'publication_year': 2019, 'abstract': None}
{'title': 'ME-Net: Towards Effective Adversarial Robustness with Matrix Estimation', 'paperID': '4f8c49cd3eccc2417c78e0b310698d9f603aa2e9', 'arxivId': '1905.11971', 'publication_year': 2019, 'abstract': None}
{'title': 'Minimum Uncertainty Based Detection of Adversaries in Deep Neural Networks', 'paperID': '37a9e8ce40c010216bad8a009fca168be2332dde', 'arxivId': '1904.02841', 'publication_year': 2019, 'abstract': None}
{'title': 'The Odds are Odd: A Statistical Test for Detecting Adversarial Examples', 'paperID': '95ea893315923ff14d7632f7a7e5d07cdf800ea7', 'arxivId': '1902.04818', 'publication_year': 2019, 'abstract': None}
{'title': 'Thwarting Adversarial Examples: An L_0-Robust Sparse Fourier Transform', 'paperID': 'bc5a73a755d43f8579770c0408b4b89ee5ae4fbe', 'arxivId': '1812.05013', 'publication_year': 2018, 'abstract': None}
{'title': 'Understanding Measures of Uncertainty for Adversarial Example Detection', 'paperID': '63ed798f1847d8a952cbeb75d3b286f16c144914', 'arxivId': '1803.08533', 'publication_year': 2018, 'abstract': None}
{'title': 'Error Correcting Output Codes Improve Probability Estimation and Adversarial Robustness of Deep Neural Networks', 'paperID': 'b0d675ebfbaf4b94bc517192bc5a6ea5890f60e8', 'arxivId': None, 'publication_year': 2019, 'abstract': None}
{'title': 'Provably robust classification of adversarial examples with detection', 'paperID': '73dd7ff60ba551fcf1b7b13fdf65ae29d6e2f37c', 'arxivId': None, 'publication_year': None, 'abstract': 'Adversarial attacks against deep networks can be defended against either by building robust classiﬁers or, by creating classiﬁers that can detect the presence of adversarial perturbations. Although it may intuitively seem easier to simply detect attacks rather than build a robust classiﬁer, this has not bourne out in practice even empirically, as most detection methods have subsequently been broken by adaptive attacks, thus necessitating veriﬁable performance for detection mechanisms. In this paper, we propose a new method for jointly training a provably robust classiﬁer and detector. Speciﬁcally, we show that by introducing an additional “abstain/detection” into a classiﬁer, we can modify existing certiﬁed defense mechanisms to allow the classiﬁer to either robustly classify or detect adversarial attacks. We extend the common interval bound propagation (IBP) method for certiﬁed robustness under (cid:96) ∞ perturbations to account for our new robust objective, and show that the method outperforms traditional IBP used in isolation, especially for large perturbation sizes. Speciﬁcally, tests on MNIST and CIFAR-10 datasets exhibit promising results, for example with provable robust error less than 63 . 63% and 67 . 92% , for 55 . 6% and 66 . 37% natural error, for (cid:15) = 8 / 255 and 16 / 255 on the CIFAR-10 dataset, respectively. and shown that such can be The effectiveness of the proposed versus SOTA robust classiﬁcation methods is corroborated by empirical tests on MNIST and CIFAR-10, against large perturbations.'}
{'title': 'Informative Dropout for Robust Representation Learning: A Shape-bias Perspective', 'paperID': '5414cb3aedbbfd5550e1f8b1aa5e27d04003700f', 'arxivId': None, 'publication_year': 2020, 'abstract': None}
{'title': 'Increasing the robustness of DNNs against image corruptions by playing the Game of Noise', 'paperID': '86974ebbf9f7d5797e8ea919a347c3dbbe9a1f17', 'arxivId': '2001.06057', 'publication_year': 2020, 'abstract': None}
{'title': 'Reducing Domain Gap via Style-Agnostic Networks', 'paperID': '6673237e21e9bb0605704f4ba3ef7ef680558ab2', 'arxivId': '1910.11645', 'publication_year': 2019, 'abstract': None}
{'title': 'Defective Convolutional Layers Learn Robust CNNs', 'paperID': '1b78742903fbf51a544fd40d4e2395cf8df044fd', 'arxivId': None, 'publication_year': 2019, 'abstract': None}
{'title': 'Benchmarking Robustness in Object Detection: Autonomous Driving when Winter is Coming', 'paperID': 'f3b76f7a1042972009c37302ea00daa30238934b', 'arxivId': '1907.07484', 'publication_year': 2019, 'abstract': None}
{'title': 'On Physical Adversarial Patches for Object Detection', 'paperID': '4974595550d47d3d444cf37fed1cee592eb50fcd', 'arxivId': '1906.11897', 'publication_year': 2019, 'abstract': None}
{'title': 'Domain-Specific Batch Normalization for Unsupervised Domain Adaptation', 'paperID': 'ae0a728d10e4c61a66021bc02b01e7bdd13030b9', 'arxivId': '1906.03950', 'publication_year': 2019, 'abstract': None}
{'title': 'Weight Standardization', 'paperID': 'caa2704320e3742bc611c30092acd7a7eb87d5d4', 'arxivId': '1903.10520', 'publication_year': 2019, 'abstract': None}
{'title': 'Approximating CNNs with Bag-of-local-Features models works surprisingly well on ImageNet', 'paperID': '810ae452a3a1f673ea241bd540f9551b2996ed5b', 'arxivId': '1904.00760', 'publication_year': 2019, 'abstract': None}
{'title': 'Deep convolutional networks do not classify based on global object shape', 'paperID': '23cfb692c55ab178a818d4a86d5d417981358086', 'arxivId': None, 'publication_year': 2018, 'abstract': None}
{'title': 'Physical Adversarial Examples for Object Detectors', 'paperID': 'c67855ff840c9f8d256486158c63a242d912e41e', 'arxivId': '1807.07769', 'publication_year': 2018, 'abstract': None}
{'title': 'Group Normalization', 'paperID': 'd08b35243edc5be07387a9ed218070b31e502901', 'arxivId': '1803.08494', 'publication_year': 2018, 'abstract': None}
{'title': 'Measuring the tendency of CNNs to Learn Surface Statistical Regularities', 'paperID': '39c940bfe6750be6a0c3e3e42e3c2d697aeb40fa', 'arxivId': '1711.11561', 'publication_year': 2017, 'abstract': None}
{'title': 'Squeeze-and-Excitation Networks', 'paperID': 'fb37561499573109fc2cebb6a7b08f44917267dd', 'arxivId': '1709.01507', 'publication_year': 2017, 'abstract': None}
{'title': 'Richer Convolutional Features for Edge Detection', 'paperID': '1bbf746cca4bcafd274d197ac9fae82b245bf97b', 'arxivId': '1612.02103', 'publication_year': 2016, 'abstract': None}
{'title': 'A Learned Representation For Artistic Style', 'paperID': '99542f614d7e4146cad17196e76c997e57a69e4d', 'arxivId': '1610.07629', 'publication_year': 2016, 'abstract': None}
{'title': 'Holistically-Nested Edge Detection', 'paperID': '8da55e685a7bef9c897788ab519a8710c695c419', 'arxivId': '1504.06375', 'publication_year': 2015, 'abstract': None}
{'title': 'Contour Detection and Hierarchical Image Segmentation', 'paperID': '0e5a262bf59b68ba8a7a1103d16fa33a9f5ffc28', 'arxivId': None, 'publication_year': 2011, 'abstract': None}
{'title': 'A Computational Approach to Edge Detection', 'paperID': 'fcf9fc4e23b45345c2404ce7d6cb0fc9dea2c9ec', 'arxivId': None, 'publication_year': 1986, 'abstract': None}
{'title': 'Does enhanced shape bias improve neural network robustness to common corruptions?', 'paperID': '3797437ea7990e99cbba6e94d402650a842ba738', 'arxivId': '2104.09789', 'publication_year': '2021', 'abstract': 'Convolutional neural networks (CNNs) learn to extract representations of complex features, such as object shapes and textures to solve image recognition tasks. Recent work indicates that CNNs trained on ImageNet are biased towards features that encode textures and that these alone are sufficient to generalize to unseen test data from the same distribution as the training data but often fail to generalize to out-of-distribution data. It has been shown that augmenting the training data with different image styles decreases this texture bias in favor of increased shape bias while at the same time improving robustness to common corruptions, such as noise and blur. Commonly, this is interpreted as shape bias increasing corruption robustness. However, this relationship is only hypothesized. We perform a systematic study of different ways of composing inputs based on natural images, explicit edge information, and stylization. While stylization is essential for achieving high corruption robustness, we do not find a clear correlation between shape bias and robustness. We conclude that the data augmentation caused by style-variation accounts for the improved corruption robustness and increased shape bias is only a byproduct.'}
{'title': 'Towards Debiasing NLU Models from Unknown Biases', 'paperID': '6a3cc30d5d6342d912851deb4362b8c47fa5ede3', 'arxivId': '2009.12303', 'publication_year': 2020, 'abstract': None}
{'title': 'Robust Bayesian Classification Using an Optimistic Score Ratio', 'paperID': '2fbea3a1cad10c9bd5a01cd7eae6ca7f46f4e8a1', 'arxivId': '2007.04458', 'publication_year': 2020, 'abstract': None}
{'title': 'Distributional Robustness with IPMs and links to Regularization and GANs', 'paperID': '03700ad9bea6cdb705fe51834f46cd037c78c13f', 'arxivId': '2006.04349', 'publication_year': 2020, 'abstract': None}
{'title': 'Demoting Racial Bias in Hate Speech Detection', 'paperID': '034415a68c3f2d0710bf80d2b97bae1c583da4c8', 'arxivId': '2005.12246', 'publication_year': 2020, 'abstract': None}
{'title': 'Don’t Stop Pretraining: Adapt Language Models to Domains and Tasks', 'paperID': 'e816f788767eec6a8ef0ea9eddd0e902435d4271', 'arxivId': '2004.10964', 'publication_year': 2020, 'abstract': None}
{'title': 'The Risk of Racial Bias in Hate Speech Detection', 'paperID': '8963317176fa81e185fd7a8f8cd001d7e11a4868', 'arxivId': None, 'publication_year': 2019, 'abstract': None}
{'title': 'Distributionally Robust Counterfactual Risk Minimization', 'paperID': '1dcc2da3fde52cacdec926d5c4e2bb425959721b', 'arxivId': '1906.06211', 'publication_year': 2019, 'abstract': None}
{'title': 'Generative Adversarial Networks in Computer Vision: A Survey and Taxonomy.', 'paperID': '2673354bc246e65962a6dca32d5f41cc8f11a249', 'arxivId': None, 'publication_year': 2019, 'abstract': None}
{'title': 'A Survey on Automatic Detection of Hate Speech in Text', 'paperID': 'f9c56fb6e3001f3acbc994a894b4190d78270e1b', 'arxivId': None, 'publication_year': 2018, 'abstract': None}
{'title': 'The Mechanics of n-Player Differentiable Games', 'paperID': '52f7ae53e58c5098133d041794b4465d36c2fdb6', 'arxivId': '1802.05642', 'publication_year': 2018, 'abstract': None}
{'title': 'Large Scale Crowdsourcing and Characterization of Twitter Abusive Behavior', 'paperID': '290af67244094745eaa927bfa8a3727e93dba78b', 'arxivId': '1802.00393', 'publication_year': 2018, 'abstract': None}
{'title': 'Predictably Unequal? The Effects of Machine Learning on Credit Markets', 'paperID': 'c3b74808e482d13c46845980008fd1a578ec2865', 'arxivId': None, 'publication_year': 2017, 'abstract': None}
{'title': 'A Survey on Hate Speech Detection using Natural Language Processing', 'paperID': '6661802f5e1ee004c20a28dcce9b582d4b5fe6d7', 'arxivId': None, 'publication_year': 2017, 'abstract': None}
{'title': 'Automated Hate Speech Detection and the Problem of Offensive Language', 'paperID': '8dd6a2c9c88c9b3465484228c93f4dcc11cfeab9', 'arxivId': '1703.04009', 'publication_year': 2017, 'abstract': None}
{'title': 'Pointer Sentinel Mixture Models', 'paperID': 'efbd381493bb9636f489b965a2034d529cd56bcd', 'arxivId': '1609.07843', 'publication_year': 2016, 'abstract': None}
{'title': 'Reward Augmented Maximum Likelihood for Neural Structured Prediction', 'paperID': '1d9600229a4cf8ba5e8f5ad4d05b41af9c8f80a6', 'arxivId': '1609.00150', 'publication_year': 2016, 'abstract': None}
{'title': 'Deep Speech 2 : End-to-End Speech Recognition in English and Mandarin', 'paperID': '13497bd108d4412d02050e646235f456568cf822', 'arxivId': '1512.02595', 'publication_year': 2015, 'abstract': None}
{'title': 'Tagging Performance Correlates with Author Age', 'paperID': 'e09aa121bca3a0b9a0fe5f7ca119f44791cba1d7', 'arxivId': None, 'publication_year': 2015, 'abstract': None}
{'title': 'Approximating the Kullback Leibler Divergence Between Gaussian Mixture Models', 'paperID': '831780b12cb41a9905c3d4f58831a2ea6d09223b', 'arxivId': None, 'publication_year': 2007, 'abstract': None}
{'title': 'From Few to Many: Illumination Cone Models for Face Recognition under Variable Lighting and Pose', 'paperID': '6642e9c6cf7432e2d11b7edf7cd47f1285acd54e', 'arxivId': None, 'publication_year': 2001, 'abstract': None}
{'title': 'Variance Reduction Techniques for Gradient Estimates in Reinforcement Learning', 'paperID': '1187a77f857ad029168863ba0005ddf6d2b957c8', 'arxivId': None, 'publication_year': 2001, 'abstract': None}
{'title': 'Nash Convergence of Gradient Dynamics in General-Sum Games', 'paperID': 'a7c183abb9b044bfbe1f09199ee970ea3a01104f', 'arxivId': '1301.3892', 'publication_year': 2000, 'abstract': None}
{'title': 'Long Short-Term Memory', 'paperID': '2e9d221c206e9503ceb452302d68d10e293f2a10', 'arxivId': None, 'publication_year': 1997, 'abstract': None}
{'title': 'On Information and Sufficiency', 'paperID': '87cbed883368d4a9efd42fdd91f47038f8d8fbe6', 'arxivId': None, 'publication_year': 1997, 'abstract': None}
{'title': 'Kullback-Leibler divergence constrained distributionally robust optimization', 'paperID': 'e10642453c5c99442eb24743c4bab60a3a0b6273', 'arxivId': None, 'publication_year': 2012, 'abstract': None}
{'title': 'LSTM Neural Networks for Language Modeling', 'paperID': 'f9a1b3850dfd837793743565a8af95973d395a4e', 'arxivId': None, 'publication_year': 2012, 'abstract': None}
{'title': 'A course in game theory', 'paperID': '26743ef8d4759d487dc3cc0993d3c6eed509e266', 'arxivId': None, 'publication_year': 1992, 'abstract': None}
{'title': 'Conference Paper', 'paperID': '810b9ffea4c74db3923336a22dc9563679cfe564', 'arxivId': None, 'publication_year': None, 'abstract': None}
{'title': 'Modeling the Second Player in Distributionally Robust Optimization', 'paperID': '5ede529879d162d2779d410a5775d3f6cd6be3f4', 'arxivId': '2103.10282', 'publication_year': '2021', 'abstract': 'Distributionally robust optimization (DRO) provides a framework for training machine learning models that are able to perform well on a collection of related data distributions (the"uncertainty set"). This is done by solving a min-max game: the model is trained to minimize its maximum expected loss among all distributions in the uncertainty set. While careful design of the uncertainty set is critical to the success of the DRO procedure, previous work has been limited to relatively simple alternatives that keep the min-max optimization problem exactly tractable, such as $f$-divergence balls. In this paper, we argue instead for the use of neural generative models to characterize the worst-case distribution, allowing for more flexible and problem-specific selection of the uncertainty set. However, while simple conceptually, this approach poses a number of implementation and optimization challenges. To circumvent these issues, we propose a relaxation of the KL-constrained inner maximization objective that makes the DRO problem more amenable to gradient-based optimization of large scale generative models, and develop model selection heuristics to guide hyper-parameter search. On both toy settings and realistic NLP tasks, we find that the proposed approach yields models that are more robust than comparable baselines.'}
{'title': 'MOT20: A benchmark for multi object tracking in crowded scenes', 'paperID': 'd11c50e49998e2156da7c179a3caea86e9601abd', 'arxivId': '2003.09003', 'publication_year': 2020, 'abstract': None}
{'title': 'Linear Regression Without Correspondences via Concave Minimization', 'paperID': '6c8f84ba9a22450c3f14bb40e6dbcf9ac816d502', 'arxivId': '2003.07706', 'publication_year': 2020, 'abstract': None}
{'title': 'Differentiable Top-k Operator with Optimal Transport', 'paperID': 'e1678aece552737a99e46b3e4ddb854347466e1e', 'arxivId': '2002.06504', 'publication_year': 2020, 'abstract': None}
{'title': 'A Two-Stage Approach to Multivariate Linear Regression with Sparsely Mismatched Data', 'paperID': '1c27871ebe0ec6c0d8611878541556a8f59747c7', 'arxivId': '1907.07148', 'publication_year': 2019, 'abstract': None}
{'title': 'How to Train Your Deep Multi-Object Tracker', 'paperID': '21b2e8702df2c2e3bd7ce760709bc221ea2cd52f', 'arxivId': '1906.06618', 'publication_year': 2019, 'abstract': None}
{'title': 'DeepMOT: A Differentiable Framework for Training Multiple Object Trackers', 'paperID': 'a1bbe29ebe5e42211b752c3a2b959cf6020556e6', 'arxivId': None, 'publication_year': 2019, 'abstract': None}
{'title': 'Convergence of Learning Dynamics in Stackelberg Games', 'paperID': '7ce80c7df1774e4483b32a813d54a8ff35dd0163', 'arxivId': '1906.01217', 'publication_year': 2019, 'abstract': None}
{'title': 'Robust approximate linear regression without correspondence', 'paperID': '61e26bd5333020a1aa4bf2f24605d265ee9f120a', 'arxivId': '1906.00273', 'publication_year': 2019, 'abstract': None}
{'title': 'Sliced Gromov-Wasserstein', 'paperID': 'e327593dc64ea38c6379b029a85d5de64a8fe9bd', 'arxivId': '1905.10124', 'publication_year': 2019, 'abstract': None}
{'title': 'Homomorphic Sensing', 'paperID': '3826a4e2cc50ef2447a7908cd55f12fb9ad5ef86', 'arxivId': '1901.07852', 'publication_year': 2019, 'abstract': None}
{'title': 'Gromov-Wasserstein Learning for Graph Matching and Node Embedding', 'paperID': 'f20049425c119f65cb7273e0abb1e48e848905b7', 'arxivId': '1901.06003', 'publication_year': 2019, 'abstract': None}
{'title': 'Spherical Regression Under Mismatch Corruption With Application to Automated Knowledge Translation', 'paperID': 'dc96f81fad85d3ccde836d8c0df09c09e59257b0', 'arxivId': '1810.05679', 'publication_year': 2018, 'abstract': None}
{'title': 'An Algebraic-Geometric Approach to Shuffled Linear Regression', 'paperID': 'b848e7704e20338302f8ffc75acf9c10040584a1', 'arxivId': '1810.05440', 'publication_year': 2018, 'abstract': None}
{'title': 'A Stochastic Expectation-Maximization Approach to Shuffled Linear Regression', 'paperID': '07ca883fe76d21a146808045cf48ca2304328381', 'arxivId': None, 'publication_year': 2018, 'abstract': None}
{'title': 'Tracking by Animation: Unsupervised Learning of Multi-Object Attentive Trackers', 'paperID': 'e799c5c7e169f471950eb76dbb329c2d031347ae', 'arxivId': '1809.03137', 'publication_year': 2018, 'abstract': None}
{'title': 'Uncoupled isotonic regression via minimum Wasserstein deconvolution', 'paperID': '311433687edee9727f3c658140ad9e2c026093ef', 'arxivId': '1806.10648', 'publication_year': 2018, 'abstract': None}
{'title': 'High Performance Visual Tracking with Siamese Region Proposal Network', 'paperID': '320d05db95ab42ade69294abe46cd1aca6aca602', 'arxivId': None, 'publication_year': 2018, 'abstract': None}
{'title': 'Differential Properties of Sinkhorn Approximation for Learning with Wasserstein Distance', 'paperID': 'a188e34579136f903f9f5939d71583c4fc0b2448', 'arxivId': '1805.11897', 'publication_year': 2018, 'abstract': None}
{'title': 'Linear Regression With Shuffled Data: Statistical and Computational Limits of Permutation Recovery', 'paperID': '287085ecd255081f8fe419a4b91db1a73b355208', 'arxivId': None, 'publication_year': 2018, 'abstract': None}
{'title': 'Linear regression with sparsely permuted data', 'paperID': 'ab6f383652f5ec1f78cb7c3c4d8ae5883407aad9', 'arxivId': '1710.06030', 'publication_year': 2017, 'abstract': None}
{'title': 'Scaling algorithms for unbalanced optimal transport problems', 'paperID': '3ecac5a84b7d8d8d15b25ecbd022ae353ad25c40', 'arxivId': None, 'publication_year': 2017, 'abstract': None}
{'title': 'Linear Regression with Shuffled Labels', 'paperID': 'fcfefcee76261aba140b5d33bb557f8f89807ceb', 'arxivId': '1705.01342', 'publication_year': 2017, 'abstract': None}
{'title': 'Linear regression without correspondence', 'paperID': 'd65ad6e4fe4229186d61798d6b796ca4ca8c3835', 'arxivId': '1705.07048', 'publication_year': 2017, 'abstract': None}
{'title': 'Denoising linear models with permuted data', 'paperID': 'ea6dd69e4eed8fb5224fa96fbab47ae643eb1647', 'arxivId': '1704.07461', 'publication_year': 2017, 'abstract': None}
{'title': 'Unlabeled sensing: Reconstruction algorithm and theoretical guarantees', 'paperID': '4e31fe12a4af9d925531a6ce6fe3c5205efd31ab', 'arxivId': None, 'publication_year': 2017, 'abstract': None}
{'title': 'Signal Recovery From Unlabeled Samples', 'paperID': '74da36b5da9af8c3b315367541f152a51866cc0f', 'arxivId': '1701.08701', 'publication_year': 2017, 'abstract': None}
{'title': 'Linear regression with an unknown permutation: Statistical and computational limits', 'paperID': 'a0fc60c26ffc730617355d208cab33e1f087e5b4', 'arxivId': '1608.02902', 'publication_year': 2016, 'abstract': None}
{'title': 'Optimization Methods for Large-Scale Machine Learning', 'paperID': 'd21703674ae562bae4a849a75847cdd9ead417df', 'arxivId': '1606.04838', 'publication_year': 2016, 'abstract': None}
{'title': 'MOT16: A Benchmark for Multi-Object Tracking', 'paperID': 'ac0d88ca5f75a4a80da90365c28fa26f1a26d4c4', 'arxivId': '1603.00831', 'publication_year': 2016, 'abstract': None}
{'title': 'Simple online and realtime tracking', 'paperID': 'a6e7513371a49cd7b8b30bb444e8fc448c5326cb', 'arxivId': '1602.00763', 'publication_year': 2016, 'abstract': None}
{'title': 'Unlabeled Sensing With Random Linear Measurements', 'paperID': '9e53217d96aee1f2cc13c0157c6185806b60ffed', 'arxivId': '1512.00115', 'publication_year': 2015, 'abstract': None}
{'title': 'Random Multi-Constraint Projection: Stochastic Gradient Methods for Convex Optimization with Many Constraints', 'paperID': '5f13cef6f5a209c878a24192b3c38010ffa7cc5c', 'arxivId': '1511.03760', 'publication_year': 2015, 'abstract': None}
{'title': 'Optimal Entropy-Transport problems and a new Hellinger–Kantorovich distance between positive measures', 'paperID': '7eed503702a760d49c744ada559481ce6cfd6502', 'arxivId': '1508.07941', 'publication_year': 2015, 'abstract': None}
{'title': 'Unbalanced optimal transport: Dynamic and Kantorovich formulations', 'paperID': 'f124d97459e402031e6f3731a871cff53b6a8c32', 'arxivId': None, 'publication_year': 2015, 'abstract': None}
{'title': 'Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks', 'paperID': '424561d8585ff8ebce7d5d07de8dbf7aae5e7270', 'arxivId': '1506.01497', 'publication_year': 2015, 'abstract': None}
{'title': 'A new optimal transport distance on the space of finite Radon measures', 'paperID': '7a7c849639e40f723c65ec98aacf746f9706fdad', 'arxivId': '1505.07746', 'publication_year': 2015, 'abstract': None}
{'title': 'Iterative Bregman Projections for Regularized Transportation Problems', 'paperID': 'd3831561301ef27a6ba0d3c68d30bdf0f27eef63', 'arxivId': '1412.5154', 'publication_year': 2014, 'abstract': None}
{'title': 'Sinkhorn Distances: Lightspeed Computation of Optimal Transport', 'paperID': '0080118b0eb02af581ff32b85a1bb6aed7081f45', 'arxivId': None, 'publication_year': 2013, 'abstract': None}
{'title': 'An Interpolating Distance Between Optimal Transport and Fisher–Rao Metrics', 'paperID': '400d517d1e51c4f292bac4f5f336745b6f8d4ec0', 'arxivId': '1506.06430', 'publication_year': 2010, 'abstract': None}
{'title': 'Object Detection with Discriminatively Trained Part Based Models', 'paperID': 'e79272fe3d65197100eae8be9fec6469107969ae', 'arxivId': None, 'publication_year': 2010, 'abstract': None}
{'title': 'Identity Aware Sensor Networks', 'paperID': 'eebb60d3406659279fd5823d14e9fb81cdf91295', 'arxivId': None, 'publication_year': 2009, 'abstract': None}
{'title': 'Array-based evolution of DNA aptamers allows modelling of an explicit sequence-fitness landscape', 'paperID': '2eebe44d0e8bb4326451b4c7880ab7b932da8ec7', 'arxivId': None, 'publication_year': 2008, 'abstract': None}
{'title': 'SoftPOSIT: Simultaneous Pose and Correspondence Determination', 'paperID': '0143dc12950df920e2540afc9afc3519de906632', 'arxivId': None, 'publication_year': 2002, 'abstract': None}
{'title': 'Galton, Pearson, and the Peas: A Brief History of Linear Regression for Statistics Instructors', 'paperID': 'a0554946249ac831077c76b345f95940e6c05496', 'arxivId': None, 'publication_year': 2001, 'abstract': None}
{'title': 'CAP3: A DNA sequence assembly program.', 'paperID': 'ec27a1f0b5655736eaa7ef20cef274a75fa8ba14', 'arxivId': None, 'publication_year': 1999, 'abstract': None}
{'title': 'Concerning nonnegative matrices and doubly stochastic matrices', 'paperID': '70e0d2487440b519b392503f4fa6b94891238c90', 'arxivId': None, 'publication_year': 1967, 'abstract': None}
{'title': 'Linear programming and extensions', 'paperID': '7212b33956f1b36acc77d0da66fa2634ff5146c5', 'arxivId': None, 'publication_year': 1965, 'abstract': None}
{'title': 'Mathematical Methods of Organizing and Planning Production', 'paperID': 'b63665e46a1c8e2286e7f88418fac29e3db8858a', 'arxivId': None, 'publication_year': 1960, 'abstract': None}
{'title': '1. A Certain Zero-sum Two-person Game Equivalent to the Optimal Assignment Problem', 'paperID': 'd40afb32a77b52bf4775f8ab21ddadf94f239218', 'arxivId': None, 'publication_year': 1953, 'abstract': None}
{'title': 'A Method for Chronologically Ordering Archaeological Deposits', 'paperID': '7e98ece450ee547d4ffa42beaa4477a9b32ef077', 'arxivId': None, 'publication_year': 1951, 'abstract': None}
{'title': 'A Sparse Representation-Based Approach to Linear Regression with Partially Shuffled Labels', 'paperID': '5edecf6197abdbb88c75e2938ebca50befab7360', 'arxivId': None, 'publication_year': 2019, 'abstract': None}
{'title': "The Collected Mathematical Papers: On Monge's “Mémoire sur la théorie des déblais et des remblais”", 'paperID': '3f83d1db7b9a53087db3ea7c796285489d83f1a0', 'arxivId': None, 'publication_year': 2009, 'abstract': None}
{'title': 'Simultaneous Localization and Mapping', 'paperID': '8e56b9e532f6f850785d625635887cf61a8d63e5', 'arxivId': None, 'publication_year': 2008, 'abstract': None}
{'title': 'Linear programming and extensions', 'paperID': '24a183b16c5c9ee803e8af3daa1ac5164c6e19e3', 'arxivId': None, 'publication_year': 1981, 'abstract': None}
{'title': 'DIAGONALS OF DOUBLY STOCHASTIC MATRICES', 'paperID': 'ee3d03e8a42fb063b53a644e56660f8125b840dd', 'arxivId': None, 'publication_year': 1959, 'abstract': None}
{'title': 'A Hypergradient Approach to Robust Regression without Correspondence', 'paperID': 'e01eeb3fc6e681cd2edac0be9f6ef6493b485574', 'arxivId': '2012.00123', 'publication_year': '2020', 'abstract': 'We consider a regression problem, where the correspondence between input and output data is not available. Such shuffled data is commonly observed in many real world problems. Taking flow cytometry as an example, the measuring instruments are unable to preserve the correspondence between the samples and the measurements. Due to the combinatorial nature, most of existing methods are only applicable when the sample size is small, and limited to linear regression models. To overcome such bottlenecks, we propose a new computational framework - ROBOT- for the shuffled regression problem, which is applicable to large data and complex models. Specifically, we propose to formulate the regression without correspondence as a continuous optimization problem. Then by exploiting the interaction between the regression model and the data correspondence, we propose to develop a hypergradient approach based on differentiable programming techniques. Such a hypergradient approach essentially views the data correspondence as an operator of the regression, and therefore allows us to find a better descent direction for the model parameter by differentiating through the data correspondence. ROBOT is quite general, and can be further extended to the inexact correspondence setting, where the input and output data are not necessarily exactly aligned. Thorough numerical experiments show that ROBOT achieves better performance than existing methods in both linear and nonlinear regression tasks, including real-world applications such as flow cytometry and multi-object tracking.'}
{'title': 'Learning with Group Noise', 'paperID': 'ccbcacc4fcde0eebcf27a774a874db7d1b391319', 'arxivId': '2103.09468', 'publication_year': 2021, 'abstract': None}
{'title': 'Provably End-to-end Label-Noise Learning without Anchor Points', 'paperID': '5b0d1cf668c92f23fa9be2e5efe6d8c8ab9376b3', 'arxivId': '2102.02400', 'publication_year': 2021, 'abstract': None}
{'title': 'Tackling Instance-Dependent Label Noise via a Universal Probabilistic Model', 'paperID': 'fde5afcab0731d751bb1ecca773b9bca7914db53', 'arxivId': '2101.05467', 'publication_year': 2021, 'abstract': None}
{'title': 'A Second-Order Approach to Learning with Instance-Dependent Label Noise', 'paperID': '39d087cd6a27a72174f365407cf82ac4450c552d', 'arxivId': '2012.11854', 'publication_year': 2020, 'abstract': None}
{'title': 'Extended <inline-formula><tex-math notation="LaTeX">$T$</tex-math><alternatives><mml:math><mml:mi>T</mml:mi></mml:math><inline-graphic xlink:href="xia-ieq1-3180545.gif"/></alternatives></inline-formula>: Learning With Mixed Closed-Set and Open-Set Noisy Labels', 'paperID': '99d86a078e6aacffa39489af93051c27f8432f10', 'arxivId': '2012.00932', 'publication_year': 2020, 'abstract': None}
{'title': 'Learning with Instance-Dependent Label Noise: A Sample Sieve Approach', 'paperID': '599ed9357448d8c55e2dc7f4f12224d5c6dd1fcc', 'arxivId': '2010.02347', 'publication_year': 2020, 'abstract': None}
{'title': 'Searching to Exploit Memorization Effect in Learning with Noisy Labels', 'paperID': '97ef364d56622a2d8431d9603aafec014f46ec0b', 'arxivId': None, 'publication_year': 2020, 'abstract': None}
{'title': 'Error-Bounded Correction of Noisy Labels', 'paperID': '233de8bacf9b57b208583965762ceb4b8e7f1d03', 'arxivId': '2011.10077', 'publication_year': 2020, 'abstract': None}
{'title': 'Early-Learning Regularization Prevents Memorization of Noisy Labels', 'paperID': 'c9b08639a28ab70a06ba9a09eaae98b2fe3dc6c9', 'arxivId': '2007.00151', 'publication_year': 2020, 'abstract': None}
{'title': 'Normalized Loss Functions for Deep Learning with Noisy Labels', 'paperID': '07cca761749bfe21c2d096ff60f32b574d5c84c4', 'arxivId': '2006.13554', 'publication_year': 2020, 'abstract': None}
{'title': 'Dual T: Reducing Estimation Error for Transition Matrix in Label-noise Learning', 'paperID': '194842d570ec3c18ef641f74cd56eb5a4c669656', 'arxivId': '2006.07805', 'publication_year': 2020, 'abstract': None}
{'title': 'Parts-dependent Label Noise: Towards Instance-dependent Label Noise', 'paperID': '23858481090f7dbd8e8de859b0795a448cbcb478', 'arxivId': '2006.07836', 'publication_year': 2020, 'abstract': None}
{'title': 'Class2Simi: A New Perspective on Learning with Label Noise', 'paperID': '71c9b6f950f96bd7e01aaefdd1593aa7c5b9a090', 'arxivId': None, 'publication_year': 2020, 'abstract': None}
{'title': 'Meta Transition Adaptation for Robust Deep Learning with Noisy Labels', 'paperID': '3d85d0d80c4052eee25bacb50b400cf61d402552', 'arxivId': '2006.05697', 'publication_year': 2020, 'abstract': None}
{'title': 'Improving Generalization by Controlling Label-Noise Information in Neural Network Weights', 'paperID': '560c7437538dbadbb1e3e27e309945f2befd521f', 'arxivId': '2002.07933', 'publication_year': 2020, 'abstract': None}
{'title': 'DivideMix: Learning with Noisy Labels as Semi-supervised Learning', 'paperID': 'ce435482acc0e195be8d8f002b2655b4c7b08be6', 'arxivId': '2002.07394', 'publication_year': 2020, 'abstract': None}
{'title': 'Identifying Mislabeled Data using the Area Under the Margin Ranking', 'paperID': '0fa23380cb18a4be40706459e088617b0232c79a', 'arxivId': '2001.10528', 'publication_year': 2020, 'abstract': None}
{'title': 'SELF: Learning to Filter Noisy Labels with Self-Ensembling', 'paperID': 'c385e811f98260b673d52abcfdb981b60e880695', 'arxivId': '1910.01842', 'publication_year': 2019, 'abstract': None}
{'title': 'Symmetric Cross Entropy for Robust Learning With Noisy Labels', 'paperID': '3ba8d3060731d64cd46d27e933cbdfb8b7853f4b', 'arxivId': '1908.06112', 'publication_year': 2019, 'abstract': None}
{'title': 'Are Anchor Points Really Indispensable in Label-Noise Learning?', 'paperID': '4f62d8a036f7616510909d4a19db19b735264d9c', 'arxivId': '1906.00189', 'publication_year': 2019, 'abstract': None}
{'title': 'Generalization Bounds of Stochastic Gradient Descent for Wide and Deep Neural Networks', 'paperID': '4b5744dd44a0026c6f386d5cb21b795499d5efb7', 'arxivId': '1905.13210', 'publication_year': 2019, 'abstract': None}
{'title': 'Simple and Effective Regularization Methods for Training on Noisily Labeled Data with Generalization Guarantee', 'paperID': '1b4c4f16a798dacbafb30ddc4511e03f98f59fd7', 'arxivId': None, 'publication_year': 2019, 'abstract': None}
{'title': 'Combating Label Noise in Deep Learning Using Abstention', 'paperID': '77c474e38d2833cfa0edaf4a6098e413a76557c5', 'arxivId': '1905.10964', 'publication_year': 2019, 'abstract': None}
{'title': 'Understanding and Utilizing Deep Neural Networks Trained with Noisy Labels', 'paperID': 'b235c83564f8cd4b27343ff30faf744929d7b961', 'arxivId': '1905.05040', 'publication_year': 2019, 'abstract': None}
{'title': 'Gradient Descent with Early Stopping is Provably Robust to Label Noise for Overparameterized Neural Networks', 'paperID': '29090beb90c184a9aaf7aa610bfed5ee1631d2f2', 'arxivId': '1903.11680', 'publication_year': 2019, 'abstract': None}
{'title': 'Stochastic Gradient Descent Optimizes Over-parameterized Deep ReLU Networks', 'paperID': '313b368457e54e6a7482b008d5eb4182eb1b4d1c', 'arxivId': '1811.08888', 'publication_year': 2018, 'abstract': None}
{'title': 'SIGUA: Forgetting May Make Learning with Noisy Labels More Robust', 'paperID': '80c82b5182c8796e452946953d0879e02db68645', 'arxivId': None, 'publication_year': 2018, 'abstract': None}
{'title': 'SNIP: Single-shot Network Pruning based on Connection Sensitivity', 'paperID': 'cf440ccce4a7a8681e238b4f26d5b95109add55d', 'arxivId': '1810.02340', 'publication_year': 2018, 'abstract': None}
{'title': 'An Efficient and Provable Approach for Mixture Proportion Estimation Using Linear Independence Assumption', 'paperID': '67f7033265a9e6babdbe28472634270297d2eb46', 'arxivId': None, 'publication_year': 2018, 'abstract': None}
{'title': 'Learning to Reweight Examples for Robust Deep Learning', 'paperID': 'c5420ef59d7508d82e53671b0d623027eb58e6ed', 'arxivId': '1803.09050', 'publication_year': 2018, 'abstract': None}
{'title': 'The Lottery Ticket Hypothesis: Finding Sparse, Trainable Neural Networks', 'paperID': '21937ecd9d66567184b83eca3d3e09eb4e6fbd60', 'arxivId': '1803.03635', 'publication_year': 2018, 'abstract': None}
{'title': 'Learning with Biased Complementary Labels', 'paperID': '32ed897dfeda3bfdb572d0f748048417bef2838d', 'arxivId': '1711.09535', 'publication_year': 2017, 'abstract': None}
{'title': 'Decoupled Weight Decay Regularization', 'paperID': 'd07284a6811f1b2745d91bdb06b040b57f226882', 'arxivId': None, 'publication_year': 2017, 'abstract': None}
{'title': 'Learning with Bounded Instance- and Label-dependent Label Noise', 'paperID': '7d34d84f0022fa7dfcecf7e9f5444c938d2bc3fe', 'arxivId': '1709.03768', 'publication_year': 2017, 'abstract': None}
{'title': 'Learning from Noisy Labels with Distillation', 'paperID': '4f48c8653cd38cd18f08924c9304bc02ed7ea492', 'arxivId': '1703.02391', 'publication_year': 2017, 'abstract': None}
{'title': 'Learning from massive noisy labeled data for image classification', 'paperID': '5d6ae67e569f974360b107060c23cbb8a13b0687', 'arxivId': None, 'publication_year': 2015, 'abstract': None}
{'title': 'Classification with Noisy Labels by Importance Reweighting', 'paperID': '4568d7951f8f4d5604a4a8528ccac4ce40a43706', 'arxivId': '1411.7718', 'publication_year': 2014, 'abstract': None}
{'title': 'Food-101 - Mining Discriminative Components with Random Forests', 'paperID': '8e3f12804882b60ad5f59aad92755c5edb34860e', 'arxivId': None, 'publication_year': 2014, 'abstract': None}
{'title': 'Convex Optimization: Algorithms and Complexity', 'paperID': '075f328ef87a076151feb4d5b1f97b66aa597a90', 'arxivId': None, 'publication_year': 2014, 'abstract': None}
{'title': 'Speech recognition with deep recurrent neural networks', 'paperID': '4177ec52d1b80ed57f2e72b0f9a42365f1a8598d', 'arxivId': '1303.5778', 'publication_year': 2013, 'abstract': None}
{'title': 'On Early Stopping in Gradient Descent Learning', 'paperID': 'e7b18110c70ccb71305dda7a973f89630ffd9879', 'arxivId': None, 'publication_year': 2007, 'abstract': None}
{'title': 'Boosting with early stopping: Convergence and consistency', 'paperID': 'b0816b4f1fdf1ebc324663f66485e05d58cbd1a7', 'arxivId': 'math/0508276', 'publication_year': 2005, 'abstract': None}
{'title': 'L_DMI: A Novel Information-theoretic Loss Function for Training Deep Nets Robust to Label Noise', 'paperID': '96261be30b1c3ed388efce149dd93772f27478f6', 'arxivId': None, 'publication_year': 2019, 'abstract': None}
{'title': 'Overfitting in Neural Nets: Backpropagation, Conjugate Gradient, and Early Stopping', 'paperID': '072d756c8b17a78018298e67ff29e6d3a4fe5770', 'arxivId': None, 'publication_year': 2000, 'abstract': None}
{'title': 'Early Stopping-But When?', 'paperID': '8c8f198d582898ef06aea1edc51cbc419d922a00', 'arxivId': None, 'publication_year': 1996, 'abstract': None}
{'title': 'Robust early-learning: Hindering the memorization of noisy labels', 'paperID': 'bafb088c459188fd22fc20eb3af6b731d4856629', 'arxivId': None, 'publication_year': None, 'abstract': 'The memorization effects of deep networks show that they will ﬁrst memorize training data with clean labels and then those with noisy labels. The early stopping method therefore can be exploited for learning with noisy labels. However, the side effect brought by noisy labels will inﬂuence the memorization of clean labels before early stopping. In this paper, motivated by the lottery ticket hypothesis which shows that only partial parameters are important for generalization, we ﬁnd that only partial parameters are important for ﬁtting clean labels and generalize well, which we term as critical parameters ; while the other parameters tend to ﬁt noisy labels and cannot generalize well, which we term as non-critical parameters . Based on this, we propose robust early-learning to reduce the side effect of noisy labels before early stopping and thus enhance the memorization of clean labels. Speciﬁcally, in each iteration, we divide all parameters into the critical and non-critical ones, and then perform different update rules for different types of parameters. Extensive experiments on benchmark-simulated and real-world label-noise datasets demonstrate the superiority of the proposed method over the state-of-the-art label-noise learning methods.'}
{'title': 'The Variational Bandwidth Bottleneck: Stochastic Evaluation on an Information Budget', 'paperID': 'b68a38f6fb6061d641f85b0de5daf7372eb29da2', 'arxivId': '2004.11935', 'publication_year': 2020, 'abstract': None}
{'title': 'CEB Improves Model Robustness', 'paperID': '27071f68e1bf7d564cdb0baef11f8a4f9320efcb', 'arxivId': '2002.05380', 'publication_year': 2020, 'abstract': None}
{'title': 'The Conditional Entropy Bottleneck', 'paperID': 'dcc2153afbbf2a21273d3ef02218805892a25e94', 'arxivId': '2002.05379', 'publication_year': 2020, 'abstract': None}
{'title': 'Generalization in Reinforcement Learning with Selective Noise Injection and Information Bottleneck', 'paperID': '2c3a1a088ef51548264197ed8882f42e0ad73a9b', 'arxivId': '1910.12911', 'publication_year': 2019, 'abstract': None}
{'title': 'Curiosity-Bottleneck: Exploration By Distilling Task-Specific Novelty', 'paperID': 'c60d789bf93dee52fc1e076c005cfb8385c84719', 'arxivId': None, 'publication_year': 2019, 'abstract': None}
{'title': 'InfoBot: Transfer and Exploration via the Information Bottleneck', 'paperID': 'bf7f1ada5feecc0992f71b39c1ebeccb19ae631b', 'arxivId': '1901.10902', 'publication_year': 2019, 'abstract': None}
{'title': 'Episodic Curiosity through Reachability', 'paperID': 'fdfeeb14bbde2ab31b18e56b92d362dcd1b14f71', 'arxivId': '1810.02274', 'publication_year': 2018, 'abstract': None}
{'title': 'Exploration by Random Network Distillation', 'paperID': '4cb3fd057949624aa4f0bbe7a6dcc8777ff04758', 'arxivId': '1810.12894', 'publication_year': 2018, 'abstract': None}
{'title': 'Variational Discriminator Bottleneck: Improving Imitation Learning, Inverse RL, and GANs by Constraining Information Flow', 'paperID': '4b59846404c085f5c9523c69cd790537613a3df5', 'arxivId': '1810.00821', 'publication_year': 2018, 'abstract': None}
{'title': 'Large-Scale Study of Curiosity-Driven Learning', 'paperID': 'ca14dce53be20d3d23d4f0db844a8389ab619db3', 'arxivId': '1808.04355', 'publication_year': 2018, 'abstract': None}
{'title': 'Invariant Representations without Adversarial Training', 'paperID': 'b13130497dbeb5032e4d26d7c6bedbf0d0c112a4', 'arxivId': '1805.09458', 'publication_year': 2018, 'abstract': None}
{'title': 'Compressing Neural Networks using the Variational Information Bottleneck', 'paperID': '3116c094f9c72fc42b7f63809849f4a63dae6b71', 'arxivId': '1802.10399', 'publication_year': 2018, 'abstract': None}
{'title': 'Learning Representations for Neural Network-Based Classification Using the Information Bottleneck Principle', 'paperID': '9198b96ad9e4d00b4d847af6becbd46e8c16eef2', 'arxivId': '1802.09766', 'publication_year': 2018, 'abstract': None}
{'title': 'Curiosity-Driven Exploration by Self-Supervised Prediction', 'paperID': '225ab689f41cef1dc18237ef5dab059a49950abf', 'arxivId': '1705.05363', 'publication_year': 2017, 'abstract': None}
{'title': 'Nonlinear Information Bottleneck', 'paperID': 'bd9febe8347eccaf5555865e549574d908d9d213', 'arxivId': '1705.02436', 'publication_year': 2017, 'abstract': None}
{'title': 'Information Dropout: Learning Optimal Representations Through Noisy Computation', 'paperID': 'c06cc4f5741e9f0ae9b9f8fc76247e87ba5aac6e', 'arxivId': '1611.01353', 'publication_year': 2016, 'abstract': None}
{'title': 'Categorical Reparameterization with Gumbel-Softmax', 'paperID': '29e944711a354c396fad71936f536e83025b6ce0', 'arxivId': '1611.01144', 'publication_year': 2016, 'abstract': None}
{'title': 'The Concrete Distribution: A Continuous Relaxation of Discrete Random Variables', 'paperID': '515a21e90117941150923e559729c59f5fdade1c', 'arxivId': '1611.00712', 'publication_year': 2016, 'abstract': None}
{'title': 'ViZDoom: A Doom-based AI research platform for visual reinforcement learning', 'paperID': 'a473f545318325ba23b7a6b477485d29777ba873', 'arxivId': '1605.02097', 'publication_year': 2016, 'abstract': None}
{'title': 'Relevant sparse codes with variational information bottleneck', 'paperID': '8b79a8dba98ad570df6b7cd85ceeccf32ab24339', 'arxivId': '1605.07332', 'publication_year': 2016, 'abstract': None}
{'title': 'The Deterministic Information Bottleneck', 'paperID': 'bf654c3339f232f9d8f7cda7f00f4e7d5e97a7d8', 'arxivId': '1604.00268', 'publication_year': 2015, 'abstract': None}
{'title': 'Mutual Information between Discrete and Continuous Data Sets', 'paperID': 'ab99cb06acad1011ae0cc791cb7b35b74577cdfc', 'arxivId': None, 'publication_year': 2014, 'abstract': None}
{'title': 'Deep Sparse Rectifier Neural Networks', 'paperID': '67107f78a84bdb2411053cb54e94fa226eea6d8e', 'arxivId': None, 'publication_year': 2011, 'abstract': None}
{'title': 'Rectified Linear Units Improve Restricted Boltzmann Machines', 'paperID': 'a538b05ebb01a40323997629e171c91aa28b8e2f', 'arxivId': None, 'publication_year': 2010, 'abstract': None}
{'title': 'Estimating mutual information.', 'paperID': '5729e9bc42a8c006fcdeaf6ca3434fabf49e7e7c', 'arxivId': 'cond-mat/0305641', 'publication_year': 2003, 'abstract': None}
{'title': 'Restricting the Flow: Information Bottlenecks for Attribution', 'paperID': '57d697214af89d8b8f77eeaaf040a43d1a0c651b', 'arxivId': '2001.00396', 'publication_year': 2020, 'abstract': None}
{'title': 'Rectiﬁed Linear Units Improve Restricted Boltzmann Machines', 'paperID': '2b114f4d05494fceb22473fcd29d940e9aa52bf4', 'arxivId': None, 'publication_year': None, 'abstract': None}
{'title': 'Drop-Bottleneck: Learning Discrete Compressed Representation for Noise-Robust Exploration', 'paperID': '05ad9fc4ba9fad5aade4b700e8505d37eefd0519', 'arxivId': '2103.12300', 'publication_year': '2021', 'abstract': "We propose a novel information bottleneck (IB) method named Drop-Bottleneck, which discretely drops features that are irrelevant to the target variable. Drop-Bottleneck not only enjoys a simple and tractable compression objective but also additionally provides a deterministic compressed representation of the input variable, which is useful for inference tasks that require consistent representation. Moreover, it can jointly learn a feature extractor and select features considering each feature dimension's relevance to the target task, which is unattainable by most neural network-based IB methods. We propose an exploration method based on Drop-Bottleneck for reinforcement learning tasks. In a multitude of noisy and reward sparse maze navigation tasks in VizDoom (Kempka et al., 2016) and DMLab (Beattie et al., 2016), our exploration method achieves state-of-the-art performance. As a new IB framework, we demonstrate that Drop-Bottleneck outperforms Variational Information Bottleneck (VIB) (Alemi et al., 2017) in multiple aspects including adversarial robustness and dimensionality reduction."}
{'title': 'Counterfactual Visual Explanations', 'paperID': '70dbe3e740a5e7927ccce00fd615365b08a6eaae', 'arxivId': '1904.07451', 'publication_year': 2019, 'abstract': None}
{'title': 'Robust Decision Trees Against Adversarial Examples', 'paperID': '320cb910e7b758bfc43f09a6ff34da3a71192a74', 'arxivId': '1902.10660', 'publication_year': 2019, 'abstract': None}
{'title': 'On the (In)fidelity and Sensitivity of Explanations', 'paperID': 'eb84415703c70ac3ab1ac3d9a4a08f29016a5066', 'arxivId': '1901.09392', 'publication_year': 2019, 'abstract': None}
{'title': 'Representer Point Selection for Explaining Deep Neural Networks', 'paperID': 'a34954d9e36ea6c57743f55124a6ae444b951c2c', 'arxivId': '1811.09720', 'publication_year': 2018, 'abstract': None}
{'title': 'Sanity Checks for Saliency Maps', 'paperID': '8dc8f3e0127adc6985d4695e9b69d04717b2fde8', 'arxivId': '1810.03292', 'publication_year': 2018, 'abstract': None}
{'title': 'Explaining Image Classifiers by Counterfactual Generation', 'paperID': 'f1173ca43481c1b33f4e7891ce77200e51eecba2', 'arxivId': '1807.08024', 'publication_year': 2018, 'abstract': None}
{'title': 'Model Agnostic Supervised Local Explanations', 'paperID': '34783ad136c0105a78dbb3546100b8864d1b38ca', 'arxivId': '1807.02910', 'publication_year': 2018, 'abstract': None}
{'title': 'RISE: Randomized Input Sampling for Explanation of Black-box Models', 'paperID': 'd00c7fc5201405d5411b5ad3da93c5575ce8f10e', 'arxivId': '1806.07421', 'publication_year': 2018, 'abstract': None}
{'title': 'Explanations based on the Missing: Towards Contrastive Explanations with Pertinent Negatives', 'paperID': '748dc54a89a276639f9d571cdd8e7d1ae3f9a57a', 'arxivId': '1802.07623', 'publication_year': 2018, 'abstract': None}
{'title': 'Evaluating the Robustness of Neural Networks: An Extreme Value Theory Approach', 'paperID': '29176632807b17bf3da444713763b4b2b568306c', 'arxivId': '1801.10578', 'publication_year': 2018, 'abstract': None}
{'title': 'Visual Explanation by Interpretation: Improving Visual Feedback Capabilities of Deep Neural Networks', 'paperID': '8d8bc608da14bc0ce32c3a5d1fdfbe037993626d', 'arxivId': '1712.06302', 'publication_year': 2017, 'abstract': None}
{'title': 'A unified view of gradient-based attribution methods for Deep Neural Networks', 'paperID': 'de2447a25012c71ad316487b4b9e7378a4fcccc0', 'arxivId': '1711.06104', 'publication_year': 2017, 'abstract': None}
{'title': 'Men Also Like Shopping: Reducing Gender Bias Amplification using Corpus-level Constraints', 'paperID': '135bafc83e9a73c88e759f98a28edfdb5c02f81d', 'arxivId': '1707.09457', 'publication_year': 2017, 'abstract': None}
{'title': 'A Unified Approach to Interpreting Model Predictions', 'paperID': '442e10a3c6640ded9408622005e3c2a8906ce4c2', 'arxivId': '1705.07874', 'publication_year': 2017, 'abstract': None}
{'title': 'Real Time Image Saliency for Black Box Classifiers', 'paperID': '7e29b68fcc39b7ae94e4d8b1edea93d058804a92', 'arxivId': '1705.07857', 'publication_year': 2017, 'abstract': None}
{'title': 'Interpretable Explanations of Black Boxes by Meaningful Perturbation', 'paperID': '7380e343dd4547e21d5118b16daf03d021d98c4e', 'arxivId': '1704.03296', 'publication_year': 2017, 'abstract': None}
{'title': 'Learning Important Features Through Propagating Activation Differences', 'paperID': '1a2118bed729579528deb51e745d58dd3629baf6', 'arxivId': '1704.02685', 'publication_year': 2017, 'abstract': None}
{'title': 'Understanding Black-box Predictions via Influence Functions', 'paperID': '08ad8fad21f6ec4cda4d56be1ca5e146b7c913a1', 'arxivId': '1703.04730', 'publication_year': 2017, 'abstract': None}
{'title': 'Axiomatic Attribution for Deep Networks', 'paperID': 'f302e136c41db5de1d624412f68c9174cf7ae8be', 'arxivId': '1703.01365', 'publication_year': 2017, 'abstract': None}
{'title': 'Towards A Rigorous Science of Interpretable Machine Learning', 'paperID': '5c39e37022661f81f79e481240ed9b175dec6513', 'arxivId': '1702.08608', 'publication_year': 2017, 'abstract': None}
{'title': 'Understanding Neural Networks through Representation Erasure', 'paperID': '4c41104e871bccbd56494350a71d77a7f1da5bb0', 'arxivId': '1612.08220', 'publication_year': 2016, 'abstract': None}
{'title': 'Evaluating the Visualization of What a Deep Neural Network Has Learned', 'paperID': '6df11b0bb0244d4d36e8955436067cc5d19734fa', 'arxivId': '1509.06321', 'publication_year': 2015, 'abstract': None}
{'title': 'On Pixel-Wise Explanations for Non-Linear Classifier Decisions by Layer-Wise Relevance Propagation', 'paperID': '17a273bbd4448083b01b5a9389b3c37f5425aac0', 'arxivId': None, 'publication_year': 2015, 'abstract': None}
{'title': 'Mathematical Properties of the Banzhaf Power Index', 'paperID': 'b04e995db245796dc207e25342ed1fc37a9d6207', 'arxivId': None, 'publication_year': 1979, 'abstract': None}
{'title': 'Committee Scoring Rules , Banzhaf Values , and Approximation Algorithms', 'paperID': 'e00f2c23b9d441a9ec32f1cf58497bc4648a6423', 'arxivId': None, 'publication_year': 2017, 'abstract': None}
{'title': 'Approximations of pseudo-Boolean functions; applications to game theory', 'paperID': '40723b6709b4ec64cf079255fc4c1f9f9e74a3ef', 'arxivId': None, 'publication_year': 1992, 'abstract': None}
{'title': 'Evaluations and Methods for Explanation through Robustness Analysis', 'paperID': '20e0abdfed000269d3eabe1313223701030c2ed9', 'arxivId': '2006.00442', 'publication_year': '2019', 'abstract': 'Among multiple ways of interpreting a machine learning model, measuring the importance of a set of features tied to a prediction is probably one of the most intuitive ways to explain a model. In this paper, we establish the link between a set of features to a prediction with a new evaluation criterion, robustness analysis, which measures the minimum distortion distance of adversarial perturbation. By measuring the tolerance level for an adversarial attack, we can extract a set of features that provides the most robust support for a prediction, and also can extract a set of features that contrasts the current prediction to a target class by setting a targeted adversarial attack. By applying this methodology to various prediction tasks across multiple domains, we observe the derived explanations are indeed capturing the significant feature set qualitatively and quantitatively.'}
{'title': 'CoKe: Contrastive Learning for Robust Keypoint Detection', 'paperID': '817de816932bf7a311fb52793f627e77a1573a9a', 'arxivId': '2009.14115', 'publication_year': 2020, 'abstract': None}
{'title': 'Category Level Object Pose Estimation via Neural Analysis-by-Synthesis', 'paperID': '20a60d836827b4dea659875bccab084da6336119', 'arxivId': '2008.08145', 'publication_year': 2020, 'abstract': None}
{'title': 'Compositional Convolutional Neural Networks: A Robust and Interpretable Model for Object Recognition Under Occlusion', 'paperID': '9bd4a01fc784d4f222b2ded2e8960fa2cb5115b7', 'arxivId': '2006.15538', 'publication_year': 2020, 'abstract': None}
{'title': 'Robust Object Detection Under Occlusion With Context-Aware CompositionalNets', 'paperID': '9ce6780acbce5d7be7da499f62ac7358938908f3', 'arxivId': '2005.11643', 'publication_year': 2020, 'abstract': None}
{'title': 'Compositional Convolutional Neural Networks: A Deep Architecture With Innate Robustness to Partial Occlusion', 'paperID': '38ea78469ef3a89f420ccd9615751f44b9194a5d', 'arxivId': '2003.04490', 'publication_year': 2020, 'abstract': None}
{'title': 'HybridPose: 6D Object Pose Estimation Under Hybrid Representations', 'paperID': '1195fbeed30ebfb13432b9a85c131af299c1dd42', 'arxivId': '2001.01869', 'publication_year': 2020, 'abstract': None}
{'title': 'Accelerating 3D deep learning with PyTorch3D', 'paperID': 'e6c71df73d6a77f6fd88a0c70454fff46a32702d', 'arxivId': '2007.08501', 'publication_year': 2019, 'abstract': None}
{'title': 'Video Representation Learning by Dense Predictive Coding', 'paperID': '0174d263d3a77bf03fce831a9a5ce2678e1959f0', 'arxivId': '1909.04656', 'publication_year': 2019, 'abstract': None}
{'title': 'Combining Compositional Models and Deep Networks For Robust Object Classification under Occlusion', 'paperID': '47962eb9deda5d280f135ac9eaaf1a35ec0dc900', 'arxivId': '1905.11826', 'publication_year': 2019, 'abstract': None}
{'title': 'DPOD: 6D Pose Object Detector and Refiner', 'paperID': 'efae64551ff0b38fb6ac938727a001a9892be67f', 'arxivId': '1902.11020', 'publication_year': 2019, 'abstract': None}
{'title': 'Normalized Object Coordinate Space for Category-Level 6D Object Pose and Size Estimation', 'paperID': 'c8844833b24cc60a0fd5622b1eac7c234da58a75', 'arxivId': '1901.02970', 'publication_year': 2019, 'abstract': None}
{'title': 'PVNet: Pixel-Wise Voting Network for 6DoF Pose Estimation', 'paperID': '743eab7fa743dc00532ea7c2bc0f6f8d87c93405', 'arxivId': '1812.11788', 'publication_year': 2018, 'abstract': None}
{'title': 'Implicit 3D Orientation Learning for 6D Object Detection from RGB Images', 'paperID': '3fc26991557d28ff720edef2d284ef2663e1e530', 'arxivId': '1902.01275', 'publication_year': 2018, 'abstract': None}
{'title': 'Unsupervised Feature Learning via Non-parametric Instance Discrimination', 'paperID': '155b7782dbd713982a4133df3aee7adfd0b6b304', 'arxivId': None, 'publication_year': 2018, 'abstract': None}
{'title': 'DeepIM: Deep Iterative Matching for 6D Pose Estimation', 'paperID': 'fd577c0b62d4d2d2d088566ab7e87bfd2d5a43f1', 'arxivId': '1804.00175', 'publication_year': 2018, 'abstract': None}
{'title': 'StarMap for Category-Agnostic Keypoint and Viewpoint Estimation', 'paperID': '8b6afef69b14b97a272c667b6b9004e441085c89', 'arxivId': '1803.09331', 'publication_year': 2018, 'abstract': None}
{'title': 'Occlusion-Aware 3D Morphable Models and an Illumination Prior for Face Image Analysis', 'paperID': '06da85e7bf9439f3b56efa9025b032f381f9bb5a', 'arxivId': None, 'publication_year': 2018, 'abstract': None}
{'title': 'Markov Chain Monte Carlo for Automated Face Image Analysis', 'paperID': '7caa3a74313f9a7a2dd5b4c2cd7f825d895d3794', 'arxivId': None, 'publication_year': 2017, 'abstract': None}
{'title': 'Click Here: Human-Localized Keypoints as Guidance for Viewpoint Estimation', 'paperID': '2ddc9c1de2eb5eebd66e23e8fd7eb59622662f5f', 'arxivId': '1703.09859', 'publication_year': 2017, 'abstract': None}
{'title': '6-DoF object pose from semantic keypoints', 'paperID': '5dfdc1ed397deca1e8451d09b7699914020b20c1', 'arxivId': '1703.04670', 'publication_year': 2017, 'abstract': None}
{'title': 'Improved Deep Metric Learning with Multi-class N-pair Loss Objective', 'paperID': '78a11b7d2d7e1b19d92d2afd51bd3624eca86c3c', 'arxivId': None, 'publication_year': 2016, 'abstract': None}
{'title': '3D Bounding Box Estimation Using Deep Learning and Geometry', 'paperID': '9e880a4283a3a4e67304f54e00daf30cc535eeef', 'arxivId': '1612.00496', 'publication_year': 2016, 'abstract': None}
{'title': 'ObjectNet3D: A Large Scale Database for 3D Object Recognition', 'paperID': '5ad704bff9bd8cc259ba9542755cc1ec5434b45f', 'arxivId': None, 'publication_year': 2016, 'abstract': None}
{'title': 'Render for CNN: Viewpoint Estimation in Images Using CNNs Trained with Rendered 3D Model Views', 'paperID': '6f115fffa3a2af837cf869996e76b805e8f8cea4', 'arxivId': '1505.05641', 'publication_year': 2015, 'abstract': None}
{'title': 'Viewpoints and keypoints', 'paperID': '794d79e03c68cdf066b0d6a5f2c8e90c1d564010', 'arxivId': '1411.6067', 'publication_year': 2014, 'abstract': None}
{'title': 'Beyond PASCAL: A benchmark for 3D object detection in the wild', 'paperID': '60c7a5d919806e18e31f139b7df9f1172b776f17', 'arxivId': None, 'publication_year': 2014, 'abstract': None}
{'title': 'Explicit Occlusion Modeling for 3D Object Class Representations', 'paperID': '4602bbec65b0c718d5887fdf2381fb7cee77a64d', 'arxivId': None, 'publication_year': 2013, 'abstract': None}
{'title': 'Object Detection with Grammar Models', 'paperID': '711a22f55111db6f5599076dcdd791a94a5e9368', 'arxivId': None, 'publication_year': 2011, 'abstract': None}
{'title': 'EPnP: An Accurate O(n) Solution to the PnP Problem', 'paperID': '49a4c7a645638bf98f5cd252a8a44356e01c5de6', 'arxivId': None, 'publication_year': 2009, 'abstract': None}
{'title': 'Face Recognition Based on Fitting a 3D Morphable Model', 'paperID': '6d66c98009018ac1512047e6bdfb525c35683b16', 'arxivId': None, 'publication_year': 2003, 'abstract': None}
{'title': 'Fast and Globally Convergent Pose Estimation from Video Images', 'paperID': '0f3c956766a250fb3c787cd7d62e45100575da35', 'arxivId': None, 'publication_year': 2000, 'abstract': None}
{'title': 'Model-based image analysis for forensic shoe print recognition', 'paperID': '999be5bede5cc405feec806d07ad220408180039', 'arxivId': None, 'publication_year': 2017, 'abstract': None}
{'title': 'A morphable model for the synthesis of 3D faces', 'paperID': '71d67283157475c4e6460c52408c00e9f6b8d2fe', 'arxivId': None, 'publication_year': 1999, 'abstract': None}
{'title': 'NeMo: Neural Mesh Models of Contrastive Features for Robust 3D Pose Estimation', 'paperID': '02200d454717ffea6c1daf64d635ab945d4fa140', 'arxivId': '2101.12378', 'publication_year': '2021', 'abstract': '3D pose estimation is a challenging but important task in computer vision. In this work, we show that standard deep learning approaches to 3D pose estimation are not robust when objects are partially occluded or viewed from a previously unseen pose. Inspired by the robustness of generative vision models to partial occlusion, we propose to integrate deep neural networks with 3D generative representations of objects into a unified neural architecture that we term NeMo. In particular, NeMo learns a generative model of neural feature activations at each vertex on a dense 3D mesh. Using differentiable rendering we estimate the 3D object pose by minimizing the reconstruction error between NeMo and the feature representation of the target image. To avoid local optima in the reconstruction loss, we train the feature extractor to maximize the distance between the individual feature representations on the mesh using contrastive learning. Our extensive experiments on PASCAL3D+, occluded-PASCAL3D+ and ObjectNet3D show that NeMo is much more robust to partial occlusion and unseen pose compared to standard deep networks, while retaining competitive performance on regular data. Interestingly, our experiments also show that NeMo performs reasonably well even when the mesh representation only crudely approximates the true object geometry with a cuboid, hence revealing that the detailed 3D geometry is not needed for accurate 3D pose estimation. The code is publicly available at https://github.com/Angtian/NeMo.'}
{'title': 'Hyperparameter Ensembles for Robustness and Uncertainty Quantification', 'paperID': '52bac2108400df6abbd729b1477b5e1d5aacf019', 'arxivId': '2006.13570', 'publication_year': 2020, 'abstract': None}
{'title': 'Efficient and Scalable Bayesian Neural Nets with Rank-1 Factors', 'paperID': '175e3e14b7c8872f7c99638e90ca978d69b41297', 'arxivId': '2005.07186', 'publication_year': 2020, 'abstract': None}
{'title': 'BatchEnsemble: An Alternative Approach to Efficient Ensemble and Lifelong Learning', 'paperID': 'b145ea2049648535d6081407ebd315b072248183', 'arxivId': '2002.06715', 'publication_year': 2020, 'abstract': None}
{'title': 'Hydra: Preserving Ensemble Diversity for Model Distillation', 'paperID': '22e8361f6bd05bb4d7fe17919acd91b54c82a7af', 'arxivId': '2001.04694', 'publication_year': 2020, 'abstract': None}
{'title': 'Aggregated Learning: A Vector-Quantization Approach to Learning Neural Network Classifiers', 'paperID': '260affdb5d8036f630f3cd1798e1c128a7d76390', 'arxivId': '2001.03955', 'publication_year': 2020, 'abstract': None}
{'title': 'A Systematic Comparison of Bayesian Deep Learning Robustness in Diabetic Retinopathy Tasks', 'paperID': '6aad42dfcc59a119269f9765936d9c55911971ab', 'arxivId': '1912.10481', 'publication_year': 2019, 'abstract': None}
{'title': 'Deep Ensembles: A Loss Landscape Perspective', 'paperID': '6ddf83bee5ca7a0542964e389a98adc1ed4a6838', 'arxivId': '1912.02757', 'publication_year': 2019, 'abstract': None}
{'title': 'Analyzing the role of model uncertainty for electronic health records', 'paperID': 'f5d073c513208cdbfd1089b440f1dc69b205cd9b', 'arxivId': '1906.03842', 'publication_year': 2019, 'abstract': None}
{'title': 'Measuring the Effects of Data Parallelism on Neural Network Training', 'paperID': 'b2c8e834ac5f7be68b9ca3691d39925036dd74a3', 'arxivId': '1811.03600', 'publication_year': 2018, 'abstract': None}
{'title': 'The Lottery Ticket Hypothesis: Training Pruned Neural Networks', 'paperID': 'f90720ed12e045ac84beb94c27271d6fb8ad48cf', 'arxivId': None, 'publication_year': 2018, 'abstract': None}
{'title': 'To prune, or not to prune: exploring the efficacy of pruning for model compression', 'paperID': '3b4d671a8c7018c0b42673ba581e5ff3ae762d6c', 'arxivId': '1710.01878', 'publication_year': 2017, 'abstract': None}
{'title': 'Pruning Convolutional Neural Networks for Resource Efficient Inference', 'paperID': '3db8730c203f88d7f08a6a99e8c02a077dc9b011', 'arxivId': None, 'publication_year': 2016, 'abstract': None}
{'title': 'Deep Exploration via Bootstrapped DQN', 'paperID': '4b63e34276aa98d5345efa7fe09bb06d8a9d8f52', 'arxivId': '1602.04621', 'publication_year': 2016, 'abstract': None}
{'title': 'Why M Heads are Better than One: Training a Diverse Ensemble of Deep Networks', 'paperID': '73801d5bab1dd5cc2aaaf8855e4365a1a5d0d109', 'arxivId': '1511.06314', 'publication_year': 2015, 'abstract': None}
{'title': 'Weight Uncertainty in Neural Networks', 'paperID': 'da6057368920585bcf2443295b98418840f1fc80', 'arxivId': '1505.05424', 'publication_year': 2015, 'abstract': None}
{'title': 'The Elements of Statistical Learning: Data Mining, Inference, and Prediction', 'paperID': 'fa25610fb8586c2b50a3654edc5bb42fa7fc4729', 'arxivId': None, 'publication_year': 2004, 'abstract': None}
{'title': 'Neural Network Ensembles', 'paperID': 'ad574fa9347bdeb5e940312f238c07f825ac0ed2', 'arxivId': None, 'publication_year': 1990, 'abstract': None}
{'title': 'Bayesian learning for neural networks', 'paperID': 'a22b36cf5dba3e85eb064220be7ef03be4efba48', 'arxivId': None, 'publication_year': 1995, 'abstract': None}
{'title': 'Training independent subnetworks for robust prediction', 'paperID': '4ea5678069a6c4213f53972872a211d780f9f42b', 'arxivId': '2010.06610', 'publication_year': '2020', 'abstract': "Recent approaches to efficiently ensemble neural networks have shown that strong robustness and uncertainty performance can be achieved with a negligible gain in parameters over the original network. However, these methods still require multiple forward passes for prediction, leading to a significant computational cost. In this work, we show a surprising result: the benefits of using multiple predictions can be achieved `for free' under a single model's forward pass. In particular, we show that, using a multi-input multi-output (MIMO) configuration, one can utilize a single model's capacity to train multiple subnetworks that independently learn the task at hand. By ensembling the predictions made by the subnetworks, we improve model robustness without increasing compute. We observe a significant improvement in negative log-likelihood, accuracy, and calibration error on CIFAR10, CIFAR100, ImageNet, and their out-of-distribution variants compared to previous methods."}
{'title': 'Robust Pre-Training by Adversarial Contrastive Learning', 'paperID': '49f4a967f66d740ee3efb704f70b8d5da197394f', 'arxivId': '2010.13337', 'publication_year': 2020, 'abstract': None}
{'title': 'Once-for-All Adversarial Training: In-Situ Tradeoff between Robustness and Accuracy for Free', 'paperID': '6218de58c9191acb49e106059fa9e3b1ecc502d9', 'arxivId': '2010.11828', 'publication_year': 2020, 'abstract': None}
{'title': 'A Unified Approach to Interpreting and Boosting Adversarial Transferability', 'paperID': '47b4744162537f40572cdd723f8f37fb489a3e75', 'arxivId': '2010.04055', 'publication_year': 2020, 'abstract': None}
{'title': 'Geometry-aware Instance-reweighted Adversarial Training', 'paperID': '99a599d8fe56529f47e78243ed61250190f96196', 'arxivId': '2010.01736', 'publication_year': 2020, 'abstract': None}
{'title': 'Label Smoothing and Adversarial Robustness', 'paperID': '61f765deaeea4a195c6b77406ee65bf58513bb0a', 'arxivId': '2009.08233', 'publication_year': 2020, 'abstract': None}
{'title': 'Adversarially Robust Neural Architectures', 'paperID': '2ed374eece816e461efc0cd9b6207c05d38df212', 'arxivId': '2009.00902', 'publication_year': 2020, 'abstract': None}
{'title': 'Adversarially Robust Learning via Entropic Regularization', 'paperID': '9851c5a26ce75133fcb5df4d7a949d943cffa9f7', 'arxivId': '2008.12338', 'publication_year': 2020, 'abstract': None}
{'title': 'Understanding and Improving Fast Adversarial Training', 'paperID': '24cf86a418c9471e8001961c87697c825f0bba8f', 'arxivId': '2007.02617', 'publication_year': 2020, 'abstract': None}
{'title': 'Self-PU: Self Boosted and Calibrated Positive-Unlabeled Training', 'paperID': '1e475a263f3e2f4a6552bfb3468b3748d940c39a', 'arxivId': '2006.11280', 'publication_year': 2020, 'abstract': None}
{'title': 'Revisiting Knowledge Distillation via Label Smoothing Regularization', 'paperID': '7ea2a78a8d8a6327bd13aa4f2d9ace9231bd9662', 'arxivId': None, 'publication_year': 2020, 'abstract': None}
{'title': 'Revisiting Loss Landscape for Adversarial Robustness', 'paperID': '232c55babd84ea40f40cccf2684dd46c02bb8a49', 'arxivId': '2004.05884', 'publication_year': 2020, 'abstract': None}
{'title': 'Adversarial Robustness: From Self-Supervised Pre-Training to Fine-Tuning', 'paperID': '962a8ffc7d72990a28d505f49a39108b4803c223', 'arxivId': '2003.12862', 'publication_year': 2020, 'abstract': None}
{'title': 'Overfitting in adversarially robust deep learning', 'paperID': '2eda2921a8da4b325f9d05f556594a5884c398a7', 'arxivId': '2002.11569', 'publication_year': 2020, 'abstract': None}
{'title': 'Attacks Which Do Not Kill Training Make Adversarial Learning Stronger', 'paperID': 'b27da51d2b33c67b1b366f6f3a1e61e84dbab230', 'arxivId': '2002.11242', 'publication_year': 2020, 'abstract': None}
{'title': 'Boosting Adversarial Training with Hypersphere Embedding', 'paperID': 'd5b84236178d7805c2e7b503cc6cf4a24b7da626', 'arxivId': '2002.08619', 'publication_year': 2020, 'abstract': None}
{'title': 'CAT: Customized Adversarial Training for Improved Robustness', 'paperID': '8de0b5b58f62f8fbc6c5b88692bcabcd93eadb30', 'arxivId': '2002.06789', 'publication_year': 2020, 'abstract': None}
{'title': 'Understanding and Improving Knowledge Distillation', 'paperID': '99716c3a0bcd2f587e3605f09888dcdcd3b4076e', 'arxivId': '2002.03532', 'publication_year': 2020, 'abstract': None}
{'title': 'Stochastic Weight Averaging in Parallel: Large-Batch Training that Generalizes Well', 'paperID': '8fc7b672ee6dd2ee08cb2315d64be07ff9779e22', 'arxivId': '2001.02312', 'publication_year': 2020, 'abstract': None}
{'title': 'Deep double descent: where bigger models and more data hurt', 'paperID': 'ea415809bf87ef4b99966c6c50de6cb996a02a97', 'arxivId': '1912.02292', 'publication_year': 2019, 'abstract': None}
{'title': 'Label Smoothing and Logit Squeezing: A Replacement for Adversarial Training?', 'paperID': '176875a416ff1b1a259e0efc7a03c5e2fa43126f', 'arxivId': '1910.11585', 'publication_year': 2019, 'abstract': None}
{'title': 'Adversarial Robustness Against the Union of Multiple Perturbation Models', 'paperID': '6c894670faadc7dc24228a86925f828edbe8085a', 'arxivId': '1909.04068', 'publication_year': 2019, 'abstract': None}
{'title': 'Metric Learning for Adversarial Robustness', 'paperID': 'e1dea4c733ee7c98aaa42972452f545821b5d3b5', 'arxivId': '1909.00900', 'publication_year': 2019, 'abstract': None}
{'title': 'Adversarial Robustness via Adversarial Label-Smoothing', 'paperID': '0fd54f51e0c9dc4a3d1abccd0f5604625d7b3156', 'arxivId': '1906.11567', 'publication_year': 2019, 'abstract': None}
{'title': 'When Does Label Smoothing Help?', 'paperID': 'f8de25118af2abc4c48afb947d6ec298e05ef1e5', 'arxivId': '1906.02629', 'publication_year': 2019, 'abstract': None}
{'title': 'SWALP : Stochastic Weight Averaging in Low-Precision Training', 'paperID': 'f79bfe86ced096597e6a8b4a88ca12f4b53be115', 'arxivId': '1904.11943', 'publication_year': 2019, 'abstract': None}
{'title': 'advertorch v0.1: An Adversarial Robustness Toolbox based on PyTorch', 'paperID': '4f53bb893ca92f0a1b9b3d1bd2ee5de3cdb7c0da', 'arxivId': '1902.07623', 'publication_year': 2019, 'abstract': None}
{'title': 'A Simple Baseline for Bayesian Uncertainty in Deep Learning', 'paperID': '36aa6c01c9683783499395953c6bc856d6101feb', 'arxivId': '1902.02476', 'publication_year': 2019, 'abstract': None}
{'title': 'Reconciling modern machine-learning practice and the classical bias–variance trade-off', 'paperID': 'f86f1748d1b6d22870f4347fd5d65314ba800583', 'arxivId': '1812.11118', 'publication_year': 2018, 'abstract': None}
{'title': 'Bilateral Adversarial Training: Towards Fast Training of More Robust Models Against Adversarial Attacks', 'paperID': '52a4555f85b18243a95b426d48aeb69e5b332322', 'arxivId': '1811.10716', 'publication_year': 2018, 'abstract': None}
{'title': 'Strength in Numbers: Trading-off Robustness and Computation via Adversarially-Trained Ensembles', 'paperID': '49956bdcfb55d8b42c696a743843f2a1e232d739', 'arxivId': '1811.09300', 'publication_year': 2018, 'abstract': None}
{'title': 'There Are Many Consistent Explanations of Unlabeled Data: Why You Should Average', 'paperID': '98286df6d923d787f26e034bbaf3a5a64ac29cb1', 'arxivId': '1806.05594', 'publication_year': 2018, 'abstract': None}
{'title': 'Born Again Neural Networks', 'paperID': '2444be7584d1f5a7e2aa9f65078de09154f14ea1', 'arxivId': '1805.04770', 'publication_year': 2018, 'abstract': None}
{'title': 'Averaging Weights Leads to Wider Optima and Better Generalization', 'paperID': 'b8989afff14fb630ca58b6afa917fb42574228ee', 'arxivId': '1803.05407', 'publication_year': 2018, 'abstract': None}
{'title': 'Sharp Minima Can Generalize For Deep Nets', 'paperID': '58123025178256279bb060ca5da971b62bc329ee', 'arxivId': '1703.04933', 'publication_year': 2017, 'abstract': None}
{'title': 'A study of the effect of JPG compression on adversarial images', 'paperID': 'c00f744f103a528f5b45bf0482f54b5e6a9f7740', 'arxivId': '1608.00853', 'publication_year': 2016, 'abstract': None}
{'title': 'Robust Overfitting may be mitigated by properly learned smoothening', 'paperID': 'e3f41f4b6b4e3ab740176f022bcad522ad4c38ec', 'arxivId': None, 'publication_year': None, 'abstract': 'A recent study'}
{'title': 'Self-supervised Adversarial Robustness for the Low-label, High-data Regime', 'paperID': 'a8e5c059d2acc2030663a088cd21cd198641974f', 'arxivId': None, 'publication_year': None, 'abstract': None}
{'title': 'Tilted Empirical Risk Minimization', 'paperID': '1f6de95137e96872274eedae1beb1bd55f03c57a', 'arxivId': '2007.01162', 'publication_year': 2020, 'abstract': None}
{'title': 'Does label smoothing mitigate label noise?', 'paperID': '82c77a88969ac0e3a4e55c9a7dc5ced4afee0225', 'arxivId': '2003.02819', 'publication_year': 2020, 'abstract': None}
{'title': 'Beyond Synthetic Noise: Deep Learning on Controlled Noisy Labels', 'paperID': '2b1effdbf6e9e34be4c98cbaf13821b8f642a73e', 'arxivId': None, 'publication_year': 2019, 'abstract': None}
{'title': 'O2U-Net: A Simple Noisy Label Detection Approach for Deep Neural Networks', 'paperID': '41b058078b0fd949594282843a3df7df3e0957eb', 'arxivId': None, 'publication_year': 2019, 'abstract': None}
{'title': 'Robust Bi-Tempered Logistic Loss Based on Bregman Divergences', 'paperID': 'fa3bcc1126adc5d4305e3db821949e46810c8f9b', 'arxivId': '1906.03361', 'publication_year': 2019, 'abstract': None}
{'title': 'Weakly Supervised Image Classification Through Noise Regularization', 'paperID': 'b8317bc29531d78942a75fa493a852535f40b2d6', 'arxivId': None, 'publication_year': 2019, 'abstract': None}
{'title': 'MixMatch: A Holistic Approach to Semi-Supervised Learning', 'paperID': 'c42816f497d663c681df20d48a6e66a5632600d8', 'arxivId': '1905.02249', 'publication_year': 2019, 'abstract': None}
{'title': 'Unsupervised label noise modeling and loss correction', 'paperID': 'eeecea3097cf5629eb72a06e5caaf24d774adce7', 'arxivId': '1904.11238', 'publication_year': 2019, 'abstract': None}
{'title': 'Probabilistic End-To-End Noise Correction for Learning With Noisy Labels', 'paperID': '58b4cf057bdd361be289601ef3dd69b4efbef83e', 'arxivId': '1903.07788', 'publication_year': 2019, 'abstract': None}
{'title': 'CurriculumNet: Weakly Supervised Learning from Large-Scale Web Images', 'paperID': '625afaba9ec6bc5125c217be5cc176ce283e3794', 'arxivId': '1808.01097', 'publication_year': 2018, 'abstract': None}
{'title': 'Minimax Curriculum Learning: Machine Teaching with Desirable Difficulties and Scheduled Diversity', 'paperID': 'f81376925a626fc053883f440a1051b244d3e813', 'arxivId': None, 'publication_year': 2018, 'abstract': None}
{'title': 'CleanNet: Transfer Learning for Scalable Image Classifier Training with Label Noise', 'paperID': 'b4bd88c2a349d29f7aeaf5c1fcb355021058b3fa', 'arxivId': '1711.07131', 'publication_year': 2017, 'abstract': None}
{'title': 'Decoupling "when to update" from "how to update"', 'paperID': '0c0017ae798f5850524941597616f87a77bb6226', 'arxivId': '1706.02613', 'publication_year': 2017, 'abstract': None}
{'title': 'Toward Robustness against Label Noise in Training Deep Discriminative Neural Networks', 'paperID': '4f6610f23af1bf193ca55b4af119b9be733bce99', 'arxivId': '1706.00038', 'publication_year': 2017, 'abstract': None}
{'title': 'Weight-averaged consistency targets improve semi-supervised deep learning results', 'paperID': '1342c1e1684620c019972e2679d5131f1e8a4a13', 'arxivId': '1703.01780', 'publication_year': 2017, 'abstract': None}
{'title': 'Robust Loss Functions under Label Noise for Deep Neural Networks', 'paperID': '33d6aa6c41ce3000161d9b5eea910a5b78e14330', 'arxivId': '1712.09482', 'publication_year': 2017, 'abstract': None}
{'title': 'Regularizing Neural Networks by Penalizing Confident Output Distributions', 'paperID': '6ce1922802169f757bbafc6e087cc274a867c763', 'arxivId': '1701.06548', 'publication_year': 2017, 'abstract': None}
{'title': 'Learning from Noisy Large-Scale Datasets with Minimal Supervision', 'paperID': '9d986c130c4e903ce07bb63c7c5b411fc95b5f9c', 'arxivId': '1701.01619', 'publication_year': 2017, 'abstract': None}
{'title': 'Regularization With Stochastic Transformations and Perturbations for Deep Semi-Supervised Learning', 'paperID': '4c20e7f95448ca3c1042a6d7fa5fa15ec27e9aeb', 'arxivId': '1606.04586', 'publication_year': 2016, 'abstract': None}
{'title': 'Semi-supervised Learning with Ladder Networks', 'paperID': '99487be08cab00554c5c8db73161b2615c694f71', 'arxivId': None, 'publication_year': 2015, 'abstract': None}
{'title': 'Teaching Classification Boundaries to Humans', 'paperID': 'e6069f2448ade3d01d957a3248529a3658796343', 'arxivId': None, 'publication_year': 2013, 'abstract': None}
{'title': 'Self-Paced Learning for Long-Term Tracking', 'paperID': '1c721511e4c0e21bd264ca71c0d909528511b7ad', 'arxivId': None, 'publication_year': 2013, 'abstract': None}
{'title': 'Shifting Weights: Adapting Object Detectors from Image to Video', 'paperID': 'f2f9acd903fc8a94fcb70671022f60630e69998b', 'arxivId': None, 'publication_year': 2012, 'abstract': None}
{'title': 'Self-paced dictionary learning for image classification', 'paperID': 'c76f02c3ef58d269e692df862362c1ee3cf1aa37', 'arxivId': None, 'publication_year': 2012, 'abstract': None}
{'title': 'How Do Humans Teach: On Curriculum Learning and Teaching Dimension', 'paperID': 'f9a824511dc4d73a09a077414ea18018cea3e49d', 'arxivId': None, 'publication_year': 2011, 'abstract': None}
{'title': 'Curriculum Learning by Optimizing Learning Dynamics', 'paperID': '282383a8c25e1987ea4a14146ed466d5b2d12727', 'arxivId': None, 'publication_year': 2021, 'abstract': None}
{'title': 'Time-Consistent Self-Supervision for Semi-Supervised Learning', 'paperID': 'b82a8645fbf29966848e4db9e3abff9f0840b9dd', 'arxivId': None, 'publication_year': 2020, 'abstract': None}
{'title': 'Curriculum Learning by Dynamic Instance Hardness', 'paperID': '3a2102945e45a720167809d29df4e3321c707c92', 'arxivId': None, 'publication_year': 2020, 'abstract': None}
{'title': 'Data Parameters: A New Family of Parameters for Learning a Differentiable Curriculum', 'paperID': 'ca029b1a3c2ff774f5f76b94367da4d6f7611572', 'arxivId': None, 'publication_year': 2019, 'abstract': None}
{'title': 'Baby Steps: How “Less is More” in Unsupervised Dependency Parsing', 'paperID': 'f917b5bc88565501f4345b989de685367cd69574', 'arxivId': None, 'publication_year': 2009, 'abstract': None}
{'title': 'Robust Curriculum Learning: from clean label detection to noisy label self-correction', 'paperID': '66d9cb93003f61e56f825d4bc62023ceceacace4', 'arxivId': None, 'publication_year': None, 'abstract': 'Neural network training can easily overﬁt noisy labels resulting in poor generalization performance. Existing methods address this problem by (1) ﬁltering out the noisy data and only using the clean data for training or (2) relabeling the noisy data by the model during training or by another model trained only on a clean dataset. However, the former does not leverage the features’ information of wrongly-labeled data, while the latter may produce wrong pseudo-labels for some data and introduce extra noises. In this paper, we propose a smooth transition and interplay between these two strategies as a curriculum that selects training samples dynamically. In particular, we start with learning from clean data and then gradually move to learn noisy-labeled data with pseudo labels produced by a time-ensemble of the model and data augmentations. Instead of using the instantaneous loss computed at the current step, our data selection is based on the dynamics of both the loss and output consistency for each sample across historical steps and different data augmentations, resulting in more precise detection of both clean labels and correct pseudo labels. On multiple benchmarks of noisy labels, we show that our curriculum learning strategy can signiﬁcantly improve the test accuracy without any auxiliary model or extra clean data.'}
{'title': 'A Differential Game Theoretic Neural Optimizer for Training Residual Networks', 'paperID': '6b8f965431aeb16aeb3f9cc387041bcb6edcec45', 'arxivId': '2007.08880', 'publication_year': 2020, 'abstract': None}
{'title': 'Differential Dynamic Programming Neural Optimizer', 'paperID': '925e6e1e9dec14569c3fe06d238f961443b3b48e', 'arxivId': '2002.08809', 'publication_year': 2020, 'abstract': None}
{'title': 'A survey of deep learning techniques for autonomous driving', 'paperID': 'a595767fa35bcc84362f629fbc4d2d9b05d7342a', 'arxivId': '1910.07738', 'publication_year': 2019, 'abstract': None}
{'title': 'Amata: An Annealing Mechanism for Adversarial Training Acceleration', 'paperID': '085f82a273239242fd511037daf0a84e7e52810b', 'arxivId': '2012.08112', 'publication_year': 2019, 'abstract': None}
{'title': 'A survey on Image Data Augmentation for Deep Learning', 'paperID': '3813b88a4ec3c63919df47e9694b577f4691f7e5', 'arxivId': None, 'publication_year': 2019, 'abstract': None}
{'title': 'An overview of deep learning in medical imaging focusing on MRI', 'paperID': '0ebc300c16f01a4e94c8551997922fdb67ac1951', 'arxivId': '1811.10052', 'publication_year': 2018, 'abstract': None}
{'title': 'On the Geometry of Adversarial Examples', 'paperID': '00f9e7f7c83a70829da876ffffcedeaeba0f7a55', 'arxivId': '1811.00525', 'publication_year': 2018, 'abstract': None}
{'title': 'A mean-field optimal control formulation of deep learning', 'paperID': '84e1dd0722c752321a4c4a7778246ec285404614', 'arxivId': '1807.01083', 'publication_year': 2018, 'abstract': None}
{'title': 'The Robust Manifold Defense: Adversarial Training using Generative Models', 'paperID': '2d015c62f258eaad5b578a3d9bef762e7943ec47', 'arxivId': '1712.09196', 'publication_year': 2017, 'abstract': None}
{'title': 'Maximum Principle Based Algorithms for Deep Learning', 'paperID': '5e3fd9e6e7bcfc37fa751385ea3c8c7c7ac80c43', 'arxivId': '1710.09513', 'publication_year': 2017, 'abstract': None}
{'title': 'Stable architectures for deep neural networks', 'paperID': '37be889f4654312109dc9c53395fe117adb0f72b', 'arxivId': '1705.03341', 'publication_year': 2017, 'abstract': None}
{'title': 'Pixel Recurrent Neural Networks', 'paperID': '41f1d50c85d3180476c4c7b3eea121278b0d8474', 'arxivId': '1601.06759', 'publication_year': 2016, 'abstract': None}
{'title': 'Testing the Manifold Hypothesis', 'paperID': 'bb1847fbde3d4809a6998c435fad81c782a38a39', 'arxivId': '1310.0425', 'publication_year': 2013, 'abstract': None}
{'title': 'Introduction to manifold learning', 'paperID': '2a8cf34a315343311f3450671bb57c187ed6ef04', 'arxivId': None, 'publication_year': 2012, 'abstract': None}
{'title': 'On the Theory of Dynamic Programming.', 'paperID': 'dc9047917d1ceb3805d954c73899ddd2d40dd5eb', 'arxivId': None, 'publication_year': 1952, 'abstract': None}
{'title': 'A Proposal on Machine Learning via Dynamical Systems', 'paperID': '08b88af20db007702b57ddcbe0539681b6d3d558', 'arxivId': None, 'publication_year': 2017, 'abstract': None}
{'title': 'Optimal control theory : an introduction', 'paperID': '977706d1dc022280f47a2c67c646e85f38d88fe2', 'arxivId': None, 'publication_year': 1970, 'abstract': None}
{'title': 'Towards Robust Neural Networks via Close-loop Control', 'paperID': '1a452afbaf41306dbc9cbeb5cdedb85b85eacb0f', 'arxivId': '2102.01862', 'publication_year': '2021', 'abstract': 'Despite their success in massive engineering applications, deep neural networks are vulnerable to various perturbations due to their black-box nature. Recent study has shown that a deep neural network can misclassify the data even if the input data is perturbed by an imperceptible amount. In this paper, we address the robustness issue of neural networks by a novel close-loop control method from the perspective of dynamic systems. Instead of modifying the parameters in a fixed neural network architecture, a close-loop control process is added to generate control signals adaptively for the perturbed or corrupted data. We connect the robustness of neural networks with optimal control using the geometrical information of underlying data to design the control objective. The detailed analysis shows how the embedding manifolds of state trajectory affect error estimation of the proposed method. Our approach can simultaneously maintain the performance on clean data and improve the robustness against many types of data perturbations. It can also further improve the performance of robustly trained neural networks against different perturbations. To the best of our knowledge, this is the first work that improves the robustness of neural networks with close-loop control.'}
{'title': 'Defense against Adversarial Attacks in NLP via Dirichlet Neighborhood Ensemble', 'paperID': 'a58c97f8421ad97da4a08c8d45b8e355ab7de2ad', 'arxivId': '2006.11627', 'publication_year': 2020, 'abstract': None}
{'title': 'Textual Adversarial Attack as Combinatorial Optimization', 'paperID': '309b906fed883e5efe4acf676c655ead21f6c17b', 'arxivId': '1910.12196', 'publication_year': 2019, 'abstract': None}
{'title': 'Universal Adversarial Perturbation via Prior Driven Uncertainty Approximation', 'paperID': '8dad8858ff6d1160f9c0764fa101f78a9fae6bc9', 'arxivId': None, 'publication_year': 2019, 'abstract': None}
{'title': 'Is BERT Really Robust? Natural Language Attack on Text Classification and Entailment', 'paperID': 'a3347bbd82938788ec085772813c095de17a0b37', 'arxivId': None, 'publication_year': 2019, 'abstract': None}
{'title': 'Generating Natural Language Adversarial Examples through Probability Weighted Word Saliency', 'paperID': '1adfa30bf112de20cb959014e44626d760aa8e4e', 'arxivId': None, 'publication_year': 2019, 'abstract': None}
{'title': 'Generating Fluent Adversarial Examples for Natural Languages', 'paperID': 'afd975a296886e89722891ad13c8dba0d26b1ed2', 'arxivId': '2007.06174', 'publication_year': 2019, 'abstract': None}
{'title': 'Interpretable Adversarial Training for Text', 'paperID': '838baf0acddf90946aeed45945613050f137743e', 'arxivId': '1905.12864', 'publication_year': 2019, 'abstract': None}
{'title': 'Combating Adversarial Misspellings with Robust Word Recognition', 'paperID': '162515d87256f13888d9d7ba95275ac4b6c35396', 'arxivId': '1905.11268', 'publication_year': 2019, 'abstract': None}
{'title': 'Text Processing Like Humans Do: Visually Attacking and Shielding NLP Systems', 'paperID': '4dda68faa3ea2c888711ce5ced009afcb612e05b', 'arxivId': '1903.11508', 'publication_year': 2019, 'abstract': None}
{'title': 'Semantically Equivalent Adversarial Rules for Debugging NLP models', 'paperID': '472644c5f4155635cf9e9e37540bfa53c20e7610', 'arxivId': None, 'publication_year': 2018, 'abstract': None}
{'title': 'Improving Adversarial Robustness by Data-Specific Discretization', 'paperID': '107a53a46f3acda939d93c47009ab960d6a33464', 'arxivId': None, 'publication_year': 2018, 'abstract': None}
{'title': 'Interpretable Adversarial Perturbation in Input Embedding Space for Text', 'paperID': '23c884679d59c5557413ff0932f3580faae3f42d', 'arxivId': '1805.02917', 'publication_year': 2018, 'abstract': None}
{'title': 'Are Generative Classifiers More Robust to Adversarial Attacks?', 'paperID': '51de2f73ad68a0ff2289d4e02957a07ffc4236f4', 'arxivId': '1802.06552', 'publication_year': 2018, 'abstract': None}
{'title': 'Adversarial Texts with Gradient Methods', 'paperID': 'f09db8a42d713774483f023b31e0ee96361823f4', 'arxivId': '1801.07175', 'publication_year': 2018, 'abstract': None}
{'title': 'Non-convex Optimization for Machine Learning', 'paperID': '43d1fe40167c5f2ed010c8e06c8e008c774fd22b', 'arxivId': '1712.07897', 'publication_year': 2017, 'abstract': None}
{'title': 'Deep Text Classification Can be Fooled', 'paperID': 'ca062c5e48d230d0ac51da96d492f3cb4bf82b39', 'arxivId': '1704.08006', 'publication_year': 2017, 'abstract': None}
{'title': "Deceiving Google's Perspective API Built for Detecting Toxic Comments", 'paperID': 'b663e16f3b466278c0ee24f1780935755c6dd436', 'arxivId': '1702.08138', 'publication_year': 2017, 'abstract': None}
{'title': 'Adversarial Training Methods for Semi-Supervised Text Classification', 'paperID': '2cd55ded95d5d13430edfa223ba591b514ebe8a5', 'arxivId': '1605.07725', 'publication_year': 2016, 'abstract': None}
{'title': 'Learning Word Vectors for Sentiment Analysis', 'paperID': '649d03490ef72c5274e3bccd03d7a299d2f8da91', 'arxivId': None, 'publication_year': 2011, 'abstract': None}
{'title': 'Detecting spammers on social networks', 'paperID': 'f66d61c73de8ee9fd75f4aaab3575db15321ccfa', 'arxivId': None, 'publication_year': 2010, 'abstract': None}
{'title': 'Learning to Detect and Classify Malicious Executables in the Wild', 'paperID': '73fb1f854dd152af88835298a54b9bfbb9f711ce', 'arxivId': None, 'publication_year': 2006, 'abstract': None}
{'title': 'WordNet : an electronic lexical database', 'paperID': 'd87ceda3042f781c341ac17109d1e94a717f5f60', 'arxivId': None, 'publication_year': 2000, 'abstract': None}
{'title': 'An algorithm for quadratic programming', 'paperID': '37ae0ead03605de4c72f6d77af19b9001c0937f9', 'arxivId': None, 'publication_year': 1956, 'abstract': None}
{'title': 'A Set of Postulates for the Science of Language', 'paperID': 'faffddbd4996df1a4f49e9f5ba86e90be372d38f', 'arxivId': None, 'publication_year': 1926, 'abstract': None}
{'title': 'API-Net: Robust Generative Classifier via a Single Discriminator', 'paperID': '5b716dcc220d26af9e7d5b76978dc2d5b265386b', 'arxivId': None, 'publication_year': 2020, 'abstract': None}
{'title': 'Under review as a conference paper at ICLR 2016', 'paperID': 'be0dd2e91bb104494feeb5da2761cf930564f650', 'arxivId': None, 'publication_year': 2015, 'abstract': None}
{'title': 'Hownet And The Computation Of Meaning', 'paperID': 'f97e0c07b44be324ec6cb2b8b2604a88596af886', 'arxivId': None, 'publication_year': 2006, 'abstract': None}
{'title': 'An Archetypal Analysis on', 'paperID': 'b83e9556c42015f36da632ca39ac565087f54e63', 'arxivId': None, 'publication_year': 2005, 'abstract': None}
{'title': 'NONLINEAR PROGRAMMING', 'paperID': '4a8c4354756c69545c8c57390c26a8dd41039724', 'arxivId': None, 'publication_year': None, 'abstract': None}
{'title': 'Towards Robustness Against Natural Language Word Substitutions', 'paperID': 'f659031ceb7bbdcb7b0690742f35e2924fd1ed75', 'arxivId': '2107.13541', 'publication_year': '2021', 'abstract': 'Robustness against word substitutions has a well-defined and widely acceptable form, i.e., using semantically similar words as substitutions, and thus it is considered as a fundamental stepping-stone towards broader robustness in natural language processing. Previous defense methods capture word substitutions in vector space by using either $l_2$-ball or hyper-rectangle, which results in perturbation sets that are not inclusive enough or unnecessarily large, and thus impedes mimicry of worst cases for robust training. In this paper, we introduce a novel \\textit{Adversarial Sparse Convex Combination} (ASCC) method. We model the word substitution attack space as a convex hull and leverages a regularization term to enforce perturbation towards an actual substitution, thus aligning our modeling better with the discrete textual space. Based on the ASCC method, we further propose ASCC-defense, which leverages ASCC to generate worst-case perturbations and incorporates adversarial training towards robustness. Experiments show that ASCC-defense outperforms the current state-of-the-arts in terms of robustness on two prevailing NLP tasks, \\emph{i.e.}, sentiment analysis and natural language inference, concerning several attacks across multiple model architectures. Besides, we also envision a new class of defense towards robustness in NLP, where our robustly trained word vectors can be plugged into a normally trained model and enforce its robustness without applying any other defense techniques.'}
{'title': 'Do Adversarially Robust ImageNet Models Transfer Better?', 'paperID': '17293cd36ee5e7ec37dcec1d5ab85f9b77ad65d5', 'arxivId': '2007.08489', 'publication_year': 2020, 'abstract': None}
{'title': 'Adversarially-Trained Deep Nets Transfer Better', 'paperID': '393619a12436701c796d8b0bf9e72efb68c4913f', 'arxivId': '2007.05869', 'publication_year': 2020, 'abstract': None}
{'title': 'Tracking by Instance Detection: A Meta-Learning Approach', 'paperID': 'af985dea540bd489397e7d28affa10f32a4d7167', 'arxivId': '2004.00830', 'publication_year': 2020, 'abstract': None}
{'title': 'When Does Self-supervision Improve Few-shot Learning?', 'paperID': '0c1513b21d703e7e0d5a1d99a2ad5f6614a2706d', 'arxivId': '1910.03560', 'publication_year': 2019, 'abstract': None}
{'title': 'Adversarially Robust Few-Shot Learning: A Meta-Learning Approach', 'paperID': '1563e56e22d40769bdda91bffe481cfa3b9dac6c', 'arxivId': None, 'publication_year': 2019, 'abstract': None}
{'title': 'ES-MAML: Simple Hessian-Free Meta Learning', 'paperID': '837ca5b8e57262398d3540649bd9545e6d6291d9', 'arxivId': '1910.01215', 'publication_year': 2019, 'abstract': None}
{'title': 'Adversarial Robustness as a Prior for Learned Representations', 'paperID': '5d28bdfa02f0766febff32b7a6b287611d6f2995', 'arxivId': None, 'publication_year': 2019, 'abstract': None}
{'title': 'Rapid Learning or Feature Reuse? Towards Understanding the Effectiveness of MAML', 'paperID': 'abf5478c24664a1380b7e213a3ab1c4af54775d0', 'arxivId': '1909.09157', 'publication_year': 2019, 'abstract': None}
{'title': 'Adversarial Attacks and Defenses in Images, Graphs and Text: A Review', 'paperID': '6ad5f1d88534715051c6aba7436d60bdf65337e8', 'arxivId': '1909.08072', 'publication_year': 2019, 'abstract': None}
{'title': 'Topology Attack and Defense for Graph Neural Networks: An Optimization Perspective', 'paperID': '341880efaef452f631a4a5cd61bef5dae47741d7', 'arxivId': '1906.04214', 'publication_year': 2019, 'abstract': None}
{'title': 'Training Medical Image Analysis Systems like Radiologists', 'paperID': '0b949c29b118d7e4321efb777c99d7f2e36984df', 'arxivId': '1805.10884', 'publication_year': 2018, 'abstract': None}
{'title': 'Natural Language to Structured Query Generation via Meta-Learning', 'paperID': '9c0912153128e31743948cd629d6eebe6d916b42', 'arxivId': '1803.02400', 'publication_year': 2018, 'abstract': None}
{'title': 'Regularizing deep networks using efficient layerwise adversarial training', 'paperID': '68409946aa855b9a14de341bd321c38762817122', 'arxivId': '1705.07819', 'publication_year': 2017, 'abstract': None}
{'title': 'Meta Networks', 'paperID': '470d11b8ca4586c930adbbfc3f60bff08f2a0161', 'arxivId': '1703.00837', 'publication_year': 2017, 'abstract': None}
{'title': 'Yet Meta Learning Can Adapt Fast, It Can Also Break Easily', 'paperID': '7ce7f49ffcb3cf58a5bcad7e6d53e42579e53f5b', 'arxivId': None, 'publication_year': 2020, 'abstract': None}
{'title': 'Siamese Neural Networks for One-Shot Image Recognition', 'paperID': 'f216444d4f2959b4520c61d20003fa30a199670a', 'arxivId': None, 'publication_year': 2015, 'abstract': None}
{'title': 'On Fast Adversarial Robustness Adaptation in Model-Agnostic Meta-Learning', 'paperID': '118a605ad954c8f8e1ad65941429d0fd2c14c918', 'arxivId': '2102.10454', 'publication_year': '2021', 'abstract': "Model-agnostic meta-learning (MAML) has emerged as one of the most successful meta-learning techniques in few-shot learning. It enables us to learn a meta-initialization} of model parameters (that we call meta-model) to rapidly adapt to new tasks using a small amount of labeled training data. Despite the generalization power of the meta-model, it remains elusive that how adversarial robustness can be maintained by MAML in few-shot learning. In addition to generalization, robustness is also desired for a meta-model to defend adversarial examples (attacks). Toward promoting adversarial robustness in MAML, we first study WHEN a robustness-promoting regularization should be incorporated, given the fact that MAML adopts a bi-level (fine-tuning vs. meta-update) learning procedure. We show that robustifying the meta-update stage is sufficient to make robustness adapted to the task-specific fine-tuning stage even if the latter uses a standard training protocol. We also make additional justification on the acquired robustness adaptation by peering into the interpretability of neurons' activation maps. Furthermore, we investigate HOW robust regularization can efficiently be designed in MAML. We propose a general but easily-optimized robustness-regularized meta-learning framework, which allows the use of unlabeled data augmentation, fast adversarial attack generation, and computationally-light fine-tuning. In particular, we for the first time show that the auxiliary contrastive learning task can enhance the adversarial robustness of MAML. Finally, extensive experiments are conducted to demonstrate the effectiveness of our proposed methods in robust few-shot learning."}
{'title': 'Stable ResNet', 'paperID': '758cf7cd62bb8b62a6a4bc550a34e0a574bbbcb2', 'arxivId': '2010.12859', 'publication_year': 2020, 'abstract': None}
{'title': 'Pruning Neural Networks at Initialization: Why are We Missing the Mark?', 'paperID': '0932abfd0fb90e8a28f7bd195633c9891bfd7ecb', 'arxivId': '2009.08576', 'publication_year': 2020, 'abstract': None}
{'title': 'Pruning neural networks without any data by iteratively conserving synaptic flow', 'paperID': '3b0fb765716ef6861a84abffcbe40643857c613b', 'arxivId': '2006.05467', 'publication_year': 2020, 'abstract': None}
{'title': '5分で分かる!? 有名論文ナナメ読み：Jacot, Arthor, Gabriel, Franck and Hongler, Clement : Neural Tangent Kernel : Convergence and Generalization in Neural Networks', 'paperID': 'dc418c0b5ac24a67fef336323ef0417600ba3718', 'arxivId': None, 'publication_year': 2020, 'abstract': None}
{'title': 'DHP: Differentiable Meta Pruning via HyperNetworks', 'paperID': '542d5cfd36963e35e55e2596b46d63a552367801', 'arxivId': '2003.13683', 'publication_year': 2020, 'abstract': None}
{'title': 'Group Sparsity: The Hinge Between Filter Pruning and Decomposition for Network Compression', 'paperID': '296adb9c495c3105924e3f9d9dc81ea2b224d3a6', 'arxivId': '2003.08935', 'publication_year': 2020, 'abstract': None}
{'title': 'Picking Winning Tickets Before Training by Preserving Gradient Flow', 'paperID': 'c114ce10c4a315d92c3815f54bc9893e7e6ef182', 'arxivId': '2002.07376', 'publication_year': 2020, 'abstract': None}
{'title': 'Large Scale Learning of General Visual Representations for Transfer', 'paperID': '231c8bdecec9a7a8d64766e75d69fb9dd2b473b7', 'arxivId': None, 'publication_year': 2019, 'abstract': None}
{'title': 'Mean-field Behaviour of Neural Tangent Kernel for Deep Neural Networks', 'paperID': 'cfc52ae6ab8d0c79d32b22415c96ce71c63baa48', 'arxivId': None, 'publication_year': 2019, 'abstract': None}
{'title': 'A Signal Propagation Perspective for Pruning Neural Networks at Initialization', 'paperID': 'e7907e7e7d470a12bdab5e6381ad12c4f832ea49', 'arxivId': '1906.06307', 'publication_year': 2019, 'abstract': None}
{'title': 'On Exact Computation with an Infinitely Wide Neural Net', 'paperID': '1029daa28aa772e441470e61bdd610c222e92932', 'arxivId': '1904.11955', 'publication_year': 2019, 'abstract': None}
{'title': 'MetaPruning: Meta Learning for Automatic Neural Network Channel Pruning', 'paperID': 'bd3df472bc848083068a76e9ce2b2ab49543dc78', 'arxivId': '1903.10258', 'publication_year': 2019, 'abstract': None}
{'title': 'A Mean Field Theory of Batch Normalization', 'paperID': 'e5b7c1ce5a46e059fce96249c0c034afdd3c287a', 'arxivId': '1902.08129', 'publication_year': 2019, 'abstract': None}
{'title': 'On the Impact of the Activation Function on Deep Neural Networks Training', 'paperID': 'e663797275a20c0ab960772fe74e86c855b33767', 'arxivId': '1902.06853', 'publication_year': 2019, 'abstract': None}
{'title': 'Wide neural networks of any depth evolve as linear models under gradient descent', 'paperID': '9f9fc406c76255fec51a6196ce167c0ff1d1efc0', 'arxivId': '1902.06720', 'publication_year': 2019, 'abstract': None}
{'title': 'Scaling Limits of Wide Neural Networks with Weight Sharing: Gaussian Process Behavior, Gradient Independence, and Neural Tangent Kernel Derivation', 'paperID': '9b15a6f2434b9274cd1228eed4288b98cd316394', 'arxivId': '1902.04760', 'publication_year': 2019, 'abstract': None}
{'title': 'Gradient Descent Provably Optimizes Over-parameterized Neural Networks', 'paperID': 'd6f6d1504cfedde4efb23e7ec0f42f006062c6a0', 'arxivId': '1810.02054', 'publication_year': 2018, 'abstract': None}
{'title': 'Dynamical Isometry and a Mean Field Theory of CNNs: How to Train 10, 000-Layer Vanilla Convolutional Neural Networks', 'paperID': 'ad6309d1ea001098189425f54d069ef12abcb583', 'arxivId': '1806.05393', 'publication_year': 2018, 'abstract': None}
{'title': '"Learning-Compression" Algorithms for Neural Net Pruning', 'paperID': 'd719009bade1c245ac6e2fa9e4cd74eddd4f34b4', 'arxivId': None, 'publication_year': 2018, 'abstract': None}
{'title': 'Towards Understanding the Role of Over-Parametrization in Generalization of Neural Networks', 'paperID': '06ee9741730e4a2c7c8cdf643f5f34bc497a0b7c', 'arxivId': '1805.12076', 'publication_year': 2018, 'abstract': None}
{'title': 'Gaussian Process Behaviour in Wide Deep Neural Networks', 'paperID': 'fb350d3b03e9308ccbd131d3d45dd44e383e6227', 'arxivId': '1804.11271', 'publication_year': 2018, 'abstract': None}
{'title': 'Mean Field Residual Networks: On the Edge of Chaos', 'paperID': '751201109e644e1422d025fe8433f29570997b7d', 'arxivId': '1712.08969', 'publication_year': 2017, 'abstract': None}
{'title': 'Learning Sparse Neural Networks through L0 Regularization', 'paperID': '2ec7156913117949ab933f27f492d0149bc0031f', 'arxivId': '1712.01312', 'publication_year': 2017, 'abstract': None}
{'title': 'Compression-aware Training of Deep Networks', 'paperID': '45a154f8be8ec31821a0e409d4b69635670a2e1e', 'arxivId': '1711.02638', 'publication_year': 2017, 'abstract': None}
{'title': 'Deep Neural Networks as Gaussian Processes', 'paperID': '075556dd42900a6bc4552a2f2531ba21b9b7b4c0', 'arxivId': '1711.00165', 'publication_year': 2017, 'abstract': None}
{'title': 'Optimization Landscape and Expressivity of Deep CNNs', 'paperID': 'b57dc63e5149dcdb94f344d2d47c048edd00e2d4', 'arxivId': None, 'publication_year': 2017, 'abstract': None}
{'title': 'Learning to Prune Deep Neural Networks via Layer-wise Optimal Brain Surgeon', 'paperID': '773d5ddc414424a8948446ddaa5275b944f50891', 'arxivId': '1705.07565', 'publication_year': 2017, 'abstract': None}
{'title': 'Random synaptic feedback weights support error backpropagation for deep learning', 'paperID': '17ebe1eb19655543a6b876f91d41917488e70f55', 'arxivId': None, 'publication_year': 2016, 'abstract': None}
{'title': 'Deep Information Propagation', 'paperID': '4fdc7df2c737141a1bf5aec27a438b77d01f8af0', 'arxivId': '1611.01232', 'publication_year': 2016, 'abstract': None}
{'title': 'Exponential expressivity in deep neural networks through transient chaos', 'paperID': '6e997fec1412abb4b630d0e6d4df95813a01e093', 'arxivId': '1606.05340', 'publication_year': 2016, 'abstract': None}
{'title': 'Probability in High Dimension', 'paperID': '9d3582ae92b9e42db13dbb56d30f782e60068aa9', 'arxivId': None, 'publication_year': 2014, 'abstract': None}
{'title': 'Optimal Brain Surgeon and general network pruning', 'paperID': 'e8eaf8aedb495b6ae0e174eea11e3cfcdf4a3724', 'arxivId': None, 'publication_year': 1993, 'abstract': None}
{'title': 'Convex Functions, Partial Orderings, and Statistical Applications', 'paperID': '0b8dedcc16c6203e1f39c4f35c03932ff40a4275', 'arxivId': None, 'publication_year': 1992, 'abstract': None}
{'title': 'Optimal Brain Damage', 'paperID': 'e7297db245c3feb1897720b173a59fe7e36babb7', 'arxivId': None, 'publication_year': 1989, 'abstract': None}
{'title': 'Skeletonization: A Technique for Trimming the Fat from a Network via Relevance Assessment', 'paperID': 'a87953825b0bea2a5d52bfccf09d2518295c5053', 'arxivId': None, 'publication_year': 1988, 'abstract': None}
{'title': 'Limit theorems for random central order statistics', 'paperID': '629c4f332b5c84ce024dec21245cfce940954882', 'arxivId': None, 'publication_year': 1986, 'abstract': None}
{'title': 'Robust Pruning at Initialization', 'paperID': '6d60d0dd613fb1bc9b6a52f6b3e8b65599cade5a', 'arxivId': '2002.08797', 'publication_year': '2020', 'abstract': 'Overparameterized Neural Networks (NN) display state-of-the-art performance. However, there is a growing need for smaller, energy-efficient, neural networks tobe able to use machine learning applications on devices with limited computational resources. A popular approach consists of using pruning techniques. While these techniques have traditionally focused on pruning pre-trained NN (LeCun et al.,1990; Hassibi et al., 1993), recent work by Lee et al. (2018) has shown promising results when pruning at initialization. However, for Deep NNs, such procedures remain unsatisfactory as the resulting pruned networks can be difficult to train and, for instance, they do not prevent one layer from being fully pruned. In this paper, we provide a comprehensive theoretical analysis of Magnitude and Gradient based pruning at initialization and training of sparse architectures. This allows us to propose novel principled approaches which we validate experimentally on a variety of NN architectures.'}
{'title': 'Neural Lyapunov Control', 'paperID': '4350f9b0fb5c2fbe6791cab4990d42908358bed7', 'arxivId': '2005.00611', 'publication_year': 2020, 'abstract': None}
{'title': 'Projection-Based Constrained Policy Optimization', 'paperID': '9ec0bd60df62b997bb371e65d254434f8851ea9b', 'arxivId': '2010.03152', 'publication_year': 2020, 'abstract': None}
{'title': 'Nonlinear systems', 'paperID': '4e97fd0688a04f3749252a3ae47b1726bacb6999', 'arxivId': None, 'publication_year': 2020, 'abstract': None}
{'title': 'H∞ Model-free Reinforcement Learning with Robust Stability Guarantee', 'paperID': 'de93aec00784fba2b9138cad0f9bc6987eacc8f5', 'arxivId': '1911.02875', 'publication_year': 2019, 'abstract': None}
{'title': 'Differentiable Convex Optimization Layers', 'paperID': '88e83776313effc1564044d7bf19972981815e3c', 'arxivId': '1910.12430', 'publication_year': 2019, 'abstract': None}
{'title': 'Policy Optimization for $\\mathcal{H}_2$ Linear Control with $\\mathcal{H}_\\infty$ Robustness Guarantee: Implicit Regularization and Global Convergence', 'paperID': '689532925c32fac5bb1aabed390c0c0a057b058f', 'arxivId': '1910.09496', 'publication_year': 2019, 'abstract': None}
{'title': "Solving Rubik's Cube with a Robot Hand", 'paperID': '320b227027030fc291de2896fc3c6da49d7614be', 'arxivId': '1910.07113', 'publication_year': 2019, 'abstract': None}
{'title': 'Deep Declarative Networks', 'paperID': '3e411d95097a12e63cc4812ab4c3fdaba50df85e', 'arxivId': '1909.04866', 'publication_year': 2019, 'abstract': None}
{'title': 'Learning stabilizable nonlinear dynamics with contraction-based regularization', 'paperID': '513ea47003a522cebe03f2f1bfe96b3efc598234', 'arxivId': '1907.13122', 'publication_year': 2019, 'abstract': None}
{'title': 'SATNet: Bridging deep learning and logical reasoning using a differentiable satisfiability solver', 'paperID': 'd3850595d3ae7c73e9488054c9b437f75511b569', 'arxivId': '1905.12149', 'publication_year': 2019, 'abstract': None}
{'title': 'Stability-Certified Reinforcement Learning: A Control-Theoretic Perspective', 'paperID': '4fee3220123ac6d9294b35cab0dce3fc313a33aa', 'arxivId': '1810.11505', 'publication_year': 2018, 'abstract': None}
{'title': 'Safe Exploration and Optimization of Constrained MDPs Using Gaussian Processes', 'paperID': 'f3b78a8b96eec9b30721022e10604a4b04a4f23b', 'arxivId': None, 'publication_year': 2018, 'abstract': None}
{'title': 'Differentiable Submodular Maximization', 'paperID': 'de5b28e232178ad7a3ed1c048563b4184a2ae8ee', 'arxivId': '1803.01785', 'publication_year': 2018, 'abstract': None}
{'title': 'Constrained Policy Optimization', 'paperID': '7a4193d0b042643a8bb9ec262ed7f9d509bdb12e', 'arxivId': '1705.10528', 'publication_year': 2017, 'abstract': None}
{'title': 'Safe Model-based Reinforcement Learning with Stability Guarantees', 'paperID': '88880d88073a99107bbc009c9f4a4197562e1e44', 'arxivId': '1705.08551', 'publication_year': 2017, 'abstract': None}
{'title': 'A robust stability approach to robot reinforcement learning based on a parameterization of stabilizing controllers', 'paperID': '35d86b54da61d95cd2cf8950b23874b5442954e7', 'arxivId': None, 'publication_year': 2017, 'abstract': None}
{'title': 'OptNet: Differentiable Optimization as a Layer in Neural Networks', 'paperID': '0076b232181e4e5be58dce8354a813ad2bbf663a', 'arxivId': '1703.00443', 'publication_year': 2017, 'abstract': None}
{'title': 'Frequency robust control in stand-alone microgrids with PV sources : design and sensitivity analysis', 'paperID': '30f2888e81d955ac9d41b66580cfe3c3b3bcfca2', 'arxivId': None, 'publication_year': 2016, 'abstract': None}
{'title': 'Safe Exploration in Finite Markov Decision Processes with Gaussian Processes', 'paperID': 'a9beebe284b2c70895d4f51fe14fc50eda41fc60', 'arxivId': '1606.04753', 'publication_year': 2016, 'abstract': None}
{'title': 'Reachability-based safe learning with Gaussian processes', 'paperID': '410c3573849dfb673ce5c6f5b3108db7a0745551', 'arxivId': None, 'publication_year': 2014, 'abstract': None}
{'title': 'Introductory Lectures on Convex Optimization - A Basic Course', 'paperID': 'd0b0c3e5a1e768490bc9b759685930541957508b', 'arxivId': None, 'publication_year': 2014, 'abstract': None}
{'title': 'Off-Policy Reinforcement Learning for  $ H_\\infty $  Control Design', 'paperID': '04f014a6c23eb56bece071b0a5d35e3545cd9685', 'arxivId': '1311.6107', 'publication_year': 2013, 'abstract': None}
{'title': 'Neural-network-based zero-sum game for discrete-time nonlinear systems via iterative adaptive dynamic programming algorithm', 'paperID': '4bfadf34f26cc9ef5594b349d89cfc16b93ebbfa', 'arxivId': None, 'publication_year': 2013, 'abstract': None}
{'title': 'A New Method to Design Robust Power Oscillation Dampers for Distributed Synchronous Generation Systems', 'paperID': '9ab97c847003bec63578fda689d3d29226acdeb4', 'arxivId': None, 'publication_year': 2013, 'abstract': None}
{'title': 'Simultaneous policy update algorithms for learning the solution of linear continuous-time H∞ state feedback control', 'paperID': 'c800730e10a269dfd61298d45fb3ebd17681c2e9', 'arxivId': None, 'publication_year': 2013, 'abstract': None}
{'title': 'A game theoretic algorithm to compute local stabilizing solutions to HJBI equations in nonlinear H∞ control', 'paperID': 'a2809d0a46df8fde2eb579f1662cb1bc3b755583', 'arxivId': None, 'publication_year': 2009, 'abstract': None}
{'title': 'Nonlinear Dynamical Systems and Control: A Lyapunov-Based Approach', 'paperID': 'ce6406918b9e029a89eb093a50281888a996047b', 'arxivId': None, 'publication_year': 2008, 'abstract': None}
{'title': 'Policy Iterations on the Hamilton–Jacobi–Isaacs Equation for $H_{\\infty}$ State Feedback Control With Input Saturation', 'paperID': '7ef670b391f1d2511ca89c3455a764cd7310c797', 'arxivId': None, 'publication_year': 2006, 'abstract': None}
{'title': 'Lyapunov Design for Safe Reinforcement Learning', 'paperID': '1c0f7087367315e4e8cd1d8654ab33db12663c2b', 'arxivId': None, 'publication_year': 2003, 'abstract': None}
{'title': 'A primal-dual semi-definite programming approach to linear quadratic control', 'paperID': 'b7f9d1bb891935f6c41738a61c27f1018607af1c', 'arxivId': None, 'publication_year': 2001, 'abstract': None}
{'title': 'Essentials of Robust Control', 'paperID': 'f61117966b1ef9cf9f016e62bca19509dae33a9b', 'arxivId': None, 'publication_year': 1997, 'abstract': None}
{'title': 'H∞-0ptimal Control and Related Minimax Design Problems: A Dynamic Game Approach', 'paperID': 'fda6ba40c325b6fae89ddf2713832387eeaf2af8', 'arxivId': None, 'publication_year': 1996, 'abstract': None}
{'title': 'Robust constrained model predictive control using linear matrix inequalities', 'paperID': '05697e41fff4bbf3aad38ed5626cdddbd6057ae3', 'arxivId': None, 'publication_year': 1994, 'abstract': None}
{'title': 'Introduction to stochastic control', 'paperID': '9ebf90f7e96961c34f2dad649d9f450acd997506', 'arxivId': None, 'publication_year': 1972, 'abstract': None}
{'title': 'Introduction to Stochastic Control Theory', 'paperID': 'ac26c803bdb46b4ade1e2e4a5ec580665cebd112', 'arxivId': None, 'publication_year': 1970, 'abstract': None}
{'title': 'Policy Optimization for H2 Linear Control with H∞ Robustness Guarantee: Implicit Regularization and Global Convergence', 'paperID': '8fa6729de2ab91811568af264c25a73884b2f1b0', 'arxivId': None, 'publication_year': 2020, 'abstract': None}
{'title': 'Efficient Exploration for Constrained MDPs', 'paperID': 'fde4234a537f35167acbab2c1e179fa896a92ecb', 'arxivId': None, 'publication_year': 2018, 'abstract': None}
{'title': 'Reinforcement learning for control: Performance, stability, and deep approximators', 'paperID': 'e16d3aeeabc610ba4a9012ee85b16521734b97e8', 'arxivId': None, 'publication_year': 2018, 'abstract': None}
{'title': 'Differentiable Learning of Submodular Models', 'paperID': '2e50405acb7818717e39ea2821f665601d0a5662', 'arxivId': None, 'publication_year': 2017, 'abstract': None}
{'title': 'Introduction To Stochastic Control Theory', 'paperID': 'adac5f6e4324a9d277242b2e9e86ed671bb7f618', 'arxivId': None, 'publication_year': 2016, 'abstract': None}
{'title': 'Underactuated Robotics: Learning, Planning, and Control for Ecient and Agile Machines Course Notes for MIT 6.832', 'paperID': 'e48ed1073dfacaa79d00c8cfdc948d6871992f1d', 'arxivId': None, 'publication_year': 2009, 'abstract': None}
{'title': 'Linear Matrix Inequalities In System And Control Theory', 'paperID': '839c64b86d978baf5180381c975c0947eacdb7ba', 'arxivId': None, 'publication_year': 1998, 'abstract': None}
{'title': 'Projection algorithms and monotone operators', 'paperID': 'cceb877d4d909d02ce6bfe6402928524842adbf5', 'arxivId': None, 'publication_year': 1996, 'abstract': None}
{'title': 'Introduction to stochastic control', 'paperID': 'f9f56f478fd001e41380c59b264e0a47a420f645', 'arxivId': None, 'publication_year': 1971, 'abstract': None}
{'title': 'Enforcing robust control guarantees within neural network policies', 'paperID': '7915568a86a196c06bb70fb98b3bc076a5a18b8d', 'arxivId': '2011.08105', 'publication_year': '2020', 'abstract': 'When designing controllers for safety-critical systems, practitioners often face a challenging tradeoff between robustness and performance. While robust control methods provide rigorous guarantees on system stability under certain worst-case disturbances, they often result in simple controllers that perform poorly in the average (non-worst) case. In contrast, nonlinear control methods trained using deep learning have achieved state-of-the-art performance on many control tasks, but often lack robustness guarantees. We propose a technique that combines the strengths of these two approaches: a generic nonlinear control policy class, parameterized by neural networks, that nonetheless enforces the same provable robustness criteria as robust control. Specifically, we show that by integrating custom convex-optimization-based projection layers into a nonlinear policy, we can construct a provably robust neural network policy class that outperforms robust control methods in the average (non-adversarial) setting. We demonstrate the power of this approach on several domains, improving in performance over existing robust control methods and in stability over (non-robust) RL methods.'}
{'title': 'Cross-Domain Imitation Learning with a Dual Structure', 'paperID': '709422784b059294bb8546fe370e1f879bbbcd27', 'arxivId': '2006.01494', 'publication_year': 2020, 'abstract': None}
{'title': 'Domain-Adversarial and -Conditional State Space Model for Imitation Learning', 'paperID': 'a71b917c48e892a2ee410870bbb2da488519e9aa', 'arxivId': '2001.11628', 'publication_year': 2020, 'abstract': None}
{'title': 'AVID: Learning Multi-Stage Tasks via Pixel-Level Translation of Human Videos', 'paperID': '465c4fe8e4e4d43cfc89802a76b99bbcaaaa565d', 'arxivId': '1912.04443', 'publication_year': 2019, 'abstract': None}
{'title': 'Third-Person Visual Imitation Learning via Decoupled Hierarchical Controller', 'paperID': 'bbd93f7a687cdece41b2d92399525f03cc00cede', 'arxivId': '1911.09676', 'publication_year': 2019, 'abstract': None}
{'title': 'Task-Relevant Adversarial Imitation Learning', 'paperID': '2542f383c4002f7e523e1bf44caaea6d68beaee6', 'arxivId': '1910.01077', 'publication_year': 2019, 'abstract': None}
{'title': 'Cross Domain Imitation Learning', 'paperID': 'f8c24f7bd963cf540e7646e3c18e6f39cc234bfa', 'arxivId': '1910.00105', 'publication_year': 2019, 'abstract': None}
{'title': 'Recent Advances in Imitation Learning from Observation', 'paperID': 'cbcbdb44d9d4ad7bb6bf4e9104653aa7623a17c5', 'arxivId': '1905.13566', 'publication_year': 2019, 'abstract': None}
{'title': 'Discriminator-Actor-Critic: Addressing Sample Inefficiency and Reward Bias in Adversarial Imitation Learning', 'paperID': '876053977063ab843dd24c78425cbad1779a62ed', 'arxivId': '1809.02925', 'publication_year': 2018, 'abstract': None}
{'title': 'Spectral Normalization for Generative Adversarial Networks', 'paperID': '84de7d27e2f6160f634a483e8548c499a2cda7fa', 'arxivId': '1802.05957', 'publication_year': 2018, 'abstract': None}
{'title': 'Mutual Information Neural Estimation', 'paperID': '6b73775f40467aed52784ff355b9bb7168e9078c', 'arxivId': '1801.04062', 'publication_year': 2018, 'abstract': None}
{'title': 'Imitation from Observation: Learning to Imitate Behaviors from Raw Video via Context Translation', 'paperID': '77fa0239b9b074e7b62ca3798b8abf6fa3823f80', 'arxivId': '1707.03374', 'publication_year': 2017, 'abstract': None}
{'title': 'Time-Contrastive Networks: Self-Supervised Learning from Video', 'paperID': '2adae2da173b9dd720c8bcac0250a90a7f1ec697', 'arxivId': '1704.06888', 'publication_year': 2017, 'abstract': None}
{'title': 'Learning Invariant Feature Spaces to Transfer Skills with Reinforcement Learning', 'paperID': '7f710932a0aa99f2c2ddbec6e7765f10c48d3fc2', 'arxivId': '1703.02949', 'publication_year': 2017, 'abstract': None}
{'title': 'Third-Person Imitation Learning', 'paperID': '2e1a1b9c2e8feeb31c6855292859bf94101e8382', 'arxivId': '1703.01703', 'publication_year': 2017, 'abstract': None}
{'title': 'Towards Principled Methods for Training Generative Adversarial Networks', 'paperID': '9a700c7a7e7468e436f00c34551fbe3e0f70e42f', 'arxivId': '1701.04862', 'publication_year': 2017, 'abstract': None}
{'title': 'A Connection between Generative Adversarial Networks, Inverse Reinforcement Learning, and Energy-Based Models', 'paperID': 'a31d0e5668b311b1ec74c5607a9f96c35b395fa8', 'arxivId': '1611.03852', 'publication_year': 2016, 'abstract': None}
{'title': 'Generative Adversarial Imitation Learning', 'paperID': '4ab53de69372ec2cd2d90c126b6a100165dc8ed1', 'arxivId': '1606.03476', 'publication_year': 2016, 'abstract': None}
{'title': 'Learning dexterous manipulation for a soft robotic hand from human demonstrations', 'paperID': '183357d25d6bad84e16bdb8db8f57ad616f3a9ce', 'arxivId': '1603.06348', 'publication_year': 2016, 'abstract': None}
{'title': 'Guided Cost Learning: Deep Inverse Optimal Control via Policy Optimization', 'paperID': '04162cb8cfaa0f7e37586823ff4ad0bff09ed21d', 'arxivId': '1603.00448', 'publication_year': 2016, 'abstract': None}
{'title': 'Maximum Entropy Deep Inverse Reinforcement Learning', 'paperID': '9ba266a4a4644e877fc37a64be3beddce8904cf7', 'arxivId': '1507.04888', 'publication_year': 2015, 'abstract': None}
{'title': 'Trust Region Policy Optimization', 'paperID': '449532187c94af3dd3aa55e16d2c50f7854d2199', 'arxivId': '1502.05477', 'publication_year': 2015, 'abstract': None}
{'title': 'Equitability, mutual information, and the maximal information coefficient', 'paperID': 'f81a40aac09d2131bd5f25eafb962a4d26cffe50', 'arxivId': '1301.7745', 'publication_year': 2013, 'abstract': None}
{'title': 'An Object-Based Approach to Map Human Hand Synergies onto Robotic Hands with Dissimilar Kinematics', 'paperID': '5c356cad0d75cc1139d5293443940027a82595d5', 'arxivId': None, 'publication_year': 2012, 'abstract': None}
{'title': 'A Reduction of Imitation Learning and Structured Prediction to No-Regret Online Learning', 'paperID': '79ab3c49903ec8cb339437ccf5cf998607fc313e', 'arxivId': '1011.0686', 'publication_year': 2010, 'abstract': None}
{'title': 'Maximum entropy inverse reinforcement learning', 'paperID': '92c78a1eeb3fb335f4427a46c8741b37b2f98f1e', 'arxivId': None, 'publication_year': 2008, 'abstract': None}
{'title': 'Maximum margin planning', 'paperID': '117a50fbdfd473e43e550c6103733e6cb4aecb4c', 'arxivId': None, 'publication_year': 2006, 'abstract': None}
{'title': 'Apprenticeship learning via inverse reinforcement learning', 'paperID': 'f65020fc3b1692d7989e099d6b6e698be5a50a93', 'arxivId': None, 'publication_year': 2004, 'abstract': None}
{'title': 'Efficient Training of Artificial Neural Networks for Autonomous Navigation', 'paperID': '8d652a1980e743c7c85ff6066409ea1e3be4d685', 'arxivId': None, 'publication_year': 1991, 'abstract': None}
{'title': 'Asymptotic evaluation of certain Markov process expectations for large time', 'paperID': '2eb46dd423a351c25dc643f1ce8c8b54d8b48527', 'arxivId': None, 'publication_year': 1975, 'abstract': None}
{'title': 'Pharmacokinetics of a novel formulation of ivermectin after administration to goats', 'paperID': 'b05b67aca720d0bc39bc9afad02a19f522c7a1bc', 'arxivId': None, 'publication_year': 2000, 'abstract': None}
{'title': 'ALVINN: An Autonomous Land Vehicle in a Neural Network', 'paperID': '7786bc6c25ba38ff0135f1bdad192f6b3c4ad0b3', 'arxivId': None, 'publication_year': 1988, 'abstract': None}
{'title': 'Domain-Robust Visual Imitation Learning with Mutual Information Constraints', 'paperID': '42a37d42369c08f15f55a57e522d0a177da20ab7', 'arxivId': '2103.05079', 'publication_year': '2021', 'abstract': "Human beings are able to understand objectives and learn by simply observing others perform a task. Imitation learning methods aim to replicate such capabilities, however, they generally depend on access to a full set of optimal states and actions taken with the agent's actuators and from the agent's point of view. In this paper, we introduce a new algorithm - called Disentangling Generative Adversarial Imitation Learning (DisentanGAIL) - with the purpose of bypassing such constraints. Our algorithm enables autonomous agents to learn directly from high dimensional observations of an expert performing a task, by making use of adversarial learning with a latent representation inside the discriminator network. Such latent representation is regularized through mutual information constraints to incentivize learning only features that encode information about the completion levels of the task being demonstrated. This allows to obtain a shared feature space to successfully perform imitation while disregarding the differences between the expert's and the agent's domains. Empirically, our algorithm is able to efficiently imitate in a diverse range of control problems including balancing, manipulation and locomotive tasks, while being robust to various domain differences in terms of both environment appearance and agent embodiment."}
{'title': 'Towards Feature Space Adversarial Attack', 'paperID': '4d3e1c4b597a44e7f020e911636f7ccc739df3d3', 'arxivId': '2004.12385', 'publication_year': 2020, 'abstract': None}
{'title': 'Manifold Regularization for Locally Stable Deep Neural Networks', 'paperID': '63d529b0a9aabfe12a8fc6c5eebda869fc471ed8', 'arxivId': None, 'publication_year': 2020, 'abstract': None}
{'title': 'Semantic Adversarial Perturbations using Learnt Representations', 'paperID': 'e6bd6b24b17e7b2df30a2787488276451bbb3344', 'arxivId': '2001.11055', 'publication_year': 2020, 'abstract': None}
{'title': 'Evaluating Robustness to Context-Sensitive Feature Perturbations of Different Granularities', 'paperID': '849e1797a24550d6a525f4475ace7c2f87c479ef', 'arxivId': None, 'publication_year': 2020, 'abstract': None}
{'title': 'Instance adaptive adversarial training: Improved accuracy tradeoffs in neural nets', 'paperID': 'a30e33d5323343fd02be10975946e14df4a962e8', 'arxivId': '1910.08051', 'publication_year': 2019, 'abstract': None}
{'title': 'Unrestricted Adversarial Examples via Semantic Manipulation', 'paperID': 'd66c7ec5cdbf4df77789748d9173e2c4775933f0', 'arxivId': '1904.06347', 'publication_year': 2019, 'abstract': None}
{'title': 'Big but Imperceptible Adversarial Perturbations via Semantic Manipulation', 'paperID': '1e01fd005f5f1c2cf1b27c1ac8b014dfd3983da3', 'arxivId': None, 'publication_year': 2019, 'abstract': None}
{'title': 'Quantifying Perceptual Distortion of Adversarial Examples', 'paperID': 'c59841c623a6cde0413349d5c0f70fd0d93a3eba', 'arxivId': '1902.08265', 'publication_year': 2019, 'abstract': None}
{'title': 'A Style-Based Generator Architecture for Generative Adversarial Networks', 'paperID': 'ceb2ebef0b41e31c1a21b28c2734123900c005e2', 'arxivId': '1812.04948', 'publication_year': 2018, 'abstract': None}
{'title': 'Multimodal Unsupervised Image-to-Image Translation', 'paperID': '60104351ac65115503c9e92e856bcab6a13b0ce8', 'arxivId': '1804.04732', 'publication_year': 2018, 'abstract': None}
{'title': 'On the Suitability of Lp-Norms for Creating and Preventing Adversarial Examples', 'paperID': '578c891983e2fb02693b748879112d7f8a9add46', 'arxivId': '1802.09653', 'publication_year': 2018, 'abstract': None}
{'title': 'The Unreasonable Effectiveness of Deep Features as a Perceptual Metric', 'paperID': 'c468bbde6a22d961829e1970e6ad5795e05418d1', 'arxivId': '1801.03924', 'publication_year': 2018, 'abstract': None}
{'title': 'Adversarial Attacks Beyond the Image Space', 'paperID': '704cffb06e002faf5d8822e5d9f9a2046deafa3a', 'arxivId': '1711.07183', 'publication_year': 2017, 'abstract': None}
{'title': 'Robust Physical-World Attacks on Deep Learning Models', 'paperID': 'd295a620fc10a7a656dc693e1b1bf668d1508a8e', 'arxivId': '1707.08945', 'publication_year': 2017, 'abstract': None}
{'title': 'Adversarial Examples for Semantic Segmentation and Object Detection', 'paperID': 'e7867244de690a1ae11a7a6d5a021e868fa75a3c', 'arxivId': '1703.08603', 'publication_year': 2017, 'abstract': None}
{'title': 'On the Limitation of Convolutional Neural Networks in Recognizing Negative Images', 'paperID': '1f07761d481d03d2dff9ea64ddf5ff5ffb3da445', 'arxivId': '1703.06857', 'publication_year': 2017, 'abstract': None}
{'title': 'HDR-VDP-2: a calibrated visual metric for visibility and quality predictions in all luminance conditions', 'paperID': 'b69d13c6a1b848c7f4816a73fbdb1d396a03928c', 'arxivId': None, 'publication_year': 2011, 'abstract': None}
{'title': 'Complex Wavelet Structural Similarity: A New Image Similarity Index', 'paperID': '13eb5c34d9c4c2374b982897a3d762c7d58fa3aa', 'arxivId': None, 'publication_year': 2009, 'abstract': None}
{'title': 'Maximum differentiation (MAD) competition: a methodology for comparing computational models of perceptual quantities.', 'paperID': '4834f221a260e02a22aec77a97472dc437a2ad80', 'arxivId': None, 'publication_year': 2008, 'abstract': None}
{'title': 'Multiscale structural similarity for image quality assessment', 'paperID': '554cb0e8a604701ca78f2d782f2a26119eadaa81', 'arxivId': None, 'publication_year': 2003, 'abstract': None}
{'title': 'Modelling the Security Ecosystem- The Dynamics of (In)Security', 'paperID': 'c2f5a9007603481292718ee1b878bf10f0e7b933', 'arxivId': None, 'publication_year': 2009, 'abstract': None}
{'title': 'Perceptual Adversarial Robustness: Defense Against Unseen Threat Models', 'paperID': '473a854a939eca4bf39420ff496f8e24e223d460', 'arxivId': '2006.12655', 'publication_year': '2020', 'abstract': 'We present adversarial attacks and defenses for the perceptual adversarial threat model: the set of all perturbations to natural images which can mislead a classifier but are imperceptible to human eyes. The perceptual threat model is broad and encompasses $L_2$, $L_\\infty$, spatial, and many other existing adversarial threat models. However, it is difficult to determine if an arbitrary perturbation is imperceptible without humans in the loop. To solve this issue, we propose to use a {\\it neural perceptual distance}, an approximation of the true perceptual distance between images using internal activations of neural networks. In particular, we use the Learned Perceptual Image Patch Similarity (LPIPS) distance. We then propose the {\\it neural perceptual threat model} that includes adversarial examples with a bounded neural perceptual distance to natural images. Under the neural perceptual threat model, we develop two novel perceptual adversarial attacks to find any imperceptible perturbations to images which can fool a classifier. Through an extensive perceptual study, we show that the LPIPS distance correlates well with human judgements of perceptibility of adversarial examples, validating our threat model. Because the LPIPS threat model is very broad, we find that Perceptual Adversarial Training (PAT) against a perceptual attack gives robustness against many other types of adversarial attacks. We test PAT on CIFAR-10 and ImageNet-100 against 12 types of adversarial attacks and find that, for each attack, PAT achieves close to the accuracy of adversarial training against just that perturbation type. That is, PAT generalizes well to unforeseen perturbation types. This is vital in sensitive applications where a particular threat model cannot be assumed, and to the best of our knowledge, PAT is the first adversarial defense with this property.'}
{'title': 'Imbalanced Gradients: A New Cause of Overestimated Adversarial Robustness', 'paperID': '1e6f6ede6707c4687c755851bc6924c1b55ef9c5', 'arxivId': None, 'publication_year': 2020, 'abstract': None}
{'title': 'Adversarial Weight Perturbation Helps Robust Generalization', 'paperID': '574e8fb91ee0e089f4cadb4145302f97f6793bdf', 'arxivId': None, 'publication_year': 2020, 'abstract': None}
{'title': 'Adversarial Camouflage: Hiding Physical-World Attacks With Natural Styles', 'paperID': '26cb37bf23299d18af4a76b11907e821910f8e88', 'arxivId': '2003.08757', 'publication_year': 2020, 'abstract': None}
{'title': 'Adversarial Neural Pruning with Latent Vulnerability Suppression', 'paperID': '8d5ed715390944c3bf07f826377ade48de4fba1a', 'arxivId': None, 'publication_year': 2019, 'abstract': None}
{'title': 'Batch Normalization is a Cause of Adversarial Vulnerability', 'paperID': '3402a06dbce96fc06e7c0089add732499d78e3bc', 'arxivId': '1905.02161', 'publication_year': 2019, 'abstract': None}
{'title': 'Harnessing the Vulnerability of Latent Layers in Adversarially Trained Models', 'paperID': '8d7cff029570cf4dc15fc49693067154823a562e', 'arxivId': '1905.05186', 'publication_year': 2019, 'abstract': None}
{'title': 'Interpreting Adversarial Examples by Activation Promotion and Suppression', 'paperID': '0ede3139fc2c7ae3d39d7498298ed1bd9c1255aa', 'arxivId': '1904.02057', 'publication_year': 2019, 'abstract': None}
{'title': 'Improved robustness to adversarial examples using Lipschitz regularization of the loss', 'paperID': '986139329ca5863b4f65d9cbca0ce49de910d487', 'arxivId': '1810.00953', 'publication_year': 2018, 'abstract': None}
{'title': 'Improving Adversarial Robustness via Channel-wise Activation Suppressing', 'paperID': 'df872e72e87a85f9b5cd28da06ace46386462fde', 'arxivId': '2103.08307', 'publication_year': '2021', 'abstract': 'The study of adversarial examples and their activation has attracted significant attention for secure and robust learning with deep neural networks (DNNs). Different from existing works, in this paper, we highlight two new characteristics of adversarial examples from the channel-wise activation perspective: 1) the activation magnitudes of adversarial examples are higher than that of natural examples; and 2) the channels are activated more uniformly by adversarial examples than natural examples. We find that the state-of-the-art defense adversarial training has addressed the first issue of high activation magnitudes via training on adversarial examples, while the second issue of uniform activation remains. This motivates us to suppress redundant activation from being activated by adversarial perturbations via a Channel-wise Activation Suppressing (CAS) strategy. We show that CAS can train a model that inherently suppresses adversarial activation, and can be easily applied to existing defense methods to further improve their robustness. Our work provides a simple but generic training strategy for robustifying the intermediate layer activation of DNNs.'}
{'title': 'Clusterability as an Alternative to Anchor Points When Learning with Noisy Labels', 'paperID': '646c28e0bee560f6a37b37289284774e53962ce6', 'arxivId': '2102.05291', 'publication_year': 2021, 'abstract': None}
{'title': 'Peer Loss Functions: Learning from Noisy Labels without Knowing Noise Rates', 'paperID': '906c299c9386f70198f44e60ee9a073c42271638', 'arxivId': '1910.03231', 'publication_year': 2019, 'abstract': None}
{'title': 'L_DMI: An Information-theoretic Noise-robust Loss Function', 'paperID': '98115d0f8aa50e9fc5237e5b81cfe1c5cbb8fce8', 'arxivId': '1909.03388', 'publication_year': 2019, 'abstract': None}
{'title': 'NLNL: Negative Learning for Noisy Labels', 'paperID': 'ab7539b938ca8a99b5fb34695e1b86ef0c6f3632', 'arxivId': '1908.07387', 'publication_year': 2019, 'abstract': None}
{'title': 'On Symmetric Losses for Learning from Corrupted Labels', 'paperID': 'de476b346ab2aa3b2b759bc9f273f1e8550409f8', 'arxivId': '1901.09314', 'publication_year': 2019, 'abstract': None}
{'title': 'Deep Bilevel Learning', 'paperID': '35216558a821ff1ae77ad2f4571e4d83327da244', 'arxivId': '1809.01465', 'publication_year': 2018, 'abstract': None}
{'title': 'On the Minimal Supervision for Training Any Binary Classifier from Only Unlabeled Data', 'paperID': '570f3c52e4e9608d65afd00076e784800c286524', 'arxivId': '1808.10585', 'publication_year': 2018, 'abstract': None}
{'title': 'f-GAN: Training Generative Neural Samplers using Variational Divergence Minimization', 'paperID': 'ffdcad14d2f6a12f607b59f88da4a939f4821691', 'arxivId': '1606.00709', 'publication_year': 2016, 'abstract': None}
{'title': 'Mixture Proportion Estimation via Kernel Embeddings of Distributions', 'paperID': 'd274f7ccf34a9e21bdd6934b2c5dc229d5ec2911', 'arxivId': '1603.02501', 'publication_year': 2016, 'abstract': None}
{'title': 'Learning from Corrupted Binary Labels via Class-Probability Estimation', 'paperID': '6d8984600e3cd9ae9d6b803f43f2410fa5c0ad0b', 'arxivId': None, 'publication_year': 2015, 'abstract': None}
{'title': 'A Rate of Convergence for Mixture Proportion Estimation, with Application to Learning from Noisy Labels', 'paperID': '001677dffb9b4ccb3ba49076f7f5cbe3f7a405eb', 'arxivId': None, 'publication_year': 2015, 'abstract': None}
{'title': 'Making risk minimization tolerant to label noise', 'paperID': '38861d0d3a0292c1f54153b303b0d791cbba1d50', 'arxivId': '1403.3610', 'publication_year': 2014, 'abstract': None}
{'title': 'Learning with Noisy Labels', 'paperID': '1ab5c006caf3bf8c128fdfad80e58277cb8b1455', 'arxivId': None, 'publication_year': 2013, 'abstract': None}
{'title': 'Classification with Asymmetric Label Noise: Consistency and Maximal Denoising', 'paperID': 'ce9de6c26a4772f2349b29d76c22b5a436f6cbca', 'arxivId': '1303.1208', 'publication_year': 2013, 'abstract': None}
{'title': 'Noise Tolerance Under Risk Minimization', 'paperID': 'a035210a6dc001a0c3404f94a5c9ec0e73507cfd', 'arxivId': '1109.5231', 'publication_year': 2011, 'abstract': None}
{'title': 'Adaptive Subgradient Methods for Online Learning and Stochastic Optimization', 'paperID': 'b78f419ace9938fad9402361e1aa0dbd288ec004', 'arxivId': None, 'publication_year': 2011, 'abstract': None}
{'title': 'When Optimizing  $f$-Divergence is Robust with Label Noise', 'paperID': '0abff557bf1c38a1fbbbeaa01dea66cd1ac5e988', 'arxivId': '2011.03687', 'publication_year': '2020', 'abstract': "We show when maximizing a properly defined $f$-divergence measure with respect to a classifier's predictions and the supervised labels is robust with label noise. Leveraging its variational form, we derive a nice decoupling property for this particular $f$-divergence when label noise presents, where the divergence is shown to be a linear combination of the variational difference defined on the clean distribution and a bias term introduced due to the noise. The above derivation helps us analyze the robustness of this measure for different $f$-divergence functions. With established robustness, this family of $f$-divergence functions arises as useful metrics for the problem of learning with noisy labels, which do not require the specification of the labels' noise rate. When they are possibly not robust, we propose fixes to make them so. In addition to the analytical results, we present thorough experimental studies."}
{'title': 'Puzzle Mix: Exploiting Saliency and Local Statistics for Optimal Mixup', 'paperID': 'a65cff2a792cd2133d2db91d88327bdac6cbf108', 'arxivId': '2009.06962', 'publication_year': 2020, 'abstract': None}
{'title': 'PatchUp: A Regularization Technique for Convolutional Neural Networks', 'paperID': 'be21780b2e2fa8abb2243e91d5af5c7bd49d4079', 'arxivId': None, 'publication_year': 2020, 'abstract': None}
{'title': 'On Mixup Regularization', 'paperID': '264972e27882e53a4671f95b2a4c789e15d12cd7', 'arxivId': '2006.06049', 'publication_year': 2020, 'abstract': None}
{'title': 'Dropout: Explicit Forms and Capacity Control', 'paperID': '404c8ec7d40d58b8ea6bc634262101486cb74300', 'arxivId': '2003.03397', 'publication_year': 2020, 'abstract': None}
{'title': 'The Implicit and Explicit Regularization Effects of Dropout', 'paperID': '0d37c762336ce69801c7fda5eb140d716ece0859', 'arxivId': '2002.12915', 'publication_year': 2020, 'abstract': None}
{'title': 'Interpolated Adversarial Training: Achieving Robust Neural Networks Without Sacrificing Too Much Accuracy', 'paperID': '6d15683422ffa9c044c2a90f45ea0ff845de83d9', 'arxivId': '1906.06784', 'publication_year': 2019, 'abstract': None}
{'title': 'On Mixup Training: Improved Calibration and Predictive Uncertainty for Deep Neural Networks', 'paperID': '7b2e26fd3e862c5f58c522a13ae86a768aaaccad', 'arxivId': '1905.11001', 'publication_year': 2019, 'abstract': None}
{'title': 'Interpolation Consistency Training for Semi-Supervised Learning', 'paperID': '743ce0d2c9d86caa5a570fec36e8d2378d031b3f', 'arxivId': '1903.03825', 'publication_year': 2019, 'abstract': None}
{'title': 'On Adversarial Mixup Resynthesis', 'paperID': 'f1aa40ba7e3166744955ceae2e6d8d60515e7021', 'arxivId': None, 'publication_year': 2019, 'abstract': None}
{'title': 'Deep Learning for Classical Japanese Literature', 'paperID': '43054544c4ff2e25513de8b1a655593b8ff89338', 'arxivId': '1812.01718', 'publication_year': 2018, 'abstract': None}
{'title': 'On the Implicit Bias of Dropout', 'paperID': '714e3e81ce270518e20d56c56967475eaffedee3', 'arxivId': '1806.09777', 'publication_year': 2018, 'abstract': None}
{'title': 'Generalization in Deep Learning', 'paperID': '430de87a0a8996bc93b1998f9a6261f7558a5679', 'arxivId': '1710.05468', 'publication_year': 2017, 'abstract': None}
{'title': 'On the Depth of Deep Neural Networks: A Theoretical View', 'paperID': 'bb8043fc95475ae862c13fba290d5b737b36bd3b', 'arxivId': None, 'publication_year': 2015, 'abstract': None}
{'title': 'On the inductive bias of dropout', 'paperID': '178b2407fb2165a0253862b52f287e333f79dbc1', 'arxivId': '1412.4736', 'publication_year': 2014, 'abstract': None}
{'title': 'Dropout Training as Adaptive Regularization', 'paperID': 'd124a098cdc6f99b9a152fcf8afa9327dac583be', 'arxivId': '1307.1493', 'publication_year': 2013, 'abstract': None}
{'title': 'Fast dropout training', 'paperID': 'ec92efde21707ddf4b81f301cd58e2051c1a2443', 'arxivId': None, 'publication_year': 2013, 'abstract': None}
{'title': 'Estimation of Dependences Based on Empirical Data', 'paperID': '4a18360a14facea50dc819145b1daf4c53d5d59e', 'arxivId': None, 'publication_year': 2006, 'abstract': None}
{'title': 'Localized Rademacher Complexities', 'paperID': 'e4fd07d80407bd974c1c550962a7af20d42d49a0', 'arxivId': None, 'publication_year': 2002, 'abstract': None}
{'title': 'Independent consultant', 'paperID': '364fb0677a5d7083e56c0e38629a78cb94836f53', 'arxivId': None, 'publication_year': 2013, 'abstract': None}
{'title': 'Can We Learn to Gamble Efficiently?', 'paperID': 'cb067015b18da10c48668e08989c2fe2cf6e2d11', 'arxivId': None, 'publication_year': 2010, 'abstract': None}
{'title': 'The Nature of Statistical Learning Theory', 'paperID': '8213dbed4db44e113af3ed17d6dad57471a0c048', 'arxivId': None, 'publication_year': 2000, 'abstract': None}
{'title': 'How Does Mixup Help With Robustness and Generalization?', 'paperID': '92ed2e34501903d922d74f28a012d6e337418fa4', 'arxivId': '2010.04819', 'publication_year': '2020', 'abstract': 'Mixup is a popular data augmentation technique based on taking convex combinations of pairs of examples and their labels. This simple technique has been shown to substantially improve both the robustness and the generalization of the trained model. However, it is not well-understood why such improvement occurs. In this paper, we provide theoretical analysis to demonstrate how using Mixup in training helps model robustness and generalization. For robustness, we show that minimizing the Mixup loss corresponds to approximately minimizing an upper bound of the adversarial loss. This explains why models obtained by Mixup training exhibits robustness to several kinds of adversarial attacks such as Fast Gradient Sign Method (FGSM). For generalization, we prove that Mixup augmentation corresponds to a specific type of data-adaptive regularization which reduces overfitting. Our analysis provides new insights and a framework to understand Mixup.'}
{'title': 'EDoG: Adversarial Edge Detection For Graph Neural Networks', 'paperID': '511aba67a50408ad52f1bc502985cf3e64345869', 'arxivId': '2212.13607', 'publication_year': 2022, 'abstract': None}
{'title': 'Reliable Graph Neural Networks via Robust Aggregation', 'paperID': 'a47424106165acd212b3233af8eb5a26cc567b4b', 'arxivId': '2010.15651', 'publication_year': 2020, 'abstract': None}
{'title': 'Adversarial Attack and Defense of Structured Prediction Models', 'paperID': '49f780951539665dea602c5ae4528fc67e656404', 'arxivId': '2010.01610', 'publication_year': 2020, 'abstract': None}
{'title': 'Uncertainty-aware Attention Graph Neural Network for Defending Adversarial Attacks', 'paperID': '9bf050287e0cd8df167cc345878335fc5a8d045e', 'arxivId': '2009.10235', 'publication_year': 2020, 'abstract': None}
{'title': 'Efficient Robustness Certificates for Discrete Data: Sparsity-Aware Randomized Smoothing for Graphs, Images and More', 'paperID': '60cb22635e8d05a986fa6de2fc7090a9451e2de3', 'arxivId': '2008.12952', 'publication_year': 2020, 'abstract': None}
{'title': 'Robust Collective Classification against Structural Attacks', 'paperID': '544f62fbe3d43d31edc7ac710ed83dee5c279b82', 'arxivId': '2007.13073', 'publication_year': 2020, 'abstract': None}
{'title': 'Detection as Regression: Certified Object Detection by Median Smoothing', 'paperID': '07c67c090ee27676ef91d288d897f4b2352b42e3', 'arxivId': '2007.03730', 'publication_year': 2020, 'abstract': None}
{'title': 'Certifiable Robustness of Graph Convolutional Networks under Structure Perturbations', 'paperID': 'ad331b2035602c58221e9092920de0fd6ed2f629', 'arxivId': None, 'publication_year': 2020, 'abstract': None}
{'title': 'Adversarial Attacks on Graph Neural Networks', 'paperID': 'a71e40e0895f9a3d1e85e0bf9c1b032855446ede', 'arxivId': None, 'publication_year': 2020, 'abstract': None}
{'title': 'DefenseVGAE: Defending against Adversarial Attacks on Graph Data via a Variational Graph Autoencoder', 'paperID': 'e8c8e6621a5646546f18c48303afc86cbcf8c0c1', 'arxivId': '2006.08900', 'publication_year': 2020, 'abstract': None}
{'title': 'Dynamic Divide-and-Conquer Adversarial Training for Robust Semantic Segmentation', 'paperID': '409c309573b0e5f0cf7bad0ed779acf95613fe5a', 'arxivId': '2003.06555', 'publication_year': 2020, 'abstract': None}
{'title': 'All You Need Is Low (Rank): Defending Against Adversarial Attacks on Graphs', 'paperID': '3aab8bea2ba6bd7f076e6f92a504a1e322ca64b8', 'arxivId': None, 'publication_year': 2020, 'abstract': None}
{'title': 'Certifiable Robustness to Graph Perturbations', 'paperID': '458757a205dc73e17683458d1c432e9bbff42e5c', 'arxivId': '1910.14356', 'publication_year': 2019, 'abstract': None}
{'title': 'Robust Graph Convolutional Networks Against Adversarial Attacks', 'paperID': 'f5252075bb34666863cd01cc82c2d941d4ffe6c6', 'arxivId': None, 'publication_year': 2019, 'abstract': None}
{'title': 'Certifiable Robustness and Robust Training for Graph Convolutional Networks', 'paperID': '1bfad6fd818bd64db381791efd9252e0313dc100', 'arxivId': '1906.12269', 'publication_year': 2019, 'abstract': None}
{'title': 'Graph Adversarial Training: Dynamically Regularizing Based on Graph Structure', 'paperID': '0349593412dbafbcec736da8c2547e94fa702607', 'arxivId': '1902.08226', 'publication_year': 2019, 'abstract': None}
{'title': 'Predict then Propagate: Graph Neural Networks meet Personalized PageRank', 'paperID': 'ac225094aab9e7b629bc5b3343e026dea0200c70', 'arxivId': '1810.05997', 'publication_year': 2018, 'abstract': None}
{'title': 'Adversarial Attacks on Neural Networks for Graph Data', 'paperID': '6c44f8e62d824bcda4f291c679a5518bbd4225f6', 'arxivId': '1805.07984', 'publication_year': 2018, 'abstract': None}
{'title': 'Threat of Adversarial Attacks on Deep Learning in Computer Vision: A Survey', 'paperID': 'b514949ad8344071c0f342f182390d2d88bcc26d', 'arxivId': '1801.00553', 'publication_year': 2018, 'abstract': None}
{'title': 'Deep Gaussian Embedding of Graphs: Unsupervised Inductive Learning via Ranking', 'paperID': '2b76b6e766547b3c6dbc2785a084ec3b72cb760d', 'arxivId': '1707.03815', 'publication_year': 2017, 'abstract': None}
{'title': 'Neural Message Passing for Quantum Chemistry', 'paperID': 'e24cdf73b3e7e590c2fe5ecac9ae8aa983801367', 'arxivId': '1704.01212', 'publication_year': 2017, 'abstract': None}
{'title': 'Automating the Construction of Internet Portals with Machine Learning', 'paperID': '04f4085c0126ba29453a582cd1e62e05c8e15c82', 'arxivId': None, 'publication_year': 2000, 'abstract': None}
{'title': 'Learning to Extract Symbolic Knowledge from the World Wide Web', 'paperID': '8446830f3c05b97c4d12a0751c022d1ae6a5115b', 'arxivId': None, 'publication_year': 1998, 'abstract': None}
{'title': 'Query-driven Active Surveying for Collective Classification', 'paperID': 'efac04450c531b3769451a886ed9a42fce4754d9', 'arxivId': None, 'publication_year': 2012, 'abstract': None}
{'title': 'Collective Robustness Certificates: Exploiting Interdependence in Graph Neural Networks', 'paperID': 'fc1ad6fbf705bb2e45f0e832fb10325a868d87f9', 'arxivId': '2302.02829', 'publication_year': '2023', 'abstract': 'In tasks like node classification, image segmentation, and named-entity recognition we have a classifier that simultaneously outputs multiple predictions (a vector of labels) based on a single input, i.e. a single graph, image, or document respectively. Existing adversarial robustness certificates consider each prediction independently and are thus overly pessimistic for such tasks. They implicitly assume that an adversary can use different perturbed inputs to attack different predictions, ignoring the fact that we have a single shared input. We propose the first collective robustness certificate which computes the number of predictions that are simultaneously guaranteed to remain stable under perturbation, i.e. cannot be attacked. We focus on Graph Neural Networks and leverage their locality property - perturbations only affect the predictions in a close neighborhood - to fuse multiple single-node certificates into a drastically stronger collective certificate. For example, on the Citeseer dataset our collective certificate for node classification increases the average number of certifiable feature perturbations from $7$ to $351$.'}
{'title': 'Theory-Inspired Path-Regularized Differential Network Architecture Search', 'paperID': '5a0859bd66ec5b70f3230bdf2181fde1e641bfde', 'arxivId': '2006.16537', 'publication_year': 2020, 'abstract': None}
{'title': 'Stabilizing Differentiable Architecture Search via Perturbation-based Regularization', 'paperID': '38b64492ac1b5d6c8166c7952073e760bfb8f46a', 'arxivId': '2002.05283', 'publication_year': 2020, 'abstract': None}
{'title': 'NAS-Bench-201: Extending the Scope of Reproducible Neural Architecture Search', 'paperID': '69599593f93023e2f91ef6673ee9860f85777d98', 'arxivId': '2001.00326', 'publication_year': 2020, 'abstract': None}
{'title': 'NAS evaluation is frustratingly hard', 'paperID': '645a24296f96f325f4a6fd324cef85661a8987da', 'arxivId': '1912.12522', 'publication_year': 2019, 'abstract': None}
{'title': 'AtomNAS: Fine-Grained End-to-End Neural Architecture Search', 'paperID': 'f5f35340893d550bd5d1a2711f04308525c6dcd2', 'arxivId': '1912.09640', 'publication_year': 2019, 'abstract': None}
{'title': 'SGAS: Sequential Greedy Architecture Search', 'paperID': '40d076d07c36c94ee43bbe0c2e66f4e4cc92d039', 'arxivId': '1912.00195', 'publication_year': 2019, 'abstract': None}
{'title': 'Fair DARTS: Eliminating Unfair Advantages in Differentiable Architecture Search', 'paperID': '52fa3eb17723571bb7127db42fed9e78cfa4c00f', 'arxivId': '1911.12126', 'publication_year': 2019, 'abstract': None}
{'title': 'GhostNet: More Features From Cheap Operations', 'paperID': 'a4cc0701170331a1fd0e58bad962bd7f39f5efc9', 'arxivId': '1911.11907', 'publication_year': 2019, 'abstract': None}
{'title': 'Stabilizing DARTS with Amended Gradient Estimation on Architectural Parameters', 'paperID': '7ffac30cd47fe173bec897d2b8b81c93e2771b85', 'arxivId': '1910.11831', 'publication_year': 2019, 'abstract': None}
{'title': 'One-Shot Neural Architecture Search via Self-Evaluated Template Network', 'paperID': '7f4b0db1111d95d7135ea8135f3530a1d9357ae2', 'arxivId': '1910.05733', 'publication_year': 2019, 'abstract': None}
{'title': 'DARTS+: Improved Differentiable Architecture Search with Early Stopping', 'paperID': '237a230fa4bc28085d470e7e990938ad32be2c37', 'arxivId': '1909.06035', 'publication_year': 2019, 'abstract': None}
{'title': 'ScarletNAS: Bridging the Gap Between Scalability and Fairness in Neural Architecture Search', 'paperID': 'a2401eea772949f79aba080a6df7bbd91d93346e', 'arxivId': None, 'publication_year': 2019, 'abstract': None}
{'title': 'MoGA: Searching Beyond Mobilenetv3', 'paperID': 'e333036efb9f3a1cd402d81d4491931563945c66', 'arxivId': '1908.01314', 'publication_year': 2019, 'abstract': None}
{'title': 'MixConv: Mixed Depthwise Convolutional Kernels', 'paperID': 'fb564bacfa790d44ab02a72256d55aa8b2209914', 'arxivId': '1907.09595', 'publication_year': 2019, 'abstract': None}
{'title': 'PC-DARTS: Partial Channel Connections for Memory-Efficient Architecture Search', 'paperID': '4ebce2425e231031f89a4a68dc52a151cd735d03', 'arxivId': '1907.05737', 'publication_year': 2019, 'abstract': None}
{'title': 'FairNAS: Rethinking Evaluation Fairness of Weight Sharing Neural Architecture Search', 'paperID': 'a7ce95c6f674b7b5b19a532491d160d142f8b2d6', 'arxivId': '1907.01845', 'publication_year': 2019, 'abstract': None}
{'title': 'MMDetection: Open MMLab Detection Toolbox and Benchmark', 'paperID': 'c2c083df88e88223e1a411e61040b94c233b1b63', 'arxivId': '1906.07155', 'publication_year': 2019, 'abstract': None}
{'title': 'Searching for a Robust Neural Architecture in Four GPU Hours', 'paperID': 'fe8907302f9d14233cd03cc2948a1c4e2a50bdb6', 'arxivId': '1910.04465', 'publication_year': 2019, 'abstract': None}
{'title': 'EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks', 'paperID': '4f2eda8077dc7a69bb2b4e0a1a086cf054adb3f9', 'arxivId': '1905.11946', 'publication_year': 2019, 'abstract': None}
{'title': 'Searching for MobileNetV3', 'paperID': '5e19eba1e6644f7c83f607383d256deea71f87ae', 'arxivId': '1905.02244', 'publication_year': 2019, 'abstract': None}
{'title': 'Progressive Differentiable Architecture Search: Bridging the Depth Gap Between Search and Evaluation', 'paperID': '727c7abef2dc19d220e9e9417cd41852a05d19fb', 'arxivId': '1904.12760', 'publication_year': 2019, 'abstract': None}
{'title': 'NAS-FPN: Learning Scalable Feature Pyramid Architecture for Object Detection', 'paperID': 'b5375995ab8d679a581ffcc2f2e8d3777d60324b', 'arxivId': '1904.07392', 'publication_year': 2019, 'abstract': None}
{'title': 'Single-Path NAS: Designing Hardware-Efficient ConvNets in less than 4 Hours', 'paperID': '18ca023bbb1a24873140b5440479e74c7f90b684', 'arxivId': '1904.02877', 'publication_year': 2019, 'abstract': None}
{'title': 'The Evolved Transformer', 'paperID': '16c844fd4d97f3c6eb38b0d6527c87d184efedc3', 'arxivId': '1901.11117', 'publication_year': 2019, 'abstract': None}
{'title': 'Fast, Accurate and Lightweight Super-Resolution with Neural Architecture Search', 'paperID': '191b88c374c8fc4367238c3f4df2af250c32a4ef', 'arxivId': '1901.07261', 'publication_year': 2019, 'abstract': None}
{'title': 'FBNet: Hardware-Aware Efficient ConvNet Design via Differentiable Neural Architecture Search', 'paperID': '45532bffbfbb5553da0b2d0844e95a1b37e59147', 'arxivId': '1812.03443', 'publication_year': 2018, 'abstract': None}
{'title': 'Multi-scale Residual Network for Image Super-Resolution', 'paperID': '7a71941e60894ae7e1f5af8e79c37cec6cd6c6ad', 'arxivId': None, 'publication_year': 2018, 'abstract': None}
{'title': 'MnasNet: Platform-Aware Neural Architecture Search for Mobile', 'paperID': '693c97ecedb0a84539b7162c95e89fa3cd84ca73', 'arxivId': '1807.11626', 'publication_year': 2018, 'abstract': None}
{'title': 'Regularized Evolution for Image Classifier Architecture Search', 'paperID': '50bdda28de3dcf82a0e10f9ec13eea248b19edb5', 'arxivId': '1802.01548', 'publication_year': 2018, 'abstract': None}
{'title': 'Visualizing the Loss Landscape of Neural Nets', 'paperID': '6baca6351dc55baac44f0416e74a7e0ba2bfd03e', 'arxivId': '1712.09913', 'publication_year': 2017, 'abstract': None}
{'title': 'Progressive Neural Architecture Search', 'paperID': '5f79398057bf0bbda9ff50067bc1f2950c2a2266', 'arxivId': '1712.00559', 'publication_year': 2017, 'abstract': None}
{'title': 'Focal Loss for Dense Object Detection', 'paperID': '79cfb51a51fc093f66aac8e858afe2e14d4a1f20', 'arxivId': None, 'publication_year': 2017, 'abstract': None}
{'title': 'Image Super-Resolution via Deep Recursive Residual Network', 'paperID': 'a55970013b984f344dfbbbba677d89dce0ba5f81', 'arxivId': None, 'publication_year': 2017, 'abstract': None}
{'title': 'Boosting the Accuracy of Multispectral Image Pansharpening by Learning a Deep Residual Network', 'paperID': 'b236322720184c558bfa2a43416aed7701526ec0', 'arxivId': '1705.07556', 'publication_year': 2017, 'abstract': None}
{'title': 'DARTS-: Robustly Stepping out of Performance Collapse Without Indicators', 'paperID': '10daddaa1e1ed27e88b08b1c124d800de865c5e3', 'arxivId': '2009.01027', 'publication_year': '2020', 'abstract': 'Despite the fast development of differentiable architecture search (DARTS), it suffers from a standing instability issue regarding searching performance, which extremely limits its application. Existing robustifying methods draw clues from the outcome instead of finding out the causing factor. Various indicators such as Hessian eigenvalues are proposed as a signal of performance collapse, and the searching should be stopped once an indicator reaches a preset threshold. However, these methods tend to easily reject good architectures if thresholds are inappropriately set, let alone the searching is intrinsically noisy. In this paper, we undertake a more subtle and direct approach to resolve the collapse. We first demonstrate that skip connections with a learnable architectural coefficient can easily recover from a disadvantageous state and become dominant. We conjecture that skip connections profit too much from this privilege, hence causing the collapse for the derived model. Therefore, we propose to factor out this benefit with an auxiliary skip connection, ensuring a fairer competition for all operations. Extensive experiments on various datasets verify that our approach can substantially improve the robustness of DARTS.'}
{'title': 'Defending Adversarial Attacks without Adversarial Attacks in Deep Reinforcement Learning', 'paperID': '634ecab404ce2b78564ae992e6dbfa4929b810fd', 'arxivId': '2008.06199', 'publication_year': 2020, 'abstract': None}
{'title': 'Robustifying Reinforcement Learning Agents via Action Space Adversarial Training', 'paperID': '87f2e2031b479fbaf0c5ec853118a82df47a0241', 'arxivId': '2007.07176', 'publication_year': 2020, 'abstract': None}
{'title': 'Implementation Matters in Deep Policy Gradients: A Case Study on PPO and TRPO', 'paperID': 'd415b724fbc35afcc8dd91738123edfa6a5db634', 'arxivId': '2005.12729', 'publication_year': 2020, 'abstract': None}
{'title': 'Policy Teaching via Environment Poisoning: Training-time Adversarial Attacks against Reinforcement Learning', 'paperID': '1764924b9c892ad85c677b95677c344d7ce99143', 'arxivId': '2003.12909', 'publication_year': 2020, 'abstract': None}
{'title': 'Automatic Perturbation Analysis on General Computational Graphs', 'paperID': '3a7d95aed866d68e189db6f4eab29f46f68c5ffc', 'arxivId': '2002.12920', 'publication_year': 2020, 'abstract': None}
{'title': 'Online Robustness Training for Deep Reinforcement Learning', 'paperID': 'c54b90aae50cf06cea8ffe912d2424a4e8b82e1a', 'arxivId': '1911.00887', 'publication_year': 2019, 'abstract': None}
{'title': 'Policy Poisoning in Batch Reinforcement Learning and Control', 'paperID': '20a53578f84be351bd90385fcd674821e1ace17d', 'arxivId': '1910.05821', 'publication_year': 2019, 'abstract': None}
{'title': 'Characterizing Attacks on Deep Reinforcement Learning', 'paperID': '9e5e1944d4b227a55127264754f17b8437d2fa7f', 'arxivId': '1907.09470', 'publication_year': 2019, 'abstract': None}
{'title': 'Robust Multi-Agent Reinforcement Learning via Minimax Deep Deterministic Policy Gradient', 'paperID': 'b224d0f575237feb681717b7e74157dc0bd500df', 'arxivId': None, 'publication_year': 2019, 'abstract': None}
{'title': 'Assessing Transferability From Simulation to Reality for Reinforcement Learning', 'paperID': '1a20a92125904772261fdf646881121059932ce6', 'arxivId': '1907.04685', 'publication_year': 2019, 'abstract': None}
{'title': 'Deceptive Reinforcement Learning Under Adversarial Manipulations on Cost Signals', 'paperID': '14a74243ce18d36c4ee7460f94b7e1d2b45b8b34', 'arxivId': '1906.10571', 'publication_year': 2019, 'abstract': None}
{'title': 'Snooping Attacks on Deep Reinforcement Learning', 'paperID': '30cb55a404cd1b470aca6c533a786af606abe593', 'arxivId': '1905.11832', 'publication_year': 2019, 'abstract': None}
{'title': 'Action Robust Reinforcement Learning and Applications in Continuous Control', 'paperID': 'bcdb21ca1703fc6f62df420626e36d138480a6a1', 'arxivId': '1901.09184', 'publication_year': 2019, 'abstract': None}
{'title': 'Trust Region Policy Optimization for POMDPs', 'paperID': '9476b41d04c1a861523eebb6fda5499d03e0aabb', 'arxivId': '1810.07900', 'publication_year': 2018, 'abstract': None}
{'title': 'Distilled Agent DQN for Provable Adversarial Robustness', 'paperID': 'fbcd128be3d539f52640ffa58f05a6b61f0749aa', 'arxivId': None, 'publication_year': 2018, 'abstract': None}
{'title': 'Voyage', 'paperID': '12e21b59a13cc4111255d926830a4cf98be57e1e', 'arxivId': None, 'publication_year': 2018, 'abstract': None}
{'title': 'Robust Partially Observable Markov Decision Processes', 'paperID': 'e37d2cafe99b198640ba4c1ea42fc718892ee268', 'arxivId': None, 'publication_year': 2018, 'abstract': None}
{'title': 'Whatever Does Not Kill Deep Reinforcement Learning, Makes It Stronger', 'paperID': '4b47531e2cf3ad58b14da00bb665e359e3bc2600', 'arxivId': '1712.09344', 'publication_year': 2017, 'abstract': None}
{'title': 'Robust Deep Reinforcement Learning with Adversarial Attacks', 'paperID': '3b6c891fbccaa564ea4fd8914a5e3952fcf42ee3', 'arxivId': '1712.03632', 'publication_year': 2017, 'abstract': None}
{'title': 'Online Algorithms for POMDPs with Continuous State, Action, and Observation Spaces', 'paperID': 'dcd4bf5124c4813388dca713df2a6e8c568c0a9d', 'arxivId': None, 'publication_year': 2017, 'abstract': None}
{'title': 'Adversarially Robust Policy Learning: Active construction of physically-plausible perturbations', 'paperID': '2a5734ea4cb938c437e5a439f3d439877029735d', 'arxivId': None, 'publication_year': 2017, 'abstract': None}
{'title': 'Deep Reinforcement Learning framework for Autonomous Driving', 'paperID': '8db9df2eadea654f128c1887722c677c708e8a47', 'arxivId': '1704.02532', 'publication_year': 2017, 'abstract': None}
{'title': 'Delving into adversarial attacks on deep policies', 'paperID': 'cf8ed2793bc6aec88da5306fe2de560dc0be9b15', 'arxivId': '1705.06452', 'publication_year': 2017, 'abstract': None}
{'title': 'Vulnerability of Deep Reinforcement Learning to Policy Induction Attacks', 'paperID': '1d65848c563b2c3a7f0153551c1b39e0e5c2d776', 'arxivId': '1701.04143', 'publication_year': 2017, 'abstract': None}
{'title': 'Deep Recurrent Q-Learning for Partially Observable MDPs', 'paperID': 'f5f323e62acb75f785e00b4c90ace16f1690076f', 'arxivId': '1507.06527', 'publication_year': 2015, 'abstract': None}
{'title': 'Robust partially observable Markov decision process', 'paperID': 'e994a15a9476ca92c4bf9c12ad89625401939d57', 'arxivId': None, 'publication_year': 2015, 'abstract': None}
{'title': 'Deep Learning for Real-Time Atari Game Play Using Offline Monte-Carlo Tree Search Planning', 'paperID': 'b6cc21b30912bdaecd9f178d700a4c545b1d0838', 'arxivId': None, 'publication_year': 2014, 'abstract': None}
{'title': 'Integrated perception and planning in the continuous space: A POMDP approach', 'paperID': '27ebe193a60186f888525a23376344254363e39b', 'arxivId': None, 'publication_year': 2013, 'abstract': None}
{'title': 'Policy teaching through reward function learning', 'paperID': '3761b43d38e826bd9c841c40ba15256fd3627215', 'arxivId': None, 'publication_year': 2009, 'abstract': None}
{'title': 'Value-Based Policy Teaching with Active Indirect Elicitation', 'paperID': '6cfc68137a1233f9bcb16a319fcbd02b5f3cf4fd', 'arxivId': None, 'publication_year': 2008, 'abstract': None}
{'title': 'SARSOP: Efficient Point-Based POMDP Planning by Approximating Optimally Reachable Belief Spaces', 'paperID': '6c485f3d910d46c88f00cdaa9883cc7c43805fb5', 'arxivId': None, 'publication_year': 2008, 'abstract': None}
{'title': 'Solving Deep Memory POMDPs with Recurrent Policy Gradients', 'paperID': '92d009217b100882376ae5c90217da2e92471ad7', 'arxivId': None, 'publication_year': 2007, 'abstract': None}
{'title': 'Robustness in Markov Decision Problems with Uncertain Transition Matrices', 'paperID': '9ea46f06b614edb9c60771e0829ef1558048a21f', 'arxivId': None, 'publication_year': 2003, 'abstract': None}
{'title': 'Noise and the Reality Gap: The Use of Simulation in Evolutionary Robotics', 'paperID': 'd6f630cf3eac618bd075ec7ce37f60f60af237da', 'arxivId': None, 'publication_year': 1995, 'abstract': None}
{'title': 'Markov Games as a Framework for Multi-Agent Reinforcement Learning', 'paperID': '7fbf55baccbc5fdc7ded1ba18330605909aef5e5', 'arxivId': None, 'publication_year': 1994, 'abstract': None}
{'title': 'Optimal control of Markov processes with incomplete state information', 'paperID': 'f5d4374d4a375afbee3979c0bd3eec60606cadbd', 'arxivId': None, 'publication_year': 1965, 'abstract': None}
{'title': 'Robust Deep Reinforcement Learning against Adversarial Perturbations on Observations', 'paperID': 'd8febb0df3d6caa480ac45ba9fd3d1d64606fd89', 'arxivId': None, 'publication_year': 2020, 'abstract': None}
{'title': 'Artificial Life and Real Robots', 'paperID': '59d59e19d3715128f609f65023517a5c61d06fde', 'arxivId': None, 'publication_year': 1992, 'abstract': None}
{'title': 'On Implicit Regularization in β-VAEs', 'paperID': 'fbc68afa5ca151a0933961ec86dbf6f330903b86', 'arxivId': '2002.00041', 'publication_year': 2020, 'abstract': None}
{'title': 'Variational Autoencoders and Nonlinear ICA: A Unifying Framework', 'paperID': '2604797ff947ba554980344a81fa91d5323abdf7', 'arxivId': '1907.04809', 'publication_year': 2019, 'abstract': None}
{'title': 'BIVA: A Very Deep Hierarchy of Latent Variables for Generative Modeling', 'paperID': 'd4463fe262306eaac336fa5cae38e98811bffa80', 'arxivId': '1902.02102', 'publication_year': 2019, 'abstract': None}
{'title': 'Practical Lossless Compression with Latent Variables using Bits Back Coding', 'paperID': 'c2ed34facd63d72e5d03ba13a6a3956ed6b2ac6c', 'arxivId': '1901.04866', 'publication_year': 2019, 'abstract': None}
{'title': 'Variational Autoencoders Pursue PCA Directions (by Accident)', 'paperID': '9e4c467d5bf3cc752f21be0b67e47f75dfb5a4ec', 'arxivId': '1812.06775', 'publication_year': 2018, 'abstract': None}
{'title': 'Disentangling Disentanglement in Variational Autoencoders', 'paperID': 'd90c771bb565db9dc027970d50e1d47096174253', 'arxivId': None, 'publication_year': 2018, 'abstract': None}
{'title': 'Challenging Common Assumptions in the Unsupervised Learning of Disentangled Representations', 'paperID': '9c5c794094fbf5da8c48df5c3242615dc0b1d245', 'arxivId': '1811.12359', 'publication_year': 2018, 'abstract': None}
{'title': 'Adversarial Attacks on Variational Autoencoders', 'paperID': '4563cbfbdba1779fc598081071ae40be021cb81d', 'arxivId': '1806.04646', 'publication_year': 2018, 'abstract': None}
{'title': 'Resisting Adversarial Attacks using Gaussian Mixture Variational Autoencoders', 'paperID': 'c5285323f3b4dd5f099dbabd73d86b9e0c13f04f', 'arxivId': '1806.00081', 'publication_year': 2018, 'abstract': None}
{'title': 'Structured Disentangled Representations', 'paperID': 'a71f1480abe044ae90494a23f994dfb5b40e6f8c', 'arxivId': '1804.02086', 'publication_year': 2018, 'abstract': None}
{'title': 'World Models', 'paperID': 'ff332c21562c87cab5891d495b7d0956f2d9228b', 'arxivId': '1803.10122', 'publication_year': 2018, 'abstract': None}
{'title': 'Isolating Sources of Disentanglement in VAEs', 'paperID': 'f53936c03fb089cc159c551081124aae8a32ec1a', 'arxivId': '1802.04942', 'publication_year': 2018, 'abstract': None}
{'title': 'On Nesting Monte Carlo Estimators', 'paperID': 'eef70764d07cb4a24986a9609e968bc1aad84df5', 'arxivId': '1709.06181', 'publication_year': 2017, 'abstract': None}
{'title': 'DARLA: Improving Zero-Shot Transfer in Reinforcement Learning', 'paperID': 'a2141a5ec0c65ea0a9861ae562f4c9fb8020d197', 'arxivId': '1707.08475', 'publication_year': 2017, 'abstract': None}
{'title': 'Learning Hierarchical Features from Deep Generative Models', 'paperID': '6b2db002cbc5312e4796de4d4b14573df2c01648', 'arxivId': None, 'publication_year': 2017, 'abstract': None}
{'title': 'Learning Disentangled Representations with Semi-Supervised Deep Generative Models', 'paperID': '097889e0b93591d75de08f9da661ff882a1532f6', 'arxivId': '1706.00400', 'publication_year': 2017, 'abstract': None}
{'title': 'Grammar Variational Autoencoder', 'paperID': '222928303a72d1389b0add8032a31abccbba41b3', 'arxivId': '1703.01925', 'publication_year': 2017, 'abstract': None}
{'title': 'Lossy Image Compression with Compressive Autoencoders', 'paperID': '977560251c2bd4c28a6c7c707c29f4091c5e6247', 'arxivId': '1703.00395', 'publication_year': 2017, 'abstract': None}
{'title': 'Learning Hierarchical Features from Generative Models', 'paperID': '657fca895e9217a0306739f8f58332c224b8a82e', 'arxivId': '1702.08396', 'publication_year': 2017, 'abstract': None}
{'title': 'Variational Autoencoder for Semi-Supervised Text Classification', 'paperID': '90f8962553280470ed0d12ebb543e89c84eb137a', 'arxivId': None, 'publication_year': 2017, 'abstract': None}
{'title': 'Adversarial Images for Variational Autoencoders', 'paperID': '4db188284236d36a77cc0e1f69e5973eddac864a', 'arxivId': '1612.00155', 'publication_year': 2016, 'abstract': None}
{'title': 'Ladder Variational Autoencoders', 'paperID': '64d698ecd01eab99e81e586400e86d3d70b9cba7', 'arxivId': '1602.02282', 'publication_year': 2016, 'abstract': None}
{'title': 'Importance Weighted Autoencoders', 'paperID': '3e47c4c2dd98c49b7771c7228812d5fd9eee56a3', 'arxivId': '1509.00519', 'publication_year': 2015, 'abstract': None}
{'title': 'Deep Convolutional Inverse Graphics Network', 'paperID': '687e80eb70c7bbad6001006d9269b202650a3354', 'arxivId': '1503.03167', 'publication_year': 2015, 'abstract': None}
{'title': 'Seeing 3D Chairs: Exemplar Part-Based 2D-3D Alignment Using a Large Dataset of CAD Models', 'paperID': '6def29d024457f8897c3a634fef8a03dcaedc9a0', 'arxivId': None, 'publication_year': 2014, 'abstract': None}
{'title': 'Representation Learning: A Review and New Perspectives', 'paperID': '184ac0766262312ba76bbdece4e7ffad0aa8180b', 'arxivId': '1206.5538', 'publication_year': 2012, 'abstract': None}
{'title': 'A 3D Face Model for Pose and Illumination Invariant Face Recognition', 'paperID': '639937b3a1b8bded3f7e9a40e85bd3770016cf3c', 'arxivId': None, 'publication_year': 2009, 'abstract': None}
{'title': 'An Information-Maximization Approach to Blind Separation and Blind Deconvolution', 'paperID': '1d7d0e8c4791700defd4b0df82a26b50055346e0', 'arxivId': None, 'publication_year': 1995, 'abstract': None}
{'title': 'A Limited Memory Algorithm for Bound Constrained Optimization', 'paperID': '7e459946cb320935ee97eb9ffa23136524866257', 'arxivId': None, 'publication_year': 1995, 'abstract': None}
{'title': 'Information Theoretical Analysis of Multivariate Correlation', 'paperID': 'bc4fca38a3b29e5d3d3d08c4836a7e637e2ce7e8', 'arxivId': None, 'publication_year': 1960, 'abstract': None}
{'title': "Improving VAEs' Robustness to Adversarial Attack", 'paperID': '7ab3551d85efbc3c844dcf5714f2a5d3e8bafcf0', 'arxivId': None, 'publication_year': '2019', 'abstract': 'Variational autoencoders (VAEs) have recently been shown to be vulnerable to adversarial attacks, wherein they are fooled into reconstructing a chosen target image. However, how to defend against such attacks remains an open problem. We make significant advances in addressing this issue by introducing methods for producing adversarially robust VAEs. Namely, we first demonstrate that methods used to obtain disentangled latent representations produce VAEs that are more robust to these attacks. However, this robustness comes at the cost of reducing the quality of the reconstructions. We, therefore, introduce a new hierarchical VAE, the $\\textit{Seatbelt-VAE}$, which can produce high-fidelity autoencoders that are also adversarially robust. We confirm the capabilities of the Seatbelt-VAE on several different datasets and with current state-of-the-art VAE adversarial attacks.'}
{'title': 'Neural Network Virtual Sensors for Fuel Injection Quantities with Provable Performance Specifications', 'paperID': '2dd907736e272888e16b7646435e6444f0d0ff73', 'arxivId': '2007.00147', 'publication_year': 2020, 'abstract': None}
{'title': 'Model-Based Robust Deep Learning', 'paperID': 'd036d7e51b975c6023a5eee9aa48008b8fb62d20', 'arxivId': '2005.10247', 'publication_year': 2020, 'abstract': None}
{'title': 'Black-box Smoothing: A Provable Defense for Pretrained Classifiers', 'paperID': 'b1ef79a7bbe51a7f1f28e403c8bde35a3b54d985', 'arxivId': '2003.01908', 'publication_year': 2020, 'abstract': None}
{'title': 'Randomized Smoothing of All Shapes and Sizes', 'paperID': '75170439ccfe2271367e4ed7298f360b0443fde2', 'arxivId': '2002.08118', 'publication_year': 2020, 'abstract': None}
{'title': 'A Simple Way to Make Neural Networks Robust Against Diverse Image Corruptions', 'paperID': '78dabf7a32f9b76da8212a101482096197b437cd', 'arxivId': None, 'publication_year': 2020, 'abstract': None}
{'title': 'Achieving Robustness in the Wild via Adversarial Mixing With Disentangled Representations', 'paperID': 'e39ed8f737b439b827d39f9be3f463859194394b', 'arxivId': '1912.03192', 'publication_year': 2019, 'abstract': None}
{'title': 'Adversarial Music: Real World Audio Adversary Against Wake-word Detection System', 'paperID': 'be8d616b2fea58aa818ba4f52d894e14937af945', 'arxivId': '1911.00126', 'publication_year': 2019, 'abstract': None}
{'title': 'A Dataset of Multi-Illumination Images in the Wild', 'paperID': 'f4a3d6d26347df2c5c89ce0848ef72f1d4f80e3e', 'arxivId': '1910.08131', 'publication_year': 2019, 'abstract': None}
{'title': 'Adversarial Objects Against LiDAR-Based Autonomous Driving Systems', 'paperID': '71e3347dde362ba369b8103c8850dd07e6c23424', 'arxivId': '1907.05418', 'publication_year': 2019, 'abstract': None}
{'title': 'AutoAugment: Learning Augmentation Strategies From Data', 'paperID': '21de3a36cb51adc205fad8a1d3d69118891dc3dd', 'arxivId': None, 'publication_year': 2019, 'abstract': None}
{'title': 'Fast AutoAugment', 'paperID': 'e808cac4b64a8c73ada719f76ad885454c71a74c', 'arxivId': '1905.00397', 'publication_year': 2019, 'abstract': None}
{'title': 'Adversarial camera stickers: A Physical Camera Attack on Deep Learning Classifier', 'paperID': '17a5cc88f3c18bd68e78755abb6285d1b59a8109', 'arxivId': None, 'publication_year': 2019, 'abstract': None}
{'title': 'Adversarial camera stickers: A physical camera-based attack on deep learning systems', 'paperID': 'ded6d20b751a7b0a8b94175c12b64a40904d80d0', 'arxivId': '1904.00759', 'publication_year': 2019, 'abstract': None}
{'title': 'A General Framework for Adversarial Examples with Objectives', 'paperID': '7b874e6fc3e3db83b350824f372761a415f5725f', 'arxivId': '1801.00349', 'publication_year': 2017, 'abstract': None}
{'title': 'Learning Structured Output Representation using Deep Conditional Generative Models', 'paperID': '3f25e17eb717e5894e0404ea634451332f85d287', 'arxivId': None, 'publication_year': 2015, 'abstract': None}
{'title': 'Spatial Transformer Networks', 'paperID': 'dbb6ded623159c867fbeca0772db7b2eb9489523', 'arxivId': '1506.02025', 'publication_year': 2015, 'abstract': None}
{'title': 'Cyclical Learning Rates for Training Neural Networks', 'paperID': '37b5dfe87d82ba8f310155165d5bf841dc92dea2', 'arxivId': '1506.01186', 'publication_year': 2015, 'abstract': None}
{'title': 'Provable robustness against all adversarial lp-perturbations for p≥1', 'paperID': 'b9ad22650772ff791e687cf67b73b00b9a22203d', 'arxivId': None, 'publication_year': 2019, 'abstract': None}
{'title': 'CONFIDENCE-CALIBRATED ADVERSARIAL TRAINING and Detection: MORE ROBUST MODELS GENERALIZ-', 'paperID': 'fac8d2bd19f3a82f92a344d758007cff499b7725', 'arxivId': None, 'publication_year': 2019, 'abstract': None}
{'title': 'Learning perturbation sets for robust machine learning', 'paperID': '857b1c3f171afb3cdf9df23d23e5d0cdfaa83efb', 'arxivId': '2007.08450', 'publication_year': '2020', 'abstract': 'Although much progress has been made towards robust deep learning, a significant gap in robustness remains between real-world perturbations and more narrowly defined sets typically studied in adversarial defenses. In this paper, we aim to bridge this gap by learning perturbation sets from data, in order to characterize real-world effects for robust training and evaluation. Specifically, we use a conditional generator that defines the perturbation set over a constrained region of the latent space. We formulate desirable properties that measure the quality of a learned perturbation set, and theoretically prove that a conditional variational autoencoder naturally satisfies these criteria. Using this framework, our approach can generate a variety of perturbations at different complexities and scales, ranging from baseline spatial transformations, through common image corruptions, to lighting variations. We measure the quality of our learned perturbation sets both quantitatively and qualitatively, finding that our models are capable of producing a diverse set of meaningful perturbations beyond the limited data seen during training. Finally, we leverage our learned perturbation sets to train models which are empirically and certifiably robust to adversarial image corruptions and adversarial lighting variations, while improving generalization on non-adversarial data. All code and configuration files for reproducing the experiments as well as pretrained model weights can be found at this https URL.'}
{'title': 'LTF: A Label Transformation Framework for Correcting Label Shift', 'paperID': '994a4f9a75ca10da4f9a0f4a3a03fd622aeeea41', 'arxivId': None, 'publication_year': 2020, 'abstract': None}
{'title': 'An Online Method for Distributionally Deep Robust Optimization', 'paperID': '8747344b26da07f5ab398b16ed85375271c7019f', 'arxivId': None, 'publication_year': 2020, 'abstract': None}
{'title': 'A Unified View of Label Shift Estimation', 'paperID': '31c53acd2a43dcec4342d9c42d0ffbfbef36e855', 'arxivId': '2003.07554', 'publication_year': 2020, 'abstract': None}
{'title': 'Domain Adaptation with Conditional Distribution Matching and Generalized Label Shift', 'paperID': 'b37a3f6e3c6e0bdfde6c5531bdf90d16df3f8d5c', 'arxivId': '2003.04475', 'publication_year': 2020, 'abstract': None}
{'title': 'Near-Optimal Algorithms for Minimax Optimization', 'paperID': '7c63f4cf082c162625c2db4234c215f07ea58dfd', 'arxivId': '2002.02417', 'publication_year': 2020, 'abstract': None}
{'title': 'Adaptive Sampling for Stochastic Risk-Averse Learning', 'paperID': '0db252455fe10261c3c439e850dabccb72097c20', 'arxivId': '1910.12511', 'publication_year': 2019, 'abstract': None}
{'title': 'Efficient Algorithms for Smooth Minimax Optimization', 'paperID': '5a6a33dddee357ffda1d9a3a948f4019b6a68dfd', 'arxivId': '1907.01543', 'publication_year': 2019, 'abstract': None}
{'title': 'On Gradient Descent Ascent for Nonconvex-Concave Minimax Problems', 'paperID': 'afd9786a6fb9c79fc6d41bacbe73607e73044950', 'arxivId': '1906.00331', 'publication_year': 2019, 'abstract': None}
{'title': 'Regularized Learning for Domain Adaptation under Label Shifts', 'paperID': '6d64363e52cd7ecad99d7ce6ae849f245dfbbf92', 'arxivId': '1903.09734', 'publication_year': 2019, 'abstract': None}
{'title': 'Fairness risk measures', 'paperID': 'd72d4e3da3788c7882d367737902ab0fd962bb89', 'arxivId': '1901.08665', 'publication_year': 2019, 'abstract': None}
{'title': 'An introduction to domain adaptation and transfer learning', 'paperID': 'c98bcc8689c34d72fd0b696f2a49e7f86d151782', 'arxivId': '1812.11806', 'publication_year': 2018, 'abstract': None}
{'title': 'Weakly-convex–concave min–max optimization: provable algorithms and applications in machine learning', 'paperID': '1d3de4dad3c3762e9ecd9fc60281a5896b8b9616', 'arxivId': '1810.02060', 'publication_year': 2018, 'abstract': None}
{'title': 'Stochastic model-based minimization of weakly convex functions', 'paperID': '4e280ac44bba6310648638eb76312a81182c70f2', 'arxivId': '1803.06523', 'publication_year': 2018, 'abstract': None}
{'title': 'Empirical Risk Minimization under Fairness Constraints', 'paperID': '0bdb738ea0f49b045a3232c61d3cc5734bcf1e93', 'arxivId': '1802.08626', 'publication_year': 2018, 'abstract': None}
{'title': 'Learning with Average Top-k Loss', 'paperID': '2cf5ac39c8299a3304c6e9808593153c894ff1b5', 'arxivId': '1705.08826', 'publication_year': 2017, 'abstract': None}
{'title': 'Fairness Beyond Disparate Treatment & Disparate Impact: Learning Classification without Disparate Mistreatment', 'paperID': '5fb808edfaae574ee7f4553ad7090ca1fed9b585', 'arxivId': '1610.08452', 'publication_year': 2016, 'abstract': None}
{'title': 'Lectures on Stochastic Programming: Modeling and Theory, Second Edition', 'paperID': '940b95df43f76005297e7be2590b531ff35b8f26', 'arxivId': None, 'publication_year': 2014, 'abstract': None}
{'title': 'Domain Adaptation under Target and Conditional Shift', 'paperID': '66c3d69f94c90a884d3f6b5367813d51708f6ded', 'arxivId': None, 'publication_year': 2013, 'abstract': None}
{'title': 'Semi-Supervised Learning of Class Balance under Class-Prior Change by Distribution Matching', 'paperID': '89024c395ce0d7e72f5b6d0e09fb4a6dc5adf209', 'arxivId': '1206.4677', 'publication_year': 2012, 'abstract': None}
{'title': 'Fixed-Point Algorithms for Inverse Problems in Science and Engineering', 'paperID': 'fd802f44c645a81d1c960fb7e1d126edeb832abd', 'arxivId': None, 'publication_year': 2011, 'abstract': None}
{'title': 'Proximal Splitting Methods in Signal Processing', 'paperID': '8e9f5c99f8c006e78eb9e515ec9c618cc34f2794', 'arxivId': '0912.3522', 'publication_year': 2009, 'abstract': None}
{'title': 'Tuning Support Vector Machines for Minimax and Neyman-Pearson Classification', 'paperID': '57c0b0fa5744a4f82514d76f111e3599f939eef4', 'arxivId': None, 'publication_year': 2008, 'abstract': None}
{'title': 'Minimax Regret Classifier for Imprecise Class Distributions', 'paperID': 'c88b6caeca4c62525c032f2c138a860a5a17833a', 'arxivId': None, 'publication_year': 2007, 'abstract': None}
{'title': 'Mixture Regression for Covariate Shift', 'paperID': '4e0c56f084a53f5c8fd7e2fb615a355f0431ee77', 'arxivId': None, 'publication_year': 2006, 'abstract': None}
{'title': 'The Logit Model and Response-Based Samples', 'paperID': 'c991ae03942ac48f1da16aa1f034aa9fb91a2aef', 'arxivId': None, 'publication_year': 1989, 'abstract': None}
{'title': 'Learning From Imbalanced Data', 'paperID': '6a7364f6ed2846ea2b705336a4c49dd287102a50', 'arxivId': None, 'publication_year': 2019, 'abstract': None}
{'title': 'Adjusting the Outputs of a Classifier to New a Priori Probabilities: A Simple Procedure', 'paperID': '99f65a048860d3f2bc500a2886c461d92188d2ca', 'arxivId': None, 'publication_year': 2002, 'abstract': None}
{'title': 'Coping with Label Shift via Distributionally Robust Optimisation', 'paperID': '8246f0d3799290be5ed47254f6b88b601fa98230', 'arxivId': '2010.12230', 'publication_year': '2020', 'abstract': 'The label shift problem refers to the supervised learning setting where the train and test label distributions do not match. Existing work addressing label shift usually assumes access to an \\emph{unlabelled} test sample. This sample may be used to estimate the test label distribution, and to then train a suitably re-weighted classifier. While approaches using this idea have proven effective, their scope is limited as it is not always feasible to access the target domain; further, they require repeated retraining if the model is to be deployed in \\emph{multiple} test environments. Can one instead learn a \\emph{single} classifier that is robust to arbitrary label shifts from a broad family? In this paper, we answer this question by proposing a model that minimises an objective based on distributionally robust optimisation (DRO). We then design and analyse a gradient descent-proximal mirror ascent algorithm tailored for large-scale problems to optimise the proposed objective. %, and establish its convergence. Finally, through experiments on CIFAR-100 and ImageNet, we show that our technique can significantly improve performance over a number of baselines in settings where label shift is present.'}
{'title': 'Learning Robust State Abstractions for Hidden-Parameter Block MDPs', 'paperID': '9835d0d85faa36d2c27bea806487b988935e92a2', 'arxivId': None, 'publication_year': None, 'abstract': None}
{'title': 'Network Randomization: A Simple Technique for Generalization in Deep Reinforcement Learning', 'paperID': 'd5c5bdbb1d0e137ba5316455627c7844ff685646', 'arxivId': '1910.05396', 'publication_year': 2019, 'abstract': None}
{'title': 'Domain Randomization and Pyramid Consistency: Simulation-to-Real Generalization Without Accessing Target Domain Data', 'paperID': '1aab4548a7d55cf8a3562f8710b50ed20ad32546', 'arxivId': '1909.00889', 'publication_year': 2019, 'abstract': None}
{'title': 'Situational Fusion of Visual Representation for Visual Navigation', 'paperID': '6cd205132c786e3bc03964fb63380cd3cf51b9c7', 'arxivId': '1908.09073', 'publication_year': 2019, 'abstract': None}
{'title': 'Weight Agnostic Neural Networks', 'paperID': '23d7d2aae6308a840a597e823ae8214278304c5a', 'arxivId': '1906.04358', 'publication_year': 2019, 'abstract': None}
{'title': 'MNIST-C: A Robustness Benchmark for Computer Vision', 'paperID': '6e4e75c88a0801c87f47a171aa69a9914f9129bf', 'arxivId': '1906.02337', 'publication_year': 2019, 'abstract': None}
{'title': 'Multi-Adversarial Discriminative Deep Domain Generalization for Face Presentation Attack Detection', 'paperID': 'edb293b7e75a9fae5dae80dc76af90e46da27a65', 'arxivId': None, 'publication_year': 2019, 'abstract': None}
{'title': 'Domain Generalization by Solving Jigsaw Puzzles', 'paperID': '7ce7941ffe5220383d4e614ebcf2397e30cb27a7', 'arxivId': '1903.06864', 'publication_year': 2019, 'abstract': None}
{'title': 'No Training Required: Exploring Random Encoders for Sentence Classification', 'paperID': '7a8f8109e65ed9a6048859681a825eb5655e5dd2', 'arxivId': '1901.10444', 'publication_year': 2019, 'abstract': None}
{'title': 'MetaReg: Towards Domain Generalization using Meta-Regularization', 'paperID': '3dd8bf5cca76b1690a2642b73b509fb3a27e4f36', 'arxivId': None, 'publication_year': 2018, 'abstract': None}
{'title': 'Learning Robust Representations by Projecting Superficial Statistics Out', 'paperID': '96b32b204a62777bef66eea595de2c47b4e9d6e9', 'arxivId': '1903.06256', 'publication_year': 2018, 'abstract': None}
{'title': 'Taking a Closer Look at Domain Shift: Category-Level Adversaries for Semantics Consistent Domain Adaptation', 'paperID': '89ff54a10869113aa1d5c6754ac4928e64b54292', 'arxivId': '1809.09478', 'publication_year': 2018, 'abstract': None}
{'title': 'Randomized Prior Functions for Deep Reinforcement Learning', 'paperID': 'f802802b3af5a22b79ac65d033ba3cbee33da91b', 'arxivId': '1806.03335', 'publication_year': 2018, 'abstract': None}
{'title': 'Generalizing to Unseen Domains via Adversarial Data Augmentation', 'paperID': 'cc01e553052a502c9f7697e90296eb9bbf7f32df', 'arxivId': '1805.12018', 'publication_year': 2018, 'abstract': None}
{'title': 'Training robust models using Random Projection', 'paperID': '1ea3cb713365e8cde0678875b8bdd787f83b7c42', 'arxivId': None, 'publication_year': 2016, 'abstract': None}
{'title': 'A Powerful Generative Model Using Random Weights for the Deep Image Representation', 'paperID': 'bb3c4327f0cbac19d9f87b4c989aee8833cdcd40', 'arxivId': '1606.04801', 'publication_year': 2016, 'abstract': None}
{'title': 'Delving Deep into Rectifiers: Surpassing Human-Level Performance on ImageNet Classification', 'paperID': 'd6f2f611da110b5b5061731be3fc4c7f45d8ee23', 'arxivId': '1502.01852', 'publication_year': 2015, 'abstract': None}
{'title': 'Big data analytics in healthcare: promise and potential', 'paperID': 'dac7344737cb824634f757aede2dd46a6eed204b', 'arxivId': None, 'publication_year': 2014, 'abstract': None}
{'title': 'On Random Weights and Unsupervised Feature Learning', 'paperID': '265069b3670930fd884b02062d7e7b79ff2a49d5', 'arxivId': None, 'publication_year': 2011, 'abstract': None}
{'title': 'Best practices for convolutional neural networks applied to visual document analysis', 'paperID': '5562a56da3a96dae82add7de705e2bd841eb00fc', 'arxivId': None, 'publication_year': 2003, 'abstract': None}
{'title': 'From Virtual to Reality: Fast Adaptation of Virtual Object Detectors to Real Domains', 'paperID': '236db916e2c73eccfe8821110274affcc9b54360', 'arxivId': None, 'publication_year': 2014, 'abstract': None}
{'title': 'Neural Network Recognizer for Hand-Written Zip Code Digits', 'paperID': '30a7fcdaa836837d87a8e4702ed015cd66e6ad03', 'arxivId': None, 'publication_year': 1988, 'abstract': None}
{'title': 'Extensions of Lipschitz mappings into Hilbert space', 'paperID': '1d0635cda34b8af995313848a0c42bac6efe79ec', 'arxivId': None, 'publication_year': 1984, 'abstract': None}
{'title': 'Fine-Tuning Pre-trained Language Model with Weak Supervision: A Contrastive-Regularized Self-Training Approach', 'paperID': '19803adec3b97fb2e3c8097f17bf33fabf311795', 'arxivId': '2010.07835', 'publication_year': 2020, 'abstract': None}
{'title': 'T3: Tree-Autoencoder Constrained Adversarial Text Generation for Targeted Attack', 'paperID': '9b9a6d6a698cce777929ecc65c9fc5d09b2232ac', 'arxivId': None, 'publication_year': 2020, 'abstract': None}
{'title': 'CLUB: A Contrastive Log-ratio Upper Bound of Mutual Information', 'paperID': '41382835ae60fb3280ea9a5b3004a236af1eb01b', 'arxivId': '2006.12013', 'publication_year': 2020, 'abstract': None}
{'title': 'Large-Scale Adversarial Training for Vision-and-Language Representation Learning', 'paperID': '2f5f81bc516a6d085d39479378af1fc27104f91e', 'arxivId': '2006.06195', 'publication_year': 2020, 'abstract': None}
{'title': 'SAFER: A Structure-free Approach for Certified Robustness to Adversarial Word Substitutions', 'paperID': '0a9c0e729dd95f5559e05f8bb4b7408f9409388e', 'arxivId': '2005.14424', 'publication_year': 2020, 'abstract': None}
{'title': 'What makes for good views for contrastive learning', 'paperID': '7f768fa192a76ab097ccfda0a68523bc36425423', 'arxivId': '2005.10243', 'publication_year': 2020, 'abstract': None}
{'title': 'Adversarial Training for Large Neural Language Models', 'paperID': '2ffcf8352223c95ae8cef4daaec995525ecc926b', 'arxivId': '2004.08994', 'publication_year': 2020, 'abstract': None}
{'title': 'Learning Adversarially Robust Representations via Worst-Case Mutual Information Maximization', 'paperID': '1fcbd3ff32ed9b909300802d77f890f84ff9b3d8', 'arxivId': '2002.11798', 'publication_year': 2020, 'abstract': None}
{'title': 'Adversarial NLI: A New Benchmark for Natural Language Understanding', 'paperID': '207da6d2c07289bf72a2b5974bb3f011ebb5dd0d', 'arxivId': '1910.14599', 'publication_year': 2019, 'abstract': None}
{'title': 'A Mutual Information Maximization Perspective of Language Representation Learning', 'paperID': 'b85d339e49399966d629973c889e8edfca56517c', 'arxivId': '1910.08350', 'publication_year': 2019, 'abstract': None}
{'title': 'Is BERT Really Robust? A Strong Baseline for Natural Language Attack on Text Classification and Entailment', 'paperID': 'ae04f3d011511ad8ed7ffdf9fcfb7f11e6899ca2', 'arxivId': '1907.11932', 'publication_year': 2019, 'abstract': None}
{'title': 'PAWS: Paraphrase Adversaries from Word Scrambling', 'paperID': 'fc09d6486be1c9bbfbef4165ce3c1ab664e5d084', 'arxivId': '1904.01130', 'publication_year': 2019, 'abstract': None}
{'title': 'A Theoretical Analysis of Contrastive Unsupervised Representation Learning', 'paperID': '403227333329b36183004f04db72362b604adef3', 'arxivId': '1902.09229', 'publication_year': 2019, 'abstract': None}
{'title': 'TextBugger: Generating Adversarial Text Against Real-world Applications', 'paperID': 'f91175950edf3804ff1573f570b03db9b108dece', 'arxivId': '1812.05271', 'publication_year': 2018, 'abstract': None}
{'title': 'SQuAD: 100,000+ Questions for Machine Comprehension of Text', 'paperID': '05dd7254b632376973f3a1b4d39485da17814df5', 'arxivId': '1606.05250', 'publication_year': 2016, 'abstract': None}
{'title': 'InfoBERT: Improving Robustness of Language Models from An Information Theoretic Perspective', 'paperID': '2dc7741c3cd3c7fc0d0ae7b60cf7358f612e175b', 'arxivId': '2010.02329', 'publication_year': '2020', 'abstract': 'Large-scale language models such as BERT have achieved state-of-the-art performance across a wide range of NLP tasks. Recent studies, however, show that such BERT-based models are vulnerable facing the threats of textual adversarial attacks. We aim to address this problem from an information-theoretic perspective, and propose InfoBERT, a novel learning framework for robust fine-tuning of pre-trained language models. InfoBERT contains two mutual-information-based regularizers for model training: (i) an Information Bottleneck regularizer, which suppresses noisy mutual information between the input and the feature representation; and (ii) a Robust Feature regularizer, which increases the mutual information between local robust features and global features. We provide a principled way to theoretically analyze and improve the robustness of representation learning for language models in both standard and adversarial training. Extensive experiments demonstrate that InfoBERT achieves state-of-the-art robust accuracy over several adversarial datasets on Natural Language Inference (NLI) and Question Answering (QA) tasks.'}
{'title': 'Mean-Covariance Robust Risk Measurement', 'paperID': '3eb495010ec95fbd6e1e15b19400b113d5955bb8', 'arxivId': '2112.09959', 'publication_year': 2021, 'abstract': None}
{'title': 'Statistical Analysis of Wasserstein Distributionally Robust Estimators', 'paperID': '6a7f6b17e3bc15ddecd10581950a8ff8430ca401', 'arxivId': '2108.02120', 'publication_year': 2021, 'abstract': None}
{'title': 'Testing Group Fairness via Optimal Transport Projections', 'paperID': 'a5590fb4f90ebd1d83b6f2d0df501cf66c0c6259', 'arxivId': '2106.01070', 'publication_year': 2021, 'abstract': None}
{'title': 'Sequential Domain Adaptation by Synthesizing Distributionally Robust Experts', 'paperID': '09b3b1e8d0d920644c2466adf3b3fd5d0333fa7e', 'arxivId': '2106.00322', 'publication_year': 2021, 'abstract': None}
{'title': 'A Distributionally Robust Approach to Fair Classification', 'paperID': '18c72c585e3ba48f99f46e9485d75c822aebb189', 'arxivId': '2007.09530', 'publication_year': 2020, 'abstract': None}
{'title': 'On linear optimization over Wasserstein balls', 'paperID': '62a3b6364ad24b8d88b260e57052a55847dffbb8', 'arxivId': '2004.07162', 'publication_year': 2020, 'abstract': None}
{'title': 'Fair Principal Component Analysis and Filter Design', 'paperID': '6be7c23245e41f11ff59115ea021ea0656f51591', 'arxivId': '2002.06557', 'publication_year': 2020, 'abstract': None}
{'title': 'Weakly Convex Optimization over Stiefel Manifold Using Riemannian Subgradient-Type Methods', 'paperID': 'b97fe7bbe8a5be93123be406f5d0701c08e6441b', 'arxivId': None, 'publication_year': 2019, 'abstract': None}
{'title': 'Bridging Bayesian and Minimax Mean Square Error Estimation via Wasserstein Distributionally Robust Optimization', 'paperID': '179bd624cda94ae8ac99dc9081d2c31e8a095767', 'arxivId': '1911.03539', 'publication_year': 2019, 'abstract': None}
{'title': 'Calculating Optimistic Likelihoods Using (Geodesically) Convex Optimization', 'paperID': 'f57d41efd502d3d9e8ee8384e7b815ac8c54104f', 'arxivId': '1910.07817', 'publication_year': 2019, 'abstract': None}
{'title': 'A Survey on Bias and Fairness in Machine Learning', 'paperID': '0090023afc66cd2741568599057f4e82b566137c', 'arxivId': '1908.09635', 'publication_year': 2019, 'abstract': None}
{'title': 'Wasserstein Distributionally Robust Optimization: Theory and Applications in Machine Learning', 'paperID': '4a0d35989d91b3b7d2318802b1de6d10e4e6e830', 'arxivId': '1908.08729', 'publication_year': 2019, 'abstract': None}
{'title': 'Optimized Score Transformation for Fair Classification', 'paperID': '0a08cdd184ee52b579aa82a70aee0168fa67ea88', 'arxivId': None, 'publication_year': 2019, 'abstract': None}
{'title': 'Fair Regression: Quantitative Definitions and Reduction-based Algorithms', 'paperID': '1f868b5839b3126209612f6e2f8c40aa431b46fd', 'arxivId': '1905.12843', 'publication_year': 2019, 'abstract': None}
{'title': 'Multi-Criteria Dimensionality Reduction with Applications to Fairness', 'paperID': '916025e6d95cb5c6d09765ad4c2894d16a5b914d', 'arxivId': None, 'publication_year': 2019, 'abstract': None}
{'title': 'The Price of Fair PCA: One Extra Dimension', 'paperID': '422513942a2a564e3fe3b6c3b7df20d6190f0d20', 'arxivId': '1811.00103', 'publication_year': 2018, 'abstract': None}
{'title': 'Adversarial Attacks and Defences: A Survey', 'paperID': '869fdb53a40290a3941fd6ab808835e9b5184d62', 'arxivId': '1810.00069', 'publication_year': 2018, 'abstract': None}
{'title': 'Fairness Definitions Explained', 'paperID': 'a78f9467070992fc8742641ec97f9972597d869a', 'arxivId': None, 'publication_year': 2018, 'abstract': None}
{'title': 'Convex Formulations for Fair Principal Component Analysis', 'paperID': '755475cf0a1101adcca81d2d0424916210565e48', 'arxivId': '1802.03765', 'publication_year': 2018, 'abstract': None}
{'title': "Does mitigating ML's impact disparity require treatment disparity?", 'paperID': '932404745d960291925b3f27b71734dff5b23633', 'arxivId': None, 'publication_year': 2017, 'abstract': None}
{'title': 'Data Decisions and Theoretical Implications when Adversarially Learning Fair Representations', 'paperID': '4eef0519f75911a2e132fac12427fa13bdb32a71', 'arxivId': '1707.00075', 'publication_year': 2017, 'abstract': None}
{'title': 'Fairness in Criminal Justice Risk Assessments: The State of the Art', 'paperID': '9eacd7d43c95be4c4771bf1a324e200918e6c0cd', 'arxivId': '1703.09207', 'publication_year': 2017, 'abstract': None}
{'title': 'Counterfactual Fairness', 'paperID': '043f084e379a44608c470059c2aa174a323e9774', 'arxivId': '1703.06856', 'publication_year': 2017, 'abstract': None}
{'title': 'Certifying and Removing Disparate Impact', 'paperID': '0fee3b6c72f7676b4934651e517d0a328048c600', 'arxivId': '1412.3756', 'publication_year': 2014, 'abstract': None}
{'title': 'Learning Fair Representations', 'paperID': '37c3303d173c055592ef923235837e1cbc6bd986', 'arxivId': None, 'publication_year': 2013, 'abstract': None}
{'title': 'Data preprocessing techniques for classification without discrimination', 'paperID': '3ac3c11bf6cd8ccc657eb629148d6e346e52c8e0', 'arxivId': None, 'publication_year': 2012, 'abstract': None}
{'title': 'Fairness-Aware Classifier with Prejudice Remover Regularizer', 'paperID': '33cb597dde84766b1cdd6f35c964d83c9a718b39', 'arxivId': None, 'publication_year': 2012, 'abstract': None}
{'title': "The Optimizer's Curse: Skepticism and Postdecision Surprise in Decision Analysis", 'paperID': '28cfed594544215673db802dce79b8c12d3ab5ab', 'arxivId': None, 'publication_year': 2006, 'abstract': None}
{'title': 'LIII. On lines and planes of closest fit to systems of points in space', 'paperID': 'cac33f91e59f0a137b46176d74cee55c7010c3f8', 'arxivId': None, 'publication_year': 1901, 'abstract': None}
{'title': 'Wasserstein Robust Support Vector Machines with Fairness Constraints', 'paperID': '23a6bf80d090a3924bae8f0c80a22967a5987589', 'arxivId': None, 'publication_year': 2021, 'abstract': None}
{'title': 'Optimized Pre-Processing for Discrimination Prevention', 'paperID': '1f9af2cb595bb283bbd5076e96128a612809e233', 'arxivId': None, 'publication_year': 2017, 'abstract': None}
{'title': 'Monte Carlo sampling-based methods for stochastic optimization', 'paperID': '02d7fe63bbd2444ea001ff6f10671b2cf8c5cdd4', 'arxivId': None, 'publication_year': 2014, 'abstract': None}
{'title': 'Optimization algorithms on matrix manifolds', 'paperID': 'f7b4c27abb76dff4c017849049541f3fc91e77be', 'arxivId': None, 'publication_year': 2009, 'abstract': None}
{'title': 'A class of Wasserstein metrics for probability distributions.', 'paperID': '0e0c4a16e11b843f2b5d841ddfb60e97a376d5af', 'arxivId': None, 'publication_year': 1984, 'abstract': None}
{'title': 'Analysis of a complex of statistical variables into principal components.', 'paperID': '9ebb5c0d6d54707a4d6181a693b6f755ec8a45a9', 'arxivId': None, 'publication_year': 1933, 'abstract': None}
{'title': 'Distributionally Robust Fair Principal Components via Geodesic Descents', 'paperID': 'bbf64d3561c3dd89c254483bf10facdfc322907f', 'arxivId': '2202.03071', 'publication_year': '2022', 'abstract': 'Principal component analysis is a simple yet useful dimensionality reduction technique in modern machine learning pipelines. In consequential domains such as college admission, healthcare and credit approval, it is imperative to take into account emerging criteria such as the fairness and the robustness of the learned projection. In this paper, we propose a distributionally robust optimization problem for principal component analysis which internalizes a fairness criterion in the objective function. The learned projection thus balances the trade-off between the total reconstruction error and the reconstruction error gap between subgroups, taken in the min-max sense over all distributions in a moment-based ambiguity set. The resulting optimization problem over the Stiefel manifold can be efficiently solved by a Riemannian subgradient descent algorithm with a sub-linear convergence rate. Our experimental results on real-world datasets show the merits of our proposed method over state-of-the-art baselines.'}
{'title': 'Robustness of Graph Neural Networks at Scale', 'paperID': '3328a42bdc552fbfba5dbd5b6c16b8aff26fea18', 'arxivId': '2110.14038', 'publication_year': 2021, 'abstract': None}
{'title': 'Derivative-free optimization adversarial attacks for graph convolutional networks', 'paperID': 'a14aeb408d1d928c5da08bde8ba7f74915835a45', 'arxivId': None, 'publication_year': 2021, 'abstract': None}
{'title': 'A Bi-Level Framework for Learning to Solve Combinatorial Optimization on Graphs', 'paperID': 'de7634ec3412712d216f01c98c75372839631825', 'arxivId': '2106.04927', 'publication_year': 2021, 'abstract': None}
{'title': 'The Transformer Network for the Traveling Salesman Problem', 'paperID': '5673d574d742168f154d214d231e3adee7bc4715', 'arxivId': '2103.03012', 'publication_year': 2021, 'abstract': None}
{'title': 'Combinatorial optimization and reasoning with graph neural networks', 'paperID': 'c2929349db20144b2a0332477699e5a2f26dc91b', 'arxivId': '2102.09544', 'publication_year': 2021, 'abstract': None}
{'title': 'A Simple Fine-tuning Is All You Need: Towards Robust Deep Learning Via Adversarial Fine-tuning', 'paperID': '3fccfd63590564038a4f7235b7ce5c4eddb9b33c', 'arxivId': '2012.13628', 'publication_year': 2020, 'abstract': None}
{'title': 'Learning TSP Requires Rethinking Generalization', 'paperID': '9d7846b1c38f280370c7b841859a1d416ed07e6a', 'arxivId': None, 'publication_year': 2020, 'abstract': None}
{'title': 'Learning Combinatorial Optimization on Graphs: A Survey With Applications to Networking', 'paperID': '89139a394ccdc8784ddbdf7d76d56e3d242cf557', 'arxivId': '2005.11081', 'publication_year': 2020, 'abstract': None}
{'title': 'Predicting Propositional Satisfiability via End-to-End Learning', 'paperID': '66eaabb2f14d04dea5773d29fa204a61f6323022', 'arxivId': None, 'publication_year': 2020, 'abstract': None}
{'title': "It's Not What Machines Can Learn, It's What We Cannot Teach", 'paperID': '0bcc81dab14626bcecfd47e3476e35f4df4c43ec', 'arxivId': '2002.09398', 'publication_year': 2020, 'abstract': None}
{'title': 'How to Evaluate Machine Learning Approaches for Combinatorial Optimization: Application to the Travelling Salesman Problem', 'paperID': '04230489b09b9bfe31904fa043b901ad3591a4c4', 'arxivId': '1909.13121', 'publication_year': 2019, 'abstract': None}
{'title': 'Improving SAT Solver Heuristics with Graph Networks and Reinforcement Learning', 'paperID': '8045f05628d588a7b6c59898cdc4070978975cad', 'arxivId': '1909.11830', 'publication_year': 2019, 'abstract': None}
{'title': 'An Efficient Graph Convolutional Network Technique for the Travelling Salesman Problem', 'paperID': 'f598a8afec169c435e48ad19356c3b768f8ce7a7', 'arxivId': '1906.01227', 'publication_year': 2019, 'abstract': None}
{'title': 'Guiding High-Performance SAT Solvers with Unsat-Core Predictions', 'paperID': '769d7c07eb58fb4957543a486c9db9db8c700500', 'arxivId': '1903.04671', 'publication_year': 2019, 'abstract': None}
{'title': 'Disentangling Adversarial Robustness and Generalization', 'paperID': '8bcd98bd5a451c2bbde4a22a4d1affe3c6407af0', 'arxivId': '1812.00740', 'publication_year': 2018, 'abstract': None}
{'title': "Machine Learning for Combinatorial Optimization: a Methodological Tour d'Horizon", 'paperID': '3f13a5148f7caa51ea946193d261d4f8ed32d81a', 'arxivId': '1811.06128', 'publication_year': 2018, 'abstract': None}
{'title': 'Combinatorial Optimization with Graph Convolutional Networks and Guided Tree Search', 'paperID': 'd77c0e84972c256a8922b952b04330e369f65f09', 'arxivId': '1810.10659', 'publication_year': 2018, 'abstract': None}
{'title': 'Learning To Solve Circuit-SAT: An Unsupervised Differentiable Approach', 'paperID': '2b64300879d6fcaabe932e87ecb412066359b286', 'arxivId': None, 'publication_year': 2018, 'abstract': None}
{'title': 'Learning to Solve NP-Complete Problems - A Graph Neural Network for the Decision TSP', 'paperID': '960d80dfff5cddf7ad16edcc95027ac9ddec2166', 'arxivId': '1809.02721', 'publication_year': 2018, 'abstract': None}
{'title': 'PySAT: A Python Toolkit for Prototyping with SAT Oracles', 'paperID': 'ea11436ed5979546c5a401d1aff4f7930d9a2ccc', 'arxivId': None, 'publication_year': 2018, 'abstract': None}
{'title': 'Learning Heuristics for the TSP by Policy Gradient', 'paperID': '4db4f1af1b94fbd5defa0fa0010fdc449dd1e96c', 'arxivId': None, 'publication_year': 2018, 'abstract': None}
{'title': 'Revisiting Adversarial Risk', 'paperID': '27a1d8192fc8449a85e0b9eb3da4813df4a24b52', 'arxivId': '1806.02924', 'publication_year': 2018, 'abstract': None}
{'title': 'Adversarial Attack on Graph Structured Data', 'paperID': '7f77058976e2fe75e98280371962c43d98c98321', 'arxivId': '1806.02371', 'publication_year': 2018, 'abstract': None}
{'title': 'Attention, Learn to Solve Routing Problems!', 'paperID': 'e7a839428d06e9ea3719cf6fe5314fd861368ee7', 'arxivId': '1803.08475', 'publication_year': 2018, 'abstract': None}
{'title': 'Learning a SAT Solver from Single-Bit Supervision', 'paperID': 'fe257027193ea4a74fdab99d7509ce4002ad7de6', 'arxivId': '1802.03685', 'publication_year': 2018, 'abstract': None}
{'title': 'Learning Combinatorial Optimization Algorithms over Graphs', 'paperID': '1e819f533ef2bf5ca50a6b2008d96eaea2a2706e', 'arxivId': '1704.01665', 'publication_year': 2017, 'abstract': None}
{'title': 'Neural Combinatorial Optimization with Reinforcement Learning', 'paperID': 'd7878c2044fb699e0ce0cad83e411824b1499dc8', 'arxivId': '1611.09940', 'publication_year': 2016, 'abstract': None}
{'title': 'A brief introduction to exact, approximation, and heuristic algorithms for solving hard combinatorial optimization problems', 'paperID': '36de9353a9c319dfedba6412dfc084074846f091', 'arxivId': None, 'publication_year': 2014, 'abstract': None}
{'title': 'AvatarSAT: An Auto-tuning Boolean SAT Solver', 'paperID': '2d9581655c87f56bbcc50c78df3b5693835175cf', 'arxivId': None, 'publication_year': 2009, 'abstract': None}
{'title': 'Predicting Learnt Clauses Quality in Modern SAT Solvers', 'paperID': 'de20cd242ec14e592b6e6d737f1d129c3e8b7467', 'arxivId': None, 'publication_year': 2009, 'abstract': None}
{'title': 'Restart Strategy Selection Using Machine Learning Techniques', 'paperID': '25732e870509248f24b8e46a9ac6b97c48691fdd', 'arxivId': '0907.5032', 'publication_year': 2009, 'abstract': None}
{'title': 'Efficient special case algorithms for the n-line planar traveling salesman problem', 'paperID': 'ed07e8f78eb97c7bd939557a0eacf27c0bb3cf14', 'arxivId': None, 'publication_year': 1980, 'abstract': None}
{'title': 'Graph Neural Networks: Adversarial Robustness', 'paperID': '721d0265fce28b9b8b738892c28e65206c9224d6', 'arxivId': None, 'publication_year': 2022, 'abstract': None}
{'title': 'Learning Local Search Heuristics for Boolean Satisfiability', 'paperID': 'f98d52cafd6de45c6c54f6067688b68d3ecea7cf', 'arxivId': None, 'publication_year': 2019, 'abstract': None}
{'title': 'MiniSat v1.13 - A SAT Solver with Conflict-Clause Minimization', 'paperID': '94a25711f91bc18d666ad343024c1c4ed6e62a8e', 'arxivId': None, 'publication_year': 2005, 'abstract': None}
{'title': 'SATLIB: An Online Resource for Research on SAT', 'paperID': '5a826febdca350f698c6e269e62479eee9ef9f38', 'arxivId': None, 'publication_year': 2000, 'abstract': None}
{'title': 'MASSACHUSETTS INSTITUTE OF TECHNOLOGY ARTIFICIAL INTELLIGENCE LABORATORY and CENTER FOR BIOLOGICAL AND COMPUTATIONAL LEARNING DEPARTMENT OF BRAIN AND COGNITIVE SCIENCES', 'paperID': '6c705e4ed89ad9b2f0310fe2ef243a6aa7e9df2b', 'arxivId': None, 'publication_year': 1998, 'abstract': None}
{'title': 'The n-line traveling salesman problem', 'paperID': 'ef40ec8296f519aef76f543197704e3c0e3fdade', 'arxivId': None, 'publication_year': 1992, 'abstract': None}
{'title': 'Generalization of Neural Combinatorial Solvers Through the Lens of Adversarial Robustness', 'paperID': '70864c48e643e852355f4a79e23baf3614740df6', 'arxivId': '2110.10942', 'publication_year': '2021', 'abstract': 'End-to-end (geometric) deep learning has seen first successes in approximating the solution of combinatorial optimization problems. However, generating data in the realm of NP-hard/-complete tasks brings practical and theoretical challenges, resulting in evaluation protocols that are too optimistic. Specifically, most datasets only capture a simpler subproblem and likely suffer from spurious features. We investigate these effects by studying adversarial robustness - a local generalization property - to reveal hard, model-specific instances and spurious features. For this purpose, we derive perturbation models for SAT and TSP. Unlike in other applications, where perturbation models are designed around subjective notions of imperceptibility, our perturbation models are efficient and sound, allowing us to determine the true label of perturbed samples without a solver. Surprisingly, with such perturbations, a sufficiently expressive neural solver does not suffer from the limitations of the accuracy-robustness trade-off common in supervised learning. Although such robust solvers exist, we show empirically that the assessed neural solvers do not generalize well w.r.t. small perturbations of the problem instance.'}
{'title': 'Fighting Gradients with Gradients: Dynamic Defenses against Adversarial Attacks', 'paperID': 'b301da25b3d432e8293ca6c4ae27fed4f2689c03', 'arxivId': '2105.08714', 'publication_year': 2021, 'abstract': None}
{'title': 'Adversarial Robustness via Runtime Masking and Cleansing', 'paperID': '4dac4feac17a56290f79443be5c011f88b48850d', 'arxivId': None, 'publication_year': 2020, 'abstract': None}
{'title': 'Beyond Perturbations: Learning Guarantees with Arbitrary Adversarial Test Examples', 'paperID': '096382c2490e205334ef7941474fae8584f53e27', 'arxivId': '2007.05145', 'publication_year': 2020, 'abstract': None}
{'title': 'Estimating Generalization under Distribution Shifts via Domain-Invariant Representations', 'paperID': 'b283f7688ebd8cfc7a46272e0beda3943ae0828c', 'arxivId': '2007.03511', 'publication_year': 2020, 'abstract': None}
{'title': 'HYDRA: Pruning Adversarially Robust Neural Networks', 'paperID': '3805147a98dab8f0c7667fed25490adbd2300fbd', 'arxivId': None, 'publication_year': 2020, 'abstract': None}
{'title': 'An Adaptive and Momental Bound Method for Stochastic Learning', 'paperID': 'c30f39f0bd346248b64ea3de89b4ea7db1145cc7', 'arxivId': '1910.12249', 'publication_year': 2019, 'abstract': None}
{'title': 'A Research Agenda: Dynamic Models to Defend Against Correlated Attacks', 'paperID': '979f4f67fb97b57c65867ffc92f9fffb9d30e137', 'arxivId': '1903.06293', 'publication_year': 2019, 'abstract': None}
{'title': 'Stochastic Hyperparameter Optimization through Hypernetworks', 'paperID': '85f75c7931b8176d38115c7679ae05e5a361b155', 'arxivId': '1802.09419', 'publication_year': 2018, 'abstract': None}
{'title': 'The Space of Transferable Adversarial Examples', 'paperID': '1deb6bd9bc6c0112cd06348fd738d7f50ff4b907', 'arxivId': '1704.03453', 'publication_year': 2017, 'abstract': None}
{'title': 'Domain-Adversarial Neural Networks', 'paperID': 'c3b38c2fd30adb316d0bdb32e983804be5595c30', 'arxivId': '1412.4446', 'publication_year': 2014, 'abstract': None}
{'title': 'Towards Evaluating the Robustness of Neural Networks Learned by Transduction', 'paperID': '90fe9785e1ff58c1d7aa22319009e0d0e3077d29', 'arxivId': '2110.14735', 'publication_year': '2021', 'abstract': 'There has been emerging interest in using transductive learning for adversarial robustness (Goldwasser et al., NeurIPS 2020; Wu et al., ICML 2020; Wang et al., ArXiv 2021). Compared to traditional defenses, these defense mechanisms"dynamically learn"the model based on test-time input; and theoretically, attacking these defenses reduces to solving a bilevel optimization problem, which poses difficulty in crafting adaptive attacks. In this paper, we examine these defense mechanisms from a principled threat analysis perspective. We formulate and analyze threat models for transductive-learning based defenses, and point out important subtleties. We propose the principle of attacking model space for solving bilevel attack objectives, and present Greedy Model Space Attack (GMSA), an attack framework that can serve as a new baseline for evaluating transductive-learning based defenses. Through systematic evaluation, we show that GMSA, even with weak instantiations, can break previous transductive-learning based defenses, which were resilient to previous attacks, such as AutoAttack. On the positive side, we report a somewhat surprising empirical result of"transductive adversarial training": Adversarially retraining the model using fresh randomness at the test time gives a significant increase in robustness against attacks we consider.'}
{'title': 'Training Certifiably Robust Neural Networks with Efficient Local Lipschitz Bounds', 'paperID': 'c3c2de457112ca1f54b08697affd68e80dabf99a', 'arxivId': '2111.01395', 'publication_year': 2021, 'abstract': None}
{'title': 'Boosting the Certified Robustness of L-infinity Distance Nets', 'paperID': 'bef771d2430af7be7525201bd677e82cec38510f', 'arxivId': '2110.06850', 'publication_year': 2021, 'abstract': None}
{'title': 'Skew Orthogonal Convolutions', 'paperID': '5ae274cc9ca0fc8a3c089d7320d103f0876bde4f', 'arxivId': '2105.11417', 'publication_year': 2021, 'abstract': None}
{'title': 'Orthogonalizing Convolutional Layers with the Cayley Transform', 'paperID': '9f0e0a59a4b3d689df8470b1218d2574244c26d6', 'arxivId': '2104.07167', 'publication_year': 2021, 'abstract': None}
{'title': 'Improved, Deterministic Smoothing for L1 Certified Robustness', 'paperID': '3fa6da03eb6c4d1ecb5560ffba299e7cc8826477', 'arxivId': '2103.10834', 'publication_year': 2021, 'abstract': None}
{'title': 'Beta-CROWN: Efficient Bound Propagation with Per-neuron Split Constraints for Neural Network Robustness Verification', 'paperID': '1bfc6f9c9db5c6646f0f3e0213d407ae14d8f7bf', 'arxivId': '2103.06624', 'publication_year': 2021, 'abstract': None}
{'title': 'Certifying Confidence via Randomized Smoothing', 'paperID': '06aaece45f8284de309d4d9d8772305fb848a66d', 'arxivId': '2009.08061', 'publication_year': 2020, 'abstract': None}
{'title': 'Second-Order Provable Defenses against Adversarial Attacks', 'paperID': '6d0036bae18aa441a19b63fc4b2daf91f63e8029', 'arxivId': '2006.00731', 'publication_year': 2020, 'abstract': None}
{'title': 'Curse of Dimensionality on Randomized Smoothing for Certifiable Robustness', 'paperID': '3f0ed6866620f76cffcb4b3653d9161a2d4aac5a', 'arxivId': '2002.03239', 'publication_year': 2020, 'abstract': None}
{'title': 'Preventing Gradient Attenuation in Lipschitz Constrained Convolutional Networks', 'paperID': 'a3123379e326e585919f360429d77f1026ec929c', 'arxivId': '1911.00937', 'publication_year': 2019, 'abstract': None}
{'title': 'Generalization bounds for deep convolutional neural networks', 'paperID': '157605ff0f90b8193bbbcaf2e9d469d9b73be0c2', 'arxivId': '1905.12600', 'publication_year': 2019, 'abstract': None}
{'title': 'Certifiably Robust Interpretation in Deep Learning', 'paperID': 'a1ea2a1dea5b126c24be2886c52b720b17e78b2d', 'arxivId': '1905.12105', 'publication_year': 2019, 'abstract': None}
{'title': 'L2-Nonexpansive Neural Networks', 'paperID': 'ef2ec69e7c94b4194ba01719ac76d4595e6b4bdf', 'arxivId': '1802.07896', 'publication_year': 2018, 'abstract': None}
{'title': 'Optimal Transport: Old and New', 'paperID': '7f05b312f2de7e59c7869558507fa4a9fa0d0971', 'arxivId': None, 'publication_year': 2008, 'abstract': None}
{'title': 'Improved deterministic l2 robustness on CIFAR-10 and CIFAR-100', 'paperID': 'a3c052386f0fae0c84c6743271ddb7a938fd755c', 'arxivId': '2108.04062', 'publication_year': '2021', 'abstract': 'Training convolutional neural networks (CNNs) with a strict Lipschitz constraint under the l2 norm is useful for provable adversarial robustness, interpretable gradients and stable training. While 1-Lipschitz CNNs can be designed by enforcing a 1-Lipschitz constraint on each layer, training such networks requires each layer to have an orthogonal Jacobian matrix (for all inputs) to prevent the gradients from vanishing during backpropagation. A layer with this property is said to be Gradient Norm Preserving (GNP). In this work, we introduce a procedure to certify the robustness of 1-Lipschitz CNNs by relaxing the orthogonalization of the last linear layer of the network that significantly advances the state of the art for both standard and provable robust accuracies on CIFAR-100 (gains of 4.80% and 4.71%, respectively). We further boost their robustness by introducing (i) a novel Gradient Norm preserving activation function called the Householder activation function (that includes every GroupSort activation) and (ii) a certificate regularization. On CIFAR-10, we achieve significant improvements over prior works in provable robust accuracy (5.81%) with only a minor drop in standard accuracy (−0.29%). Code for reproducing all experiments in the paper is available at https://github.com/singlasahil14/SOC.'}
{'title': 'Pre-train, Prompt, and Predict: A Systematic Survey of Prompting Methods in Natural Language Processing', 'paperID': '28692beece311a90f5fa1ca2ec9d0c2ce293d069', 'arxivId': '2107.13586', 'publication_year': 2021, 'abstract': None}
{'title': 'BitFit: Simple Parameter-efficient Fine-tuning for Transformer-based Masked Language-models', 'paperID': '339b2b711fb5b228d097b03ebc3e62a521779235', 'arxivId': '2106.10199', 'publication_year': 2021, 'abstract': None}
{'title': 'Knowledgeable or Educated Guess? Revisiting Language Models as Knowledge Bases', 'paperID': 'e337ed6543c2e6e7e51c312c7d998798fc79fdde', 'arxivId': '2106.09231', 'publication_year': 2021, 'abstract': None}
{'title': 'Swords: A Benchmark for Lexical Substitution with Improved Data Coverage and Quality', 'paperID': '91252e0e6fa12b7204719b05d85dab0923e0fe84', 'arxivId': '2106.04102', 'publication_year': 2021, 'abstract': None}
{'title': 'Learning How to Ask: Querying LMs with Mixtures of Soft Prompts', 'paperID': '209f9bde2dee7cf1677801586562ffe56d435d38', 'arxivId': '2104.06599', 'publication_year': 2021, 'abstract': None}
{'title': 'Static Embeddings as Efficient Knowledge Bases?', 'paperID': '92287e1b979e9a2cf0548bd503a0504ad2f6d54d', 'arxivId': '2104.07094', 'publication_year': 2021, 'abstract': None}
{'title': 'Factual Probing Is [MASK]: Learning vs. Learning to Recall', 'paperID': 'a847237e36b954c60e1959152468ebed0118f286', 'arxivId': '2104.05240', 'publication_year': 2021, 'abstract': None}
{'title': 'GPT Understands, Too', 'paperID': '128917425601a541c93c600a2f67d654512928bb', 'arxivId': '2103.10385', 'publication_year': 2021, 'abstract': None}
{'title': 'BERTese: Learning to Speak to BERT', 'paperID': 'a49e9a8d29b5838ba392d5d33fb9694f4667c59e', 'arxivId': '2103.05327', 'publication_year': 2021, 'abstract': None}
{'title': 'Measuring and Improving Consistency in Pretrained Language Models', 'paperID': '73b6de24eb0e5f6ff4f9c3bdd9257f4554faca19', 'arxivId': '2102.01017', 'publication_year': 2021, 'abstract': None}
{'title': 'Robust Encodings: A Framework for Combating Adversarial Typos', 'paperID': '32bc789f96acb37361ac55f36940bb52b759c229', 'arxivId': '2005.01229', 'publication_year': 2020, 'abstract': None}
{'title': 'How Can We Know What Language Models Know?', 'paperID': '81dd3faf762ad8f084ab1d7b8fc9e77e9e160f85', 'arxivId': '1911.12543', 'publication_year': 2019, 'abstract': None}
{'title': 'E-BERT: Efficient-Yet-Effective Entity Embeddings for BERT', 'paperID': '2bd5b4aed18400bf1a1cc866d9b8d931aa047290', 'arxivId': '1911.03681', 'publication_year': 2019, 'abstract': None}
{'title': 'Negated and Misprimed Probes for Pretrained Language Models: Birds Can Talk, But Cannot Fly', 'paperID': '68c1bf884f0fc0e86641466a1f1fa67e79f16a17', 'arxivId': '1911.03343', 'publication_year': 2019, 'abstract': None}
{'title': 'Transformers: State-of-the-Art Natural Language Processing', 'paperID': 'af3f67b6639a50fd094e1467a2f3b6b8fef7c7c2', 'arxivId': None, 'publication_year': 2019, 'abstract': None}
{'title': 'Language Models as Knowledge Bases?', 'paperID': 'd0086b86103a620a86bc918746df0aa642e2a8a3', 'arxivId': '1909.01066', 'publication_year': 2019, 'abstract': None}
{'title': 'Commonsense Knowledge Mining from Pretrained Models', 'paperID': 'f98e135986414cccf29aec593d547c0656e4d82c', 'arxivId': '1909.00505', 'publication_year': 2019, 'abstract': None}
{'title': 'A Simple Method for Commonsense Reasoning', 'paperID': 'd7b6753a2d4a2b286c396854063bde3a91b75535', 'arxivId': '1806.02847', 'publication_year': 2018, 'abstract': None}
{'title': 'T-REx: A Large Scale Alignment of Natural Language with Knowledge Base Triples', 'paperID': '11eaa4f1cba9281ecbc1ac44a6b3ba5817bf1a25', 'arxivId': None, 'publication_year': 2018, 'abstract': None}
{'title': 'P-Adapters: Robustly Extracting Factual Information from Language Models with Diverse Prompts', 'paperID': '58947177663d73b4d7809e74482b54aadaee6444', 'arxivId': '2110.07280', 'publication_year': '2021', 'abstract': 'Recent work (e.g. LAMA (Petroni et al., 2019)) has found that the quality of the factual information extracted from Large Language Models (LLMs) depends on the prompts used to query them. This inconsistency is problematic because different users will query LLMs for the same information using different wording, but should receive the same, accurate responses regardless. In this work we aim to address this shortcoming by introducing P-Adapters: lightweight models that sit between the embedding layer and first attention layer of LLMs. They take LLM embeddings as input and output continuous prompts that are used to query the LLM. Additionally, we investigate Mixture of Experts (MoE) models that learn a set of continuous prompts ("experts") and select one to query the LLM. They require a separate classifier trained on human-annotated data to map natural language prompts to the continuous ones. P-Adapters perform comparably to the more complex MoE models in extracting factual information from BERT and RoBERTa while eliminating the need for additional annotations. P-Adapters show between 12-26% absolute improvement in precision and 36-50% absolute improvement in consistency over a baseline of only using natural language queries. Finally, we investigate what makes P-Adapters successful and conclude that a significant factor is access to the LLM\'s embeddings of the original natural language prompt, particularly the subject of the entity pair being queried.'}
{'title': 'Mastering Atari Games with Limited Data', 'paperID': '3b3d7adb9047d01af6dfa2975ad8addd69715e96', 'arxivId': '2111.00210', 'publication_year': 2021, 'abstract': None}
{'title': 'CROP: Certifying Robust Policies for Reinforcement Learning through Functional Smoothing', 'paperID': '5374af7bb076f9eaea7aea3045edd9b6a76d0a3b', 'arxivId': '2106.09292', 'publication_year': 2021, 'abstract': None}
{'title': 'Corruption-Robust Offline Reinforcement Learning', 'paperID': 'dc55b6b89d536c8fee6a19a80505f447148a0b46', 'arxivId': '2106.06630', 'publication_year': 2021, 'abstract': None}
{'title': 'BACKDOORL: Backdoor Attack against Competitive Reinforcement Learning', 'paperID': '018fb0e200d9fe8cb334cec5445895c0461b585f', 'arxivId': '2105.00579', 'publication_year': 2021, 'abstract': None}
{'title': 'Defense Against Reward Poisoning Attacks in Reinforcement Learning', 'paperID': '0a26f7a7579415e854324e4caa0c436f63804e83', 'arxivId': '2102.05776', 'publication_year': 2021, 'abstract': None}
{'title': 'Certified Robustness of Nearest Neighbors against Data Poisoning Attacks', 'paperID': '2d28fe7c7983e355a502be99c3265509d5158e99', 'arxivId': None, 'publication_year': 2020, 'abstract': None}
{'title': 'Vulnerability-Aware Poisoning Mechanism for Online RL with Unknown Dynamics', 'paperID': '75454ae23df4010076b45d6e4e98723f32e68282', 'arxivId': '2009.00774', 'publication_year': 2020, 'abstract': None}
{'title': 'Robust Deep Reinforcement Learning through Adversarial Loss', 'paperID': '2c9fc230cc4b9ff40f1b61b6dd1bac797d7f5b92', 'arxivId': '2008.01976', 'publication_year': 2020, 'abstract': None}
{'title': 'TrojDRL: Evaluation of Backdoor Attacks on Deep Reinforcement Learning', 'paperID': '099dc0aa605a0c5220eb8f8b39b3d8c7649df008', 'arxivId': None, 'publication_year': 2020, 'abstract': None}
{'title': 'Deep Partition Aggregation: Provable Defense against General Poisoning Attacks', 'paperID': '6cf1116dc8b431b2471bb5407d9a8be0eb067c2d', 'arxivId': '2006.14768', 'publication_year': 2020, 'abstract': None}
{'title': 'Just How Toxic is Data Poisoning? A Unified Benchmark for Backdoor and Data Poisoning Attacks', 'paperID': '6fc7becf66166b9ad34409390082ff5b1b8a376e', 'arxivId': '2006.12557', 'publication_year': 2020, 'abstract': None}
{'title': 'Certifiable Robustness to Adversarial State Uncertainty in Deep Reinforcement Learning', 'paperID': '28b924d5c9d9ded9d28d8d24cce7c9f044330875', 'arxivId': '2004.06496', 'publication_year': 2020, 'abstract': None}
{'title': 'Adaptive Reward-Poisoning Attacks against Reinforcement Learning', 'paperID': '5a84c26c7307df75e881a490f239877015980ae3', 'arxivId': '2003.12613', 'publication_year': 2020, 'abstract': None}
{'title': 'RAB: Provable Robustness Against Backdoor Attacks', 'paperID': '4b8cc4d83437d67d803055472ed634fe8dcd1036', 'arxivId': '2003.08904', 'publication_year': 2020, 'abstract': None}
{'title': 'Stop-and-Go: Exploring Backdoor Attacks on Deep Reinforcement Learning-Based Traffic Congestion Control Systems', 'paperID': '378d1f030d7790939681f36a7b1bf4938d662213', 'arxivId': '2003.07859', 'publication_year': 2020, 'abstract': None}
{'title': 'Adversarial Machine Learning-Industry Perspectives', 'paperID': '3eb594bdc7057858a7bcd6243947c1944e89e2e3', 'arxivId': '2002.05646', 'publication_year': 2020, 'abstract': None}
{'title': 'Deep Learning Poison Data Attack Detection', 'paperID': '8713070502ef7ac1186d97b20f46bb26ecd84daa', 'arxivId': None, 'publication_year': 2019, 'abstract': None}
{'title': 'Entity Abstraction in Visual Model-Based Reinforcement Learning', 'paperID': '53f8181a5a414f77e3d887bb20878178f3e8f859', 'arxivId': '1910.12827', 'publication_year': 2019, 'abstract': None}
{'title': 'Deep k-NN Defense Against Clean-Label Data Poisoning Attacks', 'paperID': '4eb7c627650395abc205010ac14f1cdb50cf788c', 'arxivId': None, 'publication_year': 2019, 'abstract': None}
{'title': 'An Optimistic Perspective on Offline Reinforcement Learning', 'paperID': '4012d4ab621f3f5f04b0f91849a60c6eaabe64b4', 'arxivId': None, 'publication_year': 2019, 'abstract': None}
{'title': 'Mitigation of Policy Manipulation Attacks on Deep Q-Networks with Parameter-Space Noise', 'paperID': '343a4443121f27b8f1e994501a685b91824c5789', 'arxivId': '1806.02190', 'publication_year': 2018, 'abstract': None}
{'title': 'Fine-Pruning: Defending Against Backdooring Attacks on Deep Neural Networks', 'paperID': '790ec1befba47991e8fd50a24d13be6094253f93', 'arxivId': '1805.12185', 'publication_year': 2018, 'abstract': None}
{'title': 'Distributional Reinforcement Learning with Quantile Regression', 'paperID': 'fe3e91e40a950c6b6601b8f0a641884774d949ae', 'arxivId': '1710.10044', 'publication_year': 2017, 'abstract': None}
{'title': 'A Distributional Perspective on Reinforcement Learning', 'paperID': 'c1f4ef741242d629d1f56e442a09a7ba29595a0e', 'arxivId': '1707.06887', 'publication_year': 2017, 'abstract': None}
{'title': 'Noisy Networks for Exploration', 'paperID': '4cd76f8353f0c4852cc432fc0e7a5f2b91ae6ce5', 'arxivId': '1706.10295', 'publication_year': 2017, 'abstract': None}
{'title': 'Certified Defenses for Data Poisoning Attacks', 'paperID': 'd951a9a7b0d24cec84ffd1022900733186504d05', 'arxivId': '1706.03691', 'publication_year': 2017, 'abstract': None}
{'title': 'Survey of Model-Based Reinforcement Learning: Applications on Robotics', 'paperID': '059a1297a61afc812de48edede631229608dc513', 'arxivId': None, 'publication_year': 2017, 'abstract': None}
{'title': 'Safe, Multi-Agent, Reinforcement Learning for Autonomous Driving', 'paperID': '75a760c6bd5ae15e0fc489a074bc42bc1fc4e697', 'arxivId': '1610.03295', 'publication_year': 2016, 'abstract': None}
{'title': 'Playing Atari with Deep Reinforcement Learning', 'paperID': '2319a491378867c7049b3da055c5df60e1671158', 'arxivId': '1312.5602', 'publication_year': 2013, 'abstract': None}
{'title': 'Reinforcement learning in robotics: A survey', 'paperID': '65438e0ba226c1f97bd8a36333ebc3297b1a32fd', 'arxivId': None, 'publication_year': 2013, 'abstract': None}
{'title': 'A Survey on Policy Search for Robotics', 'paperID': 'b6bfae6efa1110a57a4d8362721d152d78aae358', 'arxivId': None, 'publication_year': 2013, 'abstract': None}
{'title': 'Reinforcement Learning on Slow Features of High-Dimensional Input Streams', 'paperID': 'adbb4820c55771b54b9a0a275d1f36836dfb337a', 'arxivId': None, 'publication_year': 2010, 'abstract': None}
{'title': 'Exploiting Machine Learning to Subvert Your Spam Filter', 'paperID': 'a84f4fe31fcfb4ad92c995dba0fc09ed8fe6a4f4', 'arxivId': None, 'publication_year': 2008, 'abstract': None}
{'title': 'Dynamic Programming', 'paperID': '834eaef4cb1e47cd262722ee9471901db67128bd', 'arxivId': None, 'publication_year': 2011, 'abstract': None}
{'title': 'Reducibility Among Combinatorial Problems', 'paperID': '9fb53a3bdfb47230eeaf7d956b1a238db5cba690', 'arxivId': None, 'publication_year': 1972, 'abstract': None}
{'title': 'COPA: Certifying Robust Policies for Offline Reinforcement Learning against Poisoning Attacks', 'paperID': '9700b4d0a9e6a64452192ae1c98e1aba34bc8c28', 'arxivId': '2203.08398', 'publication_year': '2022', 'abstract': 'As reinforcement learning (RL) has achieved near human-level performance in a variety of tasks, its robustness has raised great attention. While a vast body of research has explored test-time (evasion) attacks in RL and corresponding defenses, its robustness against training-time (poisoning) attacks remains largely unanswered. In this work, we focus on certifying the robustness of offline RL in the presence of poisoning attacks, where a subset of training trajectories could be arbitrarily manipulated. We propose the first certification framework, COPA, to certify the number of poisoning trajectories that can be tolerated regarding different certification criteria. Given the complex structure of RL, we propose two certification criteria: per-state action stability and cumulative reward bound. To further improve the certification, we propose new partition and aggregation protocols to train robust policies. We further prove that some of the proposed certification methods are theoretically tight and some are NP-Complete problems. We leverage COPA to certify three RL environments trained with different algorithms and conclude: (1) The proposed robust aggregation protocols such as temporal aggregation can significantly improve the certifications; (2) Our certifications for both per-state action stability and cumulative reward bound are efficient and tight; (3) The certification for different training algorithms and environments are different, implying their intrinsic robustness properties. All experimental results are available at https://copa-leaderboard.github.io.'}
{'title': 'Fast Distributionally Robust Learning with Variance Reduced Min-Max Optimization', 'paperID': '556d4ec7f098523cfbdf93a3ca5aad7908273f70', 'arxivId': '2104.13326', 'publication_year': 2021, 'abstract': None}
{'title': 'Distributionally Robust Federated Averaging', 'paperID': '1696660f0aa90803f72ee806750597162c373529', 'arxivId': '2102.12660', 'publication_year': 2021, 'abstract': None}
{'title': 'Robust experimentation in the continuous time bandit problem', 'paperID': 'a3934b02a247d52a7e5409aa2548a2d8125f3035', 'arxivId': '2104.00102', 'publication_year': 2020, 'abstract': None}
{'title': 'Federated Learning with Compression: Unified Analysis and Sharp Guarantees', 'paperID': '1c401f906d78efb466df59d6a4e523222968c63d', 'arxivId': '2007.01154', 'publication_year': 2020, 'abstract': None}
{'title': 'A Practical Online Method for Distributionally Deep Robust Optimization', 'paperID': 'f915e4b47291adbfa26668f84f99dbd1f85b4897', 'arxivId': None, 'publication_year': 2020, 'abstract': None}
{'title': 'Adaptive Personalized Federated Learning', 'paperID': '2ffc4df07df933a732d442e23ce256c52de6d7c6', 'arxivId': '2003.13461', 'publication_year': 2020, 'abstract': None}
{'title': 'Sharp Analysis of Epoch Stochastic Gradient Descent Ascent Methods for Min-Max Optimization', 'paperID': '5b3531d7f455b251d3a8a7150bb55cbaebcadf78', 'arxivId': '2002.05309', 'publication_year': 2020, 'abstract': None}
{'title': 'Robust Optimization for Fairness with Noisy Protected Groups', 'paperID': '10565078981924f27d38cdbb37353706ac9eba7d', 'arxivId': '2002.09343', 'publication_year': 2020, 'abstract': None}
{'title': 'Zeroth-order Stochastic Compositional Algorithms for Risk-Aware Learning', 'paperID': '126485ec3a7ab47432a1c6e8d9d82faa6528923f', 'arxivId': '1912.09484', 'publication_year': 2019, 'abstract': None}
{'title': 'On the Convergence of Local Descent Methods in Federated Learning', 'paperID': '52715c7ec1e333443e37f449e8ce481afd621ca1', 'arxivId': '1910.14425', 'publication_year': 2019, 'abstract': None}
{'title': 'Local SGD with Periodic Averaging: Tighter Analysis and Adaptive Synchronization', 'paperID': 'cb340ba0b1b3c56e5003bfeb51ab6e4b60148364', 'arxivId': '1910.13598', 'publication_year': 2019, 'abstract': None}
{'title': 'One Sample Stochastic Frank-Wolfe', 'paperID': 'e80f6b91767ff23c05fe42c2aa6c072531ab5380', 'arxivId': '1910.04322', 'publication_year': 2019, 'abstract': None}
{'title': 'A Simple and Effective Framework for Pairwise Deep Metric Learning', 'paperID': '6ea0a369c0384987baae1a302536cf7932954fa2', 'arxivId': '1912.11194', 'publication_year': 2019, 'abstract': None}
{'title': 'A General Analysis Framework of Lower Complexity Bounds for Finite-Sum Optimization', 'paperID': '3077990b7fb8c730252ce77882e7bfff1a0b52ea', 'arxivId': '1908.08394', 'publication_year': 2019, 'abstract': None}
{'title': 'A Stochastic Composite Gradient Method with Incremental Variance Reduction', 'paperID': 'bce1870fbd2ea280f187da313d9b621017ac99ab', 'arxivId': '1906.10186', 'publication_year': 2019, 'abstract': None}
{'title': 'Pairwise Fairness for Ranking and Regression', 'paperID': '312e6042c90338339d0366a89ac4e8b8ddf974c9', 'arxivId': '1906.05330', 'publication_year': 2019, 'abstract': None}
{'title': 'Trading Redundancy for Communication: Speeding up Distributed SGD for Non-convex Optimization', 'paperID': 'f7904d8876e3032d7a60f48773d93951611fec0a', 'arxivId': None, 'publication_year': 2019, 'abstract': None}
{'title': 'A Composite Randomized Incremental Gradient Method', 'paperID': 'e5f310e27f2e497dc98b76a10fdf7fb51d566d4e', 'arxivId': None, 'publication_year': 2019, 'abstract': None}
{'title': 'Stochastic Primal-Dual Algorithms with Faster Convergence than O(1/√T) for Problems without Bilinear Structure', 'paperID': 'ef6a4d065c215680c4abf0eba1fce14b21d4187f', 'arxivId': '1904.10112', 'publication_year': 2019, 'abstract': None}
{'title': 'SPIDER: Near-Optimal Non-Convex Optimization via Stochastic Path Integrated Differential Estimator', 'paperID': '0572951adde832f6f84e26b5fb87da8e1d1ebca5', 'arxivId': '1807.01695', 'publication_year': 2018, 'abstract': None}
{'title': 'Two-Player Games for Efficient Non-Convex Constrained Optimization', 'paperID': 'afe6b57605af91525dad183171e3a850e599841f', 'arxivId': '1804.06500', 'publication_year': 2018, 'abstract': None}
{'title': 'Accelerated Method for Stochastic Composition Optimization with Nonsmooth Regularization', 'paperID': '52e557d33bdc25e0b1b834f82f2cf04176ecbceb', 'arxivId': '1711.03937', 'publication_year': 2017, 'abstract': None}
{'title': 'Distributionally Robust Stochastic Programming', 'paperID': '30237f91f079dcdb88d48b2a9ebc7bc5322a5386', 'arxivId': None, 'publication_year': 2017, 'abstract': None}
{'title': 'First-Order Methods in Optimization', 'paperID': 'b532b74b9112e5c37a72ad6de9cc618c48b0467a', 'arxivId': None, 'publication_year': 2017, 'abstract': None}
{'title': 'Robust Optimization for Non-Convex Objectives', 'paperID': '7b5c74af1ba906b1b848c024b55a2d329a0e2b52', 'arxivId': '1707.01047', 'publication_year': 2017, 'abstract': None}
{'title': 'SARAH: A Novel Method for Machine Learning Problems Using Stochastic Recursive Gradient', 'paperID': 'db4d0e45560ceda35b6212036513bd4ab59ce99d', 'arxivId': '1703.00102', 'publication_year': 2017, 'abstract': None}
{'title': 'Finite-sum Composition Optimization via Variance Reduced Gradient Descent', 'paperID': '322c913adfd417fa82671fb06edd66edae513ac3', 'arxivId': '1610.04674', 'publication_year': 2016, 'abstract': None}
{'title': 'Linear Convergence of Gradient and Proximal-Gradient Methods Under the Polyak-Łojasiewicz Condition', 'paperID': '07f5bae91cd45eafe82f3548a43268eb5c84df7a', 'arxivId': '1608.04636', 'publication_year': 2016, 'abstract': None}
{'title': 'Accelerating Stochastic Composition Optimization', 'paperID': 'd53d179dfba4804799278fcefa414c2017f391dc', 'arxivId': '1607.07329', 'publication_year': 2016, 'abstract': None}
{'title': 'Stochastic First-Order Methods with Random Constraint Projection', 'paperID': '7753fa97349818282732dc795d4a439e32a2808a', 'arxivId': None, 'publication_year': 2016, 'abstract': None}
{'title': 'A Light Touch for Heavily Constrained SGD', 'paperID': '70115dd8641dc6e5a99cc8319a6dfe9c6ba96fb7', 'arxivId': '1512.04960', 'publication_year': 2015, 'abstract': None}
{'title': 'Linear convergence of first order methods for non-strongly convex optimization', 'paperID': '1a48e11f9b588ed9f4ff447b18426a4bbf875229', 'arxivId': '1504.06298', 'publication_year': 2015, 'abstract': None}
{'title': 'Stochastic compositional gradient descent: algorithms for minimizing compositions of expected-value functions', 'paperID': '0e16fb12330e653a251b7cb825d677d1af294b7c', 'arxivId': '1411.3803', 'publication_year': 2014, 'abstract': None}
{'title': 'SAGA: A Fast Incremental Gradient Method With Support for Non-Strongly Convex Composite Objectives', 'paperID': '4daec165c1f4aa1206b0d91c0b26f0287d1ef52d', 'arxivId': '1407.0202', 'publication_year': 2014, 'abstract': None}
{'title': 'Incremental constraint projection methods for variational inequalities', 'paperID': '09bf24d0340d0df49042b7f16dc5a58384b9a204', 'arxivId': None, 'publication_year': 2014, 'abstract': None}
{'title': 'Revisiting Frank-Wolfe: Projection-Free Sparse Convex Optimization', 'paperID': '961eabeaebd7035cd7668c9917fa9c39462e1113', 'arxivId': None, 'publication_year': 2013, 'abstract': None}
{'title': 'Introducing LETOR 4.0 Datasets', 'paperID': '3bd42cfb7e633320bbeec7f6d361e92abec60b07', 'arxivId': '1306.2597', 'publication_year': 2013, 'abstract': None}
{'title': 'Stochastic Gradient Descent with Only One Projection', 'paperID': '7a4fa3f4974af547e42bc7d0c1ce61ff2a2c8b20', 'arxivId': None, 'publication_year': 2012, 'abstract': None}
{'title': 'Solving variational inequalities with Stochastic Mirror-Prox algorithm', 'paperID': 'e50c7cba0a612e8045458dd2aa130d9b2a1ff560', 'arxivId': '0809.0815', 'publication_year': 2008, 'abstract': None}
{'title': 'Approximate Heavily-Constrained Learning with Lagrange Multiplier Models', 'paperID': '075e10678f83b2e9a33520f5d10d4c68e74ba5fe', 'arxivId': None, 'publication_year': 2020, 'abstract': None}
{'title': 'Fairness Constraints: A Flexible Approach for Fair Classification', 'paperID': '8b313c4c045bf3909e418e338b4e076e68955c85', 'arxivId': None, 'publication_year': 2019, 'abstract': None}
{'title': 'Gradient methods for minimizing composite functions', 'paperID': '15b2e43274de048e7aca3f3d2e7c0d5671a58163', 'arxivId': None, 'publication_year': 2013, 'abstract': None}
{'title': 'Learning Distributionally Robust Models at Scale via Composite Optimization', 'paperID': '3b35d09d5153edb814bfd82d63666dfb178902d0', 'arxivId': '2203.09607', 'publication_year': '2022', 'abstract': 'To train machine learning models that are robust to distribution shifts in the data, distributionally robust optimization (DRO) has been proven very effective. However, the existing approaches to learning a distributionally robust model either require solving complex optimization problems such as semidefinite programming or a first-order method whose convergence scales linearly with the number of data samples -- which hinders their scalability to large datasets. In this paper, we show how different variants of DRO are simply instances of a finite-sum composite optimization for which we provide scalable methods. We also provide empirical results that demonstrate the effectiveness of our proposed algorithm with respect to the prior art in order to learn robust models from very large datasets.'}
{'title': 'Adaptive Conformal Inference Under Distribution Shift', 'paperID': '445596c40dc421efe2354a340085b43181bea2be', 'arxivId': '2106.00170', 'publication_year': 2021, 'abstract': None}
{'title': 'Distribution-free uncertainty quantification for classification under label shift', 'paperID': '7e8a8c2f97ef62ab72aa57f175953df4b807d547', 'arxivId': '2103.03323', 'publication_year': 2021, 'abstract': None}
{'title': 'Robust Validation: Confident Predictions Even When Distributions Shift', 'paperID': 'bcc5a2d443253d5fbbfbba883685f6cd273f28d2', 'arxivId': '2008.04267', 'publication_year': 2020, 'abstract': None}
{'title': 'Making learning more transparent using conformalized performance prediction', 'paperID': '7ebd336d737609492dbc665a19c09cf42f2a4751', 'arxivId': '2007.04486', 'publication_year': 2020, 'abstract': None}
{'title': 'Classification with Valid and Adaptive Coverage', 'paperID': '00215f32433e4e69ddb5a678b3f02568334d67ca', 'arxivId': '2006.02544', 'publication_year': 2020, 'abstract': None}
{'title': 'Denoised Smoothing: A Provable Defense for Pretrained Classifiers', 'paperID': 'a33daa0f2ed0e5bdc610be01d3ba014a2a8458d1', 'arxivId': None, 'publication_year': 2020, 'abstract': None}
{'title': 'Why deep-learning AIs are so easy to fool', 'paperID': '55ce88684aca5dc53dbdf64e2c76d64b51ccd04a', 'arxivId': None, 'publication_year': 2019, 'abstract': None}
{'title': 'Filling the Soap Bubbles: Efficient Black-Box Adversarial Certification with Non-Gaussian Smoothing', 'paperID': '242a11c84c0f7198b3bef85bc89e288031eba6ca', 'arxivId': None, 'publication_year': 2019, 'abstract': None}
{'title': 'Detecting Adversarial Samples Using Influence Functions and Nearest Neighbors', 'paperID': '311ecce2e2653ca01430f65c86f0b43fc1dc7366', 'arxivId': '1909.06872', 'publication_year': 2019, 'abstract': None}
{'title': 'With Malice Towards None: Assessing Uncertainty via Equalized Coverage', 'paperID': '108bb1678a10483aaeae07967b5e6d6a8a35afb9', 'arxivId': '1908.05428', 'publication_year': 2019, 'abstract': None}
{'title': 'Prediction and outlier detection in classification problems', 'paperID': '02e2fd718da55b973965c83981e2c7fb306d2d79', 'arxivId': '1905.04396', 'publication_year': 2019, 'abstract': None}
{'title': 'Conformalized Quantile Regression', 'paperID': '6f9dc6f8519e927d948a13aa7ae0df336f443eb9', 'arxivId': '1905.03222', 'publication_year': 2019, 'abstract': None}
{'title': 'Conformal Prediction Under Covariate Shift', 'paperID': 'f08e13d65cb17856427b429d79f01922584a6f01', 'arxivId': '1904.06019', 'publication_year': 2019, 'abstract': None}
{'title': 'The limits of distribution-free conditional predictive inference', 'paperID': 'ebc3193ae46286f82f741143f5d67891c1625209', 'arxivId': '1903.04684', 'publication_year': 2019, 'abstract': None}
{'title': 'Cautious Deep Learning', 'paperID': 'f2b508ee78b240c1c6d7932f736a3eaeb4604602', 'arxivId': '1805.09460', 'publication_year': 2018, 'abstract': None}
{'title': 'DenseNet: Implementing Efficient ConvNet Descriptor Pyramids', 'paperID': '5fc662287842e5cb2d23b5fa917354e957c573bf', 'arxivId': '1404.1869', 'publication_year': 2014, 'abstract': None}
{'title': 'Distribution-Free Prediction Sets', 'paperID': 'acd3f1ee1c67bd56a8b6454f413b89a28d34288e', 'arxivId': None, 'publication_year': 2013, 'abstract': None}
{'title': 'Conditional validity of inductive conformal predictors', 'paperID': '5e7c16a648c5de60172b2a8ab9597d00ae1481b1', 'arxivId': '1209.2673', 'publication_year': 2012, 'abstract': None}
{'title': 'Randomized Smoothing for Stochastic Optimization', 'paperID': '33a0803fc10233bd05756ed83db92e8d827d3396', 'arxivId': '1103.4296', 'publication_year': 2011, 'abstract': None}
{'title': 'Inductive Conformal Prediction: Theory and Application to Neural Networks', 'paperID': '12ba5ebf8949170e200d9ebd7ee090ec54775093', 'arxivId': None, 'publication_year': 2008, 'abstract': None}
{'title': 'Inductive Confidence Machines for Regression', 'paperID': '7f96ca1a46b8e1fabcad6d459e7820dd348675f7', 'arxivId': None, 'publication_year': 2002, 'abstract': None}
{'title': 'Algorithmic Learning in a Random World', 'paperID': '4d8a2fcf9b43efd2636d5f90e0d35b98194c0025', 'arxivId': None, 'publication_year': 2006, 'abstract': None}
{'title': 'Adversarially Robust Conformal Prediction', 'paperID': 'acc8f7cc17ce5009bd2504572e8b9b76148e63a7', 'arxivId': None, 'publication_year': None, 'abstract': 'Conformal prediction is a model-agnostic tool for constructing prediction sets that are valid under the common i.i.d. assumption, which has been applied to quantify the prediction uncertainty of deep net classifiers. In this paper, we generalize this framework to the case where adversaries exist during inference time, under which the i.i.d. assumption is grossly violated. By combining conformal prediction with randomized smoothing, our proposed method forms a prediction set with finite-sample coverage guarantee that holds for any data distribution with `2norm bounded adversarial noise, generated by any adversarial attack algorithm. The core idea is to bound the Lipschitz constant of the non-conformity score by smoothing it with Gaussian noise and leverage this knowledge to account for the effect of the unknown adversarial perturbation. We demonstrate the necessity of our method in the adversarial setting and the validity of our theoretical guarantee on three widely used benchmark data sets: CIFAR10, CIFAR100, and ImageNet.'}
{'title': 'Audio Lottery: Speech Recognition Made Ultra-Lightweight, Noise-Robust, and Transferable', 'paperID': '2cecb623ba2e2ee4872bb07b794552fd73a87976', 'arxivId': None, 'publication_year': None, 'abstract': None}
{'title': 'Better than Average: Paired Evaluation of NLP systems', 'paperID': 'df37ba004c3bec70c9ed6f614944338d6ec6ec68', 'arxivId': '2110.10746', 'publication_year': 2021, 'abstract': None}
{'title': 'Are Larger Pretrained Language Models Uniformly Better? Comparing Performance at the Instance Level', 'paperID': '6a8cb4fb5a20c7e5733a9bd50cd5feaad6c11360', 'arxivId': '2105.06020', 'publication_year': 2021, 'abstract': None}
{'title': 'How Reliable are Model Diagnostics?', 'paperID': '7c799b7bd8c069c6feb7235345c97aa1f5330b84', 'arxivId': '2105.05641', 'publication_year': 2021, 'abstract': None}
{'title': 'Carbon Emissions and Large Neural Network Training', 'paperID': '79b8ef3905a42b771248719495a2117271906445', 'arxivId': '2104.10350', 'publication_year': 2021, 'abstract': None}
{'title': 'Probing Across Time: What Does RoBERTa Know and When?', 'paperID': '0672f88d5dc762002b515ca4a0a9f101017fea35', 'arxivId': '2104.07885', 'publication_year': 2021, 'abstract': None}
{'title': 'A Statistical Analysis of Summarization Evaluation Metrics Using Resampling Methods', 'paperID': 'dfb4e80deb187bcb85708f751c5d466c399f76f3', 'arxivId': '2104.00054', 'publication_year': 2021, 'abstract': None}
{'title': 'With Little Power Comes Great Responsibility', 'paperID': '186d26390779f7c54930e05812cfe85e6973961f', 'arxivId': '2010.06595', 'publication_year': 2020, 'abstract': None}
{'title': 'Measuring and Reducing Gendered Correlations in Pre-trained Models', 'paperID': '3d864a8bc5a55ccab9993aa66203d8e70b88148c', 'arxivId': '2010.06032', 'publication_year': 2020, 'abstract': None}
{'title': 'Pretrained Language Model Embryology: The Birth of ALBERT', 'paperID': 'b1d309073623d46548e55269fb73485a3b7f11a8', 'arxivId': '2010.02480', 'publication_year': 2020, 'abstract': None}
{'title': 'Revisiting Few-sample BERT Fine-tuning', 'paperID': '056935031bc5cf0aeeaa0946320de26e14a1817e', 'arxivId': '2006.05987', 'publication_year': 2020, 'abstract': None}
{'title': 'On the Stability of Fine-tuning BERT: Misconceptions, Explanations, and Strong Baselines', 'paperID': '8b9d77d5e52a70af37451d3db3d32781b83ea054', 'arxivId': '2006.04884', 'publication_year': 2020, 'abstract': None}
{'title': 'StereoSet: Measuring stereotypical bias in pretrained language models', 'paperID': 'babeda48b10a4d638252118f2238d05a06f4ec55', 'arxivId': '2004.09456', 'publication_year': 2020, 'abstract': None}
{'title': 'The Curse of Performance Instability in Analysis Datasets: Consequences, Source, and Suggestions', 'paperID': '82a44fbe798d514c81439c90c655975a32c2af10', 'arxivId': '2004.13606', 'publication_year': 2020, 'abstract': None}
{'title': 'A Primer in BERTology: What We Know About How BERT Works', 'paperID': 'bd20069f5cac3e63083ecf6479abc1799db33ce0', 'arxivId': '2002.12327', 'publication_year': 2020, 'abstract': None}
{'title': 'Fine-Tuning Pretrained Language Models: Weight Initializations, Data Orders, and Early Stopping', 'paperID': 'baf60d13c98916b77b09bc525ede1cd610ed1db5', 'arxivId': '2002.06305', 'publication_year': 2020, 'abstract': None}
{'title': 'BERTs of a feather do not generalize together: Large variability in generalization across models with similar test set performance', 'paperID': '48689c4bb52a45c0bc97d1421d72d11bab6c346b', 'arxivId': '1911.02969', 'publication_year': 2019, 'abstract': None}
{'title': 'Quantifying the Carbon Emissions of Machine Learning', 'paperID': 'b3ea2d9c8e5ea3b87ace121f0bece71565abc187', 'arxivId': '1910.09700', 'publication_year': 2019, 'abstract': None}
{'title': 'Mixout: Effective Regularization to Finetune Large-scale Pretrained Language Models', 'paperID': '222b9a7b8038120671a1610e857d3edbc7ac5550', 'arxivId': '1909.11299', 'publication_year': 2019, 'abstract': None}
{'title': 'Well-Read Students Learn Better: On the Importance of Pre-training Compact Models', 'paperID': '7402b604f14b8b91c53ed6eed04af92c59636c97', 'arxivId': None, 'publication_year': 2019, 'abstract': None}
{'title': 'Semantics-aware BERT for Language Understanding', 'paperID': '5744f56d3253bd7c4341d36de40a93fceaa266b3', 'arxivId': '1909.02209', 'publication_year': 2019, 'abstract': None}
{'title': 'Deep Dominance - How to Properly Compare Deep Neural Models', 'paperID': '6a7769116c6733dffa347444b2835e50129e0143', 'arxivId': None, 'publication_year': 2019, 'abstract': None}
{'title': 'Energy and Policy Considerations for Deep Learning in NLP', 'paperID': 'd6a083dad7114f3a39adc65c09bfbb6cf3fee9ea', 'arxivId': '1906.02243', 'publication_year': 2019, 'abstract': None}
{'title': 'Analyzing Multi-Head Self-Attention: Specialized Heads Do the Heavy Lifting, the Rest Can Be Pruned', 'paperID': '07a64686ce8e43ac475a8d820a8a9f1d87989583', 'arxivId': '1905.09418', 'publication_year': 2019, 'abstract': None}
{'title': 'BERT Rediscovers the Classical NLP Pipeline', 'paperID': '97906df07855b029b7aae7c2a1c6c5e8df1d531c', 'arxivId': '1905.05950', 'publication_year': 2019, 'abstract': None}
{'title': 'Sentence Encoders on STILTs: Supplementary Training on Intermediate Labeled-data Tasks', 'paperID': 'b47381e04739ea3f392ba6c8faaf64105493c196', 'arxivId': '1811.01088', 'publication_year': 2018, 'abstract': None}
{'title': 'The Hitchhiker’s Guide to Testing Statistical Significance in Natural Language Processing', 'paperID': 'd10df96b3fb0ab5c6b1d0cc22c7400d0acccc3cc', 'arxivId': None, 'publication_year': 2018, 'abstract': None}
{'title': 'Know What You Don’t Know: Unanswerable Questions for SQuAD', 'paperID': '4d1c856275744c0284312a3a50efb6ca9dc4cd4c', 'arxivId': '1806.03822', 'publication_year': 2018, 'abstract': None}
{'title': 'Stress Test Evaluation for Natural Language Inference', 'paperID': '175b58fe7e49bb5c0c771b73f8834bcff21b59c7', 'arxivId': '1806.00692', 'publication_year': 2018, 'abstract': None}
{'title': 'Neural Network Acceptability Judgments', 'paperID': 'cb0f3ee1e98faf92429d601cdcd76c69c1e484eb', 'arxivId': '1805.12471', 'publication_year': 2018, 'abstract': None}
{'title': 'Gender Bias in Coreference Resolution', 'paperID': '9967cb4fd949039c6f04dd9f2f4c3331dbebe6f7', 'arxivId': '1804.09301', 'publication_year': 2018, 'abstract': None}
{'title': 'GLUE: A Multi-Task Benchmark and Analysis Platform for Natural Language Understanding', 'paperID': '451d4a16e425ecbf38c4b1cca0dcf5d9bec8255c', 'arxivId': '1804.07461', 'publication_year': 2018, 'abstract': None}
{'title': 'A SIMPLE PROOF OF THE STRONG LAW OF LARGE NUMBERS WITH RATES', 'paperID': '8cb87626ceab76f8f90e0aeacde868d562a146a1', 'arxivId': None, 'publication_year': 2018, 'abstract': None}
{'title': 'SemEval-2017 Task 1: Semantic Textual Similarity Multilingual and Crosslingual Focused Evaluation', 'paperID': 'a23fa96e7217ba0e9405d9e1fe3cdedd57b6e096', 'arxivId': '1708.00055', 'publication_year': 2017, 'abstract': None}
{'title': 'Aligning Books and Movies: Towards Story-Like Visual Explanations by Watching Movies and Reading Books', 'paperID': '0e6824e137847be0599bb0032e37042ed2ef5045', 'arxivId': '1506.06724', 'publication_year': 2015, 'abstract': None}
{'title': 'What’s in a p-value in NLP?', 'paperID': '0db4e6f24f1e56f9c2cc5d7cfb6adae858f6fb19', 'arxivId': None, 'publication_year': 2014, 'abstract': None}
{'title': 'An Empirical Investigation of Statistical Significance in NLP', 'paperID': '645c9d018d6379a4c2eed5ab2f62aeb5629544ce', 'arxivId': None, 'publication_year': 2012, 'abstract': None}
{'title': 'Bootstrapping clustered data', 'paperID': '20268778b9cfef7211121ea01675c7c14ee45415', 'arxivId': None, 'publication_year': 2007, 'abstract': None}
{'title': 'OntoNotes: The 90% Solution', 'paperID': 'e54d8b07ef659f9ee2671441c4355e414e408836', 'arxivId': None, 'publication_year': 2006, 'abstract': None}
{'title': 'Statistical Significance Tests for Machine Translation Evaluation', 'paperID': 'cb826a3899752b796f14df1c50378c64954a6b0a', 'arxivId': None, 'publication_year': 2004, 'abstract': None}
{'title': 'Bleu: a Method for Automatic Evaluation of Machine Translation', 'paperID': 'd7da009f457917aa381619facfa5ffae9329a6e9', 'arxivId': None, 'publication_year': 2002, 'abstract': None}
{'title': 'Gender bias', 'paperID': 'b8894e5b2d3afde2142b7ae49d4ba08b77984b29', 'arxivId': None, 'publication_year': 1998, 'abstract': None}
{'title': 'Weak Convergence and Empirical Processes: With Applications to Statistics', 'paperID': '45ee7447b9dd406496c4a5d9d8fb6556366a01c6', 'arxivId': None, 'publication_year': 1996, 'abstract': None}
{'title': 'Marcinkiewicz-type strong laws for partially exchangeable arrays', 'paperID': 'e3649e2b89a3aabd4c3b13289f49353bffcbe66d', 'arxivId': None, 'publication_year': 1991, 'abstract': None}
{'title': 'An elementary proof of the strong law of large numbers', 'paperID': 'e61cd2d6b8cd9e964d2fb01146d20aca606d9e87', 'arxivId': None, 'publication_year': 1981, 'abstract': None}
{'title': 'The mean difference and the mean deviation of some discontinuous distributions', 'paperID': '0e72382cdd4b8e4064e2cc14febfda29540a4da6', 'arxivId': None, 'publication_year': 1958, 'abstract': None}
{'title': 'Les probabilités dénombrables et leurs applications arithmétiques', 'paperID': '4499bc6fa534c9b22241eb6f5a39a09dd2fa1905', 'arxivId': None, 'publication_year': 1909, 'abstract': None}
{'title': 'Investigating Learning Dynamics of BERT Fine-Tuning', 'paperID': '888c3a3788c52d6637d45dc4238691083884589d', 'arxivId': None, 'publication_year': 2020, 'abstract': None}
{'title': 'Quora Question Pairs', 'paperID': '8ff46c88964a36985f2b45933a3d47b81bd87bd0', 'arxivId': None, 'publication_year': 2017, 'abstract': None}
{'title': 'The Sixth PASCAL Recognizing Textual Entailment Challenge', 'paperID': 'db8885a0037fe47d973ade79d696586453710233', 'arxivId': None, 'publication_year': 2009, 'abstract': None}
{'title': 'The Fourth PASCAL Recognizing Textual Entailment Challenge', 'paperID': '351ec42df2b60c6042addf96e6b98673bbaf4dfd', 'arxivId': None, 'publication_year': 2008, 'abstract': None}
{'title': 'An Introduction to the Bootstrap', 'paperID': '75f8a4d7ed6a0f32fa098cac967de247938d9ce5', 'arxivId': None, 'publication_year': 2007, 'abstract': None}
{'title': 'Automatically Constructing a Corpus of Sentential Paraphrases', 'paperID': '475354f10798f110d34792b6d88f31d6d5cb099e', 'arxivId': None, 'publication_year': 2005, 'abstract': None}
{'title': 'Sampling techniques.', 'paperID': '35a1f341ac3453cc4982b8c13d9169119cf9a893', 'arxivId': None, 'publication_year': 2000, 'abstract': None}
{'title': 'Edinburgh Research Explorer Understanding Learning Dynamics Of Language Models with SVCCA', 'paperID': '859093f5cae3dd580ae34e39fbef19a8c89fd85f', 'arxivId': None, 'publication_year': None, 'abstract': None}
{'title': 'The MultiBERTs: BERT Reproductions for Robustness Analysis', 'paperID': '5b540745f4b51f95bf90fb3420e51edb037fc51a', 'arxivId': '2106.16163', 'publication_year': '2021', 'abstract': 'Experiments with pre-trained models such as BERT are often based on a single checkpoint. While the conclusions drawn apply to the artifact tested in the experiment (i.e., the particular instance of the model), it is not always clear whether they hold for the more general procedure which includes the architecture, training data, initialization scheme, and loss function. Recent work has shown that repeating the pre-training process can lead to substantially different performance, suggesting that an alternate strategy is needed to make principled statements about procedures. To enable researchers to draw more robust conclusions, we introduce the MultiBERTs, a set of 25 BERT-Base checkpoints, trained with similar hyper-parameters as the original BERT model but differing in random weight initialization and shuffling of training data. We also define the Multi-Bootstrap, a non-parametric bootstrap method for statistical inference designed for settings where there are multiple pre-trained models and limited test data. To illustrate our approach, we present a case study of gender bias in coreference resolution, in which the Multi-Bootstrap lets us measure effects that may not be detected with a single checkpoint. We release our models and statistical library along with an additional set of 140 intermediate checkpoints captured during pre-training to facilitate research on learning dynamics.'}
{'title': 'Examining and Combating Spurious Features under Distribution Shift', 'paperID': '714fc6626c527e05f2a31626d067d46520c6740e', 'arxivId': '2106.07171', 'publication_year': 2021, 'abstract': None}
{'title': 'DORO: Distributional and Outlier Robust Optimization', 'paperID': '984f00eb0fa62a91d9b4168190218d85eaaa9ae1', 'arxivId': '2106.06142', 'publication_year': 2021, 'abstract': None}
{'title': 'Predict then Interpolate: A Simple Algorithm to Learn Stable Classifiers', 'paperID': '791ad7876370704b69184927403dc8eefb7c3f33', 'arxivId': '2105.12628', 'publication_year': 2021, 'abstract': None}
{'title': 'A Too-Good-to-be-True Prior to Reduce Shortcut Reliance', 'paperID': '2263df3f2a10f43876aa280442f14090a9098369', 'arxivId': '2102.06406', 'publication_year': 2021, 'abstract': None}
{'title': 'On Negative Interference in Multilingual Language Models', 'paperID': '553028f7f7c850371379c621e40d7d00e75303a6', 'arxivId': '2010.03017', 'publication_year': 2020, 'abstract': None}
{'title': 'Characterizing and Avoiding Negative Transfer', 'paperID': '57eedf785fd9e3ea28b4cd30539cb0fa374f9e74', 'arxivId': '1811.09751', 'publication_year': 2018, 'abstract': None}
{'title': 'Learning to select data for transfer learning with Bayesian Optimization', 'paperID': '5f7b1cf0323893735220332ef6aecbff90f3d44b', 'arxivId': '1707.05246', 'publication_year': 2017, 'abstract': None}
{'title': 'Systematic generalisation with group invariant predictions', 'paperID': '359c56a068e4a84a9f3b78f43b53fe3b333c0ba0', 'arxivId': None, 'publication_year': 2021, 'abstract': None}
{'title': 'Overparameterisation and worst-case generalisation: friend or foe?', 'paperID': '0aae10ade8fc9e58e177e034b794fce45c32fde8', 'arxivId': None, 'publication_year': 2021, 'abstract': None}
{'title': 'Focus on the Common Good: Group Distributional Robustness Follows', 'paperID': '1e57462f93d78279549a8508e691dc4920151b35', 'arxivId': '2110.02619', 'publication_year': '2021', 'abstract': 'We consider the problem of training a classification model with group annotated training data. Recent work has established that, if there is distribution shift across different groups, models trained using the standard empirical risk minimization (ERM) objective suffer from poor performance on minority groups and that group distributionally robust optimization (Group-DRO) objective is a better alternative. The starting point of this paper is the observation that though Group-DRO performs better than ERM on minority groups for some benchmark datasets, there are several other datasets where it performs much worse than ERM. Inspired by ideas from the closely related problem of domain generalization, this paper proposes a new and simple algorithm that explicitly encourages learning of features that are shared across various groups. The key insight behind our proposed algorithm is that while Group-DRO focuses on groups with worst regularized loss, focusing instead, on groups that enable better performance even on other groups, could lead to learning of shared/common features, thereby enhancing minority performance beyond what is achieved by Group-DRO. Empirically, we show that our proposed algorithm matches or achieves better performance compared to strong contemporary baselines including ERM and Group-DRO on standard benchmarks on both minority groups and across all groups. Theoretically, we show that the proposed algorithm is a descent method and finds first order stationary points of smooth nonconvex functions.'}
{'title': 'Pervasive Label Errors in Test Sets Destabilize Machine Learning Benchmarks', 'paperID': 'a4f9e7e695bba1ffb90b30752a40d5ee907dcb36', 'arxivId': '2103.14749', 'publication_year': 2021, 'abstract': None}
{'title': 'Improved Estimation of Concentration Under $\\ell_p$-Norm Distance Metrics Using Half Spaces', 'paperID': 'ba8d84deb3633076a135e6b885da609eb7b1c7e0', 'arxivId': '2103.12913', 'publication_year': 2021, 'abstract': None}
{'title': 'RobustBench: a standardized adversarial robustness benchmark', 'paperID': '2aab97e35c43d961d645e650808d5b052ec180ab', 'arxivId': '2010.09670', 'publication_year': 2020, 'abstract': None}
{'title': 'Understanding the Intrinsic Robustness of Image Distributions using Conditional Generative Models', 'paperID': '2c624c74f64ea60402c155deeca5877a85fb9587', 'arxivId': '2003.00378', 'publication_year': 2020, 'abstract': None}
{'title': 'Confident Learning: Estimating Uncertainty in Dataset Labels', 'paperID': 'cbaaa1154c491f9da2f050d3c22970e15bb7b52b', 'arxivId': '1911.00068', 'publication_year': 2019, 'abstract': None}
{'title': 'Scalable Verified Training for Provably Robust Image Classification', 'paperID': 'c9d239db4ab86522a6fdecb86116d1083a48823c', 'arxivId': None, 'publication_year': 2019, 'abstract': None}
{'title': 'Lower Bounds on Adversarial Robustness from Optimal Transport', 'paperID': '2f255dcc2f28c11ea3b2888f537dbf9916abcc02', 'arxivId': '1909.12272', 'publication_year': 2019, 'abstract': None}
{'title': 'Human Uncertainty Makes Classification More Robust', 'paperID': 'd2a2be6ce932a0f1939f31cfff4d64ea3d76723d', 'arxivId': '1908.07086', 'publication_year': 2019, 'abstract': None}
{'title': 'Empirically Measuring Concentration: Fundamental Limits on Intrinsic Robustness', 'paperID': '30fabb3369cda7c1d515c87bf453a3ebd61e149e', 'arxivId': '1905.12202', 'publication_year': 2019, 'abstract': None}
{'title': 'Understanding the (un)interpretability of natural image distributions using generative models', 'paperID': 'ceb5e51c800e1d243f406da5d004bb39e7f4b6be', 'arxivId': '1901.01499', 'publication_year': 2019, 'abstract': None}
{'title': 'Generalized No Free Lunch Theorem for Adversarial Robustness', 'paperID': '15c1e7166708737d87545eae8f37f302599f61e1', 'arxivId': None, 'publication_year': 2018, 'abstract': None}
{'title': 'The Curse of Concentration in Robust Learning: Evasion and Poisoning Attacks from Concentration of Measure', 'paperID': '88311ee3fbb9d8d307386c0fb53aaa0283c5eb74', 'arxivId': '1809.03063', 'publication_year': 2018, 'abstract': None}
{'title': 'Are adversarial examples inevitable?', 'paperID': 'fd02c5b49bab02fb814c6999ebf161f3be377c75', 'arxivId': '1809.02104', 'publication_year': 2018, 'abstract': None}
{'title': 'Deep Label Distribution Learning With Label Ambiguity', 'paperID': 'e9b5098f6083585c15f9a6315f457db98086bf82', 'arxivId': '1611.01731', 'publication_year': 2016, 'abstract': None}
{'title': 'Label Distribution Learning', 'paperID': 'a4b4baa5d861347c21b435d938d84e5ac0ded9f2', 'arxivId': '1408.6027', 'publication_year': 2013, 'abstract': None}
{'title': 'The VC dimension of k-fold union', 'paperID': '219f2f413cf2fa2e17ba763a417b25d2e4a5247d', 'arxivId': None, 'publication_year': 2007, 'abstract': None}
{'title': 'Concentration of measure and isoperimetric inequalities in product spaces', 'paperID': '1179f0698939f0ed10f144fb87dbbb70f124525d', 'arxivId': 'math/9406212', 'publication_year': 1994, 'abstract': None}
{'title': 'The Brunn-Minkowski inequality in Gauss space', 'paperID': '5f82a74801c38b2b8cf5cb836e1de233ead164e6', 'arxivId': None, 'publication_year': 1975, 'abstract': None}
{'title': 'A Probabilistic Theory of Pattern Recognition', 'paperID': '43fcdee6c6d885ac2bd32e122dbf282f93720c22', 'arxivId': None, 'publication_year': 1996, 'abstract': None}
{'title': 'Isoperimetry and Gaussian analysis', 'paperID': 'a38b2bd0ea02ae33237fbeb3d03db0f088e725de', 'arxivId': None, 'publication_year': 1996, 'abstract': None}
{'title': 'Extremal properties of half-spaces for spherically invariant measures', 'paperID': '135f43022b71acf6dce63514b1740aee9f358937', 'arxivId': None, 'publication_year': 1978, 'abstract': None}
{'title': 'Understanding Intrinsic Robustness Using Label Uncertainty', 'paperID': '1d05745fddf59153931976d07468e710b6ef3939', 'arxivId': '2107.03250', 'publication_year': '2021', 'abstract': 'A fundamental question in adversarial machine learning is whether a robust classifier exists for a given task. A line of research has made some progress towards this goal by studying the concentration of measure, but we argue standard concentration fails to fully characterize the intrinsic robustness of a classification problem since it ignores data labels which are essential to any classification task. Building on a novel definition of label uncertainty, we empirically demonstrate that error regions induced by state-of-the-art models tend to have much higher label uncertainty than randomly-selected subsets. This observation motivates us to adapt a concentration estimation algorithm to account for label uncertainty, resulting in more accurate intrinsic robustness measures for benchmark image classification problems.'}
{'title': 'Output Diversified Initialization for Adversarial Attacks', 'paperID': '042f60694b8955f176057efd87b713815ede260c', 'arxivId': '2003.06878', 'publication_year': 2020, 'abstract': None}
{'title': 'Certified Defenses for Adversarial Patches', 'paperID': '4c9ee8358d82afa960708391e2b8e83c4a737ae9', 'arxivId': '2003.06693', 'publication_year': 2020, 'abstract': None}
{'title': 'Provable Robust Learning Based on Transformation-Specific Smoothing', 'paperID': '8ab4cf57fa4464a594638b9d684071def6db6d0b', 'arxivId': None, 'publication_year': 2020, 'abstract': None}
{'title': 'Certified Defense to Image Transformations via Randomized Smoothing', 'paperID': '163ead56c23d6b0f5df5f24f7dc74ef82cb41eb3', 'arxivId': '2002.12463', 'publication_year': 2020, 'abstract': None}
{'title': 'A New Defense Against Adversarial Images: Turning a Weakness into a Strength', 'paperID': 'e9382c9150cd53289ea7af0b1dafd1a0bb9dbd12', 'arxivId': '1910.07629', 'publication_year': 2019, 'abstract': None}
{'title': 'Enhancing Gradient-based Attacks with Symbolic Intervals', 'paperID': '45a0d88560840ea2a352ae6dd3919d40f3ab2778', 'arxivId': '1906.02282', 'publication_year': 2019, 'abstract': None}
{'title': 'Enhancing Adversarial Defense by k-Winners-Take-All', 'paperID': '649de559f530aab8f22f6022d40cdfd3bb4e1039', 'arxivId': '1905.10510', 'publication_year': 2019, 'abstract': None}
{'title': 'Property Inference for Deep Neural Networks', 'paperID': '1da3aab62fc3d4540b36c851df7993c53441d2a7', 'arxivId': None, 'publication_year': 2019, 'abstract': None}
{'title': 'On Certifying Non-uniform Bound against Adversarial Attacks', 'paperID': '23da4126cedfb52858a2e320ab28b1df774d7836', 'arxivId': '1903.06603', 'publication_year': 2019, 'abstract': None}
{'title': 'Theory of linear and integer programming', 'paperID': '3ce2d233cee585ecff73729836918ba87195c18f', 'arxivId': None, 'publication_year': 1986, 'abstract': None}
{'title': 'Certified Defenses: Why Tighter Relaxations May Hurt Training?', 'paperID': '0ae5e6f0a656aa5a133485b498a2386942821786', 'arxivId': None, 'publication_year': 2021, 'abstract': None}
{'title': 'Provably Robust Adversarial Examples', 'paperID': '7cb6a6369c6b01de8f88539687cb4acc121edb94', 'arxivId': '2007.12133', 'publication_year': '2020', 'abstract': "We introduce the concept of provably robust adversarial examples for deep neural networks - connected input regions constructed from standard adversarial examples which are guaranteed to be robust to a set of real-world perturbations (such as changes in pixel intensity and geometric transformations). We present a novel method called PARADE for generating these regions in a scalable manner which works by iteratively refining the region initially obtained via sampling until a refined region is certified to be adversarial with existing state-of-the-art verifiers. At each step, a novel optimization procedure is applied to maximize the region's volume under the constraint that the convex relaxation of the network behavior with respect to the region implies a chosen bound on the certification objective. Our experimental evaluation shows the effectiveness of PARADE: it successfully finds large provably robust regions including ones containing $\\approx 10^{573}$ adversarial examples for pixel intensity and $\\approx 10^{599}$ for geometric perturbations. The provability enables our robust examples to be significantly more effective against state-of-the-art defenses based on randomized smoothing than the individual attacks used to construct the regions."}
{'title': 'Coarsening the Granularity: Towards Structurally Sparse Lottery Tickets', 'paperID': 'e468f74ebffa8bbdd99bf8d0233822a1d2a9b430', 'arxivId': '2202.04736', 'publication_year': 2022, 'abstract': None}
{'title': 'You are caught stealing my winning lottery ticket! Making a lottery ticket claim its ownership', 'paperID': '756eac52299df7c1e525e72bb53a6e0ececdcf01', 'arxivId': '2111.00162', 'publication_year': 2021, 'abstract': None}
{'title': 'Drawing Robust Scratch Tickets: Subnetworks with Inborn Robustness Are Found within Randomly Initialized Networks', 'paperID': 'ffbcbced0ec14a9267f185be87d9386407640a11', 'arxivId': '2110.14068', 'publication_year': 2021, 'abstract': None}
{'title': 'Revisiting Adversarial Robustness Distillation: Robust Soft Labels Make Student Better', 'paperID': '5c493a976f724ea8f238509f6fe087a7bde8c93d', 'arxivId': '2108.07969', 'publication_year': 2021, 'abstract': None}
{'title': 'Training Adversarially Robust Sparse Networks via Bayesian Connectivity Sampling', 'paperID': '7a9ac680f286f56cd9206111416733bf0845618b', 'arxivId': None, 'publication_year': 2021, 'abstract': None}
{'title': 'Connectivity Matters: Neural Network Pruning Through the Lens of Effective Sparsity', 'paperID': '4ecb57ba76714ed4f14d11d3b30548225b2f15bc', 'arxivId': '2107.02306', 'publication_year': 2021, 'abstract': None}
{'title': 'Improving White-box Robustness of Pre-processing Defenses via Joint Adversarial Training', 'paperID': 'd4788b3996a5ec681ec72373111035f6d84da4f6', 'arxivId': '2106.05453', 'publication_year': 2021, 'abstract': None}
{'title': 'Top-KAST: Top-K Always Sparse Training', 'paperID': '9c4dd36ad206ca8be96ae4000568e899f4acfa91', 'arxivId': '2106.03517', 'publication_year': 2021, 'abstract': None}
{'title': 'Efficient Lottery Ticket Finding: Less Data is More', 'paperID': '6bc4681828143f5ecc49b7ecd388a86c70c7237a', 'arxivId': '2106.03225', 'publication_year': 2021, 'abstract': None}
{'title': 'Exploring Memorization in Adversarial Training', 'paperID': 'abbe3a82bb11a9f28eba39ff6dc17982a724c2fd', 'arxivId': '2106.01606', 'publication_year': 2021, 'abstract': None}
{'title': 'GANs Can Play Lottery Tickets Too', 'paperID': '23fa2f604f73785b638eb49df4c1bbf293e16cd5', 'arxivId': '2106.00134', 'publication_year': 2021, 'abstract': None}
{'title': 'Playing Lottery Tickets with Vision and Language', 'paperID': '22299b440277b4bc887168a669408d5547c1461a', 'arxivId': '2104.11832', 'publication_year': 2021, 'abstract': None}
{'title': 'Relating Adversarially Robust Generalization to Flat Minima', 'paperID': '0563077a0dbd532c19e35e60e7188ba661fb886e', 'arxivId': '2104.04448', 'publication_year': 2021, 'abstract': None}
{'title': 'Adversarially Optimized Mixup for Robust Classification', 'paperID': '009fae4facad32774d1acc61c3a779d646bc1c55', 'arxivId': '2103.11589', 'publication_year': 2021, 'abstract': None}
{'title': 'Consistency Regularization for Adversarial Robustness', 'paperID': '33ca8d34d226e47e0830b6eb73c06e0b85ae7ab7', 'arxivId': '2103.04623', 'publication_year': 2021, 'abstract': None}
{'title': 'Guided Interpolation for Adversarial Training', 'paperID': '5dbc41ce67d979a1e3b7099577a4827c99119d3b', 'arxivId': '2102.07327', 'publication_year': 2021, 'abstract': None}
{'title': 'Low Curvature Activations Reduce Overfitting in Adversarial Training', 'paperID': 'cb0691748506ab827f6f03fafbabb4141d22ca79', 'arxivId': '2102.07861', 'publication_year': 2021, 'abstract': None}
{'title': 'A Unified Lottery Ticket Hypothesis for Graph Neural Networks', 'paperID': '01217fd88d07b05affa75213672d3d31dbcb6617', 'arxivId': '2102.06790', 'publication_year': 2021, 'abstract': None}
{'title': 'Do We Actually Need Dense Over-Parameterization? In-Time Over-Parameterization in Sparse Training', 'paperID': '229a4d27d04bd3901ef0ca41942eb0cdd4f28eed', 'arxivId': '2102.02887', 'publication_year': 2021, 'abstract': None}
{'title': 'Selfish Sparse RNN Training', 'paperID': '4df2175c0daadf630623a505f623fe41a386853d', 'arxivId': '2101.09048', 'publication_year': 2021, 'abstract': None}
{'title': 'The Lottery Tickets Hypothesis for Supervised and Self-supervised Pre-training in Computer Vision Models', 'paperID': '5f6fccc32953f57fe29b2316eb8351e84b0179dc', 'arxivId': '2012.06908', 'publication_year': 2020, 'abstract': None}
{'title': 'Bag of Tricks for Adversarial Training', 'paperID': '67f74fe9d46f88661573003f8f1f12967ae49fa3', 'arxivId': '2010.00467', 'publication_year': 2020, 'abstract': None}
{'title': 'Procrustes: a Dataflow and Accelerator for Sparse Deep Neural Network Training', 'paperID': '9bc25860c60974331283216ef16425095477f84a', 'arxivId': '2009.10976', 'publication_year': 2020, 'abstract': None}
{'title': 'The Lottery Ticket Hypothesis for Pre-trained BERT Networks', 'paperID': '389036b1366b64579725457993c1f63a4f3370ba', 'arxivId': '2007.12223', 'publication_year': 2020, 'abstract': None}
{'title': 'Steepest Descent Neural Architecture Optimization: Escaping Local Optimum with Signed Neural Splitting', 'paperID': '63c9a825d002a376c1cfeb5cde0e231fb4669814', 'arxivId': '2003.10392', 'publication_year': 2020, 'abstract': None}
{'title': 'Towards Practical Lottery Ticket Hypothesis for Adversarial Training', 'paperID': '3a1e9670446a39bb26e8265e78caef0ed11b9a54', 'arxivId': '2003.05733', 'publication_year': 2020, 'abstract': None}
{'title': 'Comparing Rewinding and Fine-tuning in Neural Network Pruning', 'paperID': '850464c9006261bd632c4203f3e630db09a32faf', 'arxivId': '2003.02389', 'publication_year': 2020, 'abstract': None}
{'title': 'Sparse Weight Activation Training', 'paperID': '52184d7a541eff0b9537e75da7327dd41daba207', 'arxivId': '2001.01969', 'publication_year': 2020, 'abstract': None}
{'title': 'Linear Mode Connectivity and the Lottery Ticket Hypothesis', 'paperID': '3f06d02513a2763e472d2b5d5db08e9061081b9e', 'arxivId': '1912.05671', 'publication_year': 2019, 'abstract': None}
{'title': 'Rigging the Lottery: Making All Tickets Winners', 'paperID': '2e3002f131e1815bda7a10303eff97f79dea01ec', 'arxivId': '1911.11134', 'publication_year': 2019, 'abstract': None}
{'title': 'Splitting Steepest Descent for Growing Neural Architectures', 'paperID': 'a29c3bb07d478a354fd5bc5635f98560ede8f8bb', 'arxivId': '1910.02366', 'publication_year': 2019, 'abstract': None}
{'title': 'Drawing early-bird tickets: Towards more efficient training of deep networks', 'paperID': '336868be817536e7c7fc88c391a2860cd869ea2b', 'arxivId': '1909.11957', 'publication_year': 2019, 'abstract': None}
{'title': 'Comparing Rewinding and Fine-tuning in Neural Network Pruning', 'paperID': '30b2c7dfec16457aeb7e6f6e6e12af0300f2fef4', 'arxivId': None, 'publication_year': 2019, 'abstract': None}
{'title': 'Sparse Networks from Scratch: Faster Training without Losing Performance', 'paperID': '60ed82ca3ec8fbfef4d52e98e49ab687ce501a0c', 'arxivId': '1907.04840', 'publication_year': 2019, 'abstract': None}
{'title': 'Towards Compact and Robust Deep Neural Networks', 'paperID': '7139d823ad17ba2c958ec0f821c4bbcd69c92a69', 'arxivId': '1906.06110', 'publication_year': 2019, 'abstract': None}
{'title': 'Adversarial Risk Bounds for Neural Networks through Sparsity based Compression', 'paperID': 'c96bcdd27aaa365a770d4a6c739e1a374a441cb1', 'arxivId': '1906.00698', 'publication_year': 2019, 'abstract': None}
{'title': 'Importance Estimation for Neural Network Pruning', 'paperID': 'a6f4917d043494d2ebaebe6b65cb35e6a07fda41', 'arxivId': '1906.10771', 'publication_year': 2019, 'abstract': None}
{'title': 'The Difficulty of Training Sparse Neural Networks', 'paperID': 'dd7bae431e0e4d94f24d54b0ac3a422703d38ed3', 'arxivId': '1906.10732', 'publication_year': 2019, 'abstract': None}
{'title': 'Parameter Efficient Training of Deep Convolutional Neural Networks by Dynamic Sparse Reparameterization', 'paperID': '8e2c65ff58b28a076883c99b96840e19b5e0b916', 'arxivId': '1902.05967', 'publication_year': 2019, 'abstract': None}
{'title': 'Critical Learning Periods in Deep Networks', 'paperID': '1802a7870a642d414f435273dd9e9190a0dc4fcb', 'arxivId': None, 'publication_year': 2018, 'abstract': None}
{'title': 'ADAM-ADMM: A Unified, Systematic Framework of Structured Weight Pruning for DNNs', 'paperID': '64db2e2c76aa3f028b6866f91795a7c005a3f13b', 'arxivId': None, 'publication_year': 2018, 'abstract': None}
{'title': 'Learning Efficient Convolutional Networks through Network Slimming', 'paperID': '90a16f34d109b63d95ab4da2d491cbe3a1c8b656', 'arxivId': '1708.06519', 'publication_year': 2017, 'abstract': None}
{'title': 'Channel Pruning for Accelerating Very Deep Neural Networks', 'paperID': 'ee53c9480132fc0d09b1192226cb2c460462fd6d', 'arxivId': '1707.06168', 'publication_year': 2017, 'abstract': None}
{'title': 'DeepCloak: Masking Deep Neural Network Models for Robustness Against Adversarial Samples', 'paperID': 'ee48b932a60085d7fd5540637540509144b07030', 'arxivId': '1702.06763', 'publication_year': 2017, 'abstract': None}
{'title': 'Variational Dropout Sparsifies Deep Neural Networks', 'paperID': '34cc3ceae5c3f7c8acbb89f2bff63f9d452b00d5', 'arxivId': '1701.05369', 'publication_year': 2017, 'abstract': None}
{'title': 'Less Is More: Towards Compact CNNs', 'paperID': '3ed94217fbf29b86d5f1baec90dc33adacb40b58', 'arxivId': None, 'publication_year': 2016, 'abstract': None}
{'title': 'A topological insight into restricted Boltzmann machines', 'paperID': '0a33c01af2e563dd8e2a6f131fc8ba7943702469', 'arxivId': '1604.05978', 'publication_year': 2016, 'abstract': None}
{'title': 'Deep Compression: Compressing Deep Neural Network with Pruning, Trained Quantization and Huffman Coding', 'paperID': '642d0f49b7826adcf986616f4af77e736229990f', 'arxivId': '1510.00149', 'publication_year': 2015, 'abstract': None}
{'title': 'Long Live the Lottery: The Existence of Winning Tickets in Lifelong Learning', 'paperID': '05e2ca9357bcf542a33b3f97310d9f477cd0776f', 'arxivId': None, 'publication_year': 2021, 'abstract': None}
{'title': 'NoiLIn: Do Noisy Labels Always Hurt Adversarial Training?', 'paperID': '8d0cd2e89afc2aae9a1637b0b53b656cc7e7dd76', 'arxivId': None, 'publication_year': 2021, 'abstract': None}
{'title': 'Ultra-Data-Efficient GAN Training: Drawing A Lottery Ticket First, Then Training It Toughly', 'paperID': 'd5906006e6efc5dbc02878d76407326eb56c363a', 'arxivId': None, 'publication_year': 2021, 'abstract': None}
{'title': 'Why Lottery Ticket Wins? A Theoretical Perspective of Sample Complexity on Sparse Neural Networks', 'paperID': '3c9c6e623391d9265058b6d452a39ad78f0a251c', 'arxivId': None, 'publication_year': 2021, 'abstract': None}
{'title': 'Universality of Deep Neural Network Lottery Tickets: A Renormalization Group Perspective', 'paperID': '6ee98d9b218fcace923fe5fef742cee54ebd32f3', 'arxivId': None, 'publication_year': 2021, 'abstract': None}
{'title': 'Sparsity Winning Twice: Better Robust Generalization from More Efficient Training', 'paperID': '01594f00b0deed32cba4fc4ea8c74b60be31db4a', 'arxivId': '2202.09844', 'publication_year': '2022', 'abstract': 'Recent studies demonstrate that deep networks, even robustified by the state-of-the-art adversarial training (AT), still suffer from large robust generalization gaps, in addition to the much more expensive training costs than standard training. In this paper, we investigate this intriguing problem from a new perspective, i.e., injecting appropriate forms of sparsity during adversarial training. We introduce two alternatives for sparse adversarial training: (i) static sparsity, by leveraging recent results from the lottery ticket hypothesis to identify critical sparse subnetworks arising from the early training; (ii) dynamic sparsity, by allowing the sparse subnetwork to adaptively adjust its connectivity pattern (while sticking to the same sparsity ratio) throughout training. We find both static and dynamic sparse methods to yield win-win: substantially shrinking the robust generalization gap and alleviating the robust overfitting, meanwhile significantly saving training and inference FLOPs. Extensive experiments validate our proposals with multiple network architectures on diverse datasets, including CIFAR-10/100 and Tiny-ImageNet. For example, our methods reduce robust generalization gap and overfitting by 34.44% and 4.02%, with comparable robust/standard accuracy boosts and 87.83%/87.82% training/inference FLOPs savings on CIFAR-100 with ResNet-18. Besides, our approaches can be organically combined with existing regularizers, establishing new state-of-the-art results in AT. Codes are available in https://github.com/VITA-Group/Sparsity-Win-Robust-Generalization.'}
{'title': 'Robust Unlearnable Examples: Protecting Data Privacy Against Adversarial Learning', 'paperID': 'f943391013a0436b084d6e11b8527e1465cfff53', 'arxivId': None, 'publication_year': None, 'abstract': None}
{'title': 'Searching for an Effective Defender: Benchmarking Defense against Adversarial Word Substitution', 'paperID': '31e46ed4722a4895a19eda37dbc02da55572783a', 'arxivId': '2108.12777', 'publication_year': 2021, 'abstract': None}
{'title': 'Knowledgeable Prompt-tuning: Incorporating Knowledge into Prompt Verbalizer for Text Classification', 'paperID': '6f0aba8102d63938ce0b48ec23ff5ddd8110f2e8', 'arxivId': '2108.02035', 'publication_year': 2021, 'abstract': None}
{'title': 'Scientific Credibility of Machine Translation Research: A Meta-Evaluation of 769 Papers', 'paperID': 'e399e78f2c236802aa50aef95554a3768079edb1', 'arxivId': '2106.15195', 'publication_year': 2021, 'abstract': None}
{'title': 'Multimodal Few-Shot Learning with Frozen Language Models', 'paperID': '01b5412f3d17e90e09226d7c40ad4d4468a1414d', 'arxivId': '2106.13884', 'publication_year': 2021, 'abstract': None}
{'title': 'A Survey of Race, Racism, and Anti-Racism in NLP', 'paperID': '353c88c231ce156d604e074af276422422fc73f7', 'arxivId': '2106.11410', 'publication_year': 2021, 'abstract': None}
{'title': 'Grey-box Adversarial Attack And Defence For Sentiment Classification', 'paperID': 'e837660da43eb9637fa33aee3b58599e438d1f5f', 'arxivId': '2103.11576', 'publication_year': 2021, 'abstract': None}
{'title': 'Model Extraction and Adversarial Transferability, Your BERT is Vulnerable!', 'paperID': '16a8e329c06b4c6f61762da7fa77a84bf3e12dca', 'arxivId': '2103.10013', 'publication_year': 2021, 'abstract': None}
{'title': 'T-Miner: A Generative Approach to Defend Against Trojan Attacks on DNN-based Text Classification', 'paperID': '3ab9145d5134e4e89bcceb1c8a95f9f98c98c5ff', 'arxivId': '2103.04264', 'publication_year': 2021, 'abstract': None}
{'title': 'Unifying Vision-and-Language Tasks via Text Generation', 'paperID': 'a6ca91afe845ef5294c40c2029e0c1cba19ba40b', 'arxivId': '2102.02779', 'publication_year': 2021, 'abstract': None}
{'title': 'Making Pre-trained Language Models Better Few-shot Learners', 'paperID': '85e7d63f75c0916bd350a229e040c5fbb1472e7a', 'arxivId': '2012.15723', 'publication_year': 2021, 'abstract': None}
{'title': 'WARP: Word-level Adversarial ReProgramming', 'paperID': '5a2e45ce35fb26ab70a61b424a49f8e5b4532a8e', 'arxivId': '2101.00121', 'publication_year': 2021, 'abstract': None}
{'title': 'Better Robustness by More Coverage: Adversarial and Mixup Data Augmentation for Robust Finetuning', 'paperID': 'c5662edb2182b5e27eb73d1187c37db28c98fba6', 'arxivId': '2012.15699', 'publication_year': 2020, 'abstract': None}
{'title': 'A Sweet Rabbit Hole by DARCY: Using Honeypots to Detect Universal Trigger’s Adversarial Attacks', 'paperID': 'c94529aff09763b607b7594197f1bbf01c006759', 'arxivId': '2011.10492', 'publication_year': 2020, 'abstract': None}
{'title': 'mT5: A Massively Multilingual Pre-trained Text-to-Text Transformer', 'paperID': '74276a37bfa50f90dfae37f767b2b67784bd402a', 'arxivId': '2010.11934', 'publication_year': 2020, 'abstract': None}
{'title': 'OpenAttack: An Open-source Textual Adversarial Attack Toolkit', 'paperID': '95968b89040146cb015827aee8ff6f77d67bbaf1', 'arxivId': '2009.09191', 'publication_year': 2020, 'abstract': None}
{'title': 'Array programming with NumPy', 'paperID': '024a2c03be8e468e7c4fdf9bda36cdc0eaae85fb', 'arxivId': '2006.10256', 'publication_year': 2020, 'abstract': None}
{'title': 'Quantifying Attention Flow in Transformers', 'paperID': '76a9f336481b39515d6cea2920696f11fb686451', 'arxivId': '2005.00928', 'publication_year': 2020, 'abstract': None}
{'title': 'BAE: BERT-based Adversarial Examples for Text Classification', 'paperID': '06a427e1688f92053a38c73cb4e0da25177c89e7', 'arxivId': '2004.01970', 'publication_year': 2020, 'abstract': None}
{'title': 'Adversarial Attacks on Deep-learning Models in Natural Language Processing', 'paperID': '88338c58701f34503c7af77e34f19d9a5cd66313', 'arxivId': None, 'publication_year': 2020, 'abstract': None}
{'title': 'Automatic Perturbation Analysis for Scalable Certified Robustness and Beyond', 'paperID': '18a9bb863e3110e2e981b53618b214585a32f877', 'arxivId': None, 'publication_year': 2020, 'abstract': None}
{'title': 'Zero-shot Text Classification With Generative Language Models', 'paperID': 'bbf105d2286c5a6b09998f514f685310562973b3', 'arxivId': '1912.10165', 'publication_year': 2019, 'abstract': None}
{'title': 'Learning to Discriminate Perturbations for Blocking Adversarial Attacks in Text Classification', 'paperID': 'b60a5fcbb085f136c71b6215c4c5f4c287e99f9b', 'arxivId': '1909.03084', 'publication_year': 2019, 'abstract': None}
{'title': 'The Bottom-up Evolution of Representations in the Transformer: A Study with Machine Translation and Language Modeling Objectives', 'paperID': '112fd54ee193237b24f2ce7fce79e399609a29c5', 'arxivId': '1909.01380', 'publication_year': 2019, 'abstract': None}
{'title': 'Knowledge Enhanced Attention for Robust Natural Language Inference', 'paperID': '9f0a45103aa474ee4d0946de8b690087dd065b60', 'arxivId': '1909.00102', 'publication_year': 2019, 'abstract': None}
{'title': 'Universal Adversarial Triggers for Attacking and Analyzing NLP', 'paperID': '18a1c21f35153c45d0ef30c564bffb7d70a13ccc', 'arxivId': '1908.07125', 'publication_year': 2019, 'abstract': None}
{'title': 'Attention is not not Explanation', 'paperID': 'ce177672b00ddf46e4906157a7e997ca9338b8b9', 'arxivId': '1908.04626', 'publication_year': 2019, 'abstract': None}
{'title': 'Is Attention Interpretable?', 'paperID': '135112c7ba1762d65f39b1a61777f26ae4dfd8ad', 'arxivId': '1906.03731', 'publication_year': 2019, 'abstract': None}
{'title': 'Gender Bias in Contextualized Word Embeddings', 'paperID': 'e235ad7dcf6e97cd372f09724dc947c5b1efac79', 'arxivId': '1904.03310', 'publication_year': 2019, 'abstract': None}
{'title': 'Attention is not Explanation', 'paperID': '1e83c20def5c84efa6d4a0d80aa3159f55cb9c3f', 'arxivId': '1902.10186', 'publication_year': 2019, 'abstract': None}
{'title': 'The Natural Language Decathlon: Multitask Learning as Question Answering', 'paperID': '9784fbf77295860b2e412137b86356d70b25e3c0', 'arxivId': '1806.08730', 'publication_year': 2018, 'abstract': None}
{'title': 'Hierarchical Attention Networks for Document Classification', 'paperID': '455afd748e8834ef521e4b67c7c056d3c33429e2', 'arxivId': None, 'publication_year': 2016, 'abstract': None}
{'title': 'Defense against Synonym Substitution-based Adversarial Attacks via Dirichlet Neighborhood Ensemble', 'paperID': '0cca27a289b595763d33b0a66ac1b3fc5b3ddc73', 'arxivId': None, 'publication_year': 2021, 'abstract': None}
{'title': 'Pontryagin Maximum Principle', 'paperID': 'cef931cb5547d615f253b759a2a0fe084112cb38', 'arxivId': None, 'publication_year': 2009, 'abstract': None}
{'title': 'On Robust Prefix-Tuning for Text Classification', 'paperID': '4bcd4f8ef3f269562dce183ed0329f93b24fd4e6', 'arxivId': '2203.10378', 'publication_year': '2022', 'abstract': 'Recently, prefix-tuning has gained increasing attention as a parameter-efficient finetuning method for large-scale pretrained language models. The method keeps the pretrained models fixed and only updates the prefix token parameters for each downstream task. Despite being lightweight and modular, prefix-tuning still lacks robustness to textual adversarial attacks. However, most currently developed defense techniques necessitate auxiliary model update and storage, which inevitably hamper the modularity and low storage of prefix-tuning. In this work, we propose a robust prefix-tuning framework that preserves the efficiency and modularity of prefix-tuning. The core idea of our framework is leveraging the layerwise activations of the language model by correctly-classified training data as the standard for additional prefix finetuning. During the test phase, an extra batch-level prefix is tuned for each batch and added to the original prefix for robustness enhancement. Extensive experiments on three text classification benchmarks show that our framework substantially improves robustness over several strong baselines against five textual attacks of different types while maintaining comparable accuracy on clean texts. We also interpret our robust prefix-tuning framework from the optimal control perspective and pose several directions for future research.'}
{'title': 'Policy Smoothing for Provably Robust Reinforcement Learning', 'paperID': '7f2f8042750df1be7562023760148a391d247904', 'arxivId': '2106.11420', 'publication_year': 2021, 'abstract': None}
{'title': 'Who Is the Strongest Enemy? Towards Optimal and Efficient Evasion Attacks in Deep RL', 'paperID': '4754ad07af3dce5262382ae47e496f694b61f589', 'arxivId': '2106.05087', 'publication_year': 2021, 'abstract': None}
{'title': 'Maximum Entropy RL (Provably) Solves Some Robust RL Problems', 'paperID': 'b284afe9a7363b898661c9b3cfb7f015b158cc63', 'arxivId': '2103.06257', 'publication_year': 2021, 'abstract': None}
{'title': 'Executive Order 13960: Promoting the Use of Trustworthy Artificial Intelligence in the Federal Government', 'paperID': 'f4f28269ad1aa5231e72415945afb4a8a9a0c70a', 'arxivId': None, 'publication_year': 2020, 'abstract': None}
{'title': 'Consistency Regularization for Certified Robustness of Smoothed Classifiers', 'paperID': '62cf842a62bf9c78ec40faae72b60398dc87a576', 'arxivId': '2006.04062', 'publication_year': 2020, 'abstract': None}
{'title': 'Deep Reinforcement Learning with Robust and Smooth Policy', 'paperID': '63fde44331c14fdf1f5dc0da19921a13f39b1fe0', 'arxivId': None, 'publication_year': 2020, 'abstract': None}
{'title': 'Reinforcement-Learning based Portfolio Management with Augmented Asset Movement Prediction States', 'paperID': '61bee52afa721d13982289497f3408e54444f85b', 'arxivId': '2002.05780', 'publication_year': 2020, 'abstract': None}
{'title': 'Optimal Attacks on Reinforcement Learning Policies', 'paperID': 'fe463f18d2515a7052a575beb89e14c93c99e66a', 'arxivId': '1907.13548', 'publication_year': 2019, 'abstract': None}
{'title': 'CopyCAT: : Taking Control of Neural Policies with Constant Attacks', 'paperID': '6252044bed5824ea8ca519c71fed56a90f5a0ee2', 'arxivId': '1905.12282', 'publication_year': 2019, 'abstract': None}
{'title': 'End-to-End Safe Reinforcement Learning through Barrier Functions for Safety-Critical Continuous Control Tasks', 'paperID': 'adcd4bfd88213da0c33d3cb7057411dd15b72c7a', 'arxivId': '1903.08792', 'publication_year': 2019, 'abstract': None}
{'title': 'An adaptive portfolio trading system: A risk-return portfolio optimization using recurrent reinforcement learning with expected maximum drawdown', 'paperID': '65a2534e3bd229eb368bbaad32f92a68bd0e936a', 'arxivId': None, 'publication_year': 2017, 'abstract': None}
{'title': 'A General Safety Framework for Learning-Based Control in Uncertain Robotic Systems', 'paperID': '171bfa2abddd30ad177cd620c86b7f8fa64964d1', 'arxivId': '1705.01292', 'publication_year': 2017, 'abstract': None}
{'title': 'Deep Direct Reinforcement Learning for Financial Signal Representation and Trading', 'paperID': 'f96478d0694f18384934fc19a2655170f32e2d8c', 'arxivId': None, 'publication_year': 2017, 'abstract': None}
{'title': 'Prioritized Experience Replay', 'paperID': 'c6170fa90d3b2efede5a2e1660cb23e1c824f2ca', 'arxivId': '1511.05952', 'publication_year': 2015, 'abstract': None}
{'title': 'Deep Reinforcement Learning with Double Q-Learning', 'paperID': '3b9732bb07dc99bde5e1f9f75251c6ea5039373e', 'arxivId': '1509.06461', 'publication_year': 2015, 'abstract': None}
{'title': 'The Arcade Learning Environment: An Evaluation Platform for General Agents (Extended Abstract)', 'paperID': 'f82e4ff4f003581330338aaae71f60316e58dd26', 'arxivId': '1207.4708', 'publication_year': 2012, 'abstract': None}
{'title': 'Measures of central tendency: Median and mode', 'paperID': 'a51f6c9930b5604918a649ebbebdd2eaf8d1701e', 'arxivId': None, 'publication_year': 2011, 'abstract': None}
{'title': 'Q-learning', 'paperID': '03b7e51c52084ac1db5118342a00b5fbcfc587aa', 'arxivId': None, 'publication_year': 1992, 'abstract': None}
{'title': 'Preserving order in a forest in less than logarithmic time', 'paperID': '0bb3cdf6222e0f6d2d949edf3a83e62834652c0a', 'arxivId': None, 'publication_year': 1975, 'abstract': None}
{'title': 'Depth-First Search and Linear Graph Algorithms', 'paperID': '385742fffcf113656f0d3cf6c06ef95cb8439dc6', 'arxivId': None, 'publication_year': 1972, 'abstract': None}
{'title': '“Memo” Functions and Machine Learning', 'paperID': '22faafeba7d7443da14c1e23e549b94e40d7d6ee', 'arxivId': None, 'publication_year': 1968, 'abstract': None}
{'title': 'Probability inequalities for sum of bounded random variables', 'paperID': '1c74180188a592d20a63cedb45d53089201fe127', 'arxivId': None, 'publication_year': 1963, 'abstract': None}
{'title': 'Communication theory of secrecy systems', 'paperID': 'e073a7c5a6418d96fc16d8337a6056a457e75c1e', 'arxivId': None, 'publication_year': 1949, 'abstract': None}
{'title': 'A bound for the error in the normal approximation to the distribution of a sum of dependent random variables', 'paperID': 'c7bf61f72cce609ce7b754e570fe1ec05ca3827b', 'arxivId': None, 'publication_year': 1972, 'abstract': None}
{'title': 'The Fundamental Limits of Interval Arithmetic for Neural Networks', 'paperID': '4de70afa21e54e8d8f7925471384c28d5c685276', 'arxivId': '2112.05235', 'publication_year': 2021, 'abstract': None}
{'title': 'On the Certified Robustness for Ensemble Models and Beyond', 'paperID': 'd4aa4fd1d0ea6da1905640adb17c67db435f9f12', 'arxivId': '2107.10873', 'publication_year': 2021, 'abstract': None}
{'title': 'Boosting Randomized Smoothing with Variance Reduced Classifiers', 'paperID': '37613cdd48d6e32d995bbd2dc2e8e3902892dd76', 'arxivId': '2106.06946', 'publication_year': 2021, 'abstract': None}
{'title': 'Towards Evaluating and Training Verifiably Robust Neural Networks', 'paperID': 'baee6bd21ac34e4e96479b928917e0c4f78c9c14', 'arxivId': '2104.00447', 'publication_year': 2021, 'abstract': None}
{'title': 'Fast Certified Robust Training with Short Warmup', 'paperID': '275588741254b9c2e7f1048d66c138f8abec02b9', 'arxivId': '2103.17268', 'publication_year': 2021, 'abstract': None}
{'title': 'Globally-Robust Neural Networks', 'paperID': '04eb7cc8b9a84999ba45d56bf87b170c9ad8082e', 'arxivId': '2102.08452', 'publication_year': 2021, 'abstract': None}
{'title': 'Towards Certifying L-infinity Robustness using Neural Networks with L-inf-dist Neurons', 'paperID': '525d1f68539c436072a3cb6f3b8a88e3b124260d', 'arxivId': '2102.05363', 'publication_year': 2021, 'abstract': None}
{'title': 'Enabling certification of verification-agnostic networks via memory-efficient semidefinite programming', 'paperID': '8f3ee84811064fba1ab9b86d4f4bd39036263cef', 'arxivId': '2010.11645', 'publication_year': 2020, 'abstract': None}
{'title': 'Training Robust Neural Networks Using Lipschitz Bounds', 'paperID': '62a88def88f4993803596dade79884fd3d811bed', 'arxivId': '2005.02929', 'publication_year': 2020, 'abstract': None}
{'title': 'A Closer Look at Accuracy vs. Robustness', 'paperID': '1b434b5cf7b2d139f9576e29c2c8daec01fca27e', 'arxivId': None, 'publication_year': 2020, 'abstract': None}
{'title': 'Black-Box Certification with Randomized Smoothing: A Functional Optimization Based Framework', 'paperID': '7ea9ff6dbf22ed2327eb44e04412dddb443e41c5', 'arxivId': '2002.09169', 'publication_year': 2020, 'abstract': None}
{'title': 'Random Smoothing Might be Unable to Certify 𝓁∞ Robustness for High-Dimensional Images', 'paperID': '7d8472fe362b829dc105cf63a905339ee72e630d', 'arxivId': '2002.03517', 'publication_year': 2020, 'abstract': None}
{'title': 'Fixup Initialization: Residual Learning Without Normalization', 'paperID': '96c82727dd5a80fef93007f888bb8569feb6bd85', 'arxivId': '1901.09321', 'publication_year': 2019, 'abstract': None}
{'title': 'Limitations of the Lipschitz constant as a defense against adversarial examples', 'paperID': '5548307d3ad1c2ec777e5084ecd478964da3947b', 'arxivId': '1807.09705', 'publication_year': 2018, 'abstract': None}
{'title': 'Spectral Norm Regularization for Improving the Generalizability of Deep Learning', 'paperID': 'f07c036a26bfca2b043f7c85f0326b177cd5561f', 'arxivId': '1705.10941', 'publication_year': 2017, 'abstract': None}
{'title': 'Completing the Picture: Randomized Smoothing Suffers from the Curse of Dimensionality for a Large Family of Distributions', 'paperID': 'cac705d5bf752525f0a517ec7f34cac359cfc7ee', 'arxivId': None, 'publication_year': 2021, 'abstract': None}
{'title': 'Lipschitz-Certifiable Training with a Tight Outer Bound', 'paperID': 'f6aee5a366a798ca08c12013cffcbb78740bfd01', 'arxivId': None, 'publication_year': 2020, 'abstract': None}
{'title': 'Certified Adversarial Robustness with Additive Noise', 'paperID': '7edda0f7cbbe47c66b8a231ecf50342cef3a8504', 'arxivId': None, 'publication_year': 2019, 'abstract': None}
{'title': 'Moiré Attack (MA): A New Potential Risk of Screen Photos', 'paperID': '83d68fb9906d17c3d623ddbd70bc36e7baee96f9', 'arxivId': '2110.10444', 'publication_year': 2021, 'abstract': None}
{'title': 'Exploring Architectural Ingredients of Adversarially Robust Deep Neural Networks', 'paperID': '2d36eaa618da03d28a48a03e562a9fbc314609c4', 'arxivId': '2110.03825', 'publication_year': 2021, 'abstract': None}
{'title': 'Highly accurate protein structure prediction with AlphaFold', 'paperID': 'dc32a984b651256a8ec282be52310e6bd33d9815', 'arxivId': None, 'publication_year': 2021, 'abstract': None}
{'title': 'Improved protein contact prediction using dimensional hybrid residual networks and singularity enhanced loss function', 'paperID': '34416bf36736776715cc75859a02c1a077555bf5', 'arxivId': None, 'publication_year': 2021, 'abstract': None}
{'title': 'Fixing Data Augmentation to Improve Adversarial Robustness', 'paperID': '762752eb9a9a92b028026b17c46d50474ddf3f06', 'arxivId': '2103.01946', 'publication_year': 2021, 'abstract': None}
{'title': 'Very Deep VAEs Generalize Autoregressive Models and Can Outperform Them on Images', 'paperID': '3e577c9bdc82cb7fed337a74f90bbc4505fdfb69', 'arxivId': '2011.10650', 'publication_year': 2020, 'abstract': None}
{'title': 'A Hamiltonian Monte Carlo Method for Probabilistic Adversarial Attack and Learning', 'paperID': '8e7bc6ea46f0ccb3c86c7795af95a33799f71883', 'arxivId': '2010.07849', 'publication_year': 2020, 'abstract': None}
{'title': 'Uncovering the Limits of Adversarial Training against Norm-Bounded Adversarial Examples', 'paperID': '1bcbf1efb3f81f0e777b4b754cf5b9789841d12f', 'arxivId': '2010.03593', 'publication_year': 2020, 'abstract': None}
{'title': 'Denoising Diffusion Probabilistic Models', 'paperID': '289db3be7bf77e06e75541ba93269de3d604ac72', 'arxivId': '2006.11239', 'publication_year': 2020, 'abstract': None}
{'title': 'Transferable, Controllable, and Inconspicuous Adversarial Attacks on Person Re-identification With Deep Mis-Ranking', 'paperID': 'b852634098dd8c1fcdfc3c96c86d599d47f7c302', 'arxivId': '2004.04199', 'publication_year': 2020, 'abstract': None}
{'title': 'Detecting and Diagnosing Adversarial Images with Class-Conditional Capsule Reconstructions', 'paperID': 'f368de6a7f90daec66e1eef7922773390b75fb9d', 'arxivId': '1907.02957', 'publication_year': 2019, 'abstract': None}
{'title': 'Large Scale GAN Training for High Fidelity Natural Image Synthesis', 'paperID': '22aab110058ebbd198edb1f1e7b4f69fb13c0613', 'arxivId': '1809.11096', 'publication_year': 2018, 'abstract': None}
{'title': 'Bridging Nonlinearities and Stochastic Regularizers with Gaussian Error Linear Units', 'paperID': '4361e64f2d12d63476fdc88faf72a0f70d9a2ffb', 'arxivId': None, 'publication_year': 2016, 'abstract': None}
{'title': 'Fast and accurate recurrent neural network acoustic models for speech recognition', 'paperID': '9fca2af9a0e3f2c5c3ed47abb3ebd21b7265ac2b', 'arxivId': '1507.06947', 'publication_year': 2015, 'abstract': None}
{'title': 'Qualitatively characterizing neural network optimization problems', 'paperID': '4d4d09ae8f6a11547441f7fee36405758102a801', 'arxivId': '1412.6544', 'publication_year': 2014, 'abstract': None}
{'title': 'Ensemble selection from libraries of models', 'paperID': '6fa5d3508788f1ec9973d44f65b207092f91298f', 'arxivId': None, 'publication_year': 2004, 'abstract': None}
{'title': 'Self-ensemble Adversarial Training for Improved Robustness', 'paperID': 'a35bd2ddff96d876a0462acfbab0c3714dd906d0', 'arxivId': '2203.09678', 'publication_year': '2022', 'abstract': 'Due to numerous breakthroughs in real-world applications brought by machine intelligence, deep neural networks (DNNs) are widely employed in critical applications. However, predictions of DNNs are easily manipulated with imperceptible adversarial perturbations, which impedes the further deployment of DNNs and may result in profound security and privacy implications. By incorporating adversarial samples into the training data pool, adversarial training is the strongest principled strategy against various adversarial attacks among all sorts of defense methods. Recent works mainly focus on developing new loss functions or regularizers, attempting to find the unique optimal point in the weight space. But none of them taps the potentials of classifiers obtained from standard adversarial training, especially states on the searching trajectory of training. In this work, we are dedicated to the weight states of models through the training process and devise a simple but powerful Self-Ensemble Adversarial Training (SEAT) method for yielding a robust classifier by averaging weights of history models. This considerably improves the robustness of the target model against several well known adversarial attacks, even merely utilizing the naive cross-entropy loss to supervise. We also discuss the relationship between the ensemble of predictions from different adversarially trained models and the prediction of weight-ensembled models, as well as provide theoretical and empirical evidence that the proposed self-ensemble method provides a smoother loss landscape and better robustness than both individual models and the ensemble of predictions from different classifiers. We further analyze a subtle but fatal issue in the general settings for the self-ensemble model, which causes the deterioration of the weight-ensembled method in the late phases*.'}
{'title': 'Representation Learning via Invariant Causal Mechanisms', 'paperID': '57835c5ad5424f94ee75901c3113730f3900e656', 'arxivId': '2010.07922', 'publication_year': 2020, 'abstract': None}
{'title': 'Long-Tailed Classification by Keeping the Good and Removing the Bad Momentum Causal Effect', 'paperID': '24a07bc3826ae3518ccbd0e004c65319896e0c5d', 'arxivId': '2009.12991', 'publication_year': 2020, 'abstract': None}
{'title': 'A Causal View on Robustness of Neural Networks', 'paperID': '1a6adb28532afd81b32bf5b9e0af23bb3a4f0dc8', 'arxivId': '2005.01095', 'publication_year': 2020, 'abstract': None}
{'title': 'A Calculus for Stochastic Interventions: Causal Effect Identification and Surrogate Experiments', 'paperID': 'b311dec6aa6963e51c21fc9a89988a7c369145bc', 'arxivId': None, 'publication_year': 2020, 'abstract': None}
{'title': 'Principal Component Adversarial Example', 'paperID': '7378f30cd38496acf315bb18fd64e468f0f8001e', 'arxivId': None, 'publication_year': 2020, 'abstract': None}
{'title': 'Few-shot Domain Adaptation by Causal Mechanism Transfer', 'paperID': '38d28841d70a9d322f02268aaf218b5f33592de1', 'arxivId': '2002.03497', 'publication_year': 2020, 'abstract': None}
{'title': 'Generalization in anti-causal learning', 'paperID': '3af6d1113cd45ccbf4ecf710d6bb491436dd277b', 'arxivId': '1812.00524', 'publication_year': 2018, 'abstract': None}
{'title': 'On the Spectral Bias of Neural Networks', 'paperID': '715a73290f260cf2196307e59fe0b6776841f170', 'arxivId': '1806.08734', 'publication_year': 2018, 'abstract': None}
{'title': 'AutoZOOM: Autoencoder-based Zeroth Order Optimization Method for Attacking Black-box Neural Networks', 'paperID': '60bc5831f9aea45bc63608cb1af74cabadc39eb7', 'arxivId': '1805.11770', 'publication_year': 2018, 'abstract': None}
{'title': 'Simulation-based Adversarial Test Generation for Autonomous Vehicles with Machine Learning Components', 'paperID': 'b043ab547742422c88b8f6518d0eba3f2f5c0a76', 'arxivId': '1804.06760', 'publication_year': 2018, 'abstract': None}
{'title': 'Universal Adversarial Perturbations Against Semantic Image Segmentation', 'paperID': '1d6bc45c31c17f5091eec3def813cc2cd26d811e', 'arxivId': '1704.05712', 'publication_year': 2017, 'abstract': None}
{'title': 'What Uncertainties Do We Need in Bayesian Deep Learning for Computer Vision?', 'paperID': 'ff7bcaa4556cb13fc7bf03e477172493546172cd', 'arxivId': '1703.04977', 'publication_year': 2017, 'abstract': None}
{'title': 'Going deeper with convolutions', 'paperID': 'e15cf50aa89fee8535703b9f9512fca5bfc43327', 'arxivId': '1409.4842', 'publication_year': 2014, 'abstract': None}
{'title': 'Interventions and Causal Inference', 'paperID': '3d985d72a4ff6232503b5a95fa6f3eefbab01cef', 'arxivId': None, 'publication_year': 2007, 'abstract': None}
{'title': 'A theory of causal learning in children: causal maps and Bayes nets.', 'paperID': '792695c436fd0148a71e7f2830ea5bac7938b014', 'arxivId': None, 'publication_year': 2004, 'abstract': None}
{'title': 'Adversarial Robustness Through the Lens of Causality', 'paperID': '68b7532be018dbaf4fe7f500b19b46fd31b82ab9', 'arxivId': None, 'publication_year': None, 'abstract': 'The adversarial vulnerability of deep neural networks has attracted signiﬁcant attention in machine learning. From a causal viewpoint, adversarial attacks can be considered as a speciﬁc type of distribution change on natural data. As causal reasoning has an instinct for modeling distribution change, we propose to incorporate causality into mitigating adversarial vulnerability. However, causal formulations of the intuition of adversarial attack and the development of robust DNNs are still lacking in the literature. To bridge this gap, we construct a causal graph to model the generation process of adversarial examples and deﬁne the adversarial distribution to formalize the intuition of adversarial attacks. From a causal perspective, we ﬁnd that the label is spuriously correlated with the style (content-independent) information when an instance is given. The spurious correlation implies that the adversarial distribution is constructed via making the statistical conditional association between style information and labels drastically diﬀerent from that in natural distribution. Thus, DNNs that ﬁt the spurious correlation are vulnerable to the adversarial distribution. Inspired by the observation, we propose the adversarial distribution alignment method to eliminate the diﬀerence between the natural distribution and the adversarial distribution. Extensive experiments demonstrate the eﬃcacy of the proposed method. Our method can be seen as the ﬁrst attempt to leverage causality for mitigating adversarial vulnerability.'}
{'title': 'Simple data balancing achieves competitive worst-group-accuracy', 'paperID': '9f47fe66a23dbf48d0b2fa5fb66e378a9c51951e', 'arxivId': '2110.14503', 'publication_year': 2021, 'abstract': None}
{'title': 'An Empirical Investigation of Global and Local Normalization for Recurrent Neural Sequence Models Using a Continuous Relaxation to Beam Search', 'paperID': '5c01d5f6b113713caf9d85fb127eaa376cc01673', 'arxivId': '1904.06834', 'publication_year': 2019, 'abstract': None}
{'title': 'Training Tips for the Transformer Model', 'paperID': 'd3707cf521e3596313af1f53acba6413d0d528a6', 'arxivId': '1804.00247', 'publication_year': 2018, 'abstract': None}
{'title': 'On the Accuracy of Self-Normalized Log-Linear Models', 'paperID': 'c824cd5510fecac3a03330f79c14b23856c229c0', 'arxivId': '1506.04147', 'publication_year': 2015, 'abstract': None}
{'title': 'Learning Bounds for Importance Weighting', 'paperID': '393a553e3f601e1ec1a205eeb2981a8fc596012a', 'arxivId': None, 'publication_year': 2010, 'abstract': None}
{'title': 'Speech', 'paperID': '006a9930546a9e1f25704a07ee8454a805fd2875', 'arxivId': None, 'publication_year': 1933, 'abstract': None}
{'title': 'Distributionally Robust Models with Parametric Likelihood Ratios', 'paperID': '51836dfa1542277ed982612caa90ecf31ead4ba8', 'arxivId': '2204.06340', 'publication_year': '2022', 'abstract': 'As machine learning models are deployed ever more broadly, it becomes increasingly important that they are not only able to perform well on their training distribution, but also yield accurate predictions when confronted with distribution shift. The Distributionally Robust Optimization (DRO) framework proposes to address this issue by training models to minimize their expected risk under a collection of distributions, to imitate test-time shifts. This is most commonly achieved by instance-level re-weighting of the training objective to emulate the likelihood ratio with possible test distributions, which allows for estimating their empirical risk via importance sampling (assuming that they are subpopulations of the training distribution). However, re-weighting schemes in the literature are usually limited due to the difficulty of keeping the optimization problem tractable and the complexity of enforcing normalization constraints. In this paper, we show that three simple ideas -- mini-batch level normalization, a KL penalty and simultaneous gradient updates -- allow us to train models with DRO using a broader class of parametric likelihood ratios. In a series of experiments on both image and text classification benchmarks, we find that models trained with the resulting parametric adversaries are consistently more robust to subpopulation shifts when compared to other DRO approaches, and that the method performs reliably well with little hyper-parameter tuning. Code to reproduce our experiments can be found at https://github.com/pmichel31415/P-DRO.'}
{'title': 'How to train your ViT? Data, Augmentation, and Regularization in Vision Transformers', 'paperID': 'cf5e6e3c50a798d87033e0e108e88b3647738bbe', 'arxivId': '2106.10270', 'publication_year': 2021, 'abstract': None}
{'title': 'BEiT: BERT Pre-Training of Image Transformers', 'paperID': '722ad6ac92286507437b31486f47987d6ece05c9', 'arxivId': '2106.08254', 'publication_year': 2021, 'abstract': None}
{'title': 'When Vision Transformers Outperform ResNets without Pretraining or Strong Data Augmentations', 'paperID': '42a7015e48a1e00b70ebb442a82afb4b10017c0b', 'arxivId': '2106.01548', 'publication_year': 2021, 'abstract': None}
{'title': 'Intriguing Properties of Vision Transformers', 'paperID': '03db529f0bfae6d0b64b0feef565196327fe8d50', 'arxivId': '2105.10497', 'publication_year': 2021, 'abstract': None}
{'title': 'Towards Robust Vision Transformer', 'paperID': 'b8cee43a51c44f8f4448e78e41ecf081987707cf', 'arxivId': '2105.07926', 'publication_year': 2021, 'abstract': None}
{'title': 'Vision Transformers are Robust Learners', 'paperID': '5e4f03f68c6867d850f457dc5cc36738e5dff6c1', 'arxivId': '2105.07581', 'publication_year': 2021, 'abstract': None}
{'title': 'MLP-Mixer: An all-MLP Architecture for Vision', 'paperID': '2def61f556f9a5576ace08911496b7c7e4f970a4', 'arxivId': '2105.01601', 'publication_year': 2021, 'abstract': None}
{'title': 'Twins: Revisiting the Design of Spatial Attention in Vision Transformers', 'paperID': '6709d5583f658f589ae6a2184805933aceb18849', 'arxivId': '2104.13840', 'publication_year': 2021, 'abstract': None}
{'title': 'Understanding Robustness of Transformers for Image Classification', 'paperID': 'd2a3bb6356d439146cd8d8e72dc728a1e3d93e7f', 'arxivId': '2103.14586', 'publication_year': 2021, 'abstract': None}
{'title': 'ConViT: improving vision transformers with soft convolutional inductive biases', 'paperID': '610b302950a19acef1c45456111dcd495f638c18', 'arxivId': '2103.10697', 'publication_year': 2021, 'abstract': None}
{'title': 'Zero-Shot Text-to-Image Generation', 'paperID': '2cd605106b88c85d7d8b865b1ef0f8c8293debf1', 'arxivId': '2102.12092', 'publication_year': 2021, 'abstract': None}
{'title': 'Pyramid Vision Transformer: A Versatile Backbone for Dense Prediction without Convolutions', 'paperID': '3e398bad2d8636491a1034cc938a5e024c7aa881', 'arxivId': '2102.12122', 'publication_year': 2021, 'abstract': None}
{'title': 'Training data-efficient image transformers & distillation through attention', 'paperID': 'ad7ddcc14984caae308c397f1a589aae75d4ab71', 'arxivId': '2012.12877', 'publication_year': 2020, 'abstract': None}
{'title': 'Generative Interventions for Causal Learning', 'paperID': '945aa2eb4b7ceecebf0562dfc12fcadb8fd38970', 'arxivId': '2012.12265', 'publication_year': 2020, 'abstract': None}
{'title': 'Taming Transformers for High-Resolution Image Synthesis', 'paperID': '47f7ec3d0a5e6e83b6768ece35206a94dc81919c', 'arxivId': '2012.09841', 'publication_year': 2020, 'abstract': None}
{'title': 'Learning Visual Representations for Transfer Learning by Suppressing Texture', 'paperID': '18e2f6b0f8e5644205cecc0df7d6fe1d7105cfda', 'arxivId': '2011.01901', 'publication_year': 2020, 'abstract': None}
{'title': 'Are we done with ImageNet?', 'paperID': 'f5c8464032a936451b222be1984cabf42d6adfa8', 'arxivId': '2006.07159', 'publication_year': 2020, 'abstract': None}
{'title': 'Robust Learning Through Cross-Task Consistency', 'paperID': 'a0265f14b07811c502f9dd730ec1f10daf2ff345', 'arxivId': '2006.04096', 'publication_year': 2020, 'abstract': None}
{'title': 'The Origins and Prevalence of Texture Bias in Convolutional Neural Networks', 'paperID': '1e6de530a183cded2373c8f0ffc54f4a9b7bd02e', 'arxivId': None, 'publication_year': 2019, 'abstract': None}
{'title': 'Composing Text and Image for Image Retrieval - an Empirical Odyssey', 'paperID': 'fd5129e8ebfaa5dcce3d4ce2839b90c6cd3ca39d', 'arxivId': '1812.07119', 'publication_year': 2018, 'abstract': None}
{'title': 'DVAE#: Discrete Variational Autoencoders with Relaxed Boltzmann Priors', 'paperID': 'c940cec9b56a5766c316fb6fc1e4195d70d39ecf', 'arxivId': '1805.07445', 'publication_year': 2018, 'abstract': None}
{'title': 'Neural Discrete Representation Learning', 'paperID': 'f466157848d1a7772fb6d02cdac9a7a5e7ef982e', 'arxivId': '1711.00937', 'publication_year': 2017, 'abstract': None}
{'title': 'Perceptual Losses for Real-Time Style Transfer and Super-Resolution', 'paperID': '915c4bb289b3642489e904c65a47fa56efb60658', 'arxivId': '1603.08155', 'publication_year': 2016, 'abstract': None}
{'title': 'All About VLAD', 'paperID': '25d0fa49ca846370ff4796a6ac6688a42cf50f77', 'arxivId': None, 'publication_year': 2013, 'abstract': None}
{'title': 'Video Google: a text retrieval approach to object matching in videos', 'paperID': '642e328cae81c5adb30069b680cf60ba6b475153', 'arxivId': None, 'publication_year': 2003, 'abstract': None}
{'title': 'On the Adversarial Robustness of Vision Transformers', 'paperID': '0def290ae38abb4a04e35e0bcdc86b71d237f494', 'arxivId': '2103.15670', 'publication_year': 2022, 'abstract': None}
{'title': 'Swin Transformer: Hierarchical Vision Transformer using Shifted Windows', 'paperID': 'c8b25fab5608c3e033d34b4483ec47e68ba109b7', 'arxivId': '2103.14030', 'publication_year': 2021, 'abstract': None}
{'title': 'ObjectNet: A large-scale bias-controlled dataset for pushing the limits of object recognition models', 'paperID': '639174f32a71ecfe9041ad05ff30eb39bd4977bf', 'arxivId': None, 'publication_year': 2019, 'abstract': None}
{'title': 'Visual categorization with bags of keypoints', 'paperID': 'b91180d8853d00e8f2df7ee3532e07d3d0cce2af', 'arxivId': None, 'publication_year': 2002, 'abstract': None}
{'title': 'Discrete Representations Strengthen Vision Transformer Robustness', 'paperID': '601ab36b6f077ff57472f4a0cf2e061dd05b9b85', 'arxivId': '2111.10493', 'publication_year': '2021', 'abstract': "Vision Transformer (ViT) is emerging as the state-of-the-art architecture for image recognition. While recent studies suggest that ViTs are more robust than their convolutional counterparts, our experiments find that ViTs trained on ImageNet are overly reliant on local textures and fail to make adequate use of shape information. ViTs thus have difficulties generalizing to out-of-distribution, real-world data. To address this deficiency, we present a simple and effective architecture modification to ViT's input layer by adding discrete tokens produced by a vector-quantized encoder. Different from the standard continuous pixel tokens, discrete tokens are invariant under small perturbations and contain less information individually, which promote ViTs to learn global information that is invariant. Experimental results demonstrate that adding discrete representation on four architecture variants strengthens ViT robustness by up to 12% across seven ImageNet robustness benchmarks while maintaining the performance on ImageNet."}
{'title': 'PointGuard: Provably Robust 3D Point Cloud Classification', 'paperID': '2e025461fa02b3939f151ad17690ecfe3be728bd', 'arxivId': '2103.03046', 'publication_year': 2021, 'abstract': None}
{'title': 'Certified Robustness of Graph Neural Networks against Adversarial Structural Perturbation', 'paperID': '01203b7235355cbb99090afab02ab97ef1807034', 'arxivId': '2008.10715', 'publication_year': 2020, 'abstract': None}
{'title': 'Backdoor Attacks to Graph Neural Networks', 'paperID': 'bbcfa13ced06dedc9c346e0bdf84d8b3abcbebee', 'arxivId': '2006.11165', 'publication_year': 2020, 'abstract': None}
{'title': 'Towards Assessment of Randomized Smoothing Mechanisms for Certifying Adversarial Robustness', 'paperID': '2defb08c8b968ec2c616ed973b9950d33425a637', 'arxivId': '2005.07347', 'publication_year': 2020, 'abstract': None}
{'title': 'On Certifying Robustness against Backdoor Attacks via Randomized Smoothing', 'paperID': '4a08a4f5818b8ce9e4eb5c3910788b965d61193d', 'arxivId': '2002.11750', 'publication_year': 2020, 'abstract': None}
{'title': 'Certified Robustness of Community Detection against Adversarial Structural Perturbation via Randomized Smoothing', 'paperID': '479240dac852bbf9cdda25e991ddadf4c24327e7', 'arxivId': '2002.03421', 'publication_year': 2020, 'abstract': None}
{'title': 'Robustness Certificates for Sparse Adversarial Attacks by Randomized Ablation', 'paperID': '26dd808175870b5fc7426b11353acdcc0066304a', 'arxivId': '1911.09272', 'publication_year': 2019, 'abstract': None}
{'title': 'Wasserstein Smoothing: Certified Robustness against Wasserstein Adversarial Attacks', 'paperID': '469bae685ae7fa6dc7ff73b9076041b79aa083e0', 'arxivId': '1910.10783', 'publication_year': 2019, 'abstract': None}
{'title': 'PointNet: Deep Learning on Point Sets for 3D Classification and Segmentation', 'paperID': 'd997beefc0922d97202789d2ac307c55c2c52fba', 'arxivId': '1612.00593', 'publication_year': 2016, 'abstract': None}
{'title': '3D ShapeNets: A deep representation for volumetric shapes', 'paperID': '7c8a51d04522496c43db68f2582efd45eaf59fea', 'arxivId': None, 'publication_year': 2014, 'abstract': None}
{'title': 'Towards Verification of Artificial Neural Networks', 'paperID': 'e34b8e55b1cd9786deaf9f89191cdb77912c87e7', 'arxivId': None, 'publication_year': 2015, 'abstract': None}
{'title': 'Almost Tight L0-norm Certified Robustness of Top-k Predictions against Adversarial Perturbations', 'paperID': '0808bdbb02e60fd3ac3c13f454346ea47067b987', 'arxivId': '2011.07633', 'publication_year': '2020', 'abstract': 'Top-$k$ predictions are used in many real-world applications such as machine learning as a service, recommender systems, and web searches. $\\ell_0$-norm adversarial perturbation characterizes an attack that arbitrarily modifies some features of an input such that a classifier makes an incorrect prediction for the perturbed input. $\\ell_0$-norm adversarial perturbation is easy to interpret and can be implemented in the physical world. Therefore, certifying robustness of top-$k$ predictions against $\\ell_0$-norm adversarial perturbation is important. However, existing studies either focused on certifying $\\ell_0$-norm robustness of top-$1$ predictions or $\\ell_2$-norm robustness of top-$k$ predictions. In this work, we aim to bridge the gap. Our approach is based on randomized smoothing, which builds a provably robust classifier from an arbitrary classifier via randomizing an input. Our major theoretical contribution is an almost tight $\\ell_0$-norm certified robustness guarantee for top-$k$ predictions. We empirically evaluate our method on CIFAR10 and ImageNet. For instance, our method can build a classifier that achieves a certified top-3 accuracy of 69.2\\% on ImageNet when an attacker can arbitrarily perturb 5 pixels of a testing image.'}
{'title': 'TRS: Transferability Reduced Ensemble via Promoting Gradient Diversity and Model Smoothness', 'paperID': 'c526dcd91152cc4b155e4e76c6ee3ec931b321df', 'arxivId': '2104.00671', 'publication_year': 2021, 'abstract': None}
{'title': 'Higher-Order Certification for Randomized Smoothing', 'paperID': 'ebb3f729b9a12a4af3f82c44599812e66580922e', 'arxivId': '2010.06651', 'publication_year': 2020, 'abstract': None}
{'title': 'DVERGE: Diversifying Vulnerabilities for Enhanced Robust Generation of Ensembles', 'paperID': 'b3b88cb29938a5445edd543b0498a51c4931f840', 'arxivId': '2009.14720', 'publication_year': 2020, 'abstract': None}
{'title': 'SoK: Certified Robustness for Deep Neural Networks', 'paperID': '14becdb8b29de410fc54cd80307dc08512391edb', 'arxivId': '2009.04131', 'publication_year': 2020, 'abstract': None}
{'title': 'Boosting the Robustness of Capsule Networks with Diverse Ensemble', 'paperID': '3ac7669e6e4488080d046a9c07078ffcbaddbab1', 'arxivId': None, 'publication_year': 2020, 'abstract': None}
{'title': 'Enhancing Certified Robustness of Smoothed Classifiers via Weighted Model Ensembling', 'paperID': '0281b89a956906b7f78a5c964ab1a9b93ac8409e', 'arxivId': '2005.09363', 'publication_year': 2020, 'abstract': None}
{'title': 'Provable Robust Classification via Learned Smoothed Densities', 'paperID': '6cfca09be8522e56c4aa75e7a86dc36d505f9bda', 'arxivId': '2005.04504', 'publication_year': 2020, 'abstract': None}
{'title': 'Enhancing Certifiable Robustness via a Deep Model Ensemble', 'paperID': 'ef042af146283c59fa9e9990ce37df538fc12faa', 'arxivId': '1910.14655', 'publication_year': 2019, 'abstract': None}
{'title': 'Improving Adversarial Robustness of Ensembles with Diversity Training', 'paperID': 'd4473a41c9f7b4095599bec14ea0a88e7041e737', 'arxivId': '1901.09981', 'publication_year': 2019, 'abstract': None}
{'title': 'Why Do Adversarial Attacks Transfer? Explaining Transferability of Evasion and Poisoning Attacks', 'paperID': '8bac2716cd208cb8041650a001ab72ba81b559cd', 'arxivId': None, 'publication_year': 2018, 'abstract': None}
{'title': 'MULDEF: Multi-model-based Defense Against Adversarial Examples for Neural Networks', 'paperID': '66f72219e9870250b67bf70833bbcbcd163365a3', 'arxivId': '1809.00065', 'publication_year': 2018, 'abstract': None}
{'title': 'Deep Learning Face Representation from Predicting 10,000 Classes', 'paperID': '177bc509dd0c7b8d388bb47403f28d6228c14b5c', 'arxivId': None, 'publication_year': 2014, 'abstract': None}
{'title': 'Ensemble-based classifiers', 'paperID': '75bc3edb3655a777b8a12e0237c18d571aa610fd', 'arxivId': None, 'publication_year': 2010, 'abstract': None}
{'title': 'Maxi–Min Margin Machine: Learning Large Margin Classifiers Locally and Globally', 'paperID': '802f2afd13b209d4c6d6d3622efc48a7256d7207', 'arxivId': None, 'publication_year': 2008, 'abstract': None}
{'title': 'Ensemble based systems in decision making', 'paperID': '1a585a498551e9ba55f89207f8a735cfd79cf807', 'arxivId': None, 'publication_year': 2006, 'abstract': None}
{'title': 'Popular Ensemble Methods: An Empirical Study', 'paperID': '4af31c2819d3f2c7f01942f053750ad1a87253db', 'arxivId': '1106.0257', 'publication_year': 1999, 'abstract': None}
{'title': 'THE USE OF CONFIDENCE OR FIDUCIAL LIMITS ILLUSTRATED IN THE CASE OF THE BINOMIAL', 'paperID': '166c42895882039e4252f7c943efa13d0505109f', 'arxivId': None, 'publication_year': 1934, 'abstract': None}
{'title': 'Mixture of Robust Experts (MoRE): A Flexible Defense Against Multiple Perturbations', 'paperID': '43bbc1b737b5f29cd58cf80de0e6378ced93381a', 'arxivId': None, 'publication_year': 2021, 'abstract': None}
{'title': 'TRS: Transferability Reduced Ensemble via Encouraging Gradient Diversity and Model Smoothness', 'paperID': 'a2a591d5a8d399b14d5ab9171629b7b9eaae05ad', 'arxivId': None, 'publication_year': 2021, 'abstract': None}
{'title': 'Robust Recovery via Implicit Bias of Discrepant Learning Rates for Double Over-parameterization', 'paperID': 'd33b2544781c15e257ee8a1c3bf2e2d7307ebfef', 'arxivId': '2006.08857', 'publication_year': 2020, 'abstract': None}
{'title': 'Finding the Sparsest Vectors in a Subspace: Theory, Algorithms, and Applications', 'paperID': '7cf8ae0fbbd22b8c935e8d7af675dd4673c36e78', 'arxivId': '2001.06970', 'publication_year': 2020, 'abstract': None}
{'title': 'Alternating Iteratively Reweighted Least Squares Minimization for Low-Rank Matrix Factorization', 'paperID': '06a17b17268551232123ddded65e5b46d65d93cf', 'arxivId': None, 'publication_year': 2019, 'abstract': None}
{'title': 'Characterizing Implicit Bias in Terms of Optimization Geometry', 'paperID': '33416f2dc49db24cca520a3b234f02463a4e833e', 'arxivId': '1802.08246', 'publication_year': 2018, 'abstract': None}
{'title': 'Coherence Pursuit: Fast, Simple, and Robust Subspace Recovery', 'paperID': '14c7d66a3ae24949ec01d51e4095e5141550f824', 'arxivId': None, 'publication_year': 2017, 'abstract': None}
{'title': 'Provable Self-Representation Based Outlier Detection in a Union of Subspaces', 'paperID': '13eb4d8d61fa320fde0d049a6b4bcde6e550118f', 'arxivId': '1704.03925', 'publication_year': 2017, 'abstract': None}
{'title': 'Principal component analysis: a review and recent developments', 'paperID': '5bc875d65df812f9617d8ba508c1c85f4d219b19', 'arxivId': None, 'publication_year': 2016, 'abstract': None}
{'title': 'Dual Principal Component Pursuit', 'paperID': '9dc822d8c41d1091b3ae200fe5efa6f98bd4ecf3', 'arxivId': '1510.04390', 'publication_year': 2015, 'abstract': None}
{'title': 'Random sample consensus: a paradigm for model fitting with applications to image analysis and automated cartography', 'paperID': '4f37468a95ccc62debb9e5a4cb0d73489ca61190', 'arxivId': None, 'publication_year': 1981, 'abstract': None}
{'title': 'Dual Principal Component Pursuit for Robust Subspace Learning: Theory and Algorithms for a Holistic Approach', 'paperID': 'c0962af9155f6cd146e6566d3b8f7f7c04df9d98', 'arxivId': None, 'publication_year': 2021, 'abstract': None}
{'title': 'A Linearly Convergent Method for Non-Smooth Non-Convex Optimization on the Grassmannian with Applications to Robust Subspace and Dictionary Learning', 'paperID': 'b45a4b9bb65c64cf9eb1adcc08aa2e71cdf54718', 'arxivId': None, 'publication_year': 2019, 'abstract': None}
{'title': 'Dual Principal Component Pursuit: Improved Analysis and Efficient Algorithms', 'paperID': 'c72572e628004e83ffafb362a1aa6a37550a1bf3', 'arxivId': None, 'publication_year': 2018, 'abstract': None}
{'title': 'Implicit Bias of Projected Subgradient Method Gives Provable Robust Recovery of Subspaces of Unknown Codimension', 'paperID': 'f1057950e69b736c35a4fe9c013083d6118811ed', 'arxivId': '2201.09079', 'publication_year': '2022', 'abstract': 'Robust subspace recovery (RSR) is a fundamental problem in robust representation learning. Here we focus on a recently proposed RSR method termed Dual Principal Component Pursuit (DPCP) approach, which aims to recover a basis of the orthogonal complement of the subspace and is amenable to handling subspaces of high relative dimension. Prior work has shown that DPCP can provably recover the correct subspace in the presence of outliers, as long as the true dimension of the subspace is known. We show that DPCP can provably solve RSR problems in the {\\it unknown} subspace dimension regime, as long as orthogonality constraints -- adopted in previous DPCP formulations -- are relaxed and random initialization is used instead of spectral one. Namely, we propose a very simple algorithm based on running multiple instances of a projected sub-gradient descent method (PSGM), with each problem instance seeking to find one vector in the null space of the subspace. We theoretically prove that under mild conditions this approach will succeed with high probability. In particular, we show that 1) all of the problem instances will converge to a vector in the nullspace of the subspace and 2) the ensemble of problem instance solutions will be sufficiently diverse to fully span the nullspace of the subspace thus also revealing its true unknown codimension. We provide empirical results that corroborate our theoretical results and showcase the remarkable implicit rank regularization behavior of PSGM algorithm that allows us to perform RSR without being aware of the subspace dimension.'}
{'title': 'With Friends Like These, Who Needs Adversaries?', 'paperID': 'd6263d976be8753c4c6779eb8e986311a23b6cbf', 'arxivId': '1807.04200', 'publication_year': 2018, 'abstract': None}
{'title': 'Super-Convergence: Very Fast Training of Residual Networks Using Large Learning Rates', 'paperID': '9e21d177a7dcfa4acfb674b93103b3d12bbb5b32', 'arxivId': '1708.07120', 'publication_year': 2017, 'abstract': None}
{'title': 'Improving Adversarial Robustness Using Proxy Distributions', 'paperID': '62a6316235d36b71139579ad0588c9cfef16b9e9', 'arxivId': None, 'publication_year': 2021, 'abstract': None}
{'title': 'DAWNBench : An End-to-End Deep Learning Benchmark and Competition', 'paperID': 'b245959da6bdaa0b711341844aeaa473b7706453', 'arxivId': None, 'publication_year': 2017, 'abstract': None}
{'title': 'A method for solving the convex programming problem with convergence rate O(1/k^2)', 'paperID': '8d3a318b62d2e970122da35b2a2e70a5d12cc16f', 'arxivId': None, 'publication_year': 1983, 'abstract': None}
{'title': 'Reducing Excessive Margin to Achieve a Better Accuracy vs. Robustness Trade-off', 'paperID': 'ca1a8b92898c4e57aebcbd6c6f57e1cb9a4d0804', 'arxivId': None, 'publication_year': None, 'abstract': 'While adversarial training has become the de facto approach for training robust classiﬁers, it leads to a drop in accuracy. This has led to prior works postulating that accuracy is inherently at odds with robustness. Yet, the phenomenon remains inexplicable. In this paper, we closely examine the changes induced in the decision boundary of a deep network during adversarial training. We ﬁnd that adversarial training leads to unwarranted increase in the margin along certain adversarial directions, thereby hurting accuracy. Motivated by this observation, we present a novel algorithm, called Helper-based Adversarial Training (HAT) , to reduce this effect by incorporating additional wrongly labelled examples during training. Our proposed method provides a notable improvement in accuracy without compromising robustness. It achieves a better trade-off between accuracy and robustness in comparison to existing defenses.'}
{'title': 'Styleformer: Transformer based Generative Adversarial Networks with Style Vector', 'paperID': 'ccbadf4270417de29c4c6805a58e7b0ec819d751', 'arxivId': '2106.07023', 'publication_year': 2021, 'abstract': None}
{'title': 'Improved Denoising Diffusion Probabilistic Models', 'paperID': 'de18baa4964804cf471d85a5a090498242d2e79f', 'arxivId': '2102.09672', 'publication_year': 2021, 'abstract': None}
{'title': 'Negative Data Augmentation', 'paperID': 'b4beb15b524c583cd828300605bab66dc3caf386', 'arxivId': '2102.05113', 'publication_year': 2021, 'abstract': None}
{'title': 'Toward Better Accuracy-Efficiency Trade-Offs: Divide and Co-Training', 'paperID': '68118a9d2c29bd6bb6565cf21381ecdf1940a7ee', 'arxivId': '2011.14660', 'publication_year': 2020, 'abstract': None}
{'title': 'Learnable Boundary Guided Adversarial Training', 'paperID': '57acaf4538d1a6e26c77cfae5640e359e763952e', 'arxivId': '2011.11164', 'publication_year': 2020, 'abstract': None}
{'title': 'Denoising Diffusion Implicit Models', 'paperID': '014576b866078524286802b1d0e18628520aa886', 'arxivId': '2010.02502', 'publication_year': 2020, 'abstract': None}
{'title': 'Off-Policy Reinforcement Learning for Efficient and Effective GAN Architecture Search', 'paperID': '78ba6127fabb7056afc6f97924852bdd8b653b71', 'arxivId': '2007.09180', 'publication_year': 2020, 'abstract': None}
{'title': 'Differentiable Augmentation for Data-Efficient GAN Training', 'paperID': '670f9d0d8cafaeaeea564c88645b9816b1146cef', 'arxivId': '2006.10738', 'publication_year': 2020, 'abstract': None}
{'title': 'Improving Adversarial Robustness via Unlabeled Out-of-Domain Data', 'paperID': '4c0b4fe0fb05daba6deb12cb042d8ba2829c853d', 'arxivId': '2006.08476', 'publication_year': 2020, 'abstract': None}
{'title': 'Training Generative Adversarial Networks with Limited Data', 'paperID': '29858b40a15704398aecdca6bd2820f2fcc99891', 'arxivId': '2006.06676', 'publication_year': 2020, 'abstract': None}
{'title': 'Fawkes: Protecting Privacy against Unauthorized Deep Learning Models', 'paperID': '755a392fe813c9ba3282f60c0e1f1ec81e68f263', 'arxivId': None, 'publication_year': 2020, 'abstract': None}
{'title': 'A Review on Generative Adversarial Networks: Algorithms, Theory, and Applications', 'paperID': 'fbc5486a1ffb9039dbb5046b84f0eb32e4ce8eea', 'arxivId': '2001.06937', 'publication_year': 2020, 'abstract': None}
{'title': 'Big Transfer (BiT): General Visual Representation Learning', 'paperID': '0495d9df8eb84dcdab4e5536179823cd26279949', 'arxivId': '1912.11370', 'publication_year': 2019, 'abstract': None}
{'title': 'StarGAN v2: Diverse Image Synthesis for Multiple Domains', 'paperID': '5474ddca920f59c4ec3c243345a5b9248e64065b', 'arxivId': '1912.01865', 'publication_year': 2019, 'abstract': None}
{'title': 'Analyzing the Robustness of Open-World Machine Learning', 'paperID': '3297a6f172904430d5b4c6db84ad1a26cb706a1d', 'arxivId': None, 'publication_year': 2019, 'abstract': None}
{'title': 'Adversarial Lipschitz Regularization', 'paperID': '4538789bb5a4b3fb67123d905692800908061724', 'arxivId': '1907.05681', 'publication_year': 2019, 'abstract': None}
{'title': 'Sample-Efficient Neural Architecture Search by Learning Action Space', 'paperID': 'f3c7e853bb77d1ad360464aea81676cc9e3ca1fe', 'arxivId': '1906.06832', 'publication_year': 2019, 'abstract': None}
{'title': 'Classification Accuracy Score for Conditional Generative Models', 'paperID': 'ca42e4d7021d4e563bbeae7db35c1ce09fe38bfa', 'arxivId': '1905.10887', 'publication_year': 2019, 'abstract': None}
{'title': 'Mockingbird: Defending Against Deep-Learning-Based Website Fingerprinting Attacks With Adversarial Traces', 'paperID': '9ae649ab5201e06dbef50f005a5a35705a04bcdd', 'arxivId': '1902.06626', 'publication_year': 2019, 'abstract': None}
{'title': 'Adversarial Risk and Robustness: General Definitions and Implications for the Uniform Distribution', 'paperID': 'b4c1cd3f391c34bab08d6094c91793cb59f2da81', 'arxivId': '1810.12272', 'publication_year': 2018, 'abstract': None}
{'title': 'PATE-GAN: Generating Synthetic Data with Differential Privacy Guarantees', 'paperID': 'af1841e1db6579f1f1777a59c7e9e4658d2ac466', 'arxivId': None, 'publication_year': 2018, 'abstract': None}
{'title': 'Exploring the Limits of Weakly Supervised Pretraining', 'paperID': '0f885fd46064d271d4404cf9bb3d758e1a6f8d55', 'arxivId': '1805.00932', 'publication_year': 2018, 'abstract': None}
{'title': 'Adversarial Spheres', 'paperID': 'e77171024bf7dc2ff33db89710f1184543c694e5', 'arxivId': None, 'publication_year': 2018, 'abstract': None}
{'title': 'Revisiting Unreasonable Effectiveness of Data in Deep Learning Era', 'paperID': '8760bc7631c0cb04e7138254e9fd6451b7def8ca', 'arxivId': '1707.02968', 'publication_year': 2017, 'abstract': None}
{'title': 'GANs Trained by a Two Time-Scale Update Rule Converge to a Local Nash Equilibrium', 'paperID': '231af7dc01a166cac3b5b01ca05778238f796e41', 'arxivId': '1706.08500', 'publication_year': 2017, 'abstract': None}
{'title': 'The Fréchet distance between multivariate normal distributions', 'paperID': 'deecd9ff87d3f7daac4dfb2057335f7190287e93', 'arxivId': None, 'publication_year': 1982, 'abstract': None}
{'title': 'PAC-learning in the presence of adversaries', 'paperID': '660eb0ec1d00570c92eba6d3e2416ed7d45c2002', 'arxivId': None, 'publication_year': 2018, 'abstract': None}
{'title': 'Robust Learning Meets Generative Models: Can Proxy Distributions Improve Adversarial Robustness?', 'paperID': '8bcb5534227214b83255f5b9dedbc0d46a44794a', 'arxivId': '2104.09425', 'publication_year': '2021', 'abstract': 'While additional training data improves the robustness of deep neural networks against adversarial examples, it presents the challenge of curating a large number of specific real-world samples. We circumvent this challenge by using additional data from proxy distributions learned by advanced generative models. We first seek to formally understand the transfer of robustness from classifiers trained on proxy distributions to the real data distribution. We prove that the difference between the robustness of a classifier on the two distributions is upper bounded by the conditional Wasserstein distance between them. Next we use proxy distributions to significantly improve the performance of adversarial training on five different datasets. For example, we improve robust accuracy by up to 7.5% and 6.7% in $\\ell_{\\infty}$ and $\\ell_2$ threat model over baselines that are not using proxy distributions on the CIFAR-10 dataset. We also improve certified robust accuracy by 7.6% on the CIFAR-10 dataset. We further demonstrate that different generative models bring a disparate improvement in the performance in robust training. We propose a robust discrimination approach to characterize the impact of individual generative models and further provide a deeper understanding of why current state-of-the-art in diffusion-based generative models are a better choice for proxy distribution than generative adversarial networks.'}
{'title': 'DI-AA: An Interpretable White-box Attack for Fooling Deep Neural Networks', 'paperID': '21e6dd66d5cb82c5cd19d86bdacaaa9bce336a07', 'arxivId': '2110.07305', 'publication_year': 2021, 'abstract': None}
{'title': 'Certified Patch Robustness via Smoothed Vision Transformers', 'paperID': '6d3fc40b741054422acf55a26c756d7e61e706f3', 'arxivId': '2110.07719', 'publication_year': 2021, 'abstract': None}
{'title': 'Parallel Rectangle Flip Attack: A Query-based Black-box Attack against Object Detection', 'paperID': '12cdc1423ac0eb27a26d3883cf485b2f0a4f4e50', 'arxivId': '2201.08970', 'publication_year': 2021, 'abstract': None}
{'title': 'Meta Gradient Adversarial Attack', 'paperID': 'b4075b25bf107270fc589784aaa6d933c1ce918d', 'arxivId': '2108.04204', 'publication_year': 2021, 'abstract': None}
{'title': 'Defense Against Adversarial Attacks by Reconstructing Images', 'paperID': 'ebe970bbf1ead67dfb2b857173fbc79bb0edb161', 'arxivId': None, 'publication_year': 2021, 'abstract': None}
{'title': 'Boosting Adversarial Robustness using Feature Level Stochastic Smoothing', 'paperID': '9afd4501100f3abbad90f570331ebe09d3e375c4', 'arxivId': '2306.06462', 'publication_year': 2021, 'abstract': None}
{'title': 'Adversarial example detection for DNN models: a review and experimental comparison', 'paperID': '3a0c1300a72337871bd60178e1347084fb8bb5f0', 'arxivId': '2105.00203', 'publication_year': 2021, 'abstract': None}
{'title': 'Self Adversarial Attack as an Augmentation Method for Immunohistochemical Stainings', 'paperID': '5ad2a01ffb5408fdf14e442f80279a6e84159d0c', 'arxivId': '2103.11362', 'publication_year': 2021, 'abstract': None}
{'title': 'A Zeroth-Order Block Coordinate Descent Algorithm for Huge-Scale Black-Box Optimization', 'paperID': '32e0f1bf36ccee6ed552909c2c76f9d6b1c760ef', 'arxivId': '2102.10707', 'publication_year': 2021, 'abstract': None}
{'title': 'Towards Robust LiDAR-based Perception in Autonomous Driving: General Black-box Adversarial Sensor Attack and Countermeasures', 'paperID': '9d13c6b39f7ea80b5b91dff29f5e682ed1436893', 'arxivId': '2006.16974', 'publication_year': 2020, 'abstract': None}
{'title': 'A Primer on Zeroth-Order Optimization in Signal Processing and Machine Learning: Principals, Recent Advances, and Applications', 'paperID': '9848db2098c0d3db6ee6f10a177402bc4ec67f83', 'arxivId': '2006.06224', 'publication_year': 2020, 'abstract': None}
{'title': 'The ENIGMA‐Epilepsy working group: Mapping disease from large data sets', 'paperID': '102a1eb3cdd2014caa8f523093e192f14017024a', 'arxivId': None, 'publication_year': 2020, 'abstract': None}
{'title': 'Zeroth-Order Regularized Optimization (ZORO): Approximately Sparse Gradients and Adaptive Sampling', 'paperID': '8cc7f2d88d193fd8ecf1fdfa0a6345c3e79e1887', 'arxivId': '2003.13001', 'publication_year': 2020, 'abstract': None}
{'title': 'Improving Robustness of Deep-Learning-Based Image Reconstruction', 'paperID': '0a06a8da7667a70bf1f3836f7e7ca72b5ab72176', 'arxivId': '2002.11821', 'publication_year': 2020, 'abstract': None}
{'title': 'Secure and Robust Machine Learning for Healthcare: A Survey', 'paperID': 'e5e41ca6d5ebbf5f8ef1c77791fa4c75ef1ceb1b', 'arxivId': '2001.08103', 'publication_year': 2020, 'abstract': None}
{'title': 'Model Inversion Networks for Model-Based Optimization', 'paperID': '8403eb1de9cd5ee56f8976d6b9846cb4adc282cf', 'arxivId': '1912.13464', 'publication_year': 2019, 'abstract': None}
{'title': 'Black-Box Adversarial Attack with Transferable Model-based Embedding', 'paperID': '3f2095bbbf3e47fbac26da70e95a219c23e3bac9', 'arxivId': '1911.07140', 'publication_year': 2019, 'abstract': None}
{'title': 'Adversarial T-Shirt! Evading Person Detectors in a Physical World', 'paperID': '3d2cfca77ebe773532f9f178b726c20fcf6d4ee4', 'arxivId': None, 'publication_year': 2019, 'abstract': None}
{'title': 'Min-Max Optimization without Gradients: Convergence and Applications to Adversarial ML', 'paperID': '358b779448da4e5b57f39bf8e58f70c4d2656fab', 'arxivId': '1909.13806', 'publication_year': 2019, 'abstract': None}
{'title': 'On instabilities of deep learning in image reconstruction and the potential costs of AI', 'paperID': 'f8a2e5ebf96f55035ebf215156c87a5a9b3be1c5', 'arxivId': '1902.05300', 'publication_year': 2019, 'abstract': None}
{'title': 'Prior Convictions: Black-Box Adversarial Attacks with Bandits and Priors', 'paperID': '10ab21b120e305b6d3cbf81c5a906d36521152f1', 'arxivId': '1807.07978', 'publication_year': 2018, 'abstract': None}
{'title': 'On the Information-Adaptive Variants of the ADMM: An Iteration Complexity Perspective', 'paperID': '41f48a3b065cb038fa98f91c4775bf1a91f47764', 'arxivId': None, 'publication_year': 2018, 'abstract': None}
{'title': 'Zeroth-Order Stochastic Variance Reduction for Nonconvex Optimization', 'paperID': '65f0e9db55f498bb196de3950393f5ded14bcc72', 'arxivId': '1805.10367', 'publication_year': 2018, 'abstract': None}
{'title': 'Towards Reverse-Engineering Black-Box Neural Networks', 'paperID': 'e8b9fa6f9e0b606ff335a0557a838dea2696b084', 'arxivId': None, 'publication_year': 2017, 'abstract': None}
{'title': 'Adversarial and Clean Data Are Not Twins', 'paperID': 'adb762a645b72fc4605e6fb512ef2684db37cc93', 'arxivId': '1704.04960', 'publication_year': 2017, 'abstract': None}
{'title': 'A Comprehensive Linear Speedup Analysis for Asynchronous Stochastic Parallel Optimization from Zeroth-Order to First-Order', 'paperID': '156151365037ef177ab59db1faf7b2f2eecfadcf', 'arxivId': '1606.00498', 'publication_year': 2016, 'abstract': None}
{'title': 'Image Restoration Using Very Deep Convolutional Encoder-Decoder Networks with Symmetric Skip Connections', 'paperID': '18168aea48a22f6fe2fe407c0ff70083cba225a7', 'arxivId': None, 'publication_year': 2016, 'abstract': None}
{'title': 'Model Inversion Attacks that Exploit Confidence Information and Basic Countermeasures', 'paperID': 'd1b9a3b11e6c9571a1553556f82b605b2b4baec3', 'arxivId': None, 'publication_year': 2015, 'abstract': None}
{'title': 'Stochastic First- and Zeroth-Order Methods for Nonconvex Stochastic Programming', 'paperID': '8424a9e5a4456a2c45a42e392b9c01cd0c5c9467', 'arxivId': '1309.5549', 'publication_year': 2013, 'abstract': None}
{'title': 'signSGD via Zeroth-Order Oracle', 'paperID': '3ae1544865a18d8649a5c4939f9eb17165b23bea', 'arxivId': None, 'publication_year': 2019, 'abstract': None}
{'title': 'Making Medical Image Reconstruction Adversarially Robust', 'paperID': '3095ed47bf1d7218422cd842707b558b7c9789e1', 'arxivId': None, 'publication_year': 2019, 'abstract': None}
{'title': 'How to Robustify Black-Box ML Models? A Zeroth-Order Optimization Perspective', 'paperID': '7d56ea205f9a8f83225569e3acf4c6c8c5b0977e', 'arxivId': '2203.14195', 'publication_year': '2022', 'abstract': 'The lack of adversarial robustness has been recognized as an important issue for state-of-the-art machine learning (ML) models, e.g., deep neural networks (DNNs). Thereby, robustifying ML models against adversarial attacks is now a major focus of research. However, nearly all existing defense methods, particularly for robust training, made the white-box assumption that the defender has the access to the details of an ML model (or its surrogate alternatives if available), e.g., its architectures and parameters. Beyond existing works, in this paper we aim to address the problem of black-box defense: How to robustify a black-box model using just input queries and output feedback? Such a problem arises in practical scenarios, where the owner of the predictive model is reluctant to share model information in order to preserve privacy. To this end, we propose a general notion of defensive operation that can be applied to black-box models, and design it through the lens of denoised smoothing (DS), a first-order (FO) certified defense technique. To allow the design of merely using model queries, we further integrate DS with the zeroth-order (gradient-free) optimization. However, a direct implementation of zeroth-order (ZO) optimization suffers a high variance of gradient estimates, and thus leads to ineffective defense. To tackle this problem, we next propose to prepend an autoencoder (AE) to a given (black-box) model so that DS can be trained using variance-reduced ZO optimization. We term the eventual defense as ZO-AE-DS. In practice, we empirically show that ZO-AE- DS can achieve improved accuracy, certified robustness, and query complexity over existing baselines. And the effectiveness of our approach is justified under both image classification and image reconstruction tasks. Codes are available at https://github.com/damon-demon/Black-Box-Defense.'}
{'title': 'Robust Training in High Dimensions via Block Coordinate Geometric Median Descent', 'paperID': '46b990e2a9797214b185ff61839d137c2a1c0ddf', 'arxivId': '2106.08882', 'publication_year': 2021, 'abstract': None}
{'title': 'Byzantine-Resilient Non-Convex Stochastic Gradient Descent', 'paperID': '029c33e39236f01e83a952c4203d86e07a6c1532', 'arxivId': '2012.14368', 'publication_year': 2020, 'abstract': None}
{'title': 'Learning from History for Byzantine Robust Optimization', 'paperID': '693eb9ecd819712abb40cc6c059aa84c84d354bb', 'arxivId': '2012.10333', 'publication_year': 2020, 'abstract': None}
{'title': 'Collaborative Learning in the Jungle (Decentralized, Byzantine, Heterogeneous, Asynchronous and Nonconvex Learning)', 'paperID': '2cdc50b5b4f51a9cf08a014d0ac9f8ca3a7523f5', 'arxivId': '2008.00742', 'publication_year': 2020, 'abstract': None}
{'title': 'Attack of the Tails: Yes, You Really Can Backdoor Federated Learning', 'paperID': '0a93fce82afa33b218728a19d19d0ae40401b396', 'arxivId': '2007.05084', 'publication_year': 2020, 'abstract': None}
{'title': 'Byzantine-Resilient High-Dimensional SGD with Local Iterations on Heterogeneous Data', 'paperID': 'c471da6f4a796992e6d2c5be40f026cb176c6de6', 'arxivId': '2006.13041', 'publication_year': 2020, 'abstract': None}
{'title': 'Byzantine-Resilient SGD in High Dimensions on Heterogeneous Data', 'paperID': 'fc4e43efe5c005a2a57a82debdacb9f1fee3c30c', 'arxivId': '2005.07866', 'publication_year': 2020, 'abstract': None}
{'title': 'On the Byzantine Robustness of Clustered Federated Learning', 'paperID': 'daf0e811fbbb08ea8263ecc57747a572fe3d6b06', 'arxivId': None, 'publication_year': 2020, 'abstract': None}
{'title': 'BASGD: Buffered Asynchronous SGD for Byzantine Learning', 'paperID': '28b969d7801a3696d379fbb85a307c52284fa52a', 'arxivId': None, 'publication_year': 2020, 'abstract': None}
{'title': 'Robust Aggregation for Federated Learning', 'paperID': '6629248b79ad3e87d7f9f5694a315613ed201cca', 'arxivId': '1912.13445', 'publication_year': 2019, 'abstract': None}
{'title': 'Federated Variance-Reduced Stochastic Gradient Descent With Robustness to Byzantine Attacks', 'paperID': '57501373b7411336d1f97f5d431346e77b2bb2b0', 'arxivId': '1912.12716', 'publication_year': 2019, 'abstract': None}
{'title': 'Can You Really Backdoor Federated Learning?', 'paperID': 'fb4098dd30489715a7adc6a1f7839e283d1e37ee', 'arxivId': '1911.07963', 'publication_year': 2019, 'abstract': None}
{'title': 'Tighter Theory for Local SGD on Identical and Heterogeneous Data', 'paperID': '4f783752a59c28df08bad9b22dd9c7bafe4efb08', 'arxivId': '1909.04746', 'publication_year': 2019, 'abstract': None}
{'title': 'DETOX: A Redundancy-based Framework for Faster and More Robust Gradient Aggregation', 'paperID': 'c50e20273ac64bf59d083ef95a244ed516a5b2eb', 'arxivId': '1907.12205', 'publication_year': 2019, 'abstract': None}
{'title': 'RSA: Byzantine-Robust Stochastic Aggregation Methods for Distributed Learning from Heterogeneous Datasets', 'paperID': '1d0e74bcd599a333cd1568b74c5cfe365601987a', 'arxivId': None, 'publication_year': 2019, 'abstract': None}
{'title': 'Robust Federated Learning in a Heterogeneous Environment', 'paperID': '8f36274384f69e7e03a8a053b6ef0aed286e6caa', 'arxivId': '1906.06629', 'publication_year': 2019, 'abstract': None}
{'title': 'AGGREGATHOR: Byzantine Machine Learning via Robust Gradient Aggregation', 'paperID': 'f422b11a0b56ad4b0abba81c9fcadaaee0af4067', 'arxivId': None, 'publication_year': 2019, 'abstract': None}
{'title': 'Fall of Empires: Breaking Byzantine-tolerant SGD by Inner Product Manipulation', 'paperID': '6df8e13f9f3a620069b4eb6148d2b6ed5f2e46df', 'arxivId': '1903.03936', 'publication_year': 2019, 'abstract': None}
{'title': 'A Little Is Enough: Circumventing Defenses For Distributed Learning', 'paperID': 'c508f8ce3c84de19e41325be10ae6f9118534084', 'arxivId': '1902.06156', 'publication_year': 2019, 'abstract': None}
{'title': 'Towards Federated Learning at Scale: System Design', 'paperID': '79cf9462a583e1889781868cbf8c31e43b36dd2f', 'arxivId': '1902.01046', 'publication_year': 2019, 'abstract': None}
{'title': 'Error Feedback Fixes SignSGD and other Gradient Compression Schemes', 'paperID': '7c22a6a07e89461178b794681c675b209332ee15', 'arxivId': '1901.09847', 'publication_year': 2019, 'abstract': None}
{'title': 'Analyzing Federated Learning through an Adversarial Lens', 'paperID': '6c66108edb9af0533309055e7b2ecb8922db03d8', 'arxivId': '1811.12470', 'publication_year': 2018, 'abstract': None}
{'title': 'Fast and Faster Convergence of SGD for Over-Parameterized Models and an Accelerated Perceptron', 'paperID': '047a662fd3e5772a59d7f93f2212b8b429cfdbc6', 'arxivId': '1810.07288', 'publication_year': 2018, 'abstract': None}
{'title': 'signSGD with Majority Vote is Communication Efficient and Fault Tolerant', 'paperID': 'dbca9dbe14e9933515d2005dc1163ae2c24d9afd', 'arxivId': None, 'publication_year': 2018, 'abstract': None}
{'title': 'Parallel Restarted SGD with Faster Convergence and Less Communication: Demystifying Why Model Averaging Works for Deep Learning', 'paperID': 'e0e152748ea0badfbd798dfed3ac743abb58af26', 'arxivId': '1807.06629', 'publication_year': 2018, 'abstract': None}
{'title': 'How To Backdoor Federated Learning', 'paperID': '14d8b4fdb0262c30ae9afe20ea8e7227b115c63e', 'arxivId': '1807.00459', 'publication_year': 2018, 'abstract': None}
{'title': 'Zeno: Distributed Stochastic Gradient Descent with Suspicion-based Fault-tolerance', 'paperID': '0a4230af7869cf63159a444510627b4f91e38eed', 'arxivId': None, 'publication_year': 2018, 'abstract': None}
{'title': 'DRACO: Byzantine-resilient Distributed Training via Redundant Gradients', 'paperID': '31f8806397907e197ca1d3676f598fd197087ad6', 'arxivId': '1803.09877', 'publication_year': 2018, 'abstract': None}
{'title': 'Byzantine Stochastic Gradient Descent', 'paperID': '293346ebd2285e3ecbb297a2773830dddc4c0a34', 'arxivId': '1803.08917', 'publication_year': 2018, 'abstract': None}
{'title': 'Byzantine-Robust Distributed Learning: Towards Optimal Statistical Rates', 'paperID': '5ad1cfdc40f58c5ee078496312798f784fc80801', 'arxivId': '1803.01498', 'publication_year': 2018, 'abstract': None}
{'title': 'The Hidden Vulnerability of Distributed Learning in Byzantium', 'paperID': '81af3058f2df78be332f50ea3813be5aa1f02f58', 'arxivId': '1802.07927', 'publication_year': 2018, 'abstract': None}
{'title': 'Machine Learning with Adversaries: Byzantine Tolerant Gradient Descent', 'paperID': '9583ac53a19cdf0db81fef6eb0b63e66adbe2324', 'arxivId': None, 'publication_year': 2017, 'abstract': None}
{'title': 'Distributed Statistical Machine Learning in Adversarial Settings', 'paperID': 'b107a64c9dc343ac35231c7959090bbc3059203f', 'arxivId': '1705.05491', 'publication_year': 2017, 'abstract': None}
{'title': 'Geometric median in nearly linear time', 'paperID': '7b9d0aeeb280ef1fbc53a90c943270184c984fd3', 'arxivId': '1606.05225', 'publication_year': 2016, 'abstract': None}
{'title': 'Implementation of a Practical Distributed Calculation System with Browsers and JavaScript, and Application to Distributed Deep Learning', 'paperID': '24aa2f1004aab06000f24d5b650b891d6dc68818', 'arxivId': '1503.05743', 'publication_year': 2015, 'abstract': None}
{'title': 'MLitB: Machine Learning in the Browser', 'paperID': '6c666b51226637495953c0dfa8ba9853f2601aad', 'arxivId': '1412.2432', 'publication_year': 2014, 'abstract': None}
{'title': 'Geometric median and robust estimation in Banach spaces', 'paperID': 'adb542bb749073d80af52f2038ad6980e3874337', 'arxivId': '1308.1334', 'publication_year': 2013, 'abstract': None}
{'title': 'The Byzantine Generals Problem', 'paperID': '3e0080a34eca4eabb9b371c2b3c369dc4dc90112', 'arxivId': None, 'publication_year': 1982, 'abstract': None}
{'title': 'Byzantine-Robust Decentralized Learning via Self-Centered Clipping', 'paperID': '5273a3706a1cb40426a110b09eef7ad3ad684321', 'arxivId': None, 'publication_year': 2022, 'abstract': None}
{'title': 'Distributed Momentum for Byzantine-resilient Stochastic Gradient Descent', 'paperID': 'e175f23a38f7d589266b6e059ff8e2782d9a365b', 'arxivId': None, 'publication_year': 2021, 'abstract': None}
{'title': 'Simplified neuron model as a principal component analyzer', 'paperID': '3e00dd12caea7c4dab1633a35d1da3cb2e76b420', 'arxivId': None, 'publication_year': 1982, 'abstract': None}
{'title': 'Byzantine-Robust Learning on Heterogeneous Datasets via Bucketing', 'paperID': 'a9c13ada98fa493dd3552c794fdb3af9e9fbd523', 'arxivId': '2006.09365', 'publication_year': '2020', 'abstract': 'In Byzantine robust distributed or federated learning, a central server wants to train a machine learning model over data distributed across multiple workers. However, a fraction of these workers may deviate from the prescribed algorithm and send arbitrary messages. While this problem has received significant attention recently, most current defenses assume that the workers have identical data. For realistic cases when the data across workers are heterogeneous (non-iid), we design new attacks which circumvent current defenses, leading to significant loss of performance. We then propose a simple bucketing scheme that adapts existing robust algorithms to heterogeneous datasets at a negligible computational cost. We also theoretically and experimentally validate our approach, showing that combining bucketing with existing robust algorithms is effective against challenging attacks. Our work is the first to establish guaranteed convergence for the non-iid Byzantine robust problem under realistic assumptions.'}
{'title': 'Twice regularized MDPs and the equivalence between robustness and regularization', 'paperID': 'f56fecf83a24abaa4c6a7f132fa9cfb314ed1da8', 'arxivId': '2110.06267', 'publication_year': 2021, 'abstract': None}
{'title': 'Lyapunov Robust Constrained-MDPs: Soft-Constrained Robustly Stable Policy Optimization under Model Uncertainty', 'paperID': '7e1d5025c55e068b3645ff326c316ab4f31b72b8', 'arxivId': '2108.02701', 'publication_year': 2021, 'abstract': None}
{'title': 'Understanding Learned Reward Functions', 'paperID': 'e4609613a9efb85103424abb0cb15e814464ccd9', 'arxivId': '2012.05862', 'publication_year': 2020, 'abstract': None}
{'title': 'Recovery RL: Safe Reinforcement Learning With Learned Recovery Zones', 'paperID': '431dc05ac25510de6264084434254cca877f9ab3', 'arxivId': '2010.15920', 'publication_year': 2020, 'abstract': None}
{'title': 'Learning to be Safe: Deep RL with a Safety Critic', 'paperID': '96055d058984b15a9b83024bb2e07292ee7559f5', 'arxivId': '2010.14603', 'publication_year': 2020, 'abstract': None}
{'title': 'Munchausen Reinforcement Learning', 'paperID': '5015e3f9220b5569d21a5cd0ed2bd10c1c621693', 'arxivId': '2007.14430', 'publication_year': 2020, 'abstract': None}
{'title': 'Entropic Risk Constrained Soft-Robust Policy Optimization', 'paperID': '97b237ccba2fb7bf60acd5a9ee1b4adba947f61d', 'arxivId': '2006.11679', 'publication_year': 2020, 'abstract': None}
{'title': 'SVQN: Sequential Variational Soft Q-Learning Networks', 'paperID': '1b7c242baf54b5bda48e8f2ed1259ee4b3116686', 'arxivId': None, 'publication_year': 2020, 'abstract': None}
{'title': 'Leverage the Average: an Analysis of Regularization in RL', 'paperID': '1233591b1feebf8ddd02b015ce1cc69305c6ace0', 'arxivId': '2003.14089', 'publication_year': 2020, 'abstract': None}
{'title': 'Robust Reinforcement Learning via Adversarial training with Langevin Dynamics', 'paperID': '3d89830c0dd84bcd42b202c402aba1e0286015e7', 'arxivId': '2002.06063', 'publication_year': 2020, 'abstract': None}
{'title': 'Lipschitz Lifelong Reinforcement Learning', 'paperID': '207c7b8ea8f94463383a089e4f7f24b64503f9c0', 'arxivId': '2001.05411', 'publication_year': 2020, 'abstract': None}
{'title': 'LESS is More: Rethinking Probabilistic Models of Human Behavior', 'paperID': '976e128c32007cdaf95a4e278a1ea7aa33a2e5cc', 'arxivId': '2001.04465', 'publication_year': 2020, 'abstract': None}
{'title': 'Positive-Unlabeled Reward Learning', 'paperID': 'fcb4d00462eefa53a496b45acb87fa0d258d3500', 'arxivId': '1911.00459', 'publication_year': 2019, 'abstract': None}
{'title': 'Worst Cases Policy Gradients', 'paperID': '46712dd04ab67286efb47a8c072360d0c25946a6', 'arxivId': '1911.03618', 'publication_year': 2019, 'abstract': None}
{'title': 'Meta-World: A Benchmark and Evaluation for Multi-Task and Meta Reinforcement Learning', 'paperID': '0bc855f84668b35cb65618d996d09f6e434d28c9', 'arxivId': '1910.10897', 'publication_year': 2019, 'abstract': None}
{'title': 'Search on the Replay Buffer: Bridging Planning and Reinforcement Learning', 'paperID': 'e0889fcee1acd985af76a3907d5d0029bf260be9', 'arxivId': '1906.05253', 'publication_year': 2019, 'abstract': None}
{'title': 'Budgeted Reinforcement Learning in Continuous State Space', 'paperID': '2ef480614f3bb9034c4796404febd7f64bfc48fe', 'arxivId': None, 'publication_year': 2019, 'abstract': None}
{'title': 'Beyond Confidence Regions: Tight Bayesian Ambiguity Sets for Robust MDPs', 'paperID': 'd638241c8df4f015d894645ed2955afcfa2495fc', 'arxivId': '1902.07605', 'publication_year': 2019, 'abstract': None}
{'title': 'A Theory of Regularized Markov Decision Processes', 'paperID': 'b3b3d1d6d36ac203cd06c00bb37e66c000430275', 'arxivId': '1901.11275', 'publication_year': 2019, 'abstract': None}
{'title': 'Tsallis Reinforcement Learning: A Unified Framework for Maximum Entropy Reinforcement Learning', 'paperID': '46c5288bfddbe2dad70f846d1e69a37052b5d77e', 'arxivId': '1902.00137', 'publication_year': 2019, 'abstract': None}
{'title': 'Lyapunov-based Safe Policy Optimization for Continuous Control', 'paperID': '3fa50569925cfecc66fed5ec616682ecf3794ad7', 'arxivId': '1901.10031', 'publication_year': 2019, 'abstract': None}
{'title': 'Learning to Walk via Deep Reinforcement Learning', 'paperID': '2ed619fbc7902155d54f6f21da16ad6c120eac63', 'arxivId': '1812.11103', 'publication_year': 2018, 'abstract': None}
{'title': 'Understanding the impact of entropy on policy optimization', 'paperID': 'c4955faa27e082a80504285c28324c58eb52250c', 'arxivId': '1811.11214', 'publication_year': 2018, 'abstract': None}
{'title': 'Understanding the impact of entropy in policy learning', 'paperID': '56eca9e361f6ab91b7eb9dad051a2c8a4e652e07', 'arxivId': None, 'publication_year': 2018, 'abstract': None}
{'title': 'Illuminating Generalization in Deep Reinforcement Learning through Procedural Level Generation', 'paperID': '60fc8a885083f74c7a0aea829c81a92f2107e4d1', 'arxivId': '1806.10729', 'publication_year': 2018, 'abstract': None}
{'title': 'Reinforcement Learning and Control as Probabilistic Inference: Tutorial and Review', 'paperID': '6ecc4b1ab05f3ec12484a0ea36abfd6271c5c5ba', 'arxivId': '1805.00909', 'publication_year': 2018, 'abstract': None}
{'title': 'Variational Inverse Control with Events: A General Framework for Data-Driven Reward Definition', 'paperID': '36f7f407bbad234929c69c0dd3bdcfcd80298c7c', 'arxivId': '1805.11686', 'publication_year': 2018, 'abstract': None}
{'title': 'A Study on Overfitting in Deep Reinforcement Learning', 'paperID': '3fee7b836b71125a5f6a3696b9c383dae18c21e8', 'arxivId': '1804.06893', 'publication_year': 2018, 'abstract': None}
{'title': 'The Many Faces of Exponential Weights in Online Learning', 'paperID': 'aa42316a94e55edf562a816c3fe7520ac667a2e3', 'arxivId': '1802.07543', 'publication_year': 2018, 'abstract': None}
{'title': 'Leave no Trace: Learning to Reset for Safe and Autonomous Reinforcement Learning', 'paperID': '31c8082ac852693431b53afcdc3ea97ed7974e9a', 'arxivId': '1711.06782', 'publication_year': 2017, 'abstract': None}
{'title': 'Inverse Reward Design', 'paperID': '59094d64844ee21e32560fb08db6d53cc3af0c51', 'arxivId': '1711.02827', 'publication_year': 2017, 'abstract': None}
{'title': 'A unified view of entropy-regularized Markov decision processes', 'paperID': '2e7d1e21409a90e66106722506aeb434ee7a18f3', 'arxivId': '1705.07798', 'publication_year': 2017, 'abstract': None}
{'title': 'Reinforcement Learning with Deep Energy-Based Policies', 'paperID': '9172cd6c253edf7c3a1568e03577db20648ad0c4', 'arxivId': '1702.08165', 'publication_year': 2017, 'abstract': None}
{'title': '(CAD)$^2$RL: Real Single-Image Flight without a Single Real Image', 'paperID': 'f7ac2479e686eb2a7a8afc23f99f213fcd3c5292', 'arxivId': '1611.04201', 'publication_year': 2016, 'abstract': None}
{'title': 'EPOpt: Learning Robust Neural Network Policies Using Model Ensembles', 'paperID': '9228fa3b363229780da4cb1d258942e0c13c2947', 'arxivId': '1610.01283', 'publication_year': 2016, 'abstract': None}
{'title': 'The CMA Evolution Strategy: A Tutorial', 'paperID': '7c6409ec154ba64f5eb63d8c6e9f419ce1472289', 'arxivId': '1604.00772', 'publication_year': 2016, 'abstract': None}
{'title': 'Continuous Deep Q-Learning with Model-based Acceleration', 'paperID': 'd358d41c69450b171327ebd99462b6afef687269', 'arxivId': '1603.00748', 'publication_year': 2016, 'abstract': None}
{'title': 'Risk-Constrained Reinforcement Learning with Percentile Risk Criteria', 'paperID': '759bbd8dd50cb4790cad7a3bccbdfcbfee5e3e89', 'arxivId': '1512.01629', 'publication_year': 2015, 'abstract': None}
{'title': 'Risk-Sensitive Reinforcement Learning', 'paperID': 'f0c4b7568f378e652645232e66a1dab4c5b5293f', 'arxivId': '1311.2097', 'publication_year': 2013, 'abstract': None}
{'title': 'Online Learning and Online Convex Optimization', 'paperID': 'bcce96a2a074448953fc61a29a84afbdfc8db55a', 'arxivId': None, 'publication_year': 2012, 'abstract': None}
{'title': 'Maximum Causal Entropy Correlated Equilibria for Markov Games', 'paperID': '111b9c7263daec83fa5164fa07888fab18c6c033', 'arxivId': None, 'publication_year': 2011, 'abstract': None}
{'title': 'A Generalized Path Integral Control Approach to Reinforcement Learning', 'paperID': 'f7e59546d75b2fe71d1fdda2773f84bb04fcc6d2', 'arxivId': None, 'publication_year': 2010, 'abstract': None}
{'title': 'Robot trajectory optimization using approximate inference', 'paperID': '7a7a23f2c39f9b1526bc8853c6c71a5b7f89e68c', 'arxivId': None, 'publication_year': 2009, 'abstract': None}
{'title': 'Linearly-solvable Markov decision problems', 'paperID': '8570302f7b63e8fcf87030f556b065fd8c260021', 'arxivId': None, 'publication_year': 2006, 'abstract': None}
{'title': 'Path integrals and symmetry breaking for optimal control theory', 'paperID': 'b107acedcf1953ff498ff459f915845962c47674', 'arxivId': 'physics/0505066', 'publication_year': 2005, 'abstract': None}
{'title': 'Game theory, maximum entropy, minimum discrepancy and robust Bayesian decision theory', 'paperID': 'eb6e94817bc64429adfc786574696d6dea633939', 'arxivId': 'math/0410076', 'publication_year': 2004, 'abstract': None}
{'title': 'Robust and optimal control', 'paperID': 'b0dc50b566596f4b74a6317e260fee169336dc48', 'arxivId': None, 'publication_year': 1995, 'abstract': None}
{'title': 'Robust and Optimal Control', 'paperID': '6e4355cadf50252a10e985ac94449a574b38768e', 'arxivId': None, 'publication_year': 2014, 'abstract': None}
{'title': 'Transfer in Reinforcement Learning: A Framework and a Survey', 'paperID': '16c97a8a29b0d63fdb119daefabc47df92ff6c24', 'arxivId': None, 'publication_year': 2012, 'abstract': None}
{'title': 'Modeling Purposeful Adaptive Behavior with the Principle of Maximum Causal Entropy', 'paperID': '2a65434d43ffa6554eaf14b728780919ad4f33eb', 'arxivId': None, 'publication_year': 2010, 'abstract': None}
{'title': 'Planning by Probabilistic Inference', 'paperID': 'b25a8003a4e62d2db21560c52fb7030547834e87', 'arxivId': None, 'publication_year': 2003, 'abstract': None}
{'title': 'Solving Uncertain Markov Decision Processes', 'paperID': '85c851b739b4c7fae13bc7554f34f0ceec00f510', 'arxivId': None, 'publication_year': 2001, 'abstract': None}
{'title': 'Feedback Control Theory', 'paperID': '4645bec4bf86a94265039a357166db457b3f7aad', 'arxivId': None, 'publication_year': 1992, 'abstract': None}
{'title': 'Function Optimization using Connectionist Reinforcement Learning Algorithms', 'paperID': '6bc8db0c7444d9c07aad440393b2fd300fb3595c', 'arxivId': None, 'publication_year': 1991, 'abstract': None}
{'title': 'ACTIVITY ANALYSIS OF PRODUCTION AND ALLOCATION', 'paperID': 'a973eb892f233acb3093589393181ae633d3a244', 'arxivId': None, 'publication_year': 1952, 'abstract': None}
{'title': 'Neural SDEs as Infinite-Dimensional GANs', 'paperID': 'b2f3f828ef7d711c6d2a3174e6745f8f833ee158', 'arxivId': '2102.03657', 'publication_year': 2021, 'abstract': None}
{'title': 'Neural Rough Differential Equations for Long Time Series', 'paperID': '6c21ca5e4c2524b7373488c5674d4b3856643b98', 'arxivId': '2009.08295', 'publication_year': 2020, 'abstract': None}
{'title': 'Scalable Gradients for Stochastic Differential Equations', 'paperID': '03058f9a39d37a8bee635969eed227d59bbc8152', 'arxivId': '2001.01328', 'publication_year': 2020, 'abstract': None}
{'title': 'Graph Neural Ordinary Differential Equations', 'paperID': '8540780e6b9422f7a1264edb70f39d3ff79bb8c1', 'arxivId': '1911.07532', 'publication_year': 2019, 'abstract': None}
{'title': 'Hamiltonian Graph Networks with ODE Integrators', 'paperID': '57784e5db3504d549d16382de8f7f4ad222b3d71', 'arxivId': '1909.12790', 'publication_year': 2019, 'abstract': None}
{'title': 'Hamiltonian Neural Networks', 'paperID': 'bb758228488bd5a67a8bc7369bf090b3d2bc4cc3', 'arxivId': '1906.01563', 'publication_year': 2019, 'abstract': None}
{'title': 'Neural Jump Stochastic Differential Equations', 'paperID': '5d6563505d1da1dc4ae3b13e29fd77f03bd667be', 'arxivId': '1905.10403', 'publication_year': 2019, 'abstract': None}
{'title': 'Neural Stochastic Differential Equations: Deep Latent Gaussian Models in the Diffusion Limit', 'paperID': '1ea024f76115c1f6d9c3bbe1889ff9941f333241', 'arxivId': '1905.09883', 'publication_year': 2019, 'abstract': None}
{'title': 'Stochastic turbulence modeling in RANS simulations via Multilevel Monte Carlo', 'paperID': '166ffd62f4f095efc475fc6ae9cb7ab0c059d31d', 'arxivId': '1811.00872', 'publication_year': 2018, 'abstract': None}
{'title': 'LEARNING STOCHASTIC DIFFERENTIAL EQUATIONS WITH GAUSSIAN PROCESSES WITHOUT GRADIENT MATCHING', 'paperID': 'c9e976ddbe75a2f42d21e68846055a9952a04544', 'arxivId': '1807.05748', 'publication_year': 2018, 'abstract': None}
{'title': 'Approximate Bayes learning of stochastic differential equations.', 'paperID': '5dd88e69bdc35636eab242eb24cc718e1d8e67ac', 'arxivId': '1702.05390', 'publication_year': 2017, 'abstract': None}
{'title': 'Laplace based approximate posterior inference for differential equation models', 'paperID': '922bfe9407a0d2681c7cb75ab7017f9aebff1df7', 'arxivId': '1607.07203', 'publication_year': 2016, 'abstract': None}
{'title': 'Kernel Interpolation for Scalable Structured Gaussian Processes (KISS-GP)', 'paperID': '767d0625c4767c6b8afa0b1b30deafed7e0e8f08', 'arxivId': '1503.01057', 'publication_year': 2015, 'abstract': None}
{'title': 'Stochastic Processes and Applications: Diffusion Processes, the Fokker-Planck and Langevin Equations', 'paperID': 'd85071fa91d57ab389043db37f4e22ff71b80d2d', 'arxivId': None, 'publication_year': 2014, 'abstract': None}
{'title': 'On a perturbation theory and on strong convergence rates for stochastic ordinary and partial differential equations with nonglobally monotone coefficients', 'paperID': '69b450c38e1b9e455cc9730709c14ed36a88d74f', 'arxivId': None, 'publication_year': 2020, 'abstract': None}
{'title': 'Bayesian Estimation in Stochastic Differential Equation Models via Laplace Approximation', 'paperID': '824de969e5b8512a24db44b2c12a3930ff20a597', 'arxivId': None, 'publication_year': 2016, 'abstract': None}
{'title': 'Stochastic Calculus of Variations in Mathematical Finance', 'paperID': 'ec3e5379119a676c126353c92f4a2953d76890f6', 'arxivId': None, 'publication_year': 2005, 'abstract': None}
{'title': 'On Transforming a Certain Class of Stochastic Processes by Absolutely Continuous Substitution of Measures', 'paperID': '7b1eafc158d341831c6a7645413a557fff5dd52a', 'arxivId': None, 'publication_year': 1960, 'abstract': None}
{'title': 'Robust and Scalable SDE Learning: A Functional Perspective', 'paperID': '95088cb4b573cde65e748d9764dbbced0157309c', 'arxivId': '2110.05167', 'publication_year': '2021', 'abstract': 'Stochastic differential equations provide a rich class of flexible generative models, capable of describing a wide range of spatio-temporal processes. A host of recent work looks to learn data-representing SDEs, using neural networks and other flexible function approximators. Despite these advances, learning remains computationally expensive due to the sequential nature of SDE integrators. In this work, we propose an importance-sampling estimator for probabilities of observations of SDEs for the purposes of learning. Crucially, the approach we suggest does not rely on such integrators. The proposed method produces lower-variance gradient estimates compared to algorithms based on SDE integrators and has the added advantage of being embarrassingly parallelizable. This facilitates the effective use of large-scale parallel hardware for massive decreases in computation time.'}
{'title': 'Improving Robustness using Generated Data', 'paperID': '9c8d46b59e871e18d8d2e1ec1aa9b96d2f3d7342', 'arxivId': '2110.09468', 'publication_year': 2021, 'abstract': None}
{'title': 'Opposing effects of selectivity and invariance in peripheral vision', 'paperID': '9ebc9bcde129a7a78141379a6b476d3e8b95eedc', 'arxivId': None, 'publication_year': 2021, 'abstract': None}
{'title': 'Partial success in closing the gap between human and machine vision', 'paperID': '0e100c06d9fbdf32c434fd40469939a4aaab6c24', 'arxivId': '2106.07411', 'publication_year': 2021, 'abstract': None}
{'title': 'FoveaTer: Foveated Transformer for Image Classification', 'paperID': 'b61dc7fcb46c4c5bfa2bd6df7640a07d6b3a6ff2', 'arxivId': '2105.14173', 'publication_year': 2021, 'abstract': None}
{'title': 'How to Represent Part-Whole Hierarchies in a Neural Network', 'paperID': '5cee90b85b88e4de1d51b2963613a48b68916ac7', 'arxivId': '2102.12627', 'publication_year': 2021, 'abstract': None}
{'title': 'Comparison of Full-Reference Image Quality Models for Optimization of Image Processing Systems', 'paperID': '18bb573ab638f5ed7f1b65c92fc866736a757d19', 'arxivId': None, 'publication_year': 2021, 'abstract': None}
{'title': 'A review of interactions between peripheral and foveal vision', 'paperID': 'd20234588c318328bafdd421514667d12dad0cfa', 'arxivId': None, 'publication_year': 2020, 'abstract': None}
{'title': 'Performance vs. competence in human–machine comparisons', 'paperID': 'd3aa93e3453ea2d5ea0e39324d8f2d9a0ac0aa43', 'arxivId': None, 'publication_year': 2020, 'abstract': None}
{'title': 'Mind the Pad - CNNs can Develop Blind Spots', 'paperID': 'f24f62fabec6bca02658c320ff9b43c84947c5de', 'arxivId': '2010.02178', 'publication_year': 2020, 'abstract': None}
{'title': 'Biologically Inspired Mechanisms for Adversarial Robustness', 'paperID': '12a2eb89765f547ecc1cc08819f1e458bd6f99a0', 'arxivId': '2006.16427', 'publication_year': 2020, 'abstract': None}
{'title': 'Simulating a Primary Visual Cortex at the Front of CNNs Improves Robustness to Image Perturbations', 'paperID': '7323ff36df929ecf1b877c8d0daadffae384c3e3', 'arxivId': None, 'publication_year': 2020, 'abstract': None}
{'title': 'Emergent Properties of Foveated Perceptual Systems', 'paperID': '8b6d18a00a78174864bc16fd705ca6c9241aefb3', 'arxivId': '2006.07991', 'publication_year': 2020, 'abstract': None}
{'title': 'Five points to check when comparing visual perception in humans and machines', 'paperID': 'aae016c76f0f88353d8930522c2344804bdb635f', 'arxivId': None, 'publication_year': 2020, 'abstract': None}
{'title': 'Image Quality Assessment: Unifying Structure and Texture Similarity', 'paperID': '21549620b6c67a3a9bf10d23e4e16863bf901076', 'arxivId': '2004.07728', 'publication_year': 2020, 'abstract': None}
{'title': 'Scale and translation-invariance for novel objects in human vision', 'paperID': 'a948c242a71b470b1aa55f986737d39507bcff9e', 'arxivId': None, 'publication_year': 2020, 'abstract': None}
{'title': 'Flexible contextual modulation of naturalistic texture perception in peripheral vision', 'paperID': '411c0ebf6acf722f1da05e1568bbbf65e1bc1660', 'arxivId': None, 'publication_year': 2020, 'abstract': None}
{'title': 'Controversial stimuli: Pitting neural networks against each other as models of human cognition', 'paperID': '508cd4f136c196b14c6b67e4e3c7f4eaee2a902a', 'arxivId': '1911.09288', 'publication_year': 2019, 'abstract': None}
{'title': 'Image Synthesis with a Single (Robust) Classifier', 'paperID': '6748d363ae384b8675ade6ba2e2de75d2d215368', 'arxivId': None, 'publication_year': 2019, 'abstract': None}
{'title': 'In Praise of Artifice Reloaded: Caution With Natural Image Databases in Modeling Vision', 'paperID': '9115482a981c73627aa624d54aa3712401e210d7', 'arxivId': None, 'publication_year': 2019, 'abstract': None}
{'title': 'Mid-level visual features underlie the high-level categorical organization of the ventral stream', 'paperID': '2f477392205e146fc705b017bb7069d9aad76cac', 'arxivId': None, 'publication_year': 2018, 'abstract': None}
{'title': 'Image content is more important than Bouma’s Law for scene metamers', 'paperID': 'b32d735f0807bb92da06c3a2669c69bc525ce0ea', 'arxivId': None, 'publication_year': 2018, 'abstract': None}
{'title': 'Eigen-Distortions of Hierarchical Representations', 'paperID': '9811229959e14dd9578bd8d8336dfc40e128668c', 'arxivId': '1710.02266', 'publication_year': 2017, 'abstract': None}
{'title': 'A parametric texture model based on deep convolutional features closely matches texture appearance for humans.', 'paperID': '03c34b161fc7f953325dd451d97dc51d47914afb', 'arxivId': None, 'publication_year': 2017, 'abstract': None}
{'title': 'Towards Metamerism via Foveated Style Transfer', 'paperID': '7f3df93baabaf66bebbf7a24257f4ada252bc959', 'arxivId': '1705.10041', 'publication_year': 2017, 'abstract': None}
{'title': 'Capabilities and Limitations of Peripheral Vision.', 'paperID': '20a6a3c123cd6fdb2ffb495fb55ff8c33c40b767', 'arxivId': None, 'publication_year': 2016, 'abstract': None}
{'title': 'Selectivity and tolerance for visual texture in macaque V2', 'paperID': '692009b1a91bcf71b5f222ec55a2ccfa73483d23', 'arxivId': None, 'publication_year': 2016, 'abstract': None}
{'title': 'Texture synthesis through convolutional neural networks and spectrum constraints', 'paperID': 'a6a9dad014f29c6f8eb19f4dfa1461bf207c4a29', 'arxivId': '1605.01141', 'publication_year': 2016, 'abstract': None}
{'title': 'Texture Synthesis Using Convolutional Neural Networks', 'paperID': '0d0eeb46fc5ec778a62bb94aa2ef261b08e6f8c6', 'arxivId': None, 'publication_year': 2015, 'abstract': None}
{'title': 'Understanding deep image representations by inverting them', 'paperID': '4d790c8fae40357d24813d085fa74a436847fb49', 'arxivId': '1412.0035', 'publication_year': 2014, 'abstract': None}
{'title': 'Computational role of eccentricity dependent cortical magnification', 'paperID': '676e15313be9e5e3111e6af360238763c6835028', 'arxivId': '1406.1770', 'publication_year': 2014, 'abstract': None}
{'title': 'Deep learning in neural networks: An overview', 'paperID': '193edd20cae92c6759c18ce93eeea96afd9528eb', 'arxivId': '1404.7828', 'publication_year': 2014, 'abstract': None}
{'title': 'Saccade-confounded image statistics explain visual crowding', 'paperID': '4536ccb185343cc3eaa2fee395fe8f684f8369eb', 'arxivId': None, 'publication_year': 2012, 'abstract': None}
{'title': 'Metamers of the ventral stream', 'paperID': '1ef9dd95d3f10f22cd1de602810adf5d07aa906f', 'arxivId': None, 'publication_year': 2011, 'abstract': None}
{'title': 'A summary statistic representation in peripheral vision explains visual search.', 'paperID': '134819e2d3a9bdaf04308c32488f46264436c02b', 'arxivId': None, 'publication_year': 2009, 'abstract': None}
{'title': 'A summary-statistic representation in peripheral vision explains visual crowding.', 'paperID': '6bc9175ac08569f48c8024990fe630794598cd3c', 'arxivId': None, 'publication_year': 2009, 'abstract': None}
{'title': 'Feedback of pVisual Object Information to Foveal Retinotopic Cortex', 'paperID': 'd5553af1c623d85e8ad4d36d185902f60c5a2264', 'arxivId': None, 'publication_year': 2008, 'abstract': None}
{'title': 'Untangling invariant object recognition', 'paperID': 'a7886ec9d38ff28020e5e7e280ac930759a64483', 'arxivId': None, 'publication_year': 2007, 'abstract': None}
{'title': "'Breaking' position-invariant object recognition", 'paperID': '57a1857f4a066fd433e4790c5aca411769f0b401', 'arxivId': None, 'publication_year': 2005, 'abstract': None}
{'title': 'A Parametric Texture Model Based on Joint Statistics of Complex Wavelet Coefficients', 'paperID': '37afeac49518877dc96a3ca2ec3ebdfc5305e0a9', 'arxivId': None, 'publication_year': 2000, 'abstract': None}
{'title': 'Hierarchical models of object recognition in cortex', 'paperID': '85abadb689897997f1e37baa7b5fc6f7d497518b', 'arxivId': None, 'publication_year': 1999, 'abstract': None}
{'title': 'Real-time foveated multiresolution system for low-bandwidth video communication', 'paperID': '4568b728237772007404032e9a06b6ee92751b49', 'arxivId': None, 'publication_year': 1998, 'abstract': None}
{'title': 'Shape representation in the inferior temporal cortex of monkeys', 'paperID': '7d7721e2c556e02f35654428953ed83cfa8adff8', 'arxivId': None, 'publication_year': 1995, 'abstract': None}
{'title': 'The Laplacian Pyramid as a Compact Image Code', 'paperID': '83074157d165b6245915508d891b2d0cd066f3ad', 'arxivId': None, 'publication_year': 1983, 'abstract': None}
{'title': 'Letter: A chart demonstrating variations in acuity with retinal position.', 'paperID': '16985805560f8c4456367b6245def7482519089a', 'arxivId': None, 'publication_year': 1974, 'abstract': None}
{'title': 'Accelerated Texforms: Alternative Methods for Generating Unrecognizable Object Images with Preserved Mid-Level Features', 'paperID': '2eb5c3f2489c2c7b8456610d4c4ef84c53d1f06d', 'arxivId': None, 'publication_year': 2019, 'abstract': None}
{'title': 'Metamers of neural networks reveal divergence from human perceptual systems', 'paperID': 'acd519500bf1de81f7e46516c5f5e7fb8cbdbb92', 'arxivId': None, 'publication_year': 2019, 'abstract': None}
{'title': 'Testing models of peripheral encoding using metamerism in an oddity paradigm.', 'paperID': 'a7ed15f8113c4d4c5a994f475e6c87c54342154d', 'arxivId': None, 'publication_year': 2016, 'abstract': None}
{'title': 'Finding Biological Plausibility for Adversarially Robust Features via Metameric Tasks', 'paperID': 'c875d546411c598df075ae555fbb3108fea02910', 'arxivId': '2202.00838', 'publication_year': '2022', 'abstract': 'Recent work suggests that feature constraints in the training datasets of deep neu- 1 ral networks (DNNs) drive robustness to adversarial noise (Ilyas et al., 2019). 2 The representations learned by such adversarially robust networks have also been 3 shown to be more human perceptually-aligned than non-robust networks via image 4 manipulations (Santurkar et al., 2019; Engstrom et al., 2019). Despite appearing 5 closer to human visual perception, it is unclear if the constraints in robust DNN 6 representations match biological constraints found in human vision. Human vision 7 seems to rely on texture-based/summary statistic representations in the periphery, 8 which have been shown to explain phenomena such as crowding (Balas et al., 2009) 9 and performance on visual search tasks (Rosenholtz et al., 2012). To understand 10 how adversarially robust optimizations/representations compare to human vision, 11 we performed a psychophysics experiment using a metamer task similar to Freeman 12 & Simoncelli (2011); Wallis et al. (2019); Deza et al. (2017) where we evaluated 13 how well human observers could distinguish between images synthesized to match 14 adversarially robust representations compared to non-robust representations and a 15 texture synthesis model of peripheral vision (Texforms (Long et al., 2018)). We 16 found that the discriminability of robust representation and texture model images 17 decreased to near chance performance as stimuli were presented farther in the 18 periphery. Moreover, performance on robust and texture-model images showed 19 similar trends within participants, while performance on non-robust representa- 20 tions changed minimally across the visual ﬁeld. These results together suggest 21 that (1) adversarially robust representations capture peripheral computation better 22 than non-robust representations and (2) robust representations capture peripheral 23 computation similar to current state-of-the-art texture peripheral vision models. 24 More broadly, our ﬁndings support the idea that localized texture summary statis- 25 tic representations may drive human invariance to adversarial'}
{'title': 'Towards Understanding the Robustness Against Evasion Attack on Categorical Data', 'paperID': 'f01b92624046cadffe6d8a26805e03502ed3fd81', 'arxivId': None, 'publication_year': None, 'abstract': None}
{'title': 'Towards Transferable Adversarial Attacks on Vision Transformers', 'paperID': '3c2622daa8a658d5c85ea9869cb460a70b0f878d', 'arxivId': '2109.04176', 'publication_year': 2021, 'abstract': None}
{'title': 'SwinIR: Image Restoration Using Swin Transformer', 'paperID': '7a9a708ca61c14886aa0dcd6d13dac7879713f5f', 'arxivId': '2108.10257', 'publication_year': 2021, 'abstract': None}
{'title': 'CSWin Transformer: A General Vision Transformer Backbone with Cross-Shaped Windows', 'paperID': '800cfb3d23115cdcd4d114234b65bbdf2080f798', 'arxivId': '2107.00652', 'publication_year': 2021, 'abstract': None}
{'title': 'Focal Self-attention for Local-Global Interactions in Vision Transformers', 'paperID': '48418b285a92376a38daafa664a2dd07d42e3fe3', 'arxivId': '2107.00641', 'publication_year': 2021, 'abstract': None}
{'title': 'Early Convolutions Help Transformers See Better', 'paperID': '7b664a306b7d2f68dd816ea1d6586cf3472d75c1', 'arxivId': '2106.14881', 'publication_year': 2021, 'abstract': None}
{'title': 'Video Swin Transformer', 'paperID': '94eae578e6af3382f6449506965639f18aab3fa0', 'arxivId': '2106.13230', 'publication_year': 2021, 'abstract': None}
{'title': 'Efficient Self-supervised Vision Transformers for Representation Learning', 'paperID': 'b70bb1855e217edffb5dfa0632e8216860821870', 'arxivId': '2106.09785', 'publication_year': 2021, 'abstract': None}
{'title': 'On Improving Adversarial Transferability of Vision Transformers', 'paperID': '0918125daacb6c2b3a2d3f155ad095d5ae8fb9b9', 'arxivId': '2106.04169', 'publication_year': 2021, 'abstract': None}
{'title': 'Reveal of Vision Transformers Robustness against Adversarial Attacks', 'paperID': '922e5be564dc51dc645bf312fced4e97198942f8', 'arxivId': '2106.03734', 'publication_year': 2021, 'abstract': None}
{'title': 'Rethinking the Self-Attention in Vision Transformers', 'paperID': '100f2e2a810394503472f50938522930bd07b834', 'arxivId': None, 'publication_year': 2021, 'abstract': None}
{'title': 'Segmenter: Transformer for Semantic Segmentation', 'paperID': '68f080e0ac836ea230cb5316fbed273c70422d75', 'arxivId': '2105.05633', 'publication_year': 2021, 'abstract': None}
{'title': 'Self-Supervised Learning with Swin Transformers', 'paperID': 'db33c408174eef1e40661e8279afbbbf6db2352c', 'arxivId': '2105.04553', 'publication_year': 2021, 'abstract': None}
{'title': 'Conformer: Local Features Coupling Global Representations for Visual Recognition', 'paperID': '5faf75b5c5a4d83bd6407b4aba8fb0bccd7fa31d', 'arxivId': '2105.03889', 'publication_year': 2021, 'abstract': None}
{'title': 'Emerging Properties in Self-Supervised Vision Transformers', 'paperID': 'ad4a0938c48e61b7827869e4ac3baffd0aefab35', 'arxivId': '2104.14294', 'publication_year': 2021, 'abstract': None}
{'title': 'VidTr: Video Transformer Without Convolutions', 'paperID': '8754533bead3996f20440e4a1d0220d4971d00d7', 'arxivId': '2104.11746', 'publication_year': 2021, 'abstract': None}
{'title': 'Multiscale Vision Transformers', 'paperID': '18863dbfa32eaa1ccdb56ff180e6ab079a7f1ec6', 'arxivId': '2104.11227', 'publication_year': 2021, 'abstract': None}
{'title': 'LeViT: a Vision Transformer in ConvNet’s Clothing for Faster Inference', 'paperID': '003326a15fc4a8833785a47a741d7712474fa256', 'arxivId': '2104.01136', 'publication_year': 2021, 'abstract': None}
{'title': 'On the Robustness of Vision Transformers to Adversarial Examples', 'paperID': '43e51c1bfd69df518e2907f7a955e485985ba423', 'arxivId': '2104.02610', 'publication_year': 2021, 'abstract': None}
{'title': 'ViViT: A Video Vision Transformer', 'paperID': 'b6382a7351c0c595f91472ac71d3b2d87b3c4844', 'arxivId': '2103.15691', 'publication_year': 2021, 'abstract': None}
{'title': 'CvT: Introducing Convolutions to Vision Transformers', 'paperID': 'e775e649d815a02373eac840cf5e33a04ff85c95', 'arxivId': '2103.15808', 'publication_year': 2021, 'abstract': None}
{'title': 'Multi-Prize Lottery Ticket Hypothesis: Finding Accurate Binary Neural Networks by Pruning A Randomly Weighted Network', 'paperID': 'a52d17eac54b145cbc2b2c823f32b9e76be2595d', 'arxivId': '2103.09377', 'publication_year': 2021, 'abstract': None}
{'title': 'Rethinking Semantic Segmentation from a Sequence-to-Sequence Perspective with Transformers', 'paperID': 'd29430adccb805ab57b349afa8553954347b3197', 'arxivId': '2012.15840', 'publication_year': 2020, 'abstract': None}
{'title': 'Toward Transformer-Based Object Detection', 'paperID': 'd2e54b3a596a1dce0def9d035dfe1fb7c0c6142a', 'arxivId': '2012.09958', 'publication_year': 2020, 'abstract': None}
{'title': 'End-to-End Video Instance Segmentation with Transformers', 'paperID': '2ac7999cce9f415ee87643f56631b55ed26aa10e', 'arxivId': '2011.14503', 'publication_year': 2020, 'abstract': None}
{'title': 'Object Hider: Adversarial Patch Attack Against Object Detectors', 'paperID': '2d1c8d502d759e2948018a9633c4cadd6e8d1bc4', 'arxivId': '2010.14974', 'publication_year': 2020, 'abstract': None}
{'title': 'GreedyFool: Distortion-Aware Sparse Adversarial Attack', 'paperID': '8a7d037abb7285740c58f578ef201eb6bcf18a58', 'arxivId': '2010.13773', 'publication_year': 2020, 'abstract': None}
{'title': 'Dynamic Adversarial Patch for Evading Object Detection Models', 'paperID': 'ed73a4b875fd5efd4066fa514d7857ec7de1e7ea', 'arxivId': '2010.13070', 'publication_year': 2020, 'abstract': None}
{'title': 'End-to-End Object Detection with Transformers', 'paperID': '962dc29fdc3fbdc5930a10aba114050b82fe5a3e', 'arxivId': '2005.12872', 'publication_year': 2020, 'abstract': None}
{'title': 'Bias-Based Universal Adversarial Patch Attack for Automatic Check-Out', 'paperID': '0ebf5a0208ec2d930673e5e852cab44f9e1c8811', 'arxivId': None, 'publication_year': 2020, 'abstract': None}
{'title': 'Gradient Surgery for Multi-Task Learning', 'paperID': '449c5660d637741f7aa7ff42549c32b43c9968bf', 'arxivId': '2001.06782', 'publication_year': 2020, 'abstract': None}
{'title': 'What’s Hidden in a Randomly Weighted Neural Network?', 'paperID': '7a87ab984ca45aae2c5768d22cd6df3b5fd509f9', 'arxivId': '1911.13299', 'publication_year': 2019, 'abstract': None}
{'title': 'Sparse and Imperceivable Adversarial Attacks', 'paperID': 'e8c46dade1aaedce96ecd03178379b5921a90306', 'arxivId': '1909.05040', 'publication_year': 2019, 'abstract': None}
{'title': 'Simple Black-box Adversarial Attacks', 'paperID': '65fd9ded2c411d90bcf6d38132463797754d2d21', 'arxivId': '1905.07121', 'publication_year': 2019, 'abstract': None}
{'title': 'SparseFool: A Few Pixels Make a Big Difference', 'paperID': '8bf18d546ae7aea144663136c5704049953ce4e2', 'arxivId': '1811.02248', 'publication_year': 2018, 'abstract': None}
{'title': 'DPATCH: An Adversarial Patch Attack on Object Detectors', 'paperID': '27d2f8a0601ce4bd73339ddffc83977e858c5503', 'arxivId': '1806.02299', 'publication_year': 2018, 'abstract': None}
{'title': 'Double-Win Quant: Aggressively Winning Robustness of Quantized Deep Neural Networks via Random Precision Training and Inference', 'paperID': 'f737f6490d96d7d64e4389463592b93df8c2daec', 'arxivId': None, 'publication_year': 2021, 'abstract': None}
{'title': 'Rethinking the Design Principles of Robust Vision Transformer', 'paperID': '976a609cf540d1ded373b872d34779f7164d840a', 'arxivId': None, 'publication_year': 2021, 'abstract': None}
{'title': 'Patch-Fool: Are Vision Transformers Always Robust Against Adversarial Perturbations?', 'paperID': 'c24f4fcec3f1fba7a741f6348aafe5899d06ef77', 'arxivId': '2203.08392', 'publication_year': '2022', 'abstract': 'Vision transformers (ViTs) have recently set off a new wave in neural architecture design thanks to their record-breaking performance in various vision tasks. In parallel, to fulfill the goal of deploying ViTs into real-world vision applications, their robustness against potential malicious attacks has gained increasing attention. In particular, recent works show that ViTs are more robust against adversarial attacks as compared with convolutional neural networks (CNNs), and conjecture that this is because ViTs focus more on capturing global interactions among different input/feature patches, leading to their improved robustness to local perturbations imposed by adversarial attacks. In this work, we ask an intriguing question:"Under what kinds of perturbations do ViTs become more vulnerable learners compared to CNNs?"Driven by this question, we first conduct a comprehensive experiment regarding the robustness of both ViTs and CNNs under various existing adversarial attacks to understand the underlying reason favoring their robustness. Based on the drawn insights, we then propose a dedicated attack framework, dubbed Patch-Fool, that fools the self-attention mechanism by attacking its basic component (i.e., a single patch) with a series of attention-aware optimization techniques. Interestingly, our Patch-Fool framework shows for the first time that ViTs are not necessarily more robust than CNNs against adversarial perturbations. In particular, we find that ViTs are more vulnerable learners compared with CNNs against our Patch-Fool attack which is consistent across extensive experiments, and the observations from Sparse/Mild Patch-Fool, two variants of Patch-Fool, indicate an intriguing insight that the perturbation density and strength on each patch seem to be the key factors that influence the robustness ranking between ViTs and CNNs.'}
{'title': 'Representational Continuity for Unsupervised Continual Learning', 'paperID': '771e0af5535a0122004c265d8d17931c710677b6', 'arxivId': '2110.06976', 'publication_year': 2021, 'abstract': None}
{'title': 'Why Do Pretrained Language Models Help in Downstream Tasks? An Analysis of Head and Prompt Tuning', 'paperID': '704ac069de5a539ef42489ddb6cee0bd1650d54c', 'arxivId': '2106.09226', 'publication_year': 2021, 'abstract': None}
{'title': 'Provable Guarantees for Self-Supervised Deep Learning with Spectral Contrastive Loss', 'paperID': '3f1774d91c7c219f063f40b894e837e6c48b2bb2', 'arxivId': '2106.04156', 'publication_year': 2021, 'abstract': None}
{'title': 'When Does Contrastive Visual Representation Learning Work?', 'paperID': 'bfca930e7ca822ea098dab35a1fe0b624e15d17b', 'arxivId': '2105.05837', 'publication_year': 2021, 'abstract': None}
{'title': 'Distribution Alignment: A Unified Framework for Long-tail Visual Recognition', 'paperID': '51a33b04933f932c3a1425339c4412be89a2bdb5', 'arxivId': '2103.16370', 'publication_year': 2021, 'abstract': None}
{'title': 'Understanding the role of importance weighting for deep learning', 'paperID': '689d3394c674b8cb2906fa8ffb1c80ecc76e69d0', 'arxivId': '2103.15209', 'publication_year': 2021, 'abstract': None}
{'title': 'Contrasting Contrastive Self-Supervised Representation Learning Pipelines', 'paperID': '4f3a7aaedeacc76c414273c670b46c809590a1c2', 'arxivId': '2103.14005', 'publication_year': 2021, 'abstract': None}
{'title': 'Self-supervised Pretraining of Visual Features in the Wild', 'paperID': '0f8aa47ff8c6c49a347e192debe20ce4e5a4caea', 'arxivId': '2103.01988', 'publication_year': 2021, 'abstract': None}
{'title': 'Delving into Deep Imbalanced Regression', 'paperID': '129509ddad6ab944ff77d6da971fa3d3adb1524a', 'arxivId': '2102.09554', 'publication_year': 2021, 'abstract': None}
{'title': 'Understanding self-supervised Learning Dynamics without Contrastive Pairs', 'paperID': '2bceaa105b3d31c7d539f4a316f013a062ae7c15', 'arxivId': '2102.06810', 'publication_year': 2021, 'abstract': None}
{'title': 'Disentangling Label Distribution for Long-tailed Visual Recognition', 'paperID': 'bf9386df7a517cb888f0229a1815b76e3826f150', 'arxivId': '2012.00321', 'publication_year': 2020, 'abstract': None}
{'title': 'Exploring Simple Siamese Representation Learning', 'paperID': '0e23d2f14e7e56e81538f4a63e11689d8ac1eb9d', 'arxivId': '2011.10566', 'publication_year': 2020, 'abstract': None}
{'title': 'Posterior Re-calibration for Imbalanced Datasets', 'paperID': '4027fe2fcb6026601487c298fe2fc45d3df5e7df', 'arxivId': '2010.11820', 'publication_year': 2020, 'abstract': None}
{'title': 'Long-tailed Recognition by Routing Diverse Distribution-Aware Experts', 'paperID': 'd618752d2e666d7b25f1bd6c7c3bd7c056e19d96', 'arxivId': '2010.01809', 'publication_year': 2020, 'abstract': None}
{'title': 'Sharpness-Aware Minimization for Efficiently Improving Generalization', 'paperID': 'a2cd073b57be744533152202989228cb4122270a', 'arxivId': '2010.01412', 'publication_year': 2020, 'abstract': None}
{'title': 'High-Dimensional Probability: An Introduction with Applications in Data Science', 'paperID': 'fa5853fdef7d2f6bb68203d187ddacbbddc63a8b', 'arxivId': None, 'publication_year': 2020, 'abstract': None}
{'title': 'Contrastive learning, multi-view redundancy, and linear models', 'paperID': '1ee3fc3d32a0b56f6e568fb0590cf635e1249f42', 'arxivId': '2008.10150', 'publication_year': 2020, 'abstract': None}
{'title': 'Predicting What You Already Know Helps: Provable Self-Supervised Learning', 'paperID': 'a504b45e2cff77abcc9d78cc95159c08305e44d1', 'arxivId': '2008.01064', 'publication_year': 2020, 'abstract': None}
{'title': 'The Devil is in Classification: A Simple Framework for Long-tail Instance Segmentation', 'paperID': '596637f664b6fc1a5ad694378bb555598fac40ac', 'arxivId': '2007.11978', 'publication_year': 2020, 'abstract': None}
{'title': 'Long-tail learning via logit adjustment', 'paperID': '4f65f604d3bf5fa91634484a3232b426267b71ef', 'arxivId': '2007.07314', 'publication_year': 2020, 'abstract': None}
{'title': 'Heteroskedastic and Imbalanced Deep Learning with Adaptive Regularization', 'paperID': '542ca5253b1a5ac1e1a55d9ee777def330e9334f', 'arxivId': '2006.15766', 'publication_year': 2020, 'abstract': None}
{'title': 'Unsupervised Learning of Visual Features by Contrasting Cluster Assignments', 'paperID': '10161d83d29fc968c4612c9e9e2b61a2fc25842e', 'arxivId': '2006.09882', 'publication_year': 2020, 'abstract': None}
{'title': 'Shape Matters: Understanding the Implicit Bias of the Noise Covariance', 'paperID': '82b20ed50126e106091dd16aaeb538cbb3bfddb9', 'arxivId': '2006.08680', 'publication_year': 2020, 'abstract': None}
{'title': 'Learning to Segment the Tail', 'paperID': '60e81c0b58bf765a1cf77d9734a8e315f30c4cde', 'arxivId': '2004.00900', 'publication_year': 2020, 'abstract': None}
{'title': 'Contrastive estimation reveals topic posterior information to linear models', 'paperID': '4815e465f223ce66e6eea29b5b12bb39fc531538', 'arxivId': '2003.02234', 'publication_year': 2020, 'abstract': None}
{'title': 'Deep Representation Learning on Long-Tailed Data: A Learnable Embedding Augmentation Perspective', 'paperID': '507a0be8e4b33b8578f69e999bf6fd009422e1c6', 'arxivId': '2002.10826', 'publication_year': 2020, 'abstract': None}
{'title': 'Meta-Weight-Net: Learning an Explicit Mapping For Sample Weighting', 'paperID': '4c909ca74217234831bf2900aa83a4761823f2b1', 'arxivId': None, 'publication_year': 2019, 'abstract': None}
{'title': 'Gradient descent aligns the layers of deep linear networks', 'paperID': '5786917220aab2f6d0b00606eee9fe0ad0700f1b', 'arxivId': '1810.02032', 'publication_year': 2018, 'abstract': None}
{'title': 'Deep Imbalanced Learning for Face Recognition and Attribute Prediction', 'paperID': '576f4fd5f50c58c755eae73a983939bdccf8fac6', 'arxivId': '1806.00194', 'publication_year': 2018, 'abstract': None}
{'title': 'Transitive Invariance for Self-Supervised Visual Representation Learning', 'paperID': 'f8599ad5332cdf2c9919988ba300bb4b438b5834', 'arxivId': '1708.02901', 'publication_year': 2017, 'abstract': None}
{'title': 'Focal Loss for Dense Object Detection', 'paperID': '1a857da1a8ce47b2aa185b91b5cb215ddef24de7', 'arxivId': '1708.02002', 'publication_year': 2017, 'abstract': None}
{'title': 'Deep Over-sampling Framework for Classifying Imbalanced Data', 'paperID': '2f5250a5b54c5be194f984c3fd2b69029528dd85', 'arxivId': '1704.07515', 'publication_year': 2017, 'abstract': None}
{'title': 'Learning from imbalanced data: open challenges and future directions', 'paperID': 'f537f1bc527bf33cc5fd8da34275106329de1802', 'arxivId': None, 'publication_year': 2016, 'abstract': None}
{'title': 'Unsupervised Learning of Visual Representations by Solving Jigsaw Puzzles', 'paperID': '2ec8f7e0257a07d3914322b36072d1bbcd58a1e0', 'arxivId': '1603.09246', 'publication_year': 2016, 'abstract': None}
{'title': 'Unsupervised Visual Representation Learning by Context Prediction', 'paperID': 'fc1b1c9364c58ec406f494dd944b609a6a038ba6', 'arxivId': '1505.05192', 'publication_year': 2015, 'abstract': None}
{'title': '3D Object Representations for Fine-Grained Categorization', 'paperID': 'a83cec6a91701bd8500f8c43ad731d4353c71d55', 'arxivId': None, 'publication_year': 2013, 'abstract': None}
{'title': 'Cats and dogs', 'paperID': '84b50ebe85f7a1721800125e7882fce8c45b5c5a', 'arxivId': None, 'publication_year': 2012, 'abstract': None}
{'title': 'Diversity analysis on imbalanced data sets by using ensemble models', 'paperID': 'c7c8134ea51302e1a956035008f3049a8fc883e3', 'arxivId': None, 'publication_year': 2009, 'abstract': None}
{'title': 'ADASYN: Adaptive synthetic sampling approach for imbalanced learning', 'paperID': '48234756b7cf798bfeb47328f7c5d597fd4838c2', 'arxivId': None, 'publication_year': 2008, 'abstract': None}
{'title': 'Learning from imbalanced data sets with boosting and data generation: the DataBoost-IM approach', 'paperID': 'ae341ad66824e1f30a2675fd50742b97794c8f57', 'arxivId': None, 'publication_year': 2004, 'abstract': None}
{'title': 'The Pareto, Zipf and other power laws', 'paperID': 'da2a9df914ff14552ae1747b5bad5bbb5d66ec62', 'arxivId': None, 'publication_year': 2001, 'abstract': None}
{'title': 'The condensed nearest neighbor rule (Corresp.)', 'paperID': '7e67c9964a9defedd4f9dbe50f6e38ee58d52d62', 'arxivId': None, 'publication_year': 1968, 'abstract': None}
{'title': 'Learning to Model the Tail', 'paperID': '93f9607034c9b7b7693c60e9d2631adc15a2a524', 'arxivId': None, 'publication_year': 2017, 'abstract': None}
{'title': 'SMOTE: Synthetic Minority Over-sampling Technique', 'paperID': '8cb44f06586f609a29d9b496cc752ec01475dffe', 'arxivId': '1106.1813', 'publication_year': 2002, 'abstract': None}
{'title': 'Addressing the Curse of Imbalanced Training Sets: One-Sided Selection', 'paperID': 'ebc3914181d76c817f0e35f788b7c4c0f80abb07', 'arxivId': None, 'publication_year': 1997, 'abstract': None}
{'title': 'Certified Robustness for Deep Equilibrium Models via Interval Bound Propagation', 'paperID': '6e9577c4b4518b9976b9d421755ce37f8ea3ed7f', 'arxivId': None, 'publication_year': None, 'abstract': None}
{'title': 'On Label Shift in Domain Adaptation via Wasserstein Distance', 'paperID': '7fe935a147cce08933eb5a9d1dc123fcc3b2b8bd', 'arxivId': '2110.15520', 'publication_year': 2021, 'abstract': None}
{'title': 'Optimal Transport for Deep Generative Models: State of the Art and Research Challenges', 'paperID': 'b3594a146adea04a2728e9a8802537e7047a2f4f', 'arxivId': None, 'publication_year': 2021, 'abstract': None}
{'title': 'TIDOT: A Teacher Imitation Learning Approach for Domain Adaptation with Optimal Transport', 'paperID': '648098a11da32ffbdf857f320492e668abbaa11c', 'arxivId': None, 'publication_year': 2021, 'abstract': None}
{'title': 'Understanding and Achieving Efficient Robustness with Adversarial Supervised Contrastive Learning', 'paperID': '2c2496c3efc191feec5f163ddc80fd2370263c51', 'arxivId': '2101.10027', 'publication_year': 2021, 'abstract': None}
{'title': 'Learning to Attack with Fewer Pixels: A Probabilistic Post-hoc Framework for Refining Arbitrary Dense Adversarial Attacks', 'paperID': 'b82ebd94bcff28d702eede7227c3d3a06055aaaf', 'arxivId': '2010.06131', 'publication_year': 2020, 'abstract': None}
{'title': 'Improving Ensemble Robustness by Collaboratively Promoting and Demoting Adversarial Robustness', 'paperID': '6cfaa925c881ba5aa8efe8980a9ebe6509f0ddaa', 'arxivId': '2009.09612', 'publication_year': 2020, 'abstract': None}
{'title': 'Neural Topic Model via Optimal Transport', 'paperID': '2d79b9f90596008d4004ae8109902f4b34638367', 'arxivId': '2008.13537', 'publication_year': 2020, 'abstract': None}
{'title': 'Parameterized Rate-Distortion Stochastic Encoder', 'paperID': 'eeb771507ebb1cb934caeaeab1fe9590521fa1a0', 'arxivId': None, 'publication_year': 2020, 'abstract': None}
{'title': 'Improving Adversarial Robustness by Enforcing Local and Global Compactness', 'paperID': '2d44b08cd19c8099c626d5da4aa94160c7de9e0b', 'arxivId': '2007.05123', 'publication_year': 2020, 'abstract': None}
{'title': 'Smooth Adversarial Training', 'paperID': 'a2a349218b7889425c005880cc4b16b0a9e54dd8', 'arxivId': '2006.14536', 'publication_year': 2020, 'abstract': None}
{'title': 'Distributional Robustness and Regularization in Reinforcement Learning', 'paperID': '2bde080abcb051340586bfabb87f6fa80b34e446', 'arxivId': '2003.02894', 'publication_year': 2020, 'abstract': None}
{'title': 'Self-Adaptive Training: beyond Empirical Risk Minimization', 'paperID': '5e7f38a31083634c95b1a3df4f0c8da4cc09125d', 'arxivId': '2002.10319', 'publication_year': 2020, 'abstract': None}
{'title': 'Adversarial Distributional Training for Robust Deep Learning', 'paperID': '29cde68a09645f166cc582c99219e4452611dfef', 'arxivId': '2002.05999', 'publication_year': 2020, 'abstract': None}
{'title': 'Perturbations are not Enough: Generating Adversarial Examples with Spatial Distortions', 'paperID': '7e69287ac94ecb2af7fbec1cad0c773ea3193de9', 'arxivId': '1910.01329', 'publication_year': 2019, 'abstract': None}
{'title': 'Three-Player Wasserstein GAN via Amortised Duality', 'paperID': 'a38d273eb6f8eb0fc0b3eca232c41e80a9e54432', 'arxivId': None, 'publication_year': 2019, 'abstract': None}
{'title': 'Wasserstein Robust Reinforcement Learning', 'paperID': '4c84df2281280c31a190138a7bf8e8285d41bbef', 'arxivId': '1907.13196', 'publication_year': 2019, 'abstract': None}
{'title': 'Accurate, reliable and fast robustness evaluation', 'paperID': '31c260401df5df509c4889fb9387e361ae551f45', 'arxivId': '1907.01003', 'publication_year': 2019, 'abstract': None}
{'title': 'Distributionally Robust Reinforcement Learning', 'paperID': 'ffb976dc7e2623c34e7636ddd4a9e2fa36e09ca4', 'arxivId': '1902.08708', 'publication_year': 2019, 'abstract': None}
{'title': 'Wasserstein Distributionally Robust Stochastic Control: A Data-Driven Approach', 'paperID': '2d693c19d29e7a7670aff0784ab2f2bbf8134f35', 'arxivId': '1812.09808', 'publication_year': 2018, 'abstract': None}
{'title': 'A Robust Learning Approach for Regression Models Based on Distributionally Robust Optimization', 'paperID': '3d61c35547b3fe5a8529a46d0ef6f8e6c5bcb153', 'arxivId': None, 'publication_year': 2018, 'abstract': None}
{'title': 'Wasserstein Distributionally Robust Optimization and Variation Regularization', 'paperID': '97fe017a57819219055aa7c239628c0f7c10cdc9', 'arxivId': None, 'publication_year': 2017, 'abstract': None}
{'title': 'Semi‐supervised Learning Based on Distributionally Robust Optimization', 'paperID': '86869b1f62ef30a34fe71cccd844dad970968f6c', 'arxivId': '1702.08848', 'publication_year': 2017, 'abstract': None}
{'title': 'Distributionally Robust Stochastic Optimization with Wasserstein Distance', 'paperID': '631449eb1cb2c33c8781ba64a9ff2da197dc14dd', 'arxivId': '1604.02199', 'publication_year': 2016, 'abstract': None}
{'title': 'On Robust Optimization', 'paperID': '39a364217eecde950fe1c3f6c8cd359f8586899d', 'arxivId': None, 'publication_year': 2015, 'abstract': None}
{'title': 'On Global-view Based Defense via Adversarial Attack and Defense Risk Guaranteed Bounds', 'paperID': '76f07cec4b53a965b3d0641e138acaa0cd72fb79', 'arxivId': None, 'publication_year': 2022, 'abstract': None}
{'title': 'Particle-based Adversarial Local Distribution Regularization', 'paperID': '9a534fd4a5ee8bf37b6d4608403e67f94e7ca7c0', 'arxivId': None, 'publication_year': 2022, 'abstract': None}
{'title': 'LAMDA: Label Matching Deep Domain Adaptation', 'paperID': '9bac32b81d772cd48bfbbeb6c97a1fa5d58c7a53', 'arxivId': None, 'publication_year': 2021, 'abstract': None}
{'title': 'Most: multi-source domain adaptation via optimal transport for student-teacher learning', 'paperID': 'cb05b19743265358030e4501b33c204ae2e4e863', 'arxivId': None, 'publication_year': 2021, 'abstract': None}
{'title': 'Distributionally Robust Deep Learning as a Generalization of Adversarial Training', 'paperID': 'babe2d7073dcac97a6ca53b87b85b9506e23e1ce', 'arxivId': None, 'publication_year': 2017, 'abstract': None}
{'title': 'A Unified Wasserstein Distributional Robustness Framework for Adversarial Training', 'paperID': '9420398975d0989c638d47c6f059d09272b6992f', 'arxivId': '2202.13437', 'publication_year': '2022', 'abstract': 'It is well-known that deep neural networks (DNNs) are susceptible to adversarial attacks, exposing a severe fragility of deep learning systems. As the result, adversarial training (AT) method, by incorporating adversarial examples during training, represents a natural and effective approach to strengthen the robustness of a DNN-based classifier. However, most AT-based methods, notably PGD-AT and TRADES, typically seek a pointwise adversary that generates the worst-case adversarial example by independently perturbing each data sample, as a way to"probe"the vulnerability of the classifier. Arguably, there are unexplored benefits in considering such adversarial effects from an entire distribution. To this end, this paper presents a unified framework that connects Wasserstein distributional robustness with current state-of-the-art AT methods. We introduce a new Wasserstein cost function and a new series of risk functions, with which we show that standard AT methods are special cases of their counterparts in our framework. This connection leads to an intuitive relaxation and generalization of existing AT methods and facilitates the development of a new family of distributional robustness AT-based algorithms. Extensive experiments show that our distributional robustness AT algorithms robustify further their standard AT counterparts in various settings.'}
{'title': 'DeSKO: Stability-Assured Robust Control with a Deep Stochastic Koopman Operator', 'paperID': '6d3b65097096bb0ec52896e9d8a8ad194f18d290', 'arxivId': None, 'publication_year': None, 'abstract': None}
{'title': 'Robust Reinforcement Learning using Adversarial Populations', 'paperID': '317b1dec6d4f950d4607a80df32447827da4799a', 'arxivId': '2008.01825', 'publication_year': 2020, 'abstract': None}
{'title': 'Certified Adversarial Robustness for Deep Reinforcement Learning', 'paperID': '26edef02b17ae334e322e73caa97b8420255f118', 'arxivId': '1910.12908', 'publication_year': 2019, 'abstract': None}
{'title': 'Robustness Certificates Against Adversarial Examples for ReLU Networks', 'paperID': '5c31ff945ef663b491eedd06fc2b2232adc1d2e2', 'arxivId': '1902.01235', 'publication_year': 2019, 'abstract': None}
{'title': 'Mastering Chess and Shogi by Self-Play with a General Reinforcement Learning Algorithm', 'paperID': '38fb1902c6a2ab4f767d4532b28a92473ea737aa', 'arxivId': '1712.01815', 'publication_year': 2017, 'abstract': None}
{'title': 'Adversarial Examples Detection in Deep Networks with Convolutional Filter Statistics', 'paperID': '7dfbbc101cf9e7359a336df25dab90d66e249255', 'arxivId': '1612.07767', 'publication_year': 2016, 'abstract': None}
{'title': 'OpenAI Gym', 'paperID': '2b10281297ee001a9f3f4ea1aa9bea6b638c27df', 'arxivId': '1606.01540', 'publication_year': 2016, 'abstract': None}
{'title': 'Asynchronous Methods for Deep Reinforcement Learning', 'paperID': '69e76e16740ed69f4dc55361a3d319ac2f1293dd', 'arxivId': '1602.01783', 'publication_year': 2016, 'abstract': None}
{'title': 'Neuronlike adaptive elements that can solve difficult learning control problems', 'paperID': '8a7acaf6469c06ae5876d92f013184db5897bb13', 'arxivId': None, 'publication_year': 1983, 'abstract': None}
{'title': 'Center Smoothing for Certifiably Robust Vector-Valued Functions', 'paperID': 'a9ce5f674749ac21be036a9a4f05398eb000d826', 'arxivId': None, 'publication_year': 2021, 'abstract': None}
{'title': 'Efficient memory-based learning for robot control', 'paperID': '874b3a63422eeaf24c14435ee6091ed48247bff3', 'arxivId': None, 'publication_year': 1990, 'abstract': None}
{'title': 'Provable Robustness of Adversarial Training for Learning Halfspaces with Noise', 'paperID': 'ca45cce58cd1c6ea7eb638fed17b6c6f44bd9c6a', 'arxivId': '2104.09437', 'publication_year': 2021, 'abstract': None}
{'title': 'Interval universal approximation for neural networks', 'paperID': '493152ae263d92de457b4be7745c20bf475eb4ea', 'arxivId': '2007.06093', 'publication_year': 2020, 'abstract': None}
{'title': 'Over-parameterized Adversarial Training: An Analysis Overcoming the Curse of Dimensionality', 'paperID': '724f81cbc1197c83f546568b2aee2f0b9c4e4fd9', 'arxivId': '2002.06668', 'publication_year': 2020, 'abstract': None}
{'title': 'How Much Over-parameterization Is Sufficient to Learn Deep ReLU Networks?', 'paperID': '8f1b6eca0bdeb8cf0173d950b1157f290439cead', 'arxivId': '1911.12360', 'publication_year': 2019, 'abstract': None}
{'title': 'Universal Approximation with Certified Networks', 'paperID': 'e91b3347c8b411211a68ed68556298d12406cc83', 'arxivId': '1909.13846', 'publication_year': 2019, 'abstract': None}
{'title': 'Polylogarithmic width suffices for gradient descent to achieve arbitrarily small test error with shallow ReLU networks', 'paperID': '0fdf1a213ed08012d5d21067544b860f40c08e8f', 'arxivId': '1909.12292', 'publication_year': 2019, 'abstract': None}
{'title': 'Gradient Descent Finds Global Minima of Deep Neural Networks', 'paperID': '03e7e8663c69e691be6b6403b1eb1bbf593d31f2', 'arxivId': '1811.03804', 'publication_year': 2018, 'abstract': None}
{'title': 'A Convergence Theory for Deep Learning via Over-Parameterization', 'paperID': '42ec3db12a2e4628885451b13035c2e975220a25', 'arxivId': '1811.03962', 'publication_year': 2018, 'abstract': None}
{'title': 'Learning Overparameterized Neural Networks via Stochastic Gradient Descent on Structured Data', 'paperID': 'ccb1bafdae68c635cbd30d49fda7dbf88a3ce1b6', 'arxivId': '1808.01204', 'publication_year': 2018, 'abstract': None}
{'title': 'Fast Certified Robust Training via Better Initialization and Shorter Warmup', 'paperID': '9cbc9de49f77f9476f923ff86aa9d5fcf33011e6', 'arxivId': None, 'publication_year': 2021, 'abstract': None}
{'title': 'LOSS LANDSCAPE MATTERS: TRAINING CERTIFIABLY ROBUST MODELS WITH FAVORABLE LOSS LAND-', 'paperID': '5d3b1a36d56f1d5207332f9146bd8a0d91dae1f0', 'arxivId': None, 'publication_year': 2020, 'abstract': None}
{'title': 'On the Convergence of Certified Robust Training with Interval Bound Propagation', 'paperID': '7cd5d4942a5cd6f1299841a5fec96eb65cdb677b', 'arxivId': '2203.08961', 'publication_year': '2022', 'abstract': 'Interval Bound Propagation (IBP) is so far the base of state-of-the-art methods for training neural networks with certifiable robustness guarantees when potential adversarial perturbations present, while the convergence of IBP training remains unknown in existing literature. In this paper, we present a theoretical analysis on the convergence of IBP training. With an overparameterized assumption, we analyze the convergence of IBP robust training. We show that when using IBP training to train a randomly initialized two-layer ReLU neural network with logistic loss, gradient descent can linearly converge to zero robust training error with a high probability if we have sufficiently small perturbation radius and large network width.'}
{'title': 'DensePure: Understanding Diffusion Models for Adversarial Robustness', 'paperID': '11417522f57c13898e24d87ef22f9e45fa197cf8', 'arxivId': None, 'publication_year': None, 'abstract': None}
{'title': 'Deduplicating Training Data Mitigates Privacy Risks in Language Models', 'paperID': '55c36748f2a7c060c3313349c730b053ed03fbf7', 'arxivId': '2202.06539', 'publication_year': 2022, 'abstract': None}
{'title': 'Improving language models by retrieving from trillions of tokens', 'paperID': '002c256d30d6be4b23d365a8de8ae0e67e4c9641', 'arxivId': '2112.04426', 'publication_year': 2021, 'abstract': None}
{'title': 'Deduplicating Training Data Makes Language Models Better', 'paperID': '4566c0d22ebf3c31180066ab23b6c445aeec78d5', 'arxivId': '2107.06499', 'publication_year': 2021, 'abstract': None}
{'title': 'Addressing "Documentation Debt" in Machine Learning Research: A Retrospective Datasheet for BookCorpus', 'paperID': 'eb5fe6a806c30a9eae3f5430c6704780b230bdb7', 'arxivId': '2105.05241', 'publication_year': 2021, 'abstract': None}
{'title': 'Documenting Large Webtext Corpora: A Case Study on the Colossal Clean Crawled Corpus', 'paperID': '1adadbfa95e43a70fcd17e6ce947a0652b86bfc3', 'arxivId': '2104.08758', 'publication_year': 2021, 'abstract': None}
{'title': 'BEIR: A Heterogenous Benchmark for Zero-shot Evaluation of Information Retrieval Models', 'paperID': '807600ef43073cd9c59d4208ee710e90cf14efa8', 'arxivId': '2104.08663', 'publication_year': 2021, 'abstract': None}
{'title': 'LayoutParser: A Unified Toolkit for Deep Learning Based Document Image Analysis', 'paperID': '300cbaf1644920b15a97692e6309f5d58e1abc0e', 'arxivId': '2103.15348', 'publication_year': 2021, 'abstract': None}
{'title': 'Deduplication of Scholarly Documents using Locality Sensitive Hashing and Word Embeddings', 'paperID': '273e7a33ec437dab8c1c4640f54891dcfe8d5fab', 'arxivId': None, 'publication_year': 2020, 'abstract': None}
{'title': 'MPNet: Masked and Permuted Pre-training for Language Understanding', 'paperID': '0e002114cd379efaca0ec5cda6d262b5fe0be104', 'arxivId': '2004.09297', 'publication_year': 2020, 'abstract': None}
{'title': 'Dense Passage Retrieval for Open-Domain Question Answering', 'paperID': '79cd9f77e5258f62c0e15d11534aea6393ef73fe', 'arxivId': '2004.04906', 'publication_year': 2020, 'abstract': None}
{'title': 'Media Competition and News Diets', 'paperID': 'ebac77b8a0951dc91dbf63c906d346c7cfd3a2e7', 'arxivId': None, 'publication_year': 2020, 'abstract': None}
{'title': 'Zero-shot Entity Linking with Dense Entity Retrieval', 'paperID': '592a6691373f3936631bc4ac122f69df09c842bd', 'arxivId': '1911.03814', 'publication_year': 2019, 'abstract': None}
{'title': 'Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks', 'paperID': '93d63ec754f29fa22572615320afe0521f7ec66d', 'arxivId': '1908.10084', 'publication_year': 2019, 'abstract': None}
{'title': 'Denoising Distantly Supervised Open-Domain Question Answering', 'paperID': 'ba1382a0574baa0345fd727f259bc86797fe1381', 'arxivId': None, 'publication_year': 2018, 'abstract': None}
{'title': 'A System for Identifying and Exploring Text Repetition in Large Historical Document Corpora', 'paperID': 'cf0835767ddc35ff024f1b2a0ea5e5cd415ae498', 'arxivId': None, 'publication_year': 2017, 'abstract': None}
{'title': 'Efficient Natural Language Response Suggestion for Smart Reply', 'paperID': '435553998fbef790b5bed3491a8f634d9ec5cfa2', 'arxivId': '1705.00652', 'publication_year': 2017, 'abstract': None}
{'title': 'Deduplication in a massive clinical note dataset', 'paperID': '1b31cd40f6669ca8b1a1b1986fd41d3162424f2f', 'arxivId': '1704.05617', 'publication_year': 2017, 'abstract': None}
{'title': 'Mask R-CNN', 'paperID': '1a0912bb76777469295bb2c059faee907e7f3258', 'arxivId': '1703.06870', 'publication_year': 2017, 'abstract': None}
{'title': 'Billion-Scale Similarity Search with GPUs', 'paperID': '2cbb8de53759e75411bc528518947a3094fbce3a', 'arxivId': '1702.08734', 'publication_year': 2017, 'abstract': None}
{'title': 'Computational Methods for Uncovering Reprinted Texts in Antebellum Newspapers', 'paperID': '151c2d91a3fb03b9f3a8a91a70474de6e53b69b1', 'arxivId': None, 'publication_year': 2015, 'abstract': None}
{'title': 'Reprinting, Circulation, and the Network Author in Antebellum Newspapers', 'paperID': '0dd8ceaef659bde339bdcedfe9b111d75be59a9f', 'arxivId': None, 'publication_year': 2015, 'abstract': None}
{'title': 'On comparing partitions', 'paperID': 'f2f85ec20bcae8d67035fd446b855a75b9a0aa8d', 'arxivId': None, 'publication_year': 2015, 'abstract': None}
{'title': 'Chronicling America: Historic American Newspapers', 'paperID': '2a8c49f13c3d2919c5aa4d8dc9c7803e369eb529', 'arxivId': None, 'publication_year': 2007, 'abstract': None}
{'title': 'Noise-Robust De-Duplication at Scale', 'paperID': '7ca41cc5fc364b713aba5b573ae4ada801fd788a', 'arxivId': '2210.04261', 'publication_year': '2022', 'abstract': 'Identifying near duplicates within large, noisy text corpora has a myriad of applications that range from de-duplicating training datasets, reducing privacy risk, and evaluating test set leakage, to identifying reproduced news articles and literature within large corpora. Across these diverse applications, the overwhelming majority of work relies on N-grams. Limited efforts have been made to evaluate how well N-gram methods perform, in part because it is unclear how one could create an unbiased evaluation dataset for a massive corpus. This study uses the unique timeliness of historical news wires to create a 27,210 document dataset, with 122,876 positive duplicate pairs, for studying noise-robust de-duplication. The time-sensitivity of news makes comprehensive hand labelling feasible - despite the massive overall size of the corpus - as duplicates occur within a narrow date range. The study then develops and evaluates a range of de-duplication methods: hashing and N-gram overlap (which predominate in the literature), a contrastively trained bi-encoder, and a re-rank style approach combining a bi- and cross-encoder. The neural approaches significantly outperform hashing and N-gram overlap. We show that the bi-encoder scales well, de-duplicating a 10 million article corpus on a single GPU card in a matter of hours. The public release of our NEWS-COPY de-duplication dataset will facilitate further research and applications.'}
{'title': 'On the Adversarial Robustness of Causal Algorithmic Recourse', 'paperID': 'c3c973d1073e14fd8712db042ef4b3dca7b05c0b', 'arxivId': '2112.11313', 'publication_year': 2021, 'abstract': None}
{'title': 'Consistent Counterfactuals for Deep Models', 'paperID': 'b1fe45eda204847f5f4c0b3b8eafaecaf184859c', 'arxivId': '2110.03109', 'publication_year': 2021, 'abstract': None}
{'title': 'Deep Neural Networks and Tabular Data: A Survey', 'paperID': '3acff13163f51765bb36147f6107967765509d9b', 'arxivId': '2110.01889', 'publication_year': 2021, 'abstract': None}
{'title': 'CARLA: A Python Library to Benchmark Algorithmic Recourse and Counterfactual Explanation Algorithms', 'paperID': '7b700dbbdc38b714916a93065c1d11ea16728e7c', 'arxivId': '2108.00783', 'publication_year': 2021, 'abstract': None}
{'title': 'Counterfactual Explanations for Arbitrary Regression Models', 'paperID': 'ff2f098e2ad415841836e985ee6dfa2fbad7e0c7', 'arxivId': '2106.15212', 'publication_year': 2021, 'abstract': None}
{'title': 'Exploring Counterfactual Explanations Through the Lens of Adversarial Examples: A Theoretical and Empirical Analysis', 'paperID': '5fd221aa10d0b0582c1cf1f186a0052d855472e6', 'arxivId': '2106.09992', 'publication_year': 2021, 'abstract': None}
{'title': 'Counterfactual Explanations Can Be Manipulated', 'paperID': 'be659a7747137ef85239d849f84c5a25dcb77639', 'arxivId': '2106.02666', 'publication_year': 2021, 'abstract': None}
{'title': 'Evaluating Robustness of Counterfactual Explanations', 'paperID': '16eb4e90f7d43b6c484cdac8b1bbb3774faee960', 'arxivId': '2103.02354', 'publication_year': 2021, 'abstract': None}
{'title': 'Towards Robust and Reliable Algorithmic Recourse', 'paperID': 'cfc879af857200504ca0eefba0a2d14f998412be', 'arxivId': '2102.13620', 'publication_year': 2021, 'abstract': None}
{'title': 'Algorithmic Recourse in the Wild: Understanding the Impact of Data and Model Shifts', 'paperID': '13bcee171baaa9ea589a7cfbb3124c3146a8e7dc', 'arxivId': '2012.11788', 'publication_year': 2020, 'abstract': None}
{'title': 'Counterfactual Explanations for Machine Learning: A Review', 'paperID': '6068d39e92aef1bb0e1291e9931894c35692a85e', 'arxivId': None, 'publication_year': 2020, 'abstract': None}
{'title': 'Interpretable and Interactive Summaries of Actionable Recourses', 'paperID': 'c5dfc5fe7102fd8647edd1c9483aded82557e544', 'arxivId': '2009.07165', 'publication_year': 2020, 'abstract': None}
{'title': 'On Counterfactual Explanations under Predictive Multiplicity', 'paperID': '029a1c21accc0cbf36536cad02a12630b1c6e131', 'arxivId': '2006.13132', 'publication_year': 2020, 'abstract': None}
{'title': 'Getting a CLUE: A Method for Explaining Uncertainty Estimates', 'paperID': '8d0bf0e36d831c13e6a9522d2473e77a47f2bf0d', 'arxivId': '2006.06848', 'publication_year': 2020, 'abstract': None}
{'title': 'Algorithmic recourse under imperfect causal knowledge: a probabilistic approach', 'paperID': '06de04ade91f35446c21fa26c5621c8c88458edd', 'arxivId': '2006.06831', 'publication_year': 2020, 'abstract': None}
{'title': 'Multi-Objective Counterfactual Explanations', 'paperID': '48ace0d03aa14792922faf4a4a256385b023972c', 'arxivId': '2004.11165', 'publication_year': 2020, 'abstract': None}
{'title': 'Preserving Causal Constraints in Counterfactual Explanations for Machine Learning Classifiers', 'paperID': '148209fa0c9279bb40322794833aa075769de95b', 'arxivId': '1912.03277', 'publication_year': 2019, 'abstract': None}
{'title': 'FOCUS: Flexible Optimizable Counterfactual Explanations for Tree Ensembles', 'paperID': '337b96b55034e6ead100d26e547c942489ff2e93', 'arxivId': '1911.12199', 'publication_year': 2019, 'abstract': None}
{'title': 'Learning Model-Agnostic Counterfactual Explanations for Tabular Data', 'paperID': '5e34d223b1b8070a6090943382e80bebdb9aa4cd', 'arxivId': '1910.09398', 'publication_year': 2019, 'abstract': None}
{'title': 'Manipulation-Proof Machine Learning', 'paperID': 'c3ba9fffca667d8a64d6486b686abff833c7d3d3', 'arxivId': '2004.03865', 'publication_year': 2019, 'abstract': None}
{'title': 'Interpretable Counterfactual Explanations Guided by Prototypes', 'paperID': 'f77acbc2beef4ea85b333798621c14a6e3422502', 'arxivId': '1907.02584', 'publication_year': 2019, 'abstract': None}
{'title': 'Model-Agnostic Counterfactual Explanations for Consequential Decisions', 'paperID': '324d098c5294c69735ae1670707b2f21b605b8e5', 'arxivId': '1905.11190', 'publication_year': 2019, 'abstract': None}
{'title': 'Towards Understanding Knowledge Distillation', 'paperID': '247d6c9cb92d4afabee20b0ea29ac3d8ea92f120', 'arxivId': '2105.13093', 'publication_year': 2019, 'abstract': None}
{'title': 'Explaining machine learning classifiers through diverse counterfactual explanations', 'paperID': 'c2413fa296543159b32d16350d9e29f7db528790', 'arxivId': '1905.07697', 'publication_year': 2019, 'abstract': None}
{'title': 'Actionable Recourse in Linear Classification', 'paperID': '86841a74f0fd99ba369f635715ecae3007f22611', 'arxivId': '1809.06514', 'publication_year': 2018, 'abstract': None}
{'title': 'Inverse Classification for Comparison-based Interpretability in Machine Learning', 'paperID': '2862241b8364ee309525a1f4f7859aa38f999258', 'arxivId': '1712.08443', 'publication_year': 2017, 'abstract': None}
{'title': 'Counterfactual Explanations Without Opening the Black Box: Automated Decisions and the GDPR', 'paperID': '4f309712e705210df5695240a5d5fb53ea1f8641', 'arxivId': '1711.00399', 'publication_year': 2017, 'abstract': None}
{'title': 'The Eu General Data Protection Regulation (Gdpr): A Practical Guide', 'paperID': 'a25cf5c0974cfd62c1369ea75120097f118da301', 'arxivId': None, 'publication_year': 2017, 'abstract': None}
{'title': 'Interpretable Predictions of Tree-based Ensembles via Actionable Feature Tweaking', 'paperID': 'cb38e3f2fe39ef689a4f969758719f9ce94e1555', 'arxivId': '1706.06691', 'publication_year': 2017, 'abstract': None}
{'title': 'False Positives, False Negatives, and False Analyses: A Rejoinder to "Machine Bias: There\'s Software Used across the Country to Predict Future Criminals. and It\'s Biased against Blacks"', 'paperID': '873259438b927a32db66682f34665b517efc4dc0', 'arxivId': None, 'publication_year': 2016, 'abstract': None}
{'title': 'Model compression', 'paperID': '30c9bb327b7f2b9f1d1e5b69b9d0c97b410948d9', 'arxivId': None, 'publication_year': 2006, 'abstract': None}
{'title': 'Greedy function approximation: A gradient boosting machine.', 'paperID': '1679beddda3a183714d380e944fe6bf586c083cd', 'arxivId': None, 'publication_year': 2001, 'abstract': None}
{'title': 'The EU General Data Protection Regulation (GDPR)', 'paperID': '27b7bb095832ecb64e99a683ced3084b35247ff1', 'arxivId': None, 'publication_year': 2017, 'abstract': None}
{'title': 'Random Forests', 'paperID': '8e0be569ea77b8cb29bb0e8b031887630fe7a96c', 'arxivId': None, 'publication_year': 2004, 'abstract': None}
{'title': 'Knowledge Acquisition from Examples Via Multiple Models', 'paperID': '1a9a39da9d4fc937bc455705d508674a205620aa', 'arxivId': None, 'publication_year': 1997, 'abstract': None}
{'title': 'Probabilistically Robust Recourse: Navigating the Trade-offs between Costs and Robustness in Algorithmic Recourse', 'paperID': '31c4ad6867aa4fccdf0df6c6d27b8d956cf8d1e4', 'arxivId': '2203.06768', 'publication_year': '2022', 'abstract': 'As machine learning models are increasingly being employed to make consequential decisions in real-world settings, it becomes critical to ensure that individuals who are adversely impacted (e.g., loan denied) by the predictions of these models are provided with a means for recourse. While several approaches have been proposed to construct recourses for affected individuals, the recourses output by these methods either achieve low costs (i.e., ease-of-implementation) or robustness to small perturbations (i.e., noisy implementations of recourses), but not both due to the inherent trade-offs between the recourse costs and robustness. Furthermore, prior approaches do not provide end users with any agency over navigating the aforementioned trade-offs. In this work, we address the above challenges by proposing the first algorithmic framework which enables users to effectively manage the recourse cost vs. robustness trade-offs. More specifically, our framework Probabilistically ROBust rEcourse (\\texttt{PROBE}) lets users choose the probability with which a recourse could get invalidated (recourse invalidation rate) if small changes are made to the recourse i.e., the recourse is implemented somewhat noisily. To this end, we propose a novel objective function which simultaneously minimizes the gap between the achieved (resulting) and desired recourse invalidation rates, minimizes recourse costs, and also ensures that the resulting recourse achieves a positive model prediction. We develop novel theoretical results to characterize the recourse invalidation rates corresponding to any given instance w.r.t. different classes of underlying models (e.g., linear models, tree based models etc.), and leverage these results to efficiently optimize the proposed objective. Experimental evaluation with multiple real world datasets demonstrate the efficacy of the proposed framework.'}
{'title': 'Adaptive Robust Evidential Optimization For Open Set Detection from Imbalanced Data', 'paperID': '3e23b594fcc710f534d35b46c6017d3c6ec20cd1', 'arxivId': None, 'publication_year': None, 'abstract': None}
{'title': 'On Explaining Neural Network Robustness with Activation Path', 'paperID': '9d242b5c0c00fc36002161deb6a124f2c624e982', 'arxivId': None, 'publication_year': None, 'abstract': None}
{'title': 'Learning Fair Classifiers with Partially Annotated Group Labels', 'paperID': 'e54e0d9eaa922cefb1c69e105979399fd34497b1', 'arxivId': '2111.14581', 'publication_year': 2021, 'abstract': None}
{'title': 'Distributionally Robust Multilingual Machine Translation', 'paperID': '9b3a071734cfecb2880105d84bde6791b48bf4a3', 'arxivId': '2109.04020', 'publication_year': 2021, 'abstract': None}
{'title': 'Social Media Toxicity Classification Using Deep Learning: Real-World Application UK Brexit', 'paperID': '9eed0825348e7065c5dcc2effe609ce47f07f30e', 'arxivId': None, 'publication_year': 2021, 'abstract': None}
{'title': 'Fair Feature Distillation for Visual Recognition', 'paperID': 'c502b3d801a687ad26f592aa3416a6b2520d0f7c', 'arxivId': '2106.04411', 'publication_year': 2021, 'abstract': None}
{'title': 'Distributional Robustness Loss for Long-tail Learning', 'paperID': '6f9918ad83b2e6058acfc15ed66601879b855494', 'arxivId': '2104.03066', 'publication_year': 2021, 'abstract': None}
{'title': 'Wasserstein Robust Classification with Fairness Constraints', 'paperID': 'c1bdf40e98e52fcd31bd5f68165e5c43655117f7', 'arxivId': '2103.06828', 'publication_year': 2021, 'abstract': None}
{'title': 'Fair Mixup: Fairness via Interpolation', 'paperID': '3470256133fe185031791e600f84376262bd9015', 'arxivId': '2103.06503', 'publication_year': 2021, 'abstract': None}
{'title': 'FairBatch: Batch Selection for Model Fairness', 'paperID': 'd688594d2aac080f657b7be251e89cca6a7df165', 'arxivId': '2012.01696', 'publication_year': 2020, 'abstract': None}
{'title': 'Fairness in Machine Learning: A Survey', 'paperID': 'fee8f63972906214b77f16cfeca0b93ee8f36ba2', 'arxivId': '2010.04053', 'publication_year': 2020, 'abstract': None}
{'title': 'Ensuring Fairness Beyond the Training Data', 'paperID': '8ac7f60714087e6548edb008f33e401163bdc982', 'arxivId': '2007.06029', 'publication_year': 2020, 'abstract': None}
{'title': 'Is There a Trade-Off Between Fairness and Accuracy? A Perspective Using Mismatched Hypothesis Testing', 'paperID': '648dce875272ba601b36a164a10648decdb3044d', 'arxivId': None, 'publication_year': 2020, 'abstract': None}
{'title': 'Risk Variance Penalization: From Distributional Robustness to Causality', 'paperID': 'af4ec9e525671319fab3feb19b6f9306d94e5dd9', 'arxivId': '2006.07544', 'publication_year': 2020, 'abstract': None}
{'title': "HuggingFace's Transformers: State-of-the-art Natural Language Processing", 'paperID': '1fa9ed2bea208511ae698a967875e943049f16b6', 'arxivId': '1910.03771', 'publication_year': 2019, 'abstract': None}
{'title': 'Rényi Fair Inference', 'paperID': '1eb7b1cafe1891712a4f764c78399a53182cdcd1', 'arxivId': '1906.12005', 'publication_year': 2019, 'abstract': None}
{'title': 'Fairness for Robust Log Loss Classification', 'paperID': '5be821609481fc46fe61ea404a9322a35f84a446', 'arxivId': None, 'publication_year': 2019, 'abstract': None}
{'title': 'What is Local Optimality in Nonconvex-Nonconcave Minimax Optimization?', 'paperID': 'eb649971a40c7b0a28cff1d5aba14f8a3a37c773', 'arxivId': None, 'publication_year': 2019, 'abstract': None}
{'title': 'Identifying and Correcting Label Bias in Machine Learning', 'paperID': '0f7245155d3d2dbe588b9870c6edb1d9f6b1f546', 'arxivId': '1901.04966', 'publication_year': 2019, 'abstract': None}
{'title': 'Racial Faces in the Wild: Reducing Racial Bias by Information Maximization Adaptation Network', 'paperID': '59c47e49d8211953b1acd68984650b807ce69a71', 'arxivId': None, 'publication_year': 2018, 'abstract': None}
{'title': 'Discovering Fair Representations in the Data Domain', 'paperID': '7e96d0a69f5d81c353ca12ffb201441867a311df', 'arxivId': None, 'publication_year': 2018, 'abstract': None}
{'title': 'Optimization with Non-Differentiable Constraints with Applications to Fairness, Recall, Churn, and Other Goals', 'paperID': '28930f1472417b25ca42d251c772e38c75395d84', 'arxivId': '1809.04198', 'publication_year': 2018, 'abstract': None}
{'title': 'A Reductions Approach to Fair Classification', 'paperID': '19cb02117084b023c28da2fb356679806a299890', 'arxivId': '1803.02453', 'publication_year': 2018, 'abstract': None}
{'title': 'Age Progression/Regression by Conditional Adversarial Autoencoder', 'paperID': '7bcebd481bb1161843efdd135e4ba59dfac4b61c', 'arxivId': '1702.08423', 'publication_year': 2017, 'abstract': None}
{'title': 'Hirability in the Wild: Analysis of Online Conversational Video Resumes', 'paperID': 'cff3c2226d4a5106c639b7f90f73f0330cc94685', 'arxivId': None, 'publication_year': 2016, 'abstract': None}
{'title': 'Disciplined convex-concave programming', 'paperID': '7b814e39159da8bef0a26308ddf3e4315c687675', 'arxivId': '1604.02639', 'publication_year': 2016, 'abstract': None}
{'title': 'Fairness Constraints: Mechanisms for Fair Classification', 'paperID': '4c64ee852f082f8f4e0113cfc1302b34e31539a2', 'arxivId': None, 'publication_year': 2015, 'abstract': None}
{'title': 'Consumer Credit Risk Models Via Machine-Learning Algorithms', 'paperID': 'd64a0840bea331caf9b1a61611b8eb8d15ec4f9f', 'arxivId': None, 'publication_year': 2010, 'abstract': None}
{'title': 'Measuring Statistical Dependence with Hilbert-Schmidt Norms', 'paperID': '397306cada03c29ab9c3d5a7991a343cae92f2e3', 'arxivId': None, 'publication_year': 2005, 'abstract': None}
{'title': 'Exponentiated Gradient Versus Gradient Descent for Linear Predictors', 'paperID': '98eed3f082351c4821d1edb315846207a8fefbe9', 'arxivId': None, 'publication_year': 1997, 'abstract': None}
{'title': 'Measures of Dependence', 'paperID': '6eb79424b000e7cd0d47d480f2d7bace0e9720c4', 'arxivId': None, 'publication_year': 2011, 'abstract': None}
{'title': 'A theory of the learnable', 'paperID': '5fc0c7afc6bb27fb3752eae0ea5869413b1259b7', 'arxivId': None, 'publication_year': 1984, 'abstract': None}
{'title': 'Re-weighting Based Group Fairness Regularization via Classwise Robust Optimization', 'paperID': 'eb776076b4653f45a399e0afef781919d94b0578', 'arxivId': '2303.00442', 'publication_year': '2023', 'abstract': 'Many existing group fairness-aware training methods aim to achieve the group fairness by either re-weighting underrepresented groups based on certain rules or using weakly approximated surrogates for the fairness metrics in the objective as regularization terms. Although each of the learning schemes has its own strength in terms of applicability or performance, respectively, it is difficult for any method in the either category to be considered as a gold standard since their successful performances are typically limited to specific cases. To that end, we propose a principled method, dubbed as \\ours, which unifies the two learning schemes by incorporating a well-justified group fairness metric into the training objective using a class wise distributionally robust optimization (DRO) framework. We then develop an iterative optimization algorithm that minimizes the resulting objective by automatically producing the correct re-weights for each group. Our experiments show that FairDRO is scalable and easily adaptable to diverse applications, and consistently achieves the state-of-the-art performance on several benchmark datasets in terms of the accuracy-fairness trade-off, compared to recent strong baselines.'}
{'title': 'Robust Weight Perturbation for Adversarial Training', 'paperID': '3793754efaa4a5ae2174b72956dcb0fe8375f445', 'arxivId': '2205.14826', 'publication_year': 2022, 'abstract': None}
{'title': 'Are Transformers More Robust Than CNNs?', 'paperID': '35c0800e657faa18cf3fc3629bdbeafbb976b006', 'arxivId': '2111.05464', 'publication_year': 2021, 'abstract': None}
{'title': 'MixACM: Mixup-Based Robustness Transfer via Distillation of Activated Channel Maps', 'paperID': '564ea2fc978cc3a2b031b89e3ae80cec3f965cd3', 'arxivId': '2111.05073', 'publication_year': 2021, 'abstract': None}
{'title': 'How and When Adversarial Robustness Transfers in Knowledge Distillation?', 'paperID': '9523ccb0179e53151c8d92b21f1ff24f80980ad2', 'arxivId': '2110.12072', 'publication_year': 2021, 'abstract': None}
{'title': 'Parameterizing Activation Functions for Adversarial Robustness', 'paperID': 'ba451a3f88b0f1e08bd5cda55c99d96a88a39c71', 'arxivId': '2110.05626', 'publication_year': 2021, 'abstract': None}
{'title': 'Bridged Adversarial Training', 'paperID': 'eb5ccb3f7744ea265b068d5a7f54e8d61de1027a', 'arxivId': '2108.11135', 'publication_year': 2021, 'abstract': None}
{'title': 'Assistive Signals for Deep Neural Network Classifiers', 'paperID': '118c81057cdecce85514c9543e01ae88ffe56448', 'arxivId': None, 'publication_year': 2021, 'abstract': None}
{'title': 'With False Friends Like These, Who Can Notice Mistakes?', 'paperID': '4dea1701757513fdf7a52e64cb85750dbf0ef662', 'arxivId': '2012.14738', 'publication_year': 2020, 'abstract': None}
{'title': 'Unadversarial Examples: Designing Objects for Robust Vision', 'paperID': '6e8dc247f2a9341915ea81acca5fc2aa7d14c938', 'arxivId': '2012.12235', 'publication_year': 2020, 'abstract': None}
{'title': 'Backpropagating Linearly Improves Transferability of Adversarial Examples', 'paperID': 'bcac1b00badd7c8830e10ba4eb813ad79a3222b5', 'arxivId': '2012.03528', 'publication_year': 2020, 'abstract': None}
{'title': 'Practical No-box Adversarial Attacks against DNNs', 'paperID': '5f9eb88409bfc6e171792668fecc83d1d9e3c8cf', 'arxivId': '2012.02525', 'publication_year': 2020, 'abstract': None}
{'title': 'Do Wider Neural Networks Really Help Adversarial Robustness?', 'paperID': '99931b7b794f7d98c7b3f3eee862129133d123d7', 'arxivId': '2010.01279', 'publication_year': 2020, 'abstract': None}
{'title': 'Improving Black-box Adversarial Attacks with a Transfer-based Prior', 'paperID': 'edabab811aaf44b7b626efe5278a32bddd3bb77f', 'arxivId': '1906.06919', 'publication_year': 2019, 'abstract': None}
{'title': 'Squeeze Training for Adversarial Robustness', 'paperID': '7e9e38a9101fd6e9ee3cd44f72d9be6842b7a42d', 'arxivId': '2205.11156', 'publication_year': '2022', 'abstract': 'The vulnerability of deep neural networks (DNNs) to adversarial examples has attracted great attention in the machine learning community. The problem is related to non-flatness and non-smoothness of normally obtained loss landscapes. Training augmented with adversarial examples (a.k.a., adversarial training) is considered as an effective remedy. In this paper, we highlight that some collaborative examples, nearly perceptually indistinguishable from both adversarial and benign examples yet show extremely lower prediction loss, can be utilized to enhance adversarial training. A novel method is therefore proposed to achieve new state-of-the-arts in adversarial robustness. Code: https://github.com/qizhangli/ST-AT.'}
{'title': 'Primary visual cortex straightens natural video trajectories', 'paperID': '750b78fdf83c8bfcfd219a74873ddf4edbc11deb', 'arxivId': None, 'publication_year': 2021, 'abstract': None}
{'title': 'Predictive Coding: a Theoretical and Experimental Review', 'paperID': '3b2b0547af85be326302198a40cf434614c14f96', 'arxivId': '2107.12979', 'publication_year': 2021, 'abstract': None}
{'title': 'Increasing neural network robustness improves match to macaque V1 eigenspectrum, spatial frequency preference and predictivity', 'paperID': '5f51508a9c86ad9c35b56a0a480721c67a6f4ebe', 'arxivId': None, 'publication_year': 2021, 'abstract': None}
{'title': 'The functional specialization of visual cortex emerges from training parallel pathways with self-supervised predictive learning', 'paperID': '93538fea732a77e7ff8a5281eeba0aaaa9094876', 'arxivId': None, 'publication_year': 2021, 'abstract': None}
{'title': 'Barlow Twins: Self-Supervised Learning via Redundancy Reduction', 'paperID': '8a9d84d86ac0d76e63914802f9738325c3bece9c', 'arxivId': '2103.03230', 'publication_year': 2021, 'abstract': None}
{'title': 'Deep Analysis of CNN-based Spatio-temporal Representations for Action Recognition', 'paperID': '47b5b4c7d00cfcd980f67e62ed4f27193c088296', 'arxivId': '2010.11757', 'publication_year': 2020, 'abstract': None}
{'title': 'Integrative Benchmarking to Advance Neurally Mechanistic Models of Human Intelligence', 'paperID': '3ecc7ac21c22af073f37294df341c51e5d2d576d', 'arxivId': None, 'publication_year': 2020, 'abstract': None}
{'title': 'Unsupervised neural network models of the ventral visual stream', 'paperID': 'e692ab8e6d1b1efb11b24ca31bd9ac53caa021a6', 'arxivId': None, 'publication_year': 2020, 'abstract': None}
{'title': 'Learning Perceptually-Aligned Representations via Adversarial Robustness', 'paperID': '38a547b5933758a2018f0a40f2c3d538077c4d01', 'arxivId': '1906.00945', 'publication_year': 2019, 'abstract': None}
{'title': 'Residual Flows for Invertible Generative Modeling', 'paperID': 'ef2b790aae2c1e1c7eb8a8777515266b5094de88', 'arxivId': '1906.02735', 'publication_year': 2019, 'abstract': None}
{'title': 'Perceptual straightening of natural videos', 'paperID': '0d7f467c247540009ab1abfb1e1a5d5dc0689783', 'arxivId': None, 'publication_year': 2019, 'abstract': None}
{'title': 'Theories of Error Back-Propagation in the Brain', 'paperID': '363db281e33509fe99151a7e99ad1efe664cf3c3', 'arxivId': None, 'publication_year': 2019, 'abstract': None}
{'title': 'Neural population control via deep image synthesis', 'paperID': 'aa0ad8dd35f7b385feba07cedb30d7e3a1935381', 'arxivId': None, 'publication_year': 2018, 'abstract': None}
{'title': 'Invariant Recognition Shapes Neural Representations of Visual Input.', 'paperID': 'cb41b78c1da335d4980c272d2fe5b2c8ad819dc4', 'arxivId': None, 'publication_year': 2018, 'abstract': None}
{'title': 'Brain-Score: Which Artificial Neural Network for Object Recognition is most Brain-Like?', 'paperID': '31619c8f4f9557136a675514b22ca8ece65ed38c', 'arxivId': None, 'publication_year': 2018, 'abstract': None}
{'title': 'CORnet: Modeling the Neural Mechanisms of Core Object Recognition', 'paperID': '726dd697000e7b2fe5b388e1e72bd88ea81ff397', 'arxivId': None, 'publication_year': 2018, 'abstract': None}
{'title': 'i-RevNet: Deep Invertible Networks', 'paperID': '11e7c4182a7813d5acf1be198c8c96d164fb95a2', 'arxivId': '1802.07088', 'publication_year': 2018, 'abstract': None}
{'title': 'Dynamic Routing Between Capsules', 'paperID': 'c4c06578f4870e4b126e6837907929f3c900b99f', 'arxivId': '1710.09829', 'publication_year': 2017, 'abstract': None}
{'title': 'Comparison of deep neural networks to spatio-temporal cortical dynamics of human visual object recognition reveals hierarchical correspondence', 'paperID': '74907c562f9e55b44836bc1aebea87c617c29ad8', 'arxivId': None, 'publication_year': 2016, 'abstract': None}
{'title': 'Deep Predictive Coding Networks for Video Prediction and Unsupervised Learning', 'paperID': 'ad367b44f3434b9ba6b46b41ab083210f6827a9f', 'arxivId': '1605.08104', 'publication_year': 2016, 'abstract': None}
{'title': 'Learning to Linearize Under Uncertainty', 'paperID': 'dd2fa69647160bb2ea25dcc7b2f6409b01e40222', 'arxivId': '1506.03011', 'publication_year': 2015, 'abstract': None}
{'title': 'Deep Supervised, but Not Unsupervised, Models May Explain IT Cortical Representation', 'paperID': 'e5e3a4a13e719ce770e036b4eeb82c95527c3296', 'arxivId': None, 'publication_year': 2014, 'abstract': None}
{'title': 'Performance-optimized hierarchical models predict neural responses in higher visual cortex', 'paperID': '2bd2b120ccd5aa88a5927889a973b2204732e435', 'arxivId': None, 'publication_year': 2014, 'abstract': None}
{'title': 'Probabilistic brains: knowns and unknowns', 'paperID': 'bbab6293783b741729f4f1636b9267e085aa329f', 'arxivId': None, 'publication_year': 2013, 'abstract': None}
{'title': 'How Does the Brain Solve Visual Object Recognition?', 'paperID': '3bc8c19cd2257790f2c92c0b6b757c0550a8404b', 'arxivId': None, 'publication_year': 2012, 'abstract': None}
{'title': 'The free-energy principle: a rough guide to the brain?', 'paperID': 'a878886efacc6a5d742bf98bfc25c0734ce502b1', 'arxivId': None, 'publication_year': 2009, 'abstract': None}
{'title': 'Slow feature analysis yields a rich repertoire of complex cell properties.', 'paperID': '2af18c7b3495955d1ffa4f1b4c4ae5ea786cdedb', 'arxivId': None, 'publication_year': 2005, 'abstract': None}
{'title': 'Motion integration and postdiction in visual awareness.', 'paperID': '0e11ffcd440073a3b244f67c9278f4a0eaae75bb', 'arxivId': None, 'publication_year': 2000, 'abstract': None}
{'title': 'Fast and Robust Smallest Enclosing Balls', 'paperID': '67a5d4fc254fcbd751a0151ba3562eacfc36082e', 'arxivId': None, 'publication_year': 1999, 'abstract': None}
{'title': 'What Is the Goal of Sensory Coding?', 'paperID': 'ff1152582155acaa0e9d0ccbc900a4641504256d', 'arxivId': None, 'publication_year': 1994, 'abstract': None}
{'title': 'Robustness', 'paperID': '720a1543d94291240f34aac6ecd726f90c60e27d', 'arxivId': None, 'publication_year': 2020, 'abstract': None}
{'title': 'Predictive coding in the visual cortex: a functional interpretation of some extra-classical receptive-field effects.', 'paperID': 'a424ec3b8846f57b8ffdb566d272e28d5a525909', 'arxivId': None, 'publication_year': 1999, 'abstract': None}
{'title': 'Brain-like representational straightening of natural movies in robust feedforward neural networks', 'paperID': '2fff703a2cfe081b86ea3dc877a0a068da9ae503', 'arxivId': '2308.13870', 'publication_year': '2023', 'abstract': 'Representational straightening refers to a decrease in curvature of visual feature representations of a sequence of frames taken from natural movies. Prior work established straightening in neural representations of the primate primary visual cortex (V1) and perceptual straightening in human behavior as a hallmark of biological vision in contrast to artificial feedforward neural networks which did not demonstrate this phenomenon as they were not explicitly optimized to produce temporally predictable movie representations. Here, we show robustness to noise in the input image can produce representational straightening in feedforward neural networks. Both adversarial training (AT) and base classifiers for Random Smoothing (RS) induced remarkably straightened feature codes. Demonstrating their utility within the domain of natural movies, these codes could be inverted to generate intervening movie frames by linear interpolation in the feature space even though they were not trained on these trajectories. Demonstrating their biological utility, we found that AT and RS training improved predictions of neural data in primate V1 over baseline models providing a parsimonious, bio-plausible mechanism -- noise in the sensory input stages -- for generating representations in early visual cortex. Finally, we compared the geometric properties of frame representations in these networks to better understand how they produced representations that mimicked the straightening phenomenon from biology. Overall, this work elucidating emergent properties of robust neural networks demonstrates that it is not necessary to utilize predictive objectives or train directly on natural movie statistics to achieve models supporting straightened movie representations similar to human perception that also predict V1 neural responses.'}
{'title': 'Query-Efficient and Scalable Black-Box Adversarial Attacks on Discrete Sequential Data via Bayesian Optimization', 'paperID': 'd0e4d0203721a07191be2cc61a98b4ff71ba6fe2', 'arxivId': '2206.08575', 'publication_year': 2022, 'abstract': None}
{'title': 'Revisiting and Advancing Fast Adversarial Training Through The Lens of Bi-Level Optimization', 'paperID': 'cf3e2e46515bb1f4ccbc54b339f56c0939161def', 'arxivId': '2112.12376', 'publication_year': 2021, 'abstract': None}
{'title': 'Improving the Transferability of Adversarial Examples with Resized-Diverse-Inputs, Diversity-Ensemble and Region Fitting', 'paperID': '40cfec74524cf766f6c0030bc1f1736041a128e2', 'arxivId': '2112.06011', 'publication_year': 2021, 'abstract': None}
{'title': 'Adversarial GLUE: A Multi-Task Benchmark for Robustness Evaluation of Language Models', 'paperID': '8436897e713c2242d6291df9a6a33c1544d4dd39', 'arxivId': '2111.02840', 'publication_year': 2021, 'abstract': None}
{'title': 'Gradient-based Adversarial Attacks against Text Transformers', 'paperID': '59c2b4ef91d4ce23cd4f270c8750a00de9054ec2', 'arxivId': '2104.13733', 'publication_year': 2021, 'abstract': None}
{'title': 'A Geometry-Inspired Attack for Generating Natural Language Adversarial Examples', 'paperID': 'a3dbe3e4512ae002efd52ec92ed5905d859a696e', 'arxivId': '2010.01345', 'publication_year': 2020, 'abstract': None}
{'title': 'Contextualized Perturbation for Textual Adversarial Attack', 'paperID': '472cd41fa2ba2e520706f232cae12db4a7b5e60a', 'arxivId': '2009.07502', 'publication_year': 2020, 'abstract': None}
{'title': 'Benchmarking Adversarial Robustness on Image Classification', 'paperID': '25e9fa483a048607131a5a0e3287e8f457fb4807', 'arxivId': None, 'publication_year': 2020, 'abstract': None}
{'title': 'TextAttack: A Framework for Adversarial Attacks, Data Augmentation, and Adversarial Training in NLP', 'paperID': 'c9b56cb026a38e39bb0228faac57accd6f65e6f7', 'arxivId': None, 'publication_year': 2020, 'abstract': None}
{'title': 'BERT-ATTACK: Adversarial Attack against BERT Using BERT', 'paperID': 'dc0ce66f5ab4c5173cdef951649044e4c4c05076', 'arxivId': '2004.09984', 'publication_year': 2020, 'abstract': None}
{'title': 'ALBERT: A Lite BERT for Self-supervised Learning of Language Representations', 'paperID': '7a064df1aeada7e69e5173f7d4c8606f4470365b', 'arxivId': '1909.11942', 'publication_year': 2019, 'abstract': None}
{'title': 'Evading Defenses to Transferable Adversarial Examples by Translation-Invariant Attacks', 'paperID': '44d43bfbd23d55b1e7c4c4fd91fe101c0eaf1a06', 'arxivId': '1904.02884', 'publication_year': 2019, 'abstract': None}
{'title': 'OpenHowNet: An Open Sememe-based Lexical Knowledge Base', 'paperID': '6b1b5079dec9b1164d3415a925c1b4aca53a5e10', 'arxivId': '1901.09957', 'publication_year': 2019, 'abstract': None}
{'title': '(Preprint)', 'paperID': '6398cb8f2af1c988a097ed1e1cefb380195edfb8', 'arxivId': None, 'publication_year': 2018, 'abstract': None}
{'title': 'Particle swarm optimization', 'paperID': 'b7919bcfa38aa97514187501a23c983e8eb5482b', 'arxivId': None, 'publication_year': 1995, 'abstract': None}
{'title': 'WordNet: A Lexical Database for English', 'paperID': '68c03788224000794d5491ab459be0b2a2c38677', 'arxivId': None, 'publication_year': 1995, 'abstract': None}
{'title': 'TextGrad: Advancing Robustness Evaluation in NLP by Gradient-Driven Optimization', 'paperID': '85d08a213e9533c515601451cd78f971e547b1ae', 'arxivId': '2212.09254', 'publication_year': '2022', 'abstract': 'Robustness evaluation against adversarial examples has become increasingly important to unveil the trustworthiness of the prevailing deep models in natural language processing (NLP). However, in contrast to the computer vision domain where the first-order projected gradient descent (PGD) is used as the benchmark approach to generate adversarial examples for robustness evaluation, there lacks a principled first-order gradient-based robustness evaluation framework in NLP. The emerging optimization challenges lie in 1) the discrete nature of textual inputs together with the strong coupling between the perturbation location and the actual content, and 2) the additional constraint that the perturbed text should be fluent and achieve a low perplexity under a language model. These challenges make the development of PGD-like NLP attacks difficult. To bridge the gap, we propose TextGrad, a new attack generator using gradient-driven optimization, supporting high-accuracy and high-quality assessment of adversarial robustness in NLP. Specifically, we address the aforementioned challenges in a unified optimization framework. And we develop an effective convex relaxation method to co-optimize the continuously-relaxed site selection and perturbation variables and leverage an effective sampling method to establish an accurate mapping from the continuous optimization variables to the discrete textual perturbations. Moreover, as a first-order attack generation method, TextGrad can be baked into adversarial training to further improve the robustness of NLP models. Extensive experiments are provided to demonstrate the effectiveness of TextGrad not only in attack generation for robustness evaluation but also in adversarial defense.'}
{'title': 'Certifiably Robust Policy Learning against Adversarial Multi-Agent Communication', 'paperID': '4678c9f7ce7d91bc1770e64856b4ab9e050af2e2', 'arxivId': None, 'publication_year': None, 'abstract': None}
{'title': 'Towards Robustness Certification Against Universal Perturbations', 'paperID': 'd60709222aa772732b9ea644bdb364971c0dea13', 'arxivId': None, 'publication_year': None, 'abstract': None}
{'title': 'Understanding the effect of sparsity on neural networks robustness', 'paperID': 'dfacf0c04048c0a8c105976e9d2237ee269843ce', 'arxivId': '2206.10915', 'publication_year': 2022, 'abstract': None}
{'title': 'Masking Adversarial Damage: Finding Adversarial Saliency for Robust and Sparse Network', 'paperID': 'e23d0bf71547029968504de2ee1bb8888344c3b7', 'arxivId': '2204.02738', 'publication_year': 2022, 'abstract': None}
{'title': 'Improving Neural Network Architecture Compression by Multi-Grain Pruning', 'paperID': '753301a624a53029e16953d582b4e6f166ed4d99', 'arxivId': None, 'publication_year': 2021, 'abstract': None}
{'title': 'Adversarial Robust Model Compression using In-Train Pruning', 'paperID': 'bc4c65be9564abb0c40f5e754398bba450889568', 'arxivId': None, 'publication_year': 2021, 'abstract': None}
{'title': 'DNR: A Tunable Robust Pruning Framework Through Dynamic Network Rewiring of DNNs', 'paperID': '532035e132e27ddc2a1469e771fa658cbcaed4b3', 'arxivId': '2011.03083', 'publication_year': 2020, 'abstract': None}
{'title': 'Layer-adaptive Sparsity for the Magnitude-based Pruning', 'paperID': '9227d5897abbf297a34d447e94a802a714b8eab2', 'arxivId': '2010.07611', 'publication_year': 2020, 'abstract': None}
{'title': 'A Survey on Text Classification: From Traditional to Deep Learning', 'paperID': 'a554a0aae55be5597de8f6ece0a4dd0bd5a0e5f4', 'arxivId': '2008.00364', 'publication_year': 2020, 'abstract': None}
{'title': 'Soft Threshold Weight Reparameterization for Learnable Sparsity', 'paperID': '8eb599d5d7f1821b205e3b56fef5340b1622ba52', 'arxivId': '2002.03231', 'publication_year': 2020, 'abstract': None}
{'title': 'Parametric Noise Injection: Trainable Randomness to Improve Deep Neural Network Robustness Against Adversarial Attack', 'paperID': '3636d3f0562f3ab5f5df68c1c9a23530c0fbce64', 'arxivId': '1811.09310', 'publication_year': 2018, 'abstract': None}
{'title': 'Rethinking the Value of Network Pruning', 'paperID': '4a1004ecd34118116344633c7cdcc34493c423ee', 'arxivId': '1810.05270', 'publication_year': 2018, 'abstract': None}
{'title': 'Malware classification using deep learning methods', 'paperID': 'a1e4e65842ebd88bfda7fcf35b2e275724a6216c', 'arxivId': None, 'publication_year': 2018, 'abstract': None}
{'title': 'AMC: AutoML for Model Compression and Acceleration on Mobile Devices', 'paperID': '1717255b6aea01fe956cef998abbc3c399b5d7cf', 'arxivId': '1802.03494', 'publication_year': 2018, 'abstract': None}
{'title': 'Learning to Prune Filters in Convolutional Neural Networks', 'paperID': '2709a495f1a9d49bb852bbc512dd513ab158d0ad', 'arxivId': '1801.07365', 'publication_year': 2018, 'abstract': None}
{'title': 'Exploring the Granularity of Sparsity in Convolutional Neural Networks', 'paperID': '8e0de06951b55273667db85a65cc1a6aff158a56', 'arxivId': None, 'publication_year': 2017, 'abstract': None}
{'title': 'Designing Energy-Efficient Convolutional Neural Networks Using Energy-Aware Pruning', 'paperID': '3ac1df952ffb63abb4231a4410f6f8375ccdfe79', 'arxivId': '1611.05128', 'publication_year': 2016, 'abstract': None}
{'title': 'Optimizing Neural Networks with Kronecker-factored Approximate Curvature', 'paperID': 'cb4dc7277d1c8c3bc76dd7425eb1cc7cbaf99487', 'arxivId': '1503.05671', 'publication_year': 2015, 'abstract': None}
{'title': 'The Balanced Accuracy and Its Posterior Distribution', 'paperID': '8a097304b1c087d8ad5d25db48bcf6ad91e79ea5', 'arxivId': None, 'publication_year': 2010, 'abstract': None}
{'title': 'Non-Uniform Adversarially Robust Pruning', 'paperID': '47cbf414220626972ce2b609bf13514f98beef43', 'arxivId': None, 'publication_year': 2022, 'abstract': None}
{'title': 'SGDR: Stochastic Gradient Descent with Restarts', 'paperID': '1b7db8ad49f94da9b90db89bede5f27644bb9911', 'arxivId': None, 'publication_year': 2016, 'abstract': None}
{'title': 'Binarized Neural Networks', 'paperID': '28135fd3e80dda50a673cd556f10b9b972005d27', 'arxivId': None, 'publication_year': 2016, 'abstract': None}
{'title': 'Holistic Adversarially Robust Pruning', 'paperID': 'b6f933577c0e535ace8dcbab62a7308a2d04b980', 'arxivId': None, 'publication_year': None, 'abstract': 'Neural networks can be drastically shrunk in size by removing redundant parameters. While crucial for the deployment on resource-constraint hardware, oftentimes, compression comes with a severe drop in accuracy and lack of adversarial robustness. Despite recent advances, counteracting both aspects has only succeeded for moderate compression rates so far. We propose a novel method, HARP, that copes with aggressive pruning significantly better than prior work. For this, we consider the network holistically. We learn a global compression strategy that optimizes how many parameters (compression rate) and which parameters (scoring connections) to prune specific to each layer individually. Our method fine-tunes an existing model with dynamic regularization, that follows a step-wise incremental function balancing the different objectives. It starts by favoring robustness before shifting focus on reaching the target compression rate and only then handles the objectives equally. The learned compression strategies allow us to maintain the pre-trained model’s natural accuracy and its adversarial robustness for a reduction by 99% of the network’s original size. Moreover, we observe a crucial influence of non-uniform compression across layers. The implementation of HARP is publicly available at https://intellisec.de/research/harp.'}
{'title': 'Dual-path Image Inpainting with Auxiliary GAN Inversion', 'paperID': '9e93ea471ade297fa55d836241428e2174d43fbe', 'arxivId': None, 'publication_year': 2022, 'abstract': None}
{'title': 'PAEDID: Patch Autoencoder Based Deep Image Decomposition For Pixel-level Defective Region Segmentation', 'paperID': '41486714f22dfa7837366d253479104b8b053ca4', 'arxivId': '2203.14457', 'publication_year': 2022, 'abstract': None}
{'title': 'GAN-based anomaly detection: A review', 'paperID': '13fab6dbb9d0f3eaac0b45a52c140165ae25b8b6', 'arxivId': None, 'publication_year': 2022, 'abstract': None}
{'title': 'FastFlow: Unsupervised Anomaly Detection and Localization via 2D Normalizing Flows', 'paperID': '11709bfadfd6bbb371f4077bccb7c26d93c39cdd', 'arxivId': '2111.07677', 'publication_year': 2021, 'abstract': None}
{'title': 'Resolution-robust Large Mask Inpainting with Fourier Convolutions', 'paperID': 'fdf7012ebe9d4c4d2d93004613e7a19f69a83a93', 'arxivId': '2109.07161', 'publication_year': 2021, 'abstract': None}
{'title': 'High-Fidelity GAN Inversion for Image Attribute Editing', 'paperID': '90cf38a7431d920843c25f4bc8ea8feca99e83ff', 'arxivId': '2109.06590', 'publication_year': 2021, 'abstract': None}
{'title': 'DRÆM – A discriminatively trained reconstruction embedding for surface anomaly detection', 'paperID': '95a26eafabf06b1fc5dec6c460a927cf5964e97e', 'arxivId': '2108.07610', 'publication_year': 2021, 'abstract': None}
{'title': 'CFLOW-AD: Real-Time Unsupervised Anomaly Detection with Localization via Conditional Normalizing Flows', 'paperID': 'fc086bf5f6d1627153b68abdd5a4450e141b4ca3', 'arxivId': '2107.12571', 'publication_year': 2021, 'abstract': None}
{'title': 'Towards Total Recall in Industrial Anomaly Detection', 'paperID': '23ad8fc48530ce366f8192dfb48d0f7df1dba277', 'arxivId': '2106.08265', 'publication_year': 2021, 'abstract': None}
{'title': 'Image Inpainting by End-to-End Cascaded Refinement With Mask Awareness', 'paperID': 'd16e066ba0c50522c96a937a8f33068bf5722f90', 'arxivId': '2104.13743', 'publication_year': 2021, 'abstract': None}
{'title': 'VT-ADL: A Vision Transformer Network for Image Anomaly Detection and Localization', 'paperID': '913d43b69fd4ddee2ff64d3a1e6402d3787e2b7e', 'arxivId': '2104.10036', 'publication_year': 2021, 'abstract': None}
{'title': 'Large Scale Image Completion via Co-Modulated Generative Adversarial Networks', 'paperID': '39c2ae603902ea664adf9e74914117f79df2e612', 'arxivId': '2103.10428', 'publication_year': 2021, 'abstract': None}
{'title': 'GAN Inversion: A Survey', 'paperID': 'a3ef5a321876738a6b257de5e1eebc4a8aa5b907', 'arxivId': '2101.05278', 'publication_year': 2021, 'abstract': None}
{'title': 'PaDiM: a Patch Distribution Modeling Framework for Anomaly Detection and Localization', 'paperID': '2e8d62277e40d465343e8dfb32ecc246f320540e', 'arxivId': '2011.08785', 'publication_year': 2020, 'abstract': None}
{'title': 'BIGPrior: Toward Decoupling Learned Prior Hallucination and Data Fidelity in Image Restoration', 'paperID': 'c160e1e5431d2965b0a38d68de630a5867b18bc5', 'arxivId': '2011.01406', 'publication_year': 2020, 'abstract': None}
{'title': 'Encoding in Style: a StyleGAN Encoder for Image-to-Image Translation', 'paperID': '4cc32db67ff82cf1aa160631c35bb315c5add749', 'arxivId': '2008.00951', 'publication_year': 2020, 'abstract': None}
{'title': 'Recurrent Feature Reasoning for Image Inpainting', 'paperID': '20334266b089240d6d723efdc17511d4929a434a', 'arxivId': '2008.03737', 'publication_year': 2020, 'abstract': None}
{'title': 'High-Resolution Image Inpainting with Iterative Confidence Feedback and Guided Upsampling', 'paperID': '4106abc70ced2ff666e94ea9b668128b0f982cce', 'arxivId': '2005.11742', 'publication_year': 2020, 'abstract': None}
{'title': 'Autoencoders for Unsupervised Anomaly Segmentation in Brain MR Images: A Comparative Study', 'paperID': 'd82800c79dd335297336fe10b1a60d47706e4296', 'arxivId': '2004.03271', 'publication_year': 2020, 'abstract': None}
{'title': 'In-Domain GAN Inversion for Real Image Editing', 'paperID': '2f57b14bdedc16dd87aad2d9be6bc60690392fbf', 'arxivId': '2004.00049', 'publication_year': 2020, 'abstract': None}
{'title': 'Exploiting Deep Generative Prior for Versatile Image Restoration and Manipulation', 'paperID': '7101bc1c316740d99cd87185586829291a983a1d', 'arxivId': '2003.13659', 'publication_year': 2020, 'abstract': None}
{'title': 'VCNet: A Robust Approach to Blind Image Inpainting', 'paperID': '88bd997588ebcbade1f05b9e823503ce61fa8c80', 'arxivId': '2003.06816', 'publication_year': 2020, 'abstract': None}
{'title': 'Adversarial Discriminative Attention for Robust Anomaly Detection', 'paperID': '1a00dc525da31292e3734cbae2de681f114e30b1', 'arxivId': None, 'publication_year': 2020, 'abstract': None}
{'title': 'Image Processing Using Multi-Code GAN Prior', 'paperID': '7ad9b3ace5e2b9783100cd4205c94d7873723207', 'arxivId': '1912.07116', 'publication_year': 2019, 'abstract': None}
{'title': 'Image2StyleGAN++: How to Edit the Embedded Images?', 'paperID': '56e3b48e72f9452cb862de1b76c51ade2b681c43', 'arxivId': '1911.11544', 'publication_year': 2019, 'abstract': None}
{'title': 'StructureFlow: Image Inpainting via Structure-Aware Appearance Flow', 'paperID': '3a3eeceba9dd6dc4fcc7971eeae2d39af5e51215', 'arxivId': '1908.03852', 'publication_year': 2019, 'abstract': None}
{'title': 'MVTec AD — A Comprehensive Real-World Dataset for Unsupervised Anomaly Detection', 'paperID': '3aa681914a7da79f7d7293f51a058eefe61c8bb7', 'arxivId': None, 'publication_year': 2019, 'abstract': None}
{'title': 'Coherent Semantic Attention for Image Inpainting', 'paperID': 'b0f49ada8e9454048faf17f66d5e7520d5e46e98', 'arxivId': '1905.12384', 'publication_year': 2019, 'abstract': None}
{'title': 'f‐AnoGAN: Fast unsupervised anomaly detection with generative adversarial networks', 'paperID': 'f88cfc38dec02dcf050eb1f56d2d59d90b24e04c', 'arxivId': None, 'publication_year': 2019, 'abstract': None}
{'title': 'Learning Pyramid-Context Encoder Network for High-Quality Image Inpainting', 'paperID': 'd468363414b9ec6507ff24cbeefecb4828f52f6b', 'arxivId': '1904.07475', 'publication_year': 2019, 'abstract': None}
{'title': 'Image2StyleGAN: How to Embed Images Into the StyleGAN Latent Space?', 'paperID': '62931b3e0dce8748364e19c87ef318e22ec59c7f', 'arxivId': '1904.03189', 'publication_year': 2019, 'abstract': None}
{'title': 'Memorizing Normality to Detect Anomaly: Memory-Augmented Deep Autoencoder for Unsupervised Anomaly Detection', 'paperID': 'd65eb30e5f0d2013fd5e4f45d1413bc2969ee803', 'arxivId': '1904.02639', 'publication_year': 2019, 'abstract': None}
{'title': 'Gradient-aware blind face inpainting for deep face verification', 'paperID': '2bc1e26c454045e88a6db8cf41c4741fc734fe06', 'arxivId': None, 'publication_year': 2019, 'abstract': None}
{'title': 'Foreground-Aware Image Inpainting', 'paperID': '906b374e53357650477eebb80c6a8896b884b4bf', 'arxivId': '1901.05945', 'publication_year': 2019, 'abstract': None}
{'title': 'Detecting Overfitting of Deep Generative Networks via Latent Recovery', 'paperID': 'ed516c62512a5189c185738172ec0b151912e931', 'arxivId': '1901.03396', 'publication_year': 2019, 'abstract': None}
{'title': 'EdgeConnect: Generative Image Inpainting with Adversarial Edge Learning', 'paperID': 'f6284d750cf12669ca3bc12a1b485545af776239', 'arxivId': '1901.00212', 'publication_year': 2019, 'abstract': None}
{'title': 'MimicGAN: Corruption-Mimicking for Blind Image Recovery & Adversarial Defense', 'paperID': '308898a6bcb180f8fde1901a89e8baa213eb4954', 'arxivId': '1811.08484', 'publication_year': 2018, 'abstract': None}
{'title': 'Improving Unsupervised Defect Segmentation by Applying Structural Similarity to Autoencoders', 'paperID': '9c24454b071bc8e96ea46c5064a7bddf07cca464', 'arxivId': '1807.02011', 'publication_year': 2018, 'abstract': None}
{'title': 'Free-Form Image Inpainting With Gated Convolution', 'paperID': 'a997f1ecd85e1467d11252741d188fac8db22722', 'arxivId': '1806.03589', 'publication_year': 2018, 'abstract': None}
{'title': 'GANomaly: Semi-Supervised Anomaly Detection via Adversarial Training', 'paperID': '0535625be630c6a67f4c244ebf3aa61ad088fc70', 'arxivId': '1805.06725', 'publication_year': 2018, 'abstract': None}
{'title': 'Image Inpainting for Irregular Holes Using Partial Convolutions', 'paperID': '2a417a16473e2bcb1c98cd7814bc106760925e60', 'arxivId': '1804.07723', 'publication_year': 2018, 'abstract': None}
{'title': 'Deep Autoencoding Models for Unsupervised Anomaly Segmentation in Brain MR Images', 'paperID': 'eb60fe884c53b420edbce57059b242cfcbae0f7c', 'arxivId': '1804.04488', 'publication_year': 2018, 'abstract': None}
{'title': 'Shift-Net: Image Inpainting via Deep Feature Rearrangement', 'paperID': '904decf94f5495d1488e2bf22e3ed4df500ce4d5', 'arxivId': '1801.09392', 'publication_year': 2018, 'abstract': None}
{'title': 'Generative Image Inpainting with Contextual Attention', 'paperID': '6b0bbf3e7df725cc3b781d2648e41782cb3d8539', 'arxivId': '1801.07892', 'publication_year': 2018, 'abstract': None}
{'title': 'Deep Blind Image Inpainting', 'paperID': '80b2dbefdef33858dc6c78b0df1f8179e6c6d77a', 'arxivId': '1712.09078', 'publication_year': 2017, 'abstract': None}
{'title': 'Attentive Generative Adversarial Network for Raindrop Removal from A Single Image', 'paperID': '34e38559df559bfedfc3e1edc2b120ab2b5d444e', 'arxivId': '1711.10098', 'publication_year': 2017, 'abstract': None}
{'title': 'Contextual-Based Image Inpainting: Infer, Match, and Translate', 'paperID': '809c713a43e67ff60f2d9bf8b6571ca2a293ef08', 'arxivId': '1711.08590', 'publication_year': 2017, 'abstract': None}
{'title': 'Progressive Growing of GANs for Improved Quality, Stability, and Variation', 'paperID': '744fe47157477235032f7bb3777800f9f2f45e52', 'arxivId': '1710.10196', 'publication_year': 2017, 'abstract': None}
{'title': 'Globally and locally consistent image completion', 'paperID': 'd21ebaab3f715dc7178966ff146711882e6a6fee', 'arxivId': None, 'publication_year': 2017, 'abstract': None}
{'title': 'Generative Face Completion', 'paperID': 'b0351087a2b85f70e60fc79dfa4110b4985cc00a', 'arxivId': '1704.05838', 'publication_year': 2017, 'abstract': None}
{'title': 'Anomaly Detection in Images With Smooth Background via Smooth-Sparse Decomposition', 'paperID': 'c27824577439a90d4e5d05ed9a7147b132d7e92c', 'arxivId': None, 'publication_year': 2017, 'abstract': None}
{'title': 'High-Resolution Image Inpainting Using Multi-scale Neural Patch Synthesis', 'paperID': '3b9bfdeeb9ac6ada5a5833b1f179cb97f3e6804b', 'arxivId': '1611.09969', 'publication_year': 2016, 'abstract': None}
{'title': 'Inverting the Generator of a Generative Adversarial Network', 'paperID': '559a52d27ff8e3ae0cdf1e7948c137ff566285c8', 'arxivId': '1802.05701', 'publication_year': 2016, 'abstract': None}
{'title': 'Generative Visual Manipulation on the Natural Image Manifold', 'paperID': 'fc7822f56dd255a872326b9536a0821bbf0277dd', 'arxivId': '1609.03552', 'publication_year': 2016, 'abstract': None}
{'title': 'Semantic Image Inpainting with Deep Generative Models', 'paperID': '8a3bf4d403a39ed33f0fa8cf78dc906d6130595f', 'arxivId': '1607.07539', 'publication_year': 2016, 'abstract': None}
{'title': 'Context Encoders: Feature Learning by Inpainting', 'paperID': '7d0effebfa4bed19b6ba41f3af5b7e5b6890de87', 'arxivId': '1604.07379', 'publication_year': 2016, 'abstract': None}
{'title': 'Recent advances in robust optimization: An overview', 'paperID': '3e385b6e1b2f43464e9a0e60fdfb0cda108fe60b', 'arxivId': None, 'publication_year': 2014, 'abstract': None}
{'title': 'Robust PCA via Principal Component Pursuit: A review for a comparative evaluation in video surveillance', 'paperID': '261a2cb5ac0b550f8174d3d75f436c6d7b73e872', 'arxivId': None, 'publication_year': 2014, 'abstract': None}
{'title': 'Fast and Accurate Matrix Completion via Truncated Nuclear Norm Regularization', 'paperID': 'a657d39356c9d3b9c3c70796ad6f8b34c53d2da2', 'arxivId': None, 'publication_year': 2013, 'abstract': None}
{'title': 'Low-rank matrix completion using alternating minimization', 'paperID': 'c014c79fa37cb8dc4565d5db9c4879d98d5f904b', 'arxivId': '1212.0467', 'publication_year': 2012, 'abstract': None}
{'title': 'Statistics of Patch Offsets for Image Completion', 'paperID': '2f087cdde2ea34b911b3e9917b90fd3d42070eeb', 'arxivId': None, 'publication_year': 2012, 'abstract': None}
{'title': 'RASL: Robust alignment by sparse and low-rank decomposition for linearly correlated images', 'paperID': '3a6c9b81cc77f2d66dfec3d567a125b526c58ddd', 'arxivId': None, 'publication_year': 2010, 'abstract': None}
{'title': 'An Augmented Lagrangian Approach to the Constrained Optimization Formulation of Imaging Inverse Problems', 'paperID': '3a1b983a87a4116803fff779ecf1cd11a4b07539', 'arxivId': '0912.3481', 'publication_year': 2009, 'abstract': None}
{'title': 'Exact Matrix Completion via Convex Optimization', 'paperID': '040c161f21e0fa57ac192ac826310f55d60277b0', 'arxivId': '0805.4471', 'publication_year': 2008, 'abstract': None}
{'title': 'A Survey on Unsupervised Industrial Anomaly Detection Algorithms', 'paperID': '53c480c422d528fc379ba1cb160bd4cdbf38bffc', 'arxivId': None, 'publication_year': 2022, 'abstract': None}
{'title': 'Student-Teacher Feature Pyramid Matching for Unsupervised Anomaly Detection', 'paperID': '931dffdd56d60b6b9619a9f5ea8b533ec1ccdf04', 'arxivId': None, 'publication_year': 2021, 'abstract': None}
{'title': 'Robust Statistics', 'paperID': '8d23d6432c27843040f51dcf0191877f7a9994e9', 'arxivId': None, 'publication_year': 2004, 'abstract': None}
{'title': 'Mathematical Models for Local Nontexture Inpaintings', 'paperID': 'f66cfd6fa9bbb154f9acc5a22438c04f9874faf3', 'arxivId': None, 'publication_year': 2002, 'abstract': None}
{'title': 'RGI: robust GAN-inversion for mask-free image inpainting and unsupervised pixel-wise anomaly detection', 'paperID': 'f70801100c8d523bed156895120d53286d7aa49e', 'arxivId': '2302.12464', 'publication_year': '2023', 'abstract': "Generative adversarial networks (GANs), trained on a large-scale image dataset, can be a good approximator of the natural image manifold. GAN-inversion, using a pre-trained generator as a deep generative prior, is a promising tool for image restoration under corruptions. However, the performance of GAN-inversion can be limited by a lack of robustness to unknown gross corruptions, i.e., the restored image might easily deviate from the ground truth. In this paper, we propose a Robust GAN-inversion (RGI) method with a provable robustness guarantee to achieve image restoration under unknown \\textit{gross} corruptions, where a small fraction of pixels are completely corrupted. Under mild assumptions, we show that the restored image and the identified corrupted region mask converge asymptotically to the ground truth. Moreover, we extend RGI to Relaxed-RGI (R-RGI) for generator fine-tuning to mitigate the gap between the GAN learned manifold and the true image manifold while avoiding trivial overfitting to the corrupted input image, which further improves the image restoration and corrupted region mask identification performance. The proposed RGI/R-RGI method unifies two important applications with state-of-the-art (SOTA) performance: (i) mask-free semantic inpainting, where the corruptions are unknown missing regions, the restored background can be used to restore the missing content; (ii) unsupervised pixel-wise anomaly detection, where the corruptions are unknown anomalous regions, the retrieved mask can be used as the anomalous region's segmentation mask."}
{'title': 'Recognizing Object by Components With Human Prior Knowledge Enhances Adversarial Robustness of Deep Neural Networks', 'paperID': 'da26630c9d931952f1d68308148f1289f5332607', 'arxivId': '2212.01806', 'publication_year': 2022, 'abstract': None}
{'title': 'Generating High Fidelity Data from Low-density Regions using Diffusion Models', 'paperID': '741decb682ceccec1d06e53e6bc65b159d4e80f1', 'arxivId': '2203.17260', 'publication_year': 2022, 'abstract': None}
{'title': 'PartImageNet: A Large, High-Quality Dataset of Parts', 'paperID': '5c1dd63a45dc56009d1d499c8c2f4d7b9953a507', 'arxivId': '2112.00933', 'publication_year': 2021, 'abstract': None}
{'title': 'On the effectiveness of adversarial training against common corruptions', 'paperID': 'aac329026fb5f08f54b9f06f35ea2e0c3b664a76', 'arxivId': '2103.02325', 'publication_year': 2021, 'abstract': None}
{'title': 'RayS: A Ray Searching Method for Hard-label Adversarial Attack', 'paperID': '123877109e4a203b0db35984aa4808583573ab51', 'arxivId': '2006.12792', 'publication_year': 2020, 'abstract': None}
{'title': 'Noise or Signal: The Role of Image Backgrounds in Object Recognition', 'paperID': '5c63fc87400a4d3afea63ab8a068a47249f815c2', 'arxivId': '2006.09994', 'publication_year': 2020, 'abstract': None}
{'title': 'Cityscapes-Panoptic-Parts and PASCAL-Panoptic-Parts datasets for Scene Understanding', 'paperID': '20bf6524fded4bb666ae68955d1e48ed93ee446e', 'arxivId': '2004.07944', 'publication_year': 2020, 'abstract': None}
{'title': 'UnMask: Adversarial Detection and Defense Through Robust Feature Alignment', 'paperID': '6b4ba8d9d4ebf0dbe645fbf5ae6c0a3ede5a598d', 'arxivId': '2002.09576', 'publication_year': 2020, 'abstract': None}
{'title': 'Improving the affordability of robustness training for DNNs', 'paperID': '59f3d57a9821e07a73b4274b7a94867517414322', 'arxivId': '2002.04237', 'publication_year': 2020, 'abstract': None}
{'title': 'Rearchitecting Classification Frameworks For Increased Robustness', 'paperID': '0be998265251d163d797f1b69552c5be7d3f61bc', 'arxivId': '1905.10900', 'publication_year': 2019, 'abstract': None}
{'title': 'Unsupervised Part-Based Disentangling of Object Shape and Appearance', 'paperID': '79f36f8b6590fd59ac3e75726ccadf2f5c32b124', 'arxivId': '1903.06946', 'publication_year': 2019, 'abstract': None}
{'title': 'Semantic Part Detection via Matching: Learning to Generalize to Novel Viewpoints From Limited Training Data', 'paperID': '87bed8d35625a75d8ba1953bb6bb71a3625020c0', 'arxivId': '1811.11823', 'publication_year': 2018, 'abstract': None}
{'title': 'Learning Local RGB-to-CAD Correspondences for Object Pose Estimation', 'paperID': '0f9b94e869e655b80cacfb24f0f5585aa929e863', 'arxivId': None, 'publication_year': 2018, 'abstract': None}
{'title': 'Devil in the Details: Towards Accurate Single and Multiple Human Parsing', 'paperID': '1769d762def8bfc29b514581ea613d226b76fb63', 'arxivId': '1809.05996', 'publication_year': 2018, 'abstract': None}
{'title': 'Encoder-Decoder with Atrous Separable Convolution for Semantic Image Segmentation', 'paperID': '9217e28b2273eb3b26e4e9b7b498b4661e6e09f5', 'arxivId': '1802.02611', 'publication_year': 2018, 'abstract': None}
{'title': 'DeepVoting: A Robust and Explainable Deep Network for Semantic Part Detection Under Partial Occlusion', 'paperID': 'adecc9cb7c4e71a401099b26ed5420b8d4f4e90a', 'arxivId': None, 'publication_year': 2017, 'abstract': None}
{'title': 'Joint Multi-person Pose Estimation and Semantic Part Segmentation', 'paperID': 'fc027fccb19512a439fc17181c34ee1c3aad51b5', 'arxivId': '1708.03383', 'publication_year': 2017, 'abstract': None}
{'title': 'Unsupervised object discovery and localization in the wild: Part-based matching with bottom-up region proposals', 'paperID': '988c8578178fa263c2524d85292072c6a13a6121', 'arxivId': '1501.06170', 'publication_year': 2015, 'abstract': None}
{'title': 'Actions and Attributes from Wholes and Parts', 'paperID': '48e8cc2d5651053c0bc2fcd20787cca0782f2b94', 'arxivId': '1412.2604', 'publication_year': 2014, 'abstract': None}
{'title': 'Deformable part models are convolutional neural networks', 'paperID': '244bae85fda807361a51d4b26a14ecb2b2f8776b', 'arxivId': '1409.5403', 'publication_year': 2014, 'abstract': None}
{'title': 'Articulated Pose Estimation by a Graphical Model with Image Dependent Pairwise Relations', 'paperID': 'ed9a133865295aee70c62f8764a904be0498350e', 'arxivId': '1407.3399', 'publication_year': 2014, 'abstract': None}
{'title': 'Detect What You Can: Detecting and Representing Objects Using Holistic Models and Body Parts', 'paperID': 'caf202fd5833b1ef635923e79608e1a48d7539f9', 'arxivId': '1406.2031', 'publication_year': 2014, 'abstract': None}
{'title': 'Learning Collections of Part Models for Object Recognition', 'paperID': '9b9ea724dd5ad44ede5fa22bb8834ba7e42a9292', 'arxivId': None, 'publication_year': 2013, 'abstract': None}
{'title': 'The Pascal Visual Object Classes (VOC) Challenge', 'paperID': '0ee1916a0cb2dc7d3add086b5f1092c3d4beb38a', 'arxivId': None, 'publication_year': 2010, 'abstract': None}
{'title': 'Part-Based Models Improve Adversarial Robustness', 'paperID': '5860267c5b1761fa5ff8dbcde980edff4c3b2f2a', 'arxivId': '2209.09117', 'publication_year': '2022', 'abstract': "We show that combining human prior knowledge with end-to-end learning can improve the robustness of deep neural networks by introducing a part-based model for object classification. We believe that the richer form of annotation helps guide neural networks to learn more robust features without requiring more samples or larger models. Our model combines a part segmentation model with a tiny classifier and is trained end-to-end to simultaneously segment objects into parts and then classify the segmented object. Empirically, our part-based models achieve both higher accuracy and higher adversarial robustness than a ResNet-50 baseline on all three datasets. For instance, the clean accuracy of our part models is up to 15 percentage points higher than the baseline's, given the same level of robustness. Our experiments indicate that these models also reduce texture bias and yield better robustness against common corruptions and spurious correlations. The code is publicly available at https://github.com/chawins/adv-part-model."}
{'title': 'Building Robust Ensembles via Margin Boosting', 'paperID': 'db5c39d4ca9c4ffb33886782c4527fc5579668c5', 'arxivId': '2206.03362', 'publication_year': 2022, 'abstract': None}
{'title': 'Boosting Barely Robust Learners: A New Perspective on Adversarial Robustness', 'paperID': '5eb4b7f426094cce9e959fd0075475ebbf0d4f9c', 'arxivId': '2202.05920', 'publication_year': 2022, 'abstract': None}
{'title': 'Voting based ensemble improves robustness of defensive models', 'paperID': 'c2e83247a3a20d25f66262712673230f7cb68334', 'arxivId': '2011.14031', 'publication_year': 2020, 'abstract': None}
{'title': 'An Empirical Comparison of Voting Classification Algorithms: Bagging, Boosting, and Variants', 'paperID': 'fc80cdf18198dc5677ccabe501b6f7209c28483c', 'arxivId': None, 'publication_year': 1999, 'abstract': None}
{'title': 'NemaFootPrinter: a web based software for the identification of conserved non-coding genome sequence regions between C. elegans and C. briggsae', 'paperID': 'f0421492495a14eeb1d97bef61456afa46d2ed12', 'arxivId': None, 'publication_year': 1981, 'abstract': None}
{'title': 'Enhancing Certified Robustness via Smoothed Weighted Ensembling', 'paperID': 'ac1865efcaa3ae8992049f103225b4ec990bd7f3', 'arxivId': None, 'publication_year': 2021, 'abstract': None}
{'title': 'On the Perils of Cascading Robust Classifiers', 'paperID': 'dc15ef5398d7506ccf9c7f526f6cab8816e207d5', 'arxivId': '2206.00278', 'publication_year': '2022', 'abstract': "Ensembling certifiably robust neural networks is a promising approach for improving the \\emph{certified robust accuracy} of neural models. Black-box ensembles that assume only query-access to the constituent models (and their robustness certifiers) during prediction are particularly attractive due to their modular structure. Cascading ensembles are a popular instance of black-box ensembles that appear to improve certified robust accuracies in practice. However, we show that the robustness certifier used by a cascading ensemble is unsound. That is, when a cascading ensemble is certified as locally robust at an input $x$ (with respect to $\\epsilon$), there can be inputs $x'$ in the $\\epsilon$-ball centered at $x$, such that the cascade's prediction at $x'$ is different from $x$ and thus the ensemble is not locally robust. Our theoretical findings are accompanied by empirical results that further demonstrate this unsoundness. We present \\emph{cascade attack} (CasA), an adversarial attack against cascading ensembles, and show that: (1) there exists an adversarial input for up to 88\\% of the samples where the ensemble claims to be certifiably robust and accurate; and (2) the accuracy of a cascading ensemble under our attack is as low as 11\\% when it claims to be certifiably robust and accurate on 97\\% of the test set. Our work reveals a critical pitfall of cascading certifiably robust models by showing that the seemingly beneficial strategy of cascading can actually hurt the robustness of the resulting ensemble. Our code is available at \\url{https://github.com/TristaChi/ensembleKW}."}
{'title': 'Contrastive Adapters for Foundation Model Group Robustness', 'paperID': 'de4be9e0fa2f660eefb2d4c2a27c146d3e654a85', 'arxivId': '2207.07180', 'publication_year': 2022, 'abstract': None}
{'title': 'Informativeness and Invariance: Two Perspectives on Spurious Correlations in Natural Language', 'paperID': '53ed38af7df82242e0d7b13c19c814762de75bca', 'arxivId': '2204.04487', 'publication_year': 2022, 'abstract': None}
{'title': 'Spread Spurious Attribute: Improving Worst-group Accuracy with Spurious Attribute Estimation', 'paperID': '3d112021bb96568c830c03c779f232da3788067c', 'arxivId': '2204.02070', 'publication_year': 2022, 'abstract': None}
{'title': 'Domino: Discovering Systematic Errors with Cross-Modal Embeddings', 'paperID': '0567131ec1f839240179927ceb61f51bdd173055', 'arxivId': '2203.14960', 'publication_year': 2022, 'abstract': None}
{'title': 'Generating Data to Mitigate Spurious Correlations in Natural Language Inference Datasets', 'paperID': '1cfe67bad95a16bc249941b829d113d830031cf5', 'arxivId': '2203.12942', 'publication_year': 2022, 'abstract': None}
{'title': 'Model soups: averaging weights of multiple fine-tuned models improves accuracy without increasing inference time', 'paperID': '54020e5fe48ebb250f27d744e20a63cac2988a84', 'arxivId': '2203.05482', 'publication_year': 2022, 'abstract': None}
{'title': 'WANLI: Worker and AI Collaboration for Natural Language Inference Dataset Creation', 'paperID': '56b30c6bd9dc4a2416ab3b74ad97dbb7a2904229', 'arxivId': '2201.05955', 'publication_year': 2022, 'abstract': None}
{'title': 'The Spotlight: A General Method for Discovering Systematic Errors in Deep Learning Models', 'paperID': '05b2b28ebd8bcf0de4fe1cea9d096f20bbd3ab5f', 'arxivId': '2107.00758', 'publication_year': 2021, 'abstract': None}
{'title': 'SliceLine: Fast, Linear-Algebra-based Slice Finding for ML Model Debugging', 'paperID': 'ef685a63f00ebd44fa7b4c10282ea264807a08e0', 'arxivId': None, 'publication_year': 2021, 'abstract': None}
{'title': 'Finding and Fixing Spurious Patterns with Explanations', 'paperID': '1e58f1e94a03ef6434ce5e3360781d546f8a2f5b', 'arxivId': '2106.02112', 'publication_year': 2021, 'abstract': None}
{'title': 'On the Efficacy of Adversarial Data Collection for Question Answering: Results from a Large-Scale Randomized Study', 'paperID': 'c5e4eafd85949e6aac9d8e98d5e03b2acf444046', 'arxivId': '2106.00872', 'publication_year': 2021, 'abstract': None}
{'title': 'Polyjuice: Generating Counterfactuals for Explaining, Evaluating, and Improving Models', 'paperID': '15e71e497a67423bfedd0d63efe423c4660e5053', 'arxivId': '2101.00288', 'publication_year': 2021, 'abstract': None}
{'title': 'Understanding Failures of Deep Networks via Robust Feature Extraction', 'paperID': '6116cde7fc65eff29a1b8118b034f87909f2237f', 'arxivId': '2012.01750', 'publication_year': 2020, 'abstract': None}
{'title': "Learning from others' mistakes: Avoiding dataset biases without modeling them", 'paperID': '734f85727161f27bc7b295f0140a905363202d3f', 'arxivId': '2012.01300', 'publication_year': 2020, 'abstract': None}
{'title': 'No Subclass Left Behind: Fine-Grained Robustness in Coarse-Grained Classification Problems', 'paperID': '8c96b865bbe1f597cf2c644e20ae46eab8e7caad', 'arxivId': '2011.12945', 'publication_year': 2020, 'abstract': None}
{'title': 'An Empirical Study on Model-agnostic Debiasing Strategies for Robust Natural Language Inference', 'paperID': 'ff070fc5eff18a737545a0f96a068e9ab5a0f234', 'arxivId': '2010.03777', 'publication_year': 2020, 'abstract': None}
{'title': 'An Empirical Study on Robustness to Spurious Correlations using Pre-trained Language Models', 'paperID': '04422085a52050516b9741e0fd1fda964b73dd53', 'arxivId': '2007.06778', 'publication_year': 2020, 'abstract': None}
{'title': 'DeBERTa: Decoding-enhanced BERT with Disentangled Attention', 'paperID': '05f5f8b2065a520846d89771ebaea2bb1534e9c6', 'arxivId': '2006.03654', 'publication_year': 2020, 'abstract': None}
{'title': 'Evaluating Models’ Local Decision Boundaries via Contrast Sets', 'paperID': '35e6783307f82d1faa39be0653431305abec7271', 'arxivId': None, 'publication_year': 2020, 'abstract': None}
{'title': 'HypoNLI: Exploring the Artificial Patterns of Hypothesis-only Bias in Natural Language Inference', 'paperID': '1d8dcf5e99557c7d6b7015a280e4043439ecd1a5', 'arxivId': '2003.02756', 'publication_year': 2020, 'abstract': None}
{'title': 'End-to-End Bias Mitigation by Modelling Biases in Corpora', 'paperID': '72a1d0256b38dea6c3e7d10a63eacc51abdc96da', 'arxivId': '1909.06321', 'publication_year': 2019, 'abstract': None}
{'title': 'Unlearn Dataset Bias in Natural Language Inference by Fitting the Residual', 'paperID': '4e14cf96c60e3d35b05e3a740c7c6bbe52f14677', 'arxivId': '1908.10763', 'publication_year': 2019, 'abstract': None}
{'title': 'SpatialSense: An Adversarially Crowdsourced Benchmark for Spatial Relation Recognition', 'paperID': '1d738fa77de08592d9b77754e48cc63e276e5c0d', 'arxivId': '1908.02660', 'publication_year': 2019, 'abstract': None}
{'title': 'Slice Finder: Automated Data Slicing for Model Validation', 'paperID': '4299f004df8a927dc4132f5f9a98be574c74c2a7', 'arxivId': '1807.06068', 'publication_year': 2018, 'abstract': None}
{'title': 'Multiaccuracy: Black-Box Post-Processing for Fairness in Classification', 'paperID': '641076d8786511559cd31b96fc2c93426120ad47', 'arxivId': '1805.12317', 'publication_year': 2018, 'abstract': None}
{'title': 'Breaking NLI Systems with Sentences that Require Simple Lexical Inferences', 'paperID': '413a03a146e6f7b16c11e73243d83e6f1a6627a3', 'arxivId': '1805.02266', 'publication_year': 2018, 'abstract': None}
{'title': 'Yelp Dataset Challenge: Review Rating Prediction', 'paperID': 'fc24d32ab6acd5f1d2c478a6d0597c85afb28feb', 'arxivId': '1605.05362', 'publication_year': 2016, 'abstract': None}
{'title': 'Training Products of Experts by Minimizing Contrastive Divergence', 'paperID': '9360e5ce9c98166bb179ad479a9d2919ff13d022', 'arxivId': None, 'publication_year': 2002, 'abstract': None}
{'title': 'Learning from Failure: De-biasing Classifier from Biased Classifier', 'paperID': '68c1112480798d6d184853512d5c32c345741fc0', 'arxivId': None, 'publication_year': 2020, 'abstract': None}
{'title': 'AGRO: Adversarial discovery of error-prone Groups for Robust Optimization', 'paperID': '8c87dcaba827e5c1683086c3118fd9bffa7cff5e', 'arxivId': '2212.00921', 'publication_year': '2022', 'abstract': 'Models trained via empirical risk minimization (ERM) are known to rely on spurious correlations between labels and task-independent input features, resulting in poor generalization to distributional shifts. Group distributionally robust optimization (G-DRO) can alleviate this problem by minimizing the worst-case loss over a set of pre-defined groups over training data. G-DRO successfully improves performance of the worst-group, where the correlation does not hold. However, G-DRO assumes that the spurious correlations and associated worst groups are known in advance, making it challenging to apply it to new tasks with potentially multiple unknown spurious correlations. We propose AGRO -- Adversarial Group discovery for Distributionally Robust Optimization -- an end-to-end approach that jointly identifies error-prone groups and improves accuracy on them. AGRO equips G-DRO with an adversarial slicing model to find a group assignment for training examples which maximizes worst-case loss over the discovered groups. On the WILDS benchmark, AGRO results in 8% higher model performance on average on known worst-groups, compared to prior group discovery approaches used with G-DRO. AGRO also improves out-of-distribution performance on SST2, QQP, and MS-COCO -- datasets where potential spurious correlations are as yet uncharacterized. Human evaluation of ARGO groups shows that they contain well-defined, yet previously unstudied spurious correlations that lead to model errors.'}
{'title': 'Towards Robustness of Text-to-SQL Models Against Natural and Realistic Adversarial Table Perturbation', 'paperID': 'e262e1aa4d1efb909705a2dfcf9df53d76cb4e12', 'arxivId': '2212.09994', 'publication_year': 2022, 'abstract': None}
{'title': 'PaLM: Scaling Language Modeling with Pathways', 'paperID': '094ff971d6a8b8ff870946c9b3ce5aa173617bfb', 'arxivId': '2204.02311', 'publication_year': 2022, 'abstract': None}
{'title': 'Quality Controlled Paraphrase Generation', 'paperID': 'b46b91eaa9dcea3a50e19c726bca29cd4d25e389', 'arxivId': '2203.10940', 'publication_year': 2022, 'abstract': None}
{'title': 'Evaluating the Text-to-SQL Capabilities of Large Language Models', 'paperID': '51000d9f79be0eefd7972fe94e3c71dddc90d2c6', 'arxivId': '2204.00498', 'publication_year': 2022, 'abstract': None}
{'title': 'CoAuthor: Designing a Human-AI Collaborative Writing Dataset for Exploring Language Model Capabilities', 'paperID': '2b5d234efd26e7377698cf16c901601a3d3c4e56', 'arxivId': '2201.06796', 'publication_year': 2022, 'abstract': None}
{'title': 'MT-Teql: Evaluating and Augmenting Neural NLIDB on Real-world Linguistic and Schema Variations', 'paperID': '18ad0da02b2207288a3fe7c19ee8d223a9ee3ef4', 'arxivId': None, 'publication_year': 2021, 'abstract': None}
{'title': 'Exploring Underexplored Limitations of Cross-Domain Text-to-SQL Generalization', 'paperID': '0b3863c21a7fb5ac61a447611cba0ec9ce1ab4a4', 'arxivId': '2109.05157', 'publication_year': 2021, 'abstract': None}
{'title': 'PICARD: Parsing Incrementally for Constrained Auto-Regressive Decoding from Language Models', 'paperID': '5fbcfccd3736969d95ed660d8e6962c86b7a9113', 'arxivId': '2109.05093', 'publication_year': 2021, 'abstract': None}
{'title': 'Evaluating Large Language Models Trained on Code', 'paperID': 'acbdbf49f9bc3f151b93d9ca9a06009f4f6eb269', 'arxivId': '2107.03374', 'publication_year': 2021, 'abstract': None}
{'title': 'KaggleDBQA: Realistic Evaluation of Text-to-SQL Parsers', 'paperID': '9cd3d6eef7c574830be410598c3024191ee974d4', 'arxivId': '2106.11455', 'publication_year': 2021, 'abstract': None}
{'title': 'Prompting Contrastive Explanations for Commonsense Reasoning Tasks', 'paperID': '7747ecbc26b1688e6cad1a6ce83914efa2a3c04c', 'arxivId': '2106.06823', 'publication_year': 2021, 'abstract': None}
{'title': 'Towards Robustness of Text-to-SQL Models against Synonym Substitution', 'paperID': '84b26030b648b6d79177bdafd3e896b1dda9f91e', 'arxivId': '2106.01065', 'publication_year': 2021, 'abstract': None}
{'title': 'Generating Datasets with Pretrained Language Models', 'paperID': 'b769b629c8de35b16735214251d6b4e99cb55762', 'arxivId': '2104.07540', 'publication_year': 2021, 'abstract': None}
{'title': 'Neural Data Augmentation via Example Extrapolation', 'paperID': '10b15a695f837fbdc2babe0c38f8702c10af7bfb', 'arxivId': '2102.01335', 'publication_year': 2021, 'abstract': None}
{'title': 'On Robustness of Neural Semantic Parsers', 'paperID': 'f4cc7fa4f6a638cf79bf52341a05edcb5434fe97', 'arxivId': '2102.01563', 'publication_year': 2021, 'abstract': None}
{'title': 'Robustness Gym: Unifying the NLP Evaluation Landscape', 'paperID': '9b54941de1e21826ecc28b32730ac3f69991ede4', 'arxivId': '2101.04840', 'publication_year': 2021, 'abstract': None}
{'title': 'Bridging Textual and Tabular Data for Cross-Domain Text-to-SQL Semantic Parsing', 'paperID': '232b40980acb55afa89ec50dd9806a5e551f699b', 'arxivId': '2012.12627', 'publication_year': 2020, 'abstract': None}
{'title': 'Re-examining the Role of Schema Linking in Text-to-SQL', 'paperID': '29184b8befb6107e5a4d41bb8da4ace92fdd79b5', 'arxivId': None, 'publication_year': 2020, 'abstract': None}
{'title': 'Structure-Grounded Pretraining for Text-to-SQL', 'paperID': '3ff5f99c7924b4b28669f09ce3bfbf26fd92abc1', 'arxivId': '2010.12773', 'publication_year': 2020, 'abstract': None}
{'title': 'Compositional Generalization and Natural Language Variation: Can a Semantic Parsing Approach Handle Both?', 'paperID': 'acf8a1040034820bf99379a3422815f4e0859ec9', 'arxivId': '2010.12725', 'publication_year': 2020, 'abstract': None}
{'title': 'SmBoP: Semi-autoregressive Bottom-up Semantic Parsing', 'paperID': '5868a7bfe6a4590d332ca66b8097dbe5490c8a73', 'arxivId': '2010.12412', 'publication_year': 2020, 'abstract': None}
{'title': 'DuoRAT: Towards Simpler Text-to-SQL Models', 'paperID': 'a2462ff5546b45b1cc7cb50ffc50c7ddececca65', 'arxivId': '2010.11119', 'publication_year': 2020, 'abstract': None}
{'title': 'On the Potential of Lexico-logical Alignments for Semantic Parsing to SQL Queries', 'paperID': '6b2ccee1ac5823ed3d0cf97c75470ea335916c07', 'arxivId': '2010.11246', 'publication_year': 2020, 'abstract': None}
{'title': 'GraPPa: Grammar-Augmented Pre-Training for Table Semantic Parsing', 'paperID': '8b2cbb2f101b025c16e12d0d7628f65e5378e10d', 'arxivId': '2009.13845', 'publication_year': 2020, 'abstract': None}
{'title': 'RealToxicityPrompts: Evaluating Neural Toxic Degeneration in Language Models', 'paperID': '399e7d8129c60818ee208f236c8dda17e876d21f', 'arxivId': '2009.11462', 'publication_year': 2020, 'abstract': None}
{'title': 'Exploring Unexplored Generalization Challenges for Cross-Database Semantic Parsing', 'paperID': '7c41e58832f3af5fd9e09674924d6b5f822e8eac', 'arxivId': None, 'publication_year': 2020, 'abstract': None}
{'title': 'Beyond Accuracy: Behavioral Testing of NLP Models with CheckList', 'paperID': '33ec7eb2168e37e3007d1059aa96b9a63254b4da', 'arxivId': '2005.04118', 'publication_year': 2020, 'abstract': None}
{'title': 'RAT-SQL: Relation-Aware Schema Encoding and Linking for Text-to-SQL Parsers', 'paperID': '0c5bc409e62e65f86838968a2a7cdae5fa0b288b', 'arxivId': '1911.04942', 'publication_year': 2019, 'abstract': None}
{'title': 'Learning the Difference that Makes a Difference with Counterfactually-Augmented Data', 'paperID': '47f1eb0dc42189ba7cf21b76598c8217eb1b6e05', 'arxivId': '1909.12434', 'publication_year': 2019, 'abstract': None}
{'title': 'CTRL: A Conditional Transformer Language Model for Controllable Generation', 'paperID': '75acc731bdd2b626edc74672a30da3bc51010ae8', 'arxivId': '1909.05858', 'publication_year': 2019, 'abstract': None}
{'title': 'The Woman Worked as a Babysitter: On Biases in Language Generation', 'paperID': '5019dbe8d1da5f128f4f373d6849095cf18fd519', 'arxivId': '1909.01326', 'publication_year': 2019, 'abstract': None}
{'title': 'Spider: A Large-Scale Human-Labeled Dataset for Complex and Cross-Domain Semantic Parsing and Text-to-SQL Task', 'paperID': '8e773b1840b894603c06b677a0f15ebcf0f26378', 'arxivId': '1809.08887', 'publication_year': 2018, 'abstract': None}
{'title': 'Seq2SQL: Generating Structured Queries from Natural Language using Reinforcement Learning', 'paperID': 'cbd569036fc72ae7ff747350b91816440282596b', 'arxivId': '1709.00103', 'publication_year': 2017, 'abstract': None}
{'title': 'Dr.Spider: A Diagnostic Evaluation Benchmark towards Text-to-SQL Robustness', 'paperID': '7195ed3c7f11220f29634cecb68b1d39db2e36d9', 'arxivId': '2301.08881', 'publication_year': '2023', 'abstract': 'Neural text-to-SQL models have achieved remarkable performance in translating natural language questions into SQL queries. However, recent studies reveal that text-to-SQL models are vulnerable to task-specific perturbations. Previous curated robustness test sets usually focus on individual phenomena. In this paper, we propose a comprehensive robustness benchmark based on Spider, a cross-domain text-to-SQL benchmark, to diagnose the model robustness. We design 17 perturbations on databases, natural language questions, and SQL queries to measure the robustness from different angles. In order to collect more diversified natural question perturbations, we utilize large pretrained language models (PLMs) to simulate human behaviors in creating natural questions. We conduct a diagnostic study of the state-of-the-art models on the robustness set. Experimental results reveal that even the most robust model suffers from a 14.0% performance drop overall and a 50.7% performance drop on the most challenging perturbation. We also present a breakdown analysis regarding text-to-SQL model designs and provide insights for improving model robustness.'}
{'title': 'Min-Max Multi-objective Bilevel Optimization with Applications in Robust Machine Learning', 'paperID': '3cd5fbf89d3aa9a1872b0b89bae4aece9bb4392c', 'arxivId': None, 'publication_year': None, 'abstract': None}
{'title': 'Noise Injection as a Probe of Deep Learning Dynamics', 'paperID': '9ed96bd21a2a70cbb3466f88c84e965b702eb114', 'arxivId': '2210.13599', 'publication_year': 2022, 'abstract': None}
{'title': 'Strength of Minibatch Noise in SGD', 'paperID': '6cd064b3fb736cef8404ab24227add67c7c23779', 'arxivId': '2102.05375', 'publication_year': 2021, 'abstract': None}
{'title': 'Noise Optimization in Artificial Neural Networks', 'paperID': '4150b24323de1ae871887cccd66f4b759242a5e5', 'arxivId': '2102.04450', 'publication_year': 2021, 'abstract': None}
{'title': 'Fuzz Testing based Data Augmentation to Improve Robustness of Deep Neural Networks', 'paperID': '5b04e1f31c671e19cdd752c4c9a521c62b3ee6c7', 'arxivId': None, 'publication_year': 2020, 'abstract': None}
{'title': 'The large learning rate phase of deep learning: the catapult mechanism', 'paperID': '30ddacf5db38b5c9b4788c97bfc2dd73ab6ca040', 'arxivId': '2003.02218', 'publication_year': 2020, 'abstract': None}
{'title': 'Three Mechanisms of Weight Decay Regularization', 'paperID': 'ba618ec05a9dbef75310c5e4bcce8a559e0270b5', 'arxivId': '1810.12281', 'publication_year': 2018, 'abstract': None}
{'title': 'Adversarial Noise Layer: Regularize Neural Network by Adding Noise', 'paperID': 'a39149da8f9ec8fc398b9f1506c61e17650e3118', 'arxivId': '1805.08000', 'publication_year': 2018, 'abstract': None}
{'title': 'Regularization for Deep Learning: A Taxonomy', 'paperID': 'f152cfd441a52c9ceb2ae724d601fb4fb9ec77ea', 'arxivId': '1710.10686', 'publication_year': 2017, 'abstract': None}
{'title': 'Practical Gauss-Newton Optimisation for Deep Learning', 'paperID': 'aaed2a884af95852580fdedda4ea768f2effeb46', 'arxivId': '1706.03662', 'publication_year': 2017, 'abstract': None}
{'title': 'Adding Gradient Noise Improves Learning for Very Deep Networks', 'paperID': '6f5a0fbb1473e95d0a14ef2081985d16bc063bfb', 'arxivId': '1511.06807', 'publication_year': 2015, 'abstract': None}
{'title': 'Nonlinear Dynamics and Chaos: With Applications to Physics, Biology, Chemistry, and Engineering', 'paperID': 'd7db42b8ef68e84526922ae50420b062c2397dad', 'arxivId': None, 'publication_year': 2015, 'abstract': None}
{'title': 'Statistical Debugging of Sampled Programs', 'paperID': '829b5fb0d890b4adc40b03e1ebb02d5214ac5fe5', 'arxivId': None, 'publication_year': 2003, 'abstract': None}
{'title': 'Neural Smithing – Supervised Learning in Feedforward Artificial Neural Networks', 'paperID': '38f24db7abe5c2a3ffe900a56142bf000c0a7672', 'arxivId': None, 'publication_year': 2001, 'abstract': None}
{'title': 'Support-Vector Networks', 'paperID': '52b7bf3ba59b31f362aa07f957f1543a29a4279e', 'arxivId': None, 'publication_year': 1995, 'abstract': None}
{'title': 'A Database for Handwritten Text Recognition Research', 'paperID': '62a134740314b4469c83c8921ae2e1beea22b8f5', 'arxivId': None, 'publication_year': 1994, 'abstract': None}
{'title': 'A Simple Weight Decay Can Improve Generalization', 'paperID': '48e1de7d085808004d5f0493d486669a3d2930b5', 'arxivId': None, 'publication_year': 1991, 'abstract': None}
{'title': 'Learning Translation Invariant Recognition in Massively Parallel Networks', 'paperID': '3e6bea2649298c68d17b9421fc7dd19eeacc935e', 'arxivId': None, 'publication_year': 1987, 'abstract': None}
{'title': 'Dynamical Instability in an Anisotropic Ionized Gas of Low Density', 'paperID': 'f68b81423b8c3d4a3aabf32d001ae6289a6226d4', 'arxivId': None, 'publication_year': 1958, 'abstract': None}
{'title': 'Hydrodynamic Stability', 'paperID': '5f88150e657345dffdf3e6dea42fb18080d66531', 'arxivId': None, 'publication_year': 2008, 'abstract': None}
{'title': 'Using additive noise in back-propagation training', 'paperID': '11823e4fd9aa67ff429c6a63d99495187547c093', 'arxivId': None, 'publication_year': 1992, 'abstract': None}
{'title': 'Hydrodynamic and Hydromagnetic Stability', 'paperID': '2ab1cd775d54c9a33a1827292d286a98c64e52f7', 'arxivId': None, 'publication_year': 1961, 'abstract': None}
{'title': 'The stability of a spherical Nebula', 'paperID': '9f660a2067f08f561afa55c2d5a2e757e6e75bc9', 'arxivId': None, 'publication_year': 1901, 'abstract': None}
{'title': 'Noise Injection Node Regularization for Robust Learning', 'paperID': 'c5283314492adacea2de8a056f5529c506d0fef4', 'arxivId': '2210.15764', 'publication_year': '2022', 'abstract': 'We introduce Noise Injection Node Regularization (NINR), a method of injecting structured noise into Deep Neural Networks (DNN) during the training stage, resulting in an emergent regularizing effect. We present theoretical and empirical evidence for substantial improvement in robustness against various test data perturbations for feed-forward DNNs when trained under NINR. The novelty in our approach comes from the interplay of adaptive noise injection and initialization conditions such that noise is the dominant driver of dynamics at the start of training. As it simply requires the addition of external nodes without altering the existing network structure or optimization algorithms, this method can be easily incorporated into many standard problem specifications. We find improved stability against a number of data perturbations, including domain shifts, with the most dramatic improvement obtained for unstructured noise, where our technique outperforms other existing methods such as Dropout or $L_2$ regularization, in some cases. We further show that desirable generalization properties on clean data are generally maintained.'}
{'title': 'Streaming Algorithms for Learning with Experts: Deterministic Versus Robust', 'paperID': '5259300e83a2a6b93c6ce3d72bf67b9a4ab5a967', 'arxivId': '2303.01709', 'publication_year': 2023, 'abstract': None}
{'title': 'On Differential Privacy and Adaptive Data Analysis with Bounded Space', 'paperID': '6b559232a26086f5c2ef3724999d7b4eb02cf24f', 'arxivId': '2302.05707', 'publication_year': 2023, 'abstract': None}
{'title': 'Coloring in Graph Streams via Deterministic and Adversarially Robust Algorithms', 'paperID': '0792d8ad34761764bbd72edc900fa459a4933dfa', 'arxivId': '2212.10641', 'publication_year': 2022, 'abstract': None}
{'title': 'Sub-quadratic Algorithms for Kernel Matrices via Kernel Density Estimation', 'paperID': 'c7ce06fad686f60649f0ebe38702ad16ab3353bb', 'arxivId': '2212.00642', 'publication_year': 2022, 'abstract': None}
{'title': 'The White-Box Adversarial Data Stream Model', 'paperID': '6fea58dbc97782243ac3d040c4e01492da141207', 'arxivId': '2204.09136', 'publication_year': 2022, 'abstract': None}
{'title': 'Uniform approximations for Randomized Hadamard Transforms with applications', 'paperID': 'c45f6ea40c27e5bd6f5a59827c74a217ed93a33b', 'arxivId': '2203.01599', 'publication_year': 2022, 'abstract': None}
{'title': 'Dynamic algorithms against an adaptive adversary: generic constructions and lower bounds', 'paperID': 'aa9988bf55a092f8050b11818ca3647543263351', 'arxivId': '2111.03980', 'publication_year': 2021, 'abstract': None}
{'title': 'Adversarially Robust Coloring for Graph Streams', 'paperID': 'e43355403bbf5b6d3c11da20f1e3c743ecbd8eb3', 'arxivId': '2109.11130', 'publication_year': 2021, 'abstract': None}
{'title': 'Adversarially Robust Streaming via Dense-Sparse Trade-offs', 'paperID': '3562b7c2d0286b55e95d163ce3e49146695a5e9e', 'arxivId': '2109.03785', 'publication_year': 2021, 'abstract': None}
{'title': 'A Framework for Adversarial Streaming via Differential Privacy and Difference Estimators', 'paperID': 'c3c424efea89be2401295fab842b149b81367c6a', 'arxivId': '2107.14527', 'publication_year': 2021, 'abstract': None}
{'title': 'Adversarial Robustness of Streaming Algorithms through Importance Sampling', 'paperID': '729a2228220b349ab79e58d4f295d56155d14adf', 'arxivId': '2106.14952', 'publication_year': 2021, 'abstract': None}
{'title': 'Tight Bounds for Adversarially Robust Streams and Sliding Windows via Difference Estimators', 'paperID': '5cf1c3b9d3a9cc68d23e783dcd28bbacac042611', 'arxivId': '2011.07471', 'publication_year': 2020, 'abstract': None}
{'title': 'Quantum-Inspired Algorithms from Randomized Numerical Linear Algebra', 'paperID': '3a5af79aadeef874c4afdea3221676db027e4445', 'arxivId': '2011.04125', 'publication_year': 2020, 'abstract': None}
{'title': 'Kernel Density Estimation through Density Constrained Near Neighbor Search', 'paperID': '0de0bbcee7df3f4b6255eb443ad77ef50f829e11', 'arxivId': '2011.06997', 'publication_year': 2020, 'abstract': None}
{'title': 'On Adaptive Distance Estimation', 'paperID': 'dd13a6c091a258130c903371a75f08700df04596', 'arxivId': '2010.11252', 'publication_year': 2020, 'abstract': None}
{'title': 'Fully-Dynamic Graph Sparsifiers Against an Adaptive Adversary', 'paperID': '67eb93329588502db6bfd86115677fc19604a90a', 'arxivId': '2004.08432', 'publication_year': 2020, 'abstract': None}
{'title': 'Adversarially Robust Streaming Algorithms via Differential Privacy', 'paperID': 'a91634efce426bb6d0ef1bd2ababb925fb503165', 'arxivId': '2004.05975', 'publication_year': 2020, 'abstract': None}
{'title': 'A Framework for Adversarially Robust Streaming Algorithms', 'paperID': '7edd8f4e0fbeecc3846865b3e838140a1ffa6a0c', 'arxivId': '2003.14265', 'publication_year': 2020, 'abstract': None}
{'title': 'Rounding dynamic matchings against an adaptive adversary', 'paperID': 'ddf2e411971b31607c5ae8dcddb72c43c9f9a0aa', 'arxivId': '1911.05545', 'publication_year': 2019, 'abstract': None}
{'title': 'Faster Update Time for Turnstile Streaming Algorithms', 'paperID': '67bc33577fb46cf9a47609620af8f2e0d82ebc32', 'arxivId': '1911.01351', 'publication_year': 2019, 'abstract': None}
{'title': 'Adversarially Robust Submodular Maximization under Knapsack Constraints', 'paperID': 'b2d4cdf364557c4454c1ce8de25727c9fa5b8dd0', 'arxivId': '1905.02367', 'publication_year': 2019, 'abstract': None}
{'title': 'Efficient Density Evaluation for Smooth Kernels', 'paperID': '70792aa3bb6fb98494d7fdfbb39387966b145546', 'arxivId': None, 'publication_year': 2018, 'abstract': None}
{'title': 'Hashing-Based-Estimators for Kernel Density in High Dimensions', 'paperID': 'a953cacb510035198235a10235121e42c8eef579', 'arxivId': '1808.10530', 'publication_year': 2017, 'abstract': None}
{'title': 'Robust Submodular Maximization: A Non-Uniform Partitioning Approach', 'paperID': 'dfd18b71f5c53ec2a95fcbe327cf7710da3b4851', 'arxivId': '1706.04918', 'publication_year': 2017, 'abstract': None}
{'title': 'Algorithmic stability for adaptive data analysis', 'paperID': 'e42b526085ac96d83bbaf6fd6918b1cc6ee85d3a', 'arxivId': '1511.02513', 'publication_year': 2015, 'abstract': None}
{'title': 'Practical and Optimal LSH for Angular Distance', 'paperID': '50645e3dc912d597e89d59bffb96ccc0f8e1aefa', 'arxivId': '1509.02897', 'publication_year': 2015, 'abstract': None}
{'title': 'Strategic Classification', 'paperID': '81fd20c2b903d979075e0c6a59258b0a84213095', 'arxivId': '1506.06980', 'publication_year': 2015, 'abstract': None}
{'title': 'Differentially Private Release and Learning of Threshold Functions', 'paperID': '80d43be894c2819a7a4c8908f8eaa37ad2b6cb9d', 'arxivId': '1504.07553', 'publication_year': 2015, 'abstract': None}
{'title': 'Bloom Filters in Adversarial Environments', 'paperID': 'c8be69b5a68f443424905adda669eb3145ee24b1', 'arxivId': '1412.8356', 'publication_year': 2014, 'abstract': None}
{'title': 'Sketching as a Tool for Numerical Linear Algebra', 'paperID': '5fd338baae2a1e2918e56064f387b47e38d8f927', 'arxivId': '1411.4357', 'publication_year': 2014, 'abstract': None}
{'title': 'Reusable low-error compressive sampling schemes through privacy', 'paperID': '9004e445894afbd58dc275b2b274bbd6b112c239', 'arxivId': None, 'publication_year': 2012, 'abstract': None}
{'title': 'Low-Rank Approximation and Regression in Input Sparsity Time', 'paperID': '2c1fbecd90a0dfc3233a871fee043065419e286a', 'arxivId': '1207.6365', 'publication_year': 2012, 'abstract': None}
{'title': 'Randomized Algorithms for Matrices and Data', 'paperID': '4f025554aae684dffed8d08ef8077c644175d7e1', 'arxivId': '1104.5557', 'publication_year': 2011, 'abstract': None}
{'title': 'Sketching in adversarial environments', 'paperID': '801fed8c4a80c620a35606f8b75147aa0f8950ae', 'arxivId': None, 'publication_year': 2008, 'abstract': None}
{'title': 'Algorithms for distributed functional monitoring', 'paperID': '5f04cd3a7c5820b3a0a2d726ee698bfb2a6bab9d', 'arxivId': None, 'publication_year': 2008, 'abstract': None}
{'title': 'Estimators and tail bounds for dimension reduction in lα (0 < α ≤ 2) using stable random projections', 'paperID': '13dec17a485061c130143ea020d1512d8cb2741c', 'arxivId': None, 'publication_year': 2008, 'abstract': None}
{'title': 'Improved Approximation Algorithms for Large Matrices via Random Projections', 'paperID': '238a0814109dc166f1a1c0c3b5c33bc59250ae3f', 'arxivId': None, 'publication_year': 2006, 'abstract': None}
{'title': 'Calibrating Noise to Sensitivity in Private Data Analysis', 'paperID': 'e4ce10063cd25447dcde75c2d9ce327446ced952', 'arxivId': None, 'publication_year': 2006, 'abstract': None}
{'title': 'Finding frequent items in data streams', 'paperID': '24763030fb1e9813dad51d28bea9c5d1414f9cda', 'arxivId': None, 'publication_year': 2002, 'abstract': None}
{'title': 'Stable distributions, pseudorandom generators, embeddings and data stream computation', 'paperID': 'c982cb13d2a870ca09a2a1f0bf3c602cc528724e', 'arxivId': None, 'publication_year': 2000, 'abstract': None}
{'title': 'The discrepancy method - randomness and complexity', 'paperID': '0f84bab544302935f59d1ce31f02fdc42a80cb66', 'arxivId': None, 'publication_year': 2000, 'abstract': None}
{'title': 'How hard is half-space range searching?', 'paperID': '1d9a1d649569aaa256fb8f41ef87f2825546ace1', 'arxivId': None, 'publication_year': 1993, 'abstract': None}
{'title': 'Dynamic Least-Squares Regression', 'paperID': '4c440d3f4f302ff130ea1fb102a603e451b08efd', 'arxivId': None, 'publication_year': 2022, 'abstract': None}
{'title': 'Separating Adaptive Streaming from Oblivious Streaming Using the Bounded Storage Model', 'paperID': 'fc041bb3d34442911794d6e3748b87d1aabba204', 'arxivId': None, 'publication_year': 2021, 'abstract': None}
{'title': 'Space and Time Efficient Kernel Density Estimation in High Dimensions', 'paperID': '6978959aa7011b437292556a923750fd91bca799', 'arxivId': None, 'publication_year': 2019, 'abstract': None}
{'title': 'Randomized Algorithms for Matrices and Data', 'paperID': '3c282296103f0016403c6b5377e750b8c02cc193', 'arxivId': None, 'publication_year': 2010, 'abstract': None}
{'title': 'Approximate range searching in higher dimension', 'paperID': '69ca0f0c77f8c065248cd9a52489b06962620b9b', 'arxivId': None, 'publication_year': 2004, 'abstract': None}
{'title': 'In handbook of discrete and computational geometry', 'paperID': '43bfd29bcc2d88f615b40c92ee91e57c826f87ce', 'arxivId': None, 'publication_year': 1997, 'abstract': None}
{'title': 'One-dimensional stable distributions', 'paperID': '50afda9f6a9a92a6c1cd678bc4a659f36114defc', 'arxivId': None, 'publication_year': 1986, 'abstract': None}
{'title': 'Robust Algorithms on Adaptive Inputs from Bounded Adversaries', 'paperID': 'd10e3ef7fa49e13915d0e93c0877f2f2a26cd97a', 'arxivId': '2304.07413', 'publication_year': '2023', 'abstract': 'We study dynamic algorithms robust to adaptive input generated from sources with bounded capabilities, such as sparsity or limited interaction. For example, we consider robust linear algebraic algorithms when the updates to the input are sparse but given by an adversary with access to a query oracle. We also study robust algorithms in the standard centralized setting, where an adversary queries an algorithm in an adaptive manner, but the number of interactions between the adversary and the algorithm is bounded. We first recall a unified framework of [HKM+20, BKM+22, ACSS23] for answering $Q$ adaptive queries that incurs $\\widetilde{\\mathcal{O}}(\\sqrt{Q})$ overhead in space, which is roughly a quadratic improvement over the na\\"{i}ve implementation, and only incurs a logarithmic overhead in query time. Although the general framework has diverse applications in machine learning and data science, such as adaptive distance estimation, kernel density estimation, linear regression, range queries, and point queries and serves as a preliminary benchmark, we demonstrate even better algorithmic improvements for (1) reducing the pre-processing time for adaptive distance estimation and (2) permitting an unlimited number of adaptive queries for kernel density estimation. Finally, we complement our theoretical results with additional empirical evaluations.'}
{'title': 'A query-optimal algorithm for finding counterfactuals', 'paperID': 'ce93e2210ccb54b911d900341295157b1fde9271', 'arxivId': '2207.07072', 'publication_year': 2022, 'abstract': None}
{'title': 'Individual Fairness Guarantees for Neural Networks', 'paperID': 'a81374107c36b4a8d4d8f2d282722cc14a769a8a', 'arxivId': '2205.05763', 'publication_year': 2022, 'abstract': None}
{'title': 'Provably efficient, succinct, and precise explanations', 'paperID': '4ed4711cc471a0f4515b93ad9c6add184d625b22', 'arxivId': '2111.01576', 'publication_year': 2021, 'abstract': None}
{'title': 'A Simple and Effective Method to Defend Against Saliency Map Attack', 'paperID': '3c885f38e82f9c73a7de43adb1ea47b639dbfbea', 'arxivId': None, 'publication_year': 2021, 'abstract': None}
{'title': 'On Guaranteed Optimal Robust Explanations for NLP Models', 'paperID': 'd17761ca69acbef07f92f2477be488b99d1c63d7', 'arxivId': '2105.03640', 'publication_year': 2021, 'abstract': None}
{'title': "Make Sure You're Unsure: A Framework for Verifying Probabilistic Specifications", 'paperID': '37bc09cc6c4fa10bde98614c3fc13a67306b5db1', 'arxivId': '2102.09479', 'publication_year': 2021, 'abstract': None}
{'title': 'Bayesian Inference with Certifiable Adversarial Robustness', 'paperID': '4db97295efb7f6e2dfabac5fcb8570140740dfe9', 'arxivId': '2102.05289', 'publication_year': 2021, 'abstract': None}
{'title': 'Towards Robust Explanations for Deep Neural Networks', 'paperID': '20bd4b46aa53c0edc1bcee7e982b454771198a22', 'arxivId': '2012.10425', 'publication_year': 2020, 'abstract': None}
{'title': 'Robust and Stable Black Box Explanations', 'paperID': '41e613ebea2e5ae78899eccac9339bd524d4e6a1', 'arxivId': '2011.06169', 'publication_year': 2020, 'abstract': None}
{'title': 'Debugging Tests for Model Explanations', 'paperID': '7e63be5285e6596fbbc6c56bc89f7b6fd8bbe8c5', 'arxivId': '2011.05429', 'publication_year': 2020, 'abstract': None}
{'title': 'FAR: A General Framework for Attributional Robustness', 'paperID': '2034bd333f857023dbbca04db470aec0b306d94c', 'arxivId': '2010.07393', 'publication_year': 2020, 'abstract': None}
{'title': 'Scaling Guarantees for Nearest Counterfactual Explanations', 'paperID': '92923234f562dd589e7bf5872898ecaa9ef54501', 'arxivId': '2010.04965', 'publication_year': 2020, 'abstract': None}
{'title': 'A simple defense against adversarial attacks on heatmap explanations', 'paperID': 'acca8fe674c0968b40e7329c2b53cf7048683e4c', 'arxivId': '2007.06381', 'publication_year': 2020, 'abstract': None}
{'title': 'Fairwashing Explanations with Off-Manifold Detergent', 'paperID': '8bdfc8d09bfb4e7ff63faeb25d0e3514ebdc2d18', 'arxivId': '2007.09969', 'publication_year': 2020, 'abstract': None}
{'title': 'Machine Learning Explainability for External Stakeholders', 'paperID': 'dfc09849e6e9481a6ad1441b4409cc271cadfb63', 'arxivId': '2007.05408', 'publication_year': 2020, 'abstract': None}
{'title': 'Smoothed Geometry for Robust Attribution', 'paperID': 'af8376f8114ce2de4440a33445b43b6579df28c5', 'arxivId': '2006.06643', 'publication_year': 2020, 'abstract': None}
{'title': 'Probabilistic Safety for Bayesian Neural Networks', 'paperID': '84e729fe76dc90521b0512df11e49ab577ce0d6e', 'arxivId': '2004.10281', 'publication_year': 2020, 'abstract': None}
{'title': "You Shouldn't Trust Me: Learning Models Which Conceal Unfairness From Multiple Explanation Methods", 'paperID': '95d4cdaec450c0e26e45f13e231c075c1809ac7c', 'arxivId': None, 'publication_year': 2020, 'abstract': None}
{'title': 'On the apparent conflict between individual and group fairness', 'paperID': '31bfb37c0dc6d68ff9261b785b042a039b9156cb', 'arxivId': '1912.06883', 'publication_year': 2019, 'abstract': None}
{'title': 'Attributional Robustness Training Using Input-Gradient Spatial Alignment', 'paperID': '0d590420f5e0ed2fef653a89d5f2ed8a8ca1e798', 'arxivId': None, 'publication_year': 2019, 'abstract': None}
{'title': '"How do I fool you?": Manipulating User Trust via Misleading Black Box Explanations', 'paperID': 'e656b0376ca11f533ea01097c70f98c0ff655c00', 'arxivId': '1911.06473', 'publication_year': 2019, 'abstract': None}
{'title': 'Fooling LIME and SHAP: Adversarial Attacks on Post hoc Explanation Methods', 'paperID': '653864b10564ab4712c07a3d4043a1d794b13c46', 'arxivId': '1911.02508', 'publication_year': 2019, 'abstract': None}
{'title': 'Explainable machine learning in deployment', 'paperID': '1b0f4bd3872bb590d457990ac2b26b29f770fc44', 'arxivId': '1909.06342', 'publication_year': 2019, 'abstract': None}
{'title': 'Automatic Model Monitoring for Data Streams', 'paperID': '3b91867718169e6ff4e4d70dd61323218111278a', 'arxivId': '1908.04240', 'publication_year': 2019, 'abstract': None}
{'title': 'Robust Attribution Regularization', 'paperID': '28ae8aa1cb2346036c2af817e21569003eabc862', 'arxivId': '1905.09957', 'publication_year': 2019, 'abstract': None}
{'title': 'Safety Verification and Robustness Analysis of Neural Networks via Quadratic Constraints and Semidefinite Programming', 'paperID': '9972d742b8f197d2086906e7b06bb03900212bbd', 'arxivId': '1903.01287', 'publication_year': 2019, 'abstract': None}
{'title': 'Fooling Neural Network Interpretations via Adversarial Model Manipulation', 'paperID': 'ef7de986f5f5ed664938a5eed433a4c30dad6493', 'arxivId': '1902.02041', 'publication_year': 2019, 'abstract': None}
{'title': 'Abduction-Based Explanations for Machine Learning Models', 'paperID': '9a044eec8de883d45bd748ef0694324f8b1a7812', 'arxivId': '1811.10656', 'publication_year': 2018, 'abstract': None}
{'title': 'Stop explaining black box machine learning models for high stakes decisions and use interpretable models instead', 'paperID': 'bc00ff34ec7772080c7039b17f7069a2f7df0889', 'arxivId': None, 'publication_year': 2018, 'abstract': None}
{'title': 'A Game-Based Approximate Verification of Deep Neural Networks with Provable Guarantees', 'paperID': 'c708ff4a7f19b6747d775a2dc49ffda010dee339', 'arxivId': '1807.03571', 'publication_year': 2018, 'abstract': None}
{'title': 'Interpretation of Neural Networks is Fragile', 'paperID': 'e9d783c81b53ce967ae343a33cbbbcb4aaf3280f', 'arxivId': '1710.10547', 'publication_year': 2017, 'abstract': None}
{'title': 'Feature-Guided Black-Box Safety Testing of Deep Neural Networks', 'paperID': 'ccfc078af1ca7afda886c6ee4d2d9ef7544e087d', 'arxivId': '1710.07859', 'publication_year': 2017, 'abstract': None}
{'title': 'Visualizing Deep Neural Network Decisions: Prediction Difference Analysis', 'paperID': '29069976eb7f828de91ed243cd12fd99fef56d94', 'arxivId': '1702.04595', 'publication_year': 2017, 'abstract': None}
{'title': 'European Union Regulations on Algorithmic Decision-Making and a "Right to Explanation"', 'paperID': 'cc5afe344cc7ed7acd68a28b9774ea8023a162dc', 'arxivId': '1606.08813', 'publication_year': 2016, 'abstract': None}
{'title': 'Learning Deep Features for Discriminative Localization', 'paperID': '31f9eb39d840821979e5df9f34a6e92dd9c879f2', 'arxivId': '1512.04150', 'publication_year': 2015, 'abstract': None}
{'title': 'Improving generalization performance using double backpropagation', 'paperID': 'fbd86e19157ea0e4ffb05f14d7b94603a5667e0a', 'arxivId': None, 'publication_year': 1992, 'abstract': None}
{'title': 'Robust Explanation Constraints for Neural Networks', 'paperID': 'ac9c07f716e43db03b088d3e17bc9093c271662e', 'arxivId': '2212.08507', 'publication_year': '2022', 'abstract': 'Post-hoc explanation methods are used with the intent of providing insights about neural networks and are sometimes said to help engender trust in their outputs. However, popular explanations methods have been found to be fragile to minor perturbations of input features or model parameters. Relying on constraint relaxation techniques from non-convex optimization, we develop a method that upper-bounds the largest change an adversary can make to a gradient-based explanation via bounded manipulation of either the input features or model parameters. By propagating a compact input or parameter set as symbolic intervals through the forwards and backwards computations of the neural network we can formally certify the robustness of gradient-based explanations. Our bounds are differentiable, hence we can incorporate provable explanation robustness into neural network training. Empirically, our method surpasses the robustness provided by previous heuristic approaches. We find that our training method is the only method able to learn neural networks with certificates of explanation robustness across all six datasets tested.'}
{'title': 'IA-GM: A Deep Bidirectional Learning Method for Graph Matching', 'paperID': 'ca64fd7bafca59d35bfd001f04efd46b9fb79748', 'arxivId': None, 'publication_year': 2021, 'abstract': None}
{'title': 'Deep Graph Matching under Quadratic Constraint', 'paperID': '1a7586571ec088deea57bc43a96479f37e8d3130', 'arxivId': '2103.06643', 'publication_year': 2021, 'abstract': None}
{'title': 'First-Order Problem Solving through Neural MCTS based Reinforcement Learning', 'paperID': '8173fdf7440dd20fa7f2c9135d8e53ad3e881d65', 'arxivId': '2101.04167', 'publication_year': 2021, 'abstract': None}
{'title': 'Partial Gromov-Wasserstein Learning for Partial Graph Matching', 'paperID': 'dedbb80a396b17739cd6741940130c1dc13eeb4e', 'arxivId': None, 'publication_year': 2020, 'abstract': None}
{'title': 'Combinatorial Learning of Graph Edit Distance via Dynamic Embedding', 'paperID': '05f9689124903a6c6537421a16b7a4c6b4b122d6', 'arxivId': '2011.15039', 'publication_year': 2020, 'abstract': None}
{'title': 'Image Matching from Handcrafted to Deep Features: A Survey', 'paperID': '77a956512e22e37223ac6a00dcf191a086951505', 'arxivId': None, 'publication_year': 2020, 'abstract': None}
{'title': 'Learning for Graph Matching and Related Combinatorial Optimization Problems', 'paperID': '4aecd229673052c73b4713550f1f75c85739a155', 'arxivId': None, 'publication_year': 2020, 'abstract': None}
{'title': 'Learning Combinatorial Solver for Graph Matching', 'paperID': '50e728460362fd298cd8760a6bc5cab2429e7560', 'arxivId': None, 'publication_year': 2020, 'abstract': None}
{'title': 'Learning deep graph matching with channel-independent embedding and Hungarian attention', 'paperID': 'b8bd415d5c294e4e928f135d19b6b6f978322d28', 'arxivId': None, 'publication_year': 2020, 'abstract': None}
{'title': 'Unifying Offline and Online Multi-Graph Matching via Finding Shortest Paths on Supergraph', 'paperID': 'ce3a37aafab257853b931474cd7f0805f69db31b', 'arxivId': None, 'publication_year': 2020, 'abstract': None}
{'title': 'Zero-Assignment Constraint for Graph Matching With Outliers', 'paperID': '8ce9e511417ac35040ea7875fe9bd76ee4ac62f7', 'arxivId': '2003.11928', 'publication_year': 2020, 'abstract': None}
{'title': 'Deep Graph Matching via Blackbox Differentiation of Combinatorial Solvers', 'paperID': 'aac513b5f9a8538807ea80b5e2d2403c691877c5', 'arxivId': '2003.11657', 'publication_year': 2020, 'abstract': None}
{'title': 'GLSearch: Maximum Common Subgraph Detection via Learning to Search', 'paperID': '28cfe68822fd79fc788698aa13d0bddc09ed61dc', 'arxivId': '2002.03129', 'publication_year': 2020, 'abstract': None}
{'title': 'Deep Graph Matching Consensus', 'paperID': '339d6340960fe77bc597cad48eecf45fc237e742', 'arxivId': '2001.09621', 'publication_year': 2020, 'abstract': None}
{'title': 'Neural Graph Matching Network: Learning Lawler’s Quadratic Assignment Problem With Extension to Hypergraph and Multiple-Graph Matching', 'paperID': '80ec527ccf5562ba0afe00fa0e0386a02784283e', 'arxivId': '1911.11308', 'publication_year': 2019, 'abstract': None}
{'title': 'GLMNet: Graph Learning-Matching Networks for Feature Matching', 'paperID': '9692cb3a1e5513e7579e3f43ad385da0fa3c886c', 'arxivId': '1911.07681', 'publication_year': 2019, 'abstract': None}
{'title': 'Combinatorial Reinforcement Learning of Linear Assignment Problems', 'paperID': 'fca2d693caf3e8cf8c1bf83f2057f45b831bcc52', 'arxivId': None, 'publication_year': 2019, 'abstract': None}
{'title': 'Exploratory Combinatorial Optimization with Reinforcement Learning', 'paperID': '6572cecbe7f2fb071ac7427265f4eb312a5a5cf2', 'arxivId': '1909.04063', 'publication_year': 2019, 'abstract': None}
{'title': 'Learning Two-View Correspondences and Geometry Using Order-Aware Network', 'paperID': 'd46da5ef2fbe6602bcc890e6207a8c8da7933e58', 'arxivId': '1908.04964', 'publication_year': 2019, 'abstract': None}
{'title': 'Modern Deep Reinforcement Learning Algorithms', 'paperID': 'a5d5f064a99eb51c08a3fadca2326c0bdd7504f1', 'arxivId': '1906.10025', 'publication_year': 2019, 'abstract': None}
{'title': 'Causal Discovery with Reinforcement Learning', 'paperID': 'f844925066c3de9cd9ad662059e25a9d47a59843', 'arxivId': '1906.04477', 'publication_year': 2019, 'abstract': None}
{'title': 'Graph Matching Networks for Learning the Similarity of Graph Structured Objects', 'paperID': 'b85c74900ff716119f51852146de7a3d7d43230e', 'arxivId': '1904.12787', 'publication_year': 2019, 'abstract': None}
{'title': 'Learning Combinatorial Embedding Networks for Deep Graph Matching', 'paperID': 'd682db90cf13aeee2b2672cc7b007f978432d259', 'arxivId': '1904.00597', 'publication_year': 2019, 'abstract': None}
{'title': 'Adaptive Dynamic Bipartite Graph Matching: A Reinforcement Learning Approach', 'paperID': 'a3814c0798a1ada633aacfeeab82e59b68b7d27d', 'arxivId': None, 'publication_year': 2019, 'abstract': None}
{'title': 'A Functional Representation for Graph Matching', 'paperID': '81203855a4551931f858564ad907933f6f70ab34', 'arxivId': '1901.05179', 'publication_year': 2019, 'abstract': None}
{'title': 'Graph Matching with Adaptive and Branching Path Following', 'paperID': '83ad453332eee9317855662ee0cc97e2c36546dc', 'arxivId': None, 'publication_year': 2018, 'abstract': None}
{'title': 'Learning to Perform Local Rewriting for Combinatorial Optimization', 'paperID': 'f2b840c3c14b9f05106589c1be0a2dd4a494c0ba', 'arxivId': '1810.00337', 'publication_year': 2018, 'abstract': None}
{'title': 'An Algorithm for Finding the Most Similar Given Sized Subgraphs in Two Weighted Graphs', 'paperID': 'e2c74ef6070fc21bcf97cae001d716a9ffb8c426', 'arxivId': None, 'publication_year': 2018, 'abstract': None}
{'title': 'Deep Learning of Graph Matching', 'paperID': 'd6c1e14e8bea932f821352ea9e33928129f7d065', 'arxivId': None, 'publication_year': 2018, 'abstract': None}
{'title': 'Reinforcement Learning for Solving the Vehicle Routing Problem', 'paperID': '0366b6396610708a77540564050a90a761a28937', 'arxivId': '1802.04240', 'publication_year': 2018, 'abstract': None}
{'title': 'Learning to Find Good Correspondences', 'paperID': '901e8381aae4b1fbb0d4dcef714d39fbf02f9681', 'arxivId': '1711.05971', 'publication_year': 2017, 'abstract': None}
{'title': 'Sinkhorn Algorithm for Lifted Assignment Problems', 'paperID': 'e637332a8b8ba356d4d3b2c232a29fc7ea0783b2', 'arxivId': '1707.07285', 'publication_year': 2017, 'abstract': None}
{'title': 'Sample Efficient Actor-Critic with Experience Replay', 'paperID': '6a43d91c8d883e3463b358571125fa0ec7298b3a', 'arxivId': '1611.01224', 'publication_year': 2016, 'abstract': None}
{'title': 'Multi-Graph Matching via Affinity Optimization with Graduated Consistency Regularization', 'paperID': '678db2df7ea05455b486dd68b805640fc2b986b5', 'arxivId': None, 'publication_year': 2016, 'abstract': None}
{'title': 'Discriminative Embeddings of Latent Variable Models for Structured Data', 'paperID': '322cf9bcde458a45eaeca989a1eec92f7c6db984', 'arxivId': '1603.05629', 'publication_year': 2016, 'abstract': None}
{'title': 'Dueling Network Architectures for Deep Reinforcement Learning', 'paperID': '4c05d7caa357148f0bbd61720bdd35f0bc05eb81', 'arxivId': '1511.06581', 'publication_year': 2015, 'abstract': None}
{'title': 'Pointer Networks', 'paperID': '9653d5c2c7844347343d073bbedd96e05d52f69b', 'arxivId': '1506.03134', 'publication_year': 2015, 'abstract': None}
{'title': 'Outlier robust point correspondence based on GNCCP', 'paperID': '490d3a61db122d4d94ddcfd8d2cc20737106ea18', 'arxivId': None, 'publication_year': 2015, 'abstract': None}
{'title': 'Finding Matches in a Haystack: A Max-Pooling Strategy for Graph Matching in the Presence of Outliers', 'paperID': 'e3c5498b8bea3394d0a40654607021860a700348', 'arxivId': None, 'publication_year': 2014, 'abstract': None}
{'title': 'Deterministic Policy Gradient Algorithms', 'paperID': '687d0e59d5c35f022ce4638b3e3a6142068efc94', 'arxivId': None, 'publication_year': 2014, 'abstract': None}
{'title': 'Learning Graphs to Match', 'paperID': '1fe4bba72cac39cbca6dc111a48fb4970a7ce4a3', 'arxivId': None, 'publication_year': 2013, 'abstract': None}
{'title': 'A Dual Decomposition Approach to Feature Correspondence', 'paperID': '977d63d1ad9f03a1e08b900ba76e2f1602f020db', 'arxivId': None, 'publication_year': 2013, 'abstract': None}
{'title': 'An Extended Path Following Algorithm for Graph-Matching Problem', 'paperID': '41b8446d97c083f76718dc2e96900b84b9e73473', 'arxivId': None, 'publication_year': 2012, 'abstract': None}
{'title': 'Factorized Graph Matching', 'paperID': '186dce59aa6bd5bcb228c4f80f55ff032fa272b9', 'arxivId': None, 'publication_year': 2012, 'abstract': None}
{'title': 'Reweighted Random Walks for Graph Matching', 'paperID': '2edace819fc4b52018678e44b610144f7dddb789', 'arxivId': None, 'publication_year': 2010, 'abstract': None}
{'title': 'An Integer Projected Fixed Point Method for Graph Matching and MAP Inference', 'paperID': '692a262fab75e1cdefb8cffa5ba7be7cf988b939', 'arxivId': None, 'publication_year': 2009, 'abstract': None}
{'title': 'Poselets: Body part detectors trained using 3D human pose annotations', 'paperID': '55b29a2505149d06d8c1d616cd30edca40cb029c', 'arxivId': None, 'publication_year': 2009, 'abstract': None}
{'title': 'Global alignment of protein–protein interaction networks by graph matching methods', 'paperID': '8cd3277a3f3deb0f39cbe9d9ae3c59787c5e630a', 'arxivId': '0905.1106', 'publication_year': 2009, 'abstract': None}
{'title': 'Probabilistic Subgraph Matching Based on Convex Relaxation', 'paperID': '850b9a920aaff2c2d31221b071ae0be4e20dce16', 'arxivId': None, 'publication_year': 2005, 'abstract': None}
{'title': 'A spectral technique for correspondence problems using pairwise constraints', 'paperID': '56ca893694e7a36f913d508105ce6391f7f6f7f0', 'arxivId': None, 'publication_year': 2005, 'abstract': None}
{'title': 'QAPLIB – A Quadratic Assignment Problem Library', 'paperID': 'f7c7edbd264fd80246ef3fa05fb1273051b7139c', 'arxivId': None, 'publication_year': 1997, 'abstract': None}
{'title': 'A Graduated Assignment Algorithm for Graph Matching', 'paperID': '9899003369af99d02f699cbcbf48b79019666158', 'arxivId': None, 'publication_year': 1996, 'abstract': None}
{'title': 'Deep Neural Network Fusion via Graph Matching with Applications to Model Ensemble and Federated Learning', 'paperID': 'ad4d553ae695a5da33ef188ac37f2a7037c303f5', 'arxivId': None, 'publication_year': 2022, 'abstract': None}
{'title': 'Graduated Assignment for Joint Multi-Graph Matching and Clustering with Application to Unsupervised Graph Matching Network Learning', 'paperID': 'c641d071faab5a605fe25cc115bcb82430a5f473', 'arxivId': None, 'publication_year': 2020, 'abstract': None}
{'title': 'A Survey of the Quadratic Assignment Problem', 'paperID': 'd7917db3303a702908edc94f4da4e5e01c016cfe', 'arxivId': None, 'publication_year': 2014, 'abstract': None}
{'title': 'A Probabilistic Approach to Spectral Graph Matching', 'paperID': '87605c2054a6b581c5ea1ef9c28dbf3ee5f3064c', 'arxivId': None, 'publication_year': 2013, 'abstract': None}
{'title': 'Sinkhorn Distances: Lightspeed Computation of Optimal Transportation', 'paperID': '73c6442a0395c2cc2b0924a467793b9de6ced88e', 'arxivId': None, 'publication_year': 2013, 'abstract': None}
{'title': 'The Quadratic Assignment Problem', 'paperID': 'e9cffbd7dfa3faa4d78d6a4605a2ba84cf7cd71c', 'arxivId': None, 'publication_year': 2002, 'abstract': None}
{'title': 'Assignment Problems and the Location of Economic Activities', 'paperID': '9c281533ab0404a4f83971aaa8c89d5ed5dee418', 'arxivId': None, 'publication_year': 1957, 'abstract': None}
{'title': 'Revocable Deep Reinforcement Learning with Affinity Regularization for Outlier-Robust Graph Matching', 'paperID': '086586bdc6169cd6e9169ceca3c821803e3bf856', 'arxivId': '2012.08950', 'publication_year': '2020', 'abstract': "Graph matching (GM) has been a building block in various areas including computer vision and pattern recognition. Despite recent impressive progress, existing deep GM methods often have obvious difficulty in handling outliers, which are ubiquitous in practice. We propose a deep reinforcement learning based approach RGM, whose sequential node matching scheme naturally fits the strategy for selective inlier matching against outliers. A revocable action framework is devised to improve the agent's flexibility against the complex constrained GM. Moreover, we propose a quadratic approximation technique to regularize the affinity score, in the presence of outliers. As such, the agent can finish inlier matching timely when the affinity score stops growing, for which otherwise an additional parameter i.e. the number of inliers is needed to avoid matching outliers. In this paper, we focus on learning the back-end solver under the most general form of GM: the Lawler's QAP, whose input is the affinity matrix. Especially, our approach can also boost existing GM methods that use such input. Experiments on multiple real-world datasets demonstrate its performance regarding both accuracy and robustness."}
{'title': 'Rethinking Lipschitz Neural Networks and Certified Robustness: A Boolean Function Perspective', 'paperID': '455e65d4e32087f25c3bdacfd27e0408958bced7', 'arxivId': '2210.01787', 'publication_year': 2022, 'abstract': None}
{'title': '(Certified!!) Adversarial Robustness for Free!', 'paperID': '05c0b2d72a943dc0be26ef9e8fedd1380f2ff9ba', 'arxivId': '2206.10550', 'publication_year': 2022, 'abstract': None}
{'title': 'SimMIM: a Simple Framework for Masked Image Modeling', 'paperID': '9c4753ef43d2928866dc5bf6cec53d03373ec2fa', 'arxivId': '2111.09886', 'publication_year': 2021, 'abstract': None}
{'title': 'SmoothMix: Training Confidence-calibrated Smoothed Classifiers for Certified Robustness', 'paperID': 'f56da2152c462e39dff21267602d8a1f7884134d', 'arxivId': '2111.09277', 'publication_year': 2021, 'abstract': None}
{'title': 'Masked Autoencoders Are Scalable Vision Learners', 'paperID': '6351ebb4a3287f5f3e1273464b3b91e5df5a16d7', 'arxivId': '2111.06377', 'publication_year': 2021, 'abstract': None}
{'title': 'Noise2Same: Optimizing A Self-Supervised Bound for Image Denoising', 'paperID': '9d9ad34f43d9968cc58d4f8b929021f95cbd0b05', 'arxivId': '2010.11971', 'publication_year': 2020, 'abstract': None}
{'title': 'Noise2Self: Blind Denoising by Self-Supervision', 'paperID': 'ea9cf47573638745c9992cf9c5ebdabadd3c6849', 'arxivId': '1901.11365', 'publication_year': 2019, 'abstract': None}
{'title': 'Stacked Denoising Autoencoders: Learning Useful Representations in a Deep Network with a Local Denoising Criterion', 'paperID': 'e2b7f37cd97a7907b1b8a41138721ed06a0b76cd', 'arxivId': None, 'publication_year': 2010, 'abstract': None}
{'title': 'Extracting and composing robust features with denoising autoencoders', 'paperID': '843959ffdccf31c6694d135fad07425924f785b1', 'arxivId': None, 'publication_year': 2008, 'abstract': None}
{'title': 'Towards Fast Computation of Certified Robustness for ReLU Networks', 'paperID': '3e982d5d3508019d4571aeda20469a12ecb9e286', 'arxivId': None, 'publication_year': 2018, 'abstract': None}
{'title': 'Denoising Masked Autoencoders Help Robust Classification', 'paperID': 'f7227e206e11923e5d29a84ecc7dbd623a168f25', 'arxivId': '2210.06983', 'publication_year': '2022', 'abstract': 'In this paper, we propose a new self-supervised method, which is called Denoising Masked AutoEncoders (DMAE), for learning certified robust classifiers of images. In DMAE, we corrupt each image by adding Gaussian noises to each pixel value and randomly masking several patches. A Transformer-based encoder-decoder model is then trained to reconstruct the original image from the corrupted one. In this learning paradigm, the encoder will learn to capture relevant semantics for the downstream tasks, which is also robust to Gaussian additive noises. We show that the pre-trained encoder can naturally be used as the base classifier in Gaussian smoothed models, where we can analytically compute the certified radius for any data point. Although the proposed method is simple, it yields significant performance improvement in downstream classification tasks. We show that the DMAE ViT-Base model, which just uses 1/10 parameters of the model developed in recent work arXiv:2206.10550, achieves competitive or better certified accuracy in various settings. The DMAE ViT-Large model significantly surpasses all previous results, establishing a new state-of-the-art on ImageNet dataset. We further demonstrate that the pre-trained model has good transferability to the CIFAR-10 dataset, suggesting its wide adaptability. Models and code are available at https://github.com/quanlin-wu/dmae.'}
{'title': 'Object Representations as Fixed Points: Training Iterative Refinement Algorithms with Implicit Differentiation', 'paperID': 'b67c812cc4c9a96e73e228ead44cb9939d356a68', 'arxivId': '2207.00787', 'publication_year': 2022, 'abstract': None}
{'title': 'Towards Self-Supervised Learning of Global and Object-Centric Representations', 'paperID': '9aa5a492c9188bcf9441af36fed69b3be74ac1b3', 'arxivId': '2203.05997', 'publication_year': 2022, 'abstract': None}
{'title': 'Conditional Object-Centric Learning from Video', 'paperID': '95805eb7ab0edcd05128cf0256feaea8e2497de9', 'arxivId': '2111.12594', 'publication_year': 2021, 'abstract': None}
{'title': 'Unsupervised Learning of Compositional Energy Concepts', 'paperID': 'e52e9d290680d4ab492f97e035de0f619cc4ab33', 'arxivId': '2111.03042', 'publication_year': 2021, 'abstract': None}
{'title': 'Controllable and Compositional Generation with Latent-Space Energy-Based Models', 'paperID': 'a4727b807ae052c9dcddcf424a5d233bcc3c5a9e', 'arxivId': '2110.10873', 'publication_year': 2021, 'abstract': None}
{'title': 'Generalization and Robustness Implications in Object-Centric Learning', 'paperID': '02b9e41693c0ad91dbe09c781dc6818b2c4b8a3c', 'arxivId': '2107.00637', 'publication_year': 2021, 'abstract': None}
{'title': 'Unsupervised Object-Level Representation Learning from Scene Images', 'paperID': 'bd4d21a608a949607799138272529b5a82472ae6', 'arxivId': '2106.11952', 'publication_year': 2021, 'abstract': None}
{'title': 'GENESIS-V2: Inferring Unordered Object Representations without Iterative Refinement', 'paperID': '61081d610808ddd0c741c6d61bb4edd7c89855fe', 'arxivId': '2104.09958', 'publication_year': 2021, 'abstract': None}
{'title': 'Object-Centric Representation Learning for Video Question Answering', 'paperID': '37cf93dc3e15a1364dfd2f11a60831c0ebfcb45c', 'arxivId': '2104.05166', 'publication_year': 2021, 'abstract': None}
{'title': 'Object-Centric Neural Scene Rendering', 'paperID': 'b7d35e7107c9e090cd18dc494307be8e2c93a72a', 'arxivId': '2012.08503', 'publication_year': 2020, 'abstract': None}
{'title': 'Learning Object-Centric Video Models by Contrasting Sets', 'paperID': 'd354de207393d35dd74fd8e656c837a4dbed752c', 'arxivId': '2011.10287', 'publication_year': 2020, 'abstract': None}
{'title': 'Set Prediction without Imposing Structure as Conditional Density Estimation', 'paperID': '9da628bd954e2250ec3a8aec9670eab096575c2d', 'arxivId': '2010.04109', 'publication_year': 2020, 'abstract': None}
{'title': 'Slot Contrastive Networks: A Contrastive Approach for Representing Objects', 'paperID': '148af1bdbd8a93e085b34827d88994949be1f771', 'arxivId': '2007.09294', 'publication_year': 2020, 'abstract': None}
{'title': 'Object-Centric Learning with Slot Attention', 'paperID': '5156381d63bb3e873533b08f203cb56c2d79b6c9', 'arxivId': '2006.15055', 'publication_year': 2020, 'abstract': None}
{'title': 'Conditional Set Generation with Transformers', 'paperID': '0e10d8d17f0a81c4815af44375266c5cf404331a', 'arxivId': '2006.16841', 'publication_year': 2020, 'abstract': None}
{'title': 'Set Distribution Networks: a Generative Model for Sets of Images', 'paperID': 'f5d91e2908b0ba6416e16f24681b2a86e98adca0', 'arxivId': '2006.10705', 'publication_year': 2020, 'abstract': None}
{'title': 'Your GAN is Secretly an Energy-based Model and You Should use Discriminator Driven Latent Sampling', 'paperID': 'bc128adcfacdb03e23c455abbc1486ca21b1d559', 'arxivId': '2003.06060', 'publication_year': 2020, 'abstract': None}
{'title': 'Better Set Representations For Relational Reasoning', 'paperID': '476bc3ba7e953486af8c300619f5509c14dda271', 'arxivId': None, 'publication_year': 2020, 'abstract': None}
{'title': 'Learn to Predict Sets Using Feed-Forward Neural Networks', 'paperID': 'b8eefc7a59aea78d2a410b274e6802a00ed0570e', 'arxivId': '2001.11845', 'publication_year': 2020, 'abstract': None}
{'title': 'SPACE: Unsupervised Object-Oriented Scene Representation via Spatial Attention and Decomposition', 'paperID': '5a3a1aed872ef687e91bc98ea5acf5041fd342ae', 'arxivId': '2001.02407', 'publication_year': 2020, 'abstract': None}
{'title': 'Contrastive Learning of Structured World Models', 'paperID': '19b924dd9121f01165276a7afb764cf394acb80b', 'arxivId': '1911.12247', 'publication_year': 2019, 'abstract': None}
{'title': 'GENESIS: Generative Scene Inference and Sampling with Object-Centric Latent Representations', 'paperID': 'a50b7a45f704f30d7f97dd229d4d53433d5df3b1', 'arxivId': '1907.13052', 'publication_year': 2019, 'abstract': None}
{'title': 'Deep Set Prediction Networks', 'paperID': 'c91907248cd832ba4f766394cd86a27946047a9e', 'arxivId': '1906.06565', 'publication_year': 2019, 'abstract': None}
{'title': 'Online Object Representations with Contrastive Learning', 'paperID': '3e874d31af82de73f8dd2d55461c2f4ec838a07c', 'arxivId': '1906.04312', 'publication_year': 2019, 'abstract': None}
{'title': 'Multi-Object Representation Learning with Iterative Variational Inference', 'paperID': '9b8327b04667269fdae78cd34064eb2ee05ddee8', 'arxivId': '1903.00450', 'publication_year': 2019, 'abstract': None}
{'title': 'Measuring Compositionality in Representation Learning', 'paperID': 'ba4cf6046d420af0ae86e2f4b587a8d50d219be3', 'arxivId': '1902.07181', 'publication_year': 2019, 'abstract': None}
{'title': 'MONet: Unsupervised Scene Decomposition and Representation', 'paperID': 'd25b1edda507cba944938ec8784d8b124c2381a5', 'arxivId': '1901.11390', 'publication_year': 2019, 'abstract': None}
{'title': 'Spatial Broadcast Decoder: A Simple Architecture for Learning Disentangled Representations in VAEs', 'paperID': 'ef1fd3e181d66ffb18596fe03a0897963fa12ab2', 'arxivId': '1901.07017', 'publication_year': 2019, 'abstract': None}
{'title': 'Deep Perm-Set Net: Learn to predict sets with unknown permutation and cardinality using deep neural networks', 'paperID': '41573c31c21a7057cc8c4a35d09ca479ffc44ba1', 'arxivId': '1805.00613', 'publication_year': 2018, 'abstract': None}
{'title': 'Concept Learning with Energy-Based Models', 'paperID': '3aba6b43ab2cb3891557d9d61cb706ca658019e4', 'arxivId': '1811.02486', 'publication_year': 2018, 'abstract': None}
{'title': 'Neural Expectation Maximization', 'paperID': '3532848bf87449d49fad7fdf774c3562127b0e78', 'arxivId': '1708.03498', 'publication_year': 2017, 'abstract': None}
{'title': 'CLEVR: A Diagnostic Dataset for Compositional Language and Elementary Visual Reasoning', 'paperID': '03eb382e04cca8cca743f7799070869954f1402a', 'arxivId': '1612.06890', 'publication_year': 2016, 'abstract': None}
{'title': 'Tagger: Deep Unsupervised Perceptual Grouping', 'paperID': '66eb9741cee7fdeac0a437cc5e737535b7314f06', 'arxivId': '1606.06724', 'publication_year': 2016, 'abstract': None}
{'title': 'Attend, Infer, Repeat: Fast Scene Understanding with Generative Models', 'paperID': '2b5f51588f1c4cdca0865de20c1e2e1ff3570fd1', 'arxivId': '1603.08575', 'publication_year': 2016, 'abstract': None}
{'title': 'Binding via Reconstruction Clustering', 'paperID': '40c6dcb1f2c236590be8f264d88fef390cc48820', 'arxivId': '1511.06418', 'publication_year': 2015, 'abstract': None}
{'title': 'A Neural Algorithm of Artistic Style', 'paperID': 'f37e90c0bd5c4a9619ccfb763c45cb2d84abd3e6', 'arxivId': '1508.06576', 'publication_year': 2015, 'abstract': None}
{'title': 'Bayesian Learning via Stochastic Gradient Langevin Dynamics', 'paperID': 'aeed631d6a84100b5e9a021ec1914095c66de415', 'arxivId': None, 'publication_year': 2011, 'abstract': None}
{'title': 'MCMC Using Hamiltonian Dynamics', 'paperID': '502e8e0d8502ff9d8cbfc565d9360afdfb2aea45', 'arxivId': '1206.1901', 'publication_year': 2011, 'abstract': None}
{'title': 'Hybrid Monte Carlo', 'paperID': '75f063c9b32912f4b1b1f08dbcf6b0575ce16bf1', 'arxivId': None, 'publication_year': 1987, 'abstract': None}
{'title': 'The Hungarian method for the assignment problem', 'paperID': 'b6a0f30260302a2001da9999096cfdd89bc1f7fb', 'arxivId': None, 'publication_year': 1955, 'abstract': None}
{'title': 'Compositional Visual Generation with Energy Based Models', 'paperID': '0fc5a4f52a53f7d7809b7782a2aeb96da5ec6fd1', 'arxivId': None, 'publication_year': 2020, 'abstract': None}
{'title': 'Implicit Generation and Modeling with Energy Based Models', 'paperID': '9d2714b20d3bca952403be13b1c69b86004f91dc', 'arxivId': None, 'publication_year': 2019, 'abstract': None}
{'title': 'Order Matters: Sequence to sequence for sets', 'paperID': 'd52a4faafc388e8c75a523422cd4d05672797e0c', 'arxivId': None, 'publication_year': 2016, 'abstract': None}
{'title': 'A Tutorial on Energy-Based Learning', 'paperID': '7fc604e1a3e45cd2d2742f96d62741930a363efa', 'arxivId': None, 'publication_year': 2006, 'abstract': None}
{'title': 'Principles of Object Perception', 'paperID': '2b0752d91bde8b37e00e21219c441d9f6dfe74db', 'arxivId': None, 'publication_year': 1990, 'abstract': None}
{'title': 'Robust and Controllable Object-Centric Learning through Energy-based Models', 'paperID': '81f5859549221ecf9f42262b8c13e68d68b0a9a1', 'arxivId': '2210.05519', 'publication_year': '2022', 'abstract': "Humans are remarkably good at understanding and reasoning about complex visual scenes. The capability to decompose low-level observations into discrete objects allows us to build a grounded abstract representation and identify the compositional structure of the world. Accordingly, it is a crucial step for machine learning models to be capable of inferring objects and their properties from visual scenes without explicit supervision. However, existing works on object-centric representation learning either rely on tailor-made neural network modules or strong probabilistic assumptions in the underlying generative and inference processes. In this work, we present \\ours, a conceptually simple and general approach to learning object-centric representations through an energy-based model. By forming a permutation-invariant energy function using vanilla attention blocks readily available in Transformers, we can infer object-centric latent variables via gradient-based MCMC methods where permutation equivariance is automatically guaranteed. We show that \\ours can be easily integrated into existing architectures and can effectively extract high-quality object-centric representations, leading to better segmentation accuracy and competitive downstream task performance. Further, empirical evaluations show that \\ours's learned representations are robust against distribution shift. Finally, we demonstrate the effectiveness of \\ours in systematic compositional generalization, by re-composing learned energy functions for novel scene generation and manipulation."}
{'title': 'An Empirical Study on Distribution Shift Robustness From the Perspective of Pre-Training and Data Augmentation', 'paperID': '150bbe7a496b3e58ae705f342a6d915c194e3561', 'arxivId': '2205.12753', 'publication_year': 2022, 'abstract': None}
{'title': 'Robust and Efficient Medical Imaging with Self-Supervision', 'paperID': 'fa499cccb093dcb61ba5a270c5afaefc2502a241', 'arxivId': '2205.09723', 'publication_year': 2022, 'abstract': None}
{'title': 'Are Vision Transformers Robust to Spurious Correlations?', 'paperID': '2cf49c54f038f9b033f6d625a260011730383bcf', 'arxivId': '2203.09125', 'publication_year': 2022, 'abstract': None}
{'title': 'Solo-learn: A Library of Self-supervised Methods for Visual Representation Learning', 'paperID': 'e95a2817efcbc12b2fa5a7ca3b6cb8c57c20715f', 'arxivId': '2108.01775', 'publication_year': 2021, 'abstract': None}
{'title': 'Preventing dataset shift from breaking machine-learning biomarkers', 'paperID': 'e6b401b8b56bc50618690066a4c74344dacfd5c0', 'arxivId': '2107.09947', 'publication_year': 2021, 'abstract': None}
{'title': 'Rectifying the Shortcut Learning of Background for Few-Shot Learning', 'paperID': '4b613c1a87223bb043ac6b593964aee85cdaa168', 'arxivId': '2107.07746', 'publication_year': 2021, 'abstract': None}
{'title': 'Towards Unsupervised Domain Generalization', 'paperID': '370e2e712c0ffc661845636b6d14f99db59fdd8e', 'arxivId': '2107.06219', 'publication_year': 2021, 'abstract': None}
{'title': 'Can contrastive learning avoid shortcut solutions?', 'paperID': 'ebe510dc7b8025e496e11530192f2cccc184d002', 'arxivId': '2106.11230', 'publication_year': 2021, 'abstract': None}
{'title': 'What shapes feature representations? Exploring datasets, architectures, and training', 'paperID': '009c42dac6316c0f72b14e353b654560906a0e0f', 'arxivId': '2006.12433', 'publication_year': 2020, 'abstract': None}
{'title': 'Adversarial Filters of Dataset Biases', 'paperID': '22d834f7983fbd7cf2418978571f23efcd224bd9', 'arxivId': '2002.04108', 'publication_year': 2020, 'abstract': None}
{'title': 'Machine Learning with Multi-Site Imaging Data: An Empirical Study on the Impact of Scanner Effects', 'paperID': '082e8b2667653d800b5b53d44c16357ee4fe9255', 'arxivId': '1910.04597', 'publication_year': 2019, 'abstract': None}
{'title': 'SGD on Neural Networks Learns Functions of Increasing Complexity', 'paperID': '4e431827bf1ed1d8c435c01e75b12c79ba968721', 'arxivId': '1905.11604', 'publication_year': 2019, 'abstract': None}
{'title': 'Unmasking Clever Hans predictors and assessing what machines really learn', 'paperID': '4f51a64793d3b2a60e9e5846c31dae023cf5c69a', 'arxivId': '1902.10178', 'publication_year': 2019, 'abstract': None}
{'title': 'Learning Not to Learn: Training Deep Neural Networks With Biased Data', 'paperID': 'b79fe48ae523dc66185aa04df2dac7041afa8683', 'arxivId': '1812.10352', 'publication_year': 2018, 'abstract': None}
{'title': 'Most people are not WEIRD', 'paperID': '2a6d4a539681f9e8220efd5164d1a381ac346d73', 'arxivId': None, 'publication_year': 2010, 'abstract': None}
{'title': 'Covariate Shift by Kernel Mean Matching', 'paperID': '9d946ed8743c14be3fd22346fae1230098d8fa0d', 'arxivId': None, 'publication_year': 2009, 'abstract': None}
{'title': 'Learning internal representations by error propagation', 'paperID': '111fd833a4ae576cfdbb27d87d2f8fc0640af355', 'arxivId': None, 'publication_year': 1986, 'abstract': None}
{'title': 'Supplementary Material for Unsupervised Domain Generalization by Learning a Bridge Across Domains', 'paperID': '44500ee2032590019801404a4c334b1ac33ab987', 'arxivId': None, 'publication_year': 2022, 'abstract': None}
{'title': 'How robust is unsupervised representation learning to distribution shift?', 'paperID': '38cad5ae86da1c728e18cc49f77e988e927768fa', 'arxivId': '2206.08871', 'publication_year': '2022', 'abstract': 'The robustness of machine learning algorithms to distributions shift is primarily discussed in the context of supervised learning (SL). As such, there is a lack of insight on the robustness of the representations learned from unsupervised methods, such as self-supervised learning (SSL) and auto-encoder based algorithms (AE), to distribution shift. We posit that the input-driven objectives of unsupervised algorithms lead to representations that are more robust to distribution shift than the target-driven objective of SL. We verify this by extensively evaluating the performance of SSL and AE on both synthetic and realistic distribution shift datasets. Following observations that the linear layer used for classification itself can be susceptible to spurious correlations, we evaluate the representations using a linear head trained on a small amount of out-of-distribution (OOD) data, to isolate the robustness of the learned representations from that of the linear head. We also develop"controllable"versions of existing realistic domain generalisation datasets with adjustable degrees of distribution shifts. This allows us to study the robustness of different learning algorithms under versatile yet realistic distribution shift conditions. Our experiments show that representations learned from unsupervised learning algorithms generalise better than SL under a wide variety of extreme as well as realistic distribution shifts.'}
{'title': 'On Pseudo-Labeling for Class-Mismatch Semi-Supervised Learning', 'paperID': '2a7e4a52707f60a0cc616f5705595727515dd553', 'arxivId': '2301.06010', 'publication_year': 2023, 'abstract': None}
{'title': 'On the Importance of Calibration in Semi-supervised Learning', 'paperID': 'ac7225c5d5aa71d686cd28d84983fa6bb9896d02', 'arxivId': '2210.04783', 'publication_year': 2022, 'abstract': None}
{'title': 'Open-Set Semi-Supervised Object Detection', 'paperID': 'abb94f85a1fb77012aae2e89875b3a59cf4827ab', 'arxivId': '2208.13722', 'publication_year': 2022, 'abstract': None}
{'title': 'Semi-supervised Vision Transformers at Scale', 'paperID': '0904945439e7f23b1b6ae6ce358c398accc3cd9a', 'arxivId': '2208.05688', 'publication_year': 2022, 'abstract': None}
{'title': 'Towards Realistic Semi-Supervised Learning', 'paperID': 'cce61de63d6691fce13bf1a1c8d231553df12f31', 'arxivId': '2207.02269', 'publication_year': 2022, 'abstract': None}
{'title': 'Class-Aware Contrastive Semi-Supervised Learning', 'paperID': '8c382d6c53a317d0011fd4affc6955186956ecc9', 'arxivId': '2203.02261', 'publication_year': 2022, 'abstract': None}
{'title': 'Vision Models Are More Robust And Fair When Pretrained On Uncurated Images Without Supervision', 'paperID': '07c6a2ccb65913f2478234e96dd50c9593989c5c', 'arxivId': '2202.08360', 'publication_year': 2022, 'abstract': None}
{'title': 'Generalized Category Discovery', 'paperID': 'e6936c5da35d1de228c427704f97eb93ff5382cd', 'arxivId': '2201.02609', 'publication_year': 2022, 'abstract': None}
{'title': 'Semi-Supervised Learning with Taxonomic Labels', 'paperID': '09c3ca27403c2f73fbebf04729856a675f3fecaf', 'arxivId': '2111.11595', 'publication_year': 2021, 'abstract': None}
{'title': 'Trash to Treasure: Harvesting OOD Data with Cross-Modal Matching for Open-Set Semi-Supervised Learning', 'paperID': '85de3579e2142fafecb04b88452ee1c53d4faf3f', 'arxivId': '2108.05617', 'publication_year': 2021, 'abstract': None}
{'title': 'Object-aware Contrastive Learning for Debiased Scene Representation', 'paperID': '37de04f1055d97acdec3d3710a8db219ba8e0273', 'arxivId': '2108.00049', 'publication_year': 2021, 'abstract': None}
{'title': 'OpenCoS: Contrastive Semi-supervised Learning for Handling Open-set Unlabeled Data', 'paperID': '7413f4f695f216b013f8d7a3c5f26017da8d329f', 'arxivId': '2107.08943', 'publication_year': 2021, 'abstract': None}
{'title': 'RETRIEVE: Coreset Selection for Efficient and Robust Semi-Supervised Learning', 'paperID': '9257963d2b442c72eb8d17f7951da582b22d9990', 'arxivId': '2106.07760', 'publication_year': 2021, 'abstract': None}
{'title': 'The Semi-Supervised iNaturalist Challenge at the FGVC8 Workshop', 'paperID': '1f8abba432749862e332ded109be3b3027558677', 'arxivId': '2106.01364', 'publication_year': 2021, 'abstract': None}
{'title': 'OpenMatch: Open-set Consistency Regularization for Semi-supervised Learning with Outliers', 'paperID': '866169f5b40c631dc2c81bbe2378232dff728e0a', 'arxivId': '2105.14148', 'publication_year': 2021, 'abstract': None}
{'title': 'Divide and Contrast: Self-supervised Learning from Uncurated Data', 'paperID': 'e9d0781e517d8dd9995079027e91c79927ec46af', 'arxivId': '2105.08054', 'publication_year': 2021, 'abstract': None}
{'title': 'All Labels Are Not Created Equal: Enhancing Semi-supervision via Label Grouping and Co-training', 'paperID': '2bb6dad01d726e4c828a05b113c7d00f4c9ec74c', 'arxivId': '2104.05248', 'publication_year': 2021, 'abstract': None}
{'title': 'A Realistic Evaluation of Semi-Supervised Learning for Fine-Grained Classification', 'paperID': '7ce8f0dda13a434314562f92d56147c7970f1c62', 'arxivId': '2104.00679', 'publication_year': 2021, 'abstract': None}
{'title': 'SimPLE: Similar Pseudo Label Exploitation for Semi-Supervised Classification', 'paperID': '72fe90517d8df2894a955ad01568ab7586495fda', 'arxivId': '2103.16725', 'publication_year': 2021, 'abstract': None}
{'title': 'Self-Supervised Pretraining Improves Self-Supervised Pretraining', 'paperID': 'dc9d32cab9f8856455821925eab7cb9f1fa9a18e', 'arxivId': '2103.12718', 'publication_year': 2021, 'abstract': None}
{'title': 'CReST: A Class-Rebalancing Self-Training Framework for Imbalanced Semi-Supervised Learning', 'paperID': '09acced5fcb49322f5a26ac7a4cbe9f1308657c4', 'arxivId': '2102.09559', 'publication_year': 2021, 'abstract': None}
{'title': 'Open-World Semi-Supervised Learning', 'paperID': '0016122bc5dfe0684baaa672c53014d48b79a65f', 'arxivId': '2102.03526', 'publication_year': 2021, 'abstract': None}
{'title': 'An Empirical Study and Analysis on Open-Set Semi-Supervised Learning', 'paperID': '4b324aafefcafbc49c70ccfcc1323e65ff2238c2', 'arxivId': '2101.08237', 'publication_year': 2021, 'abstract': None}
{'title': 'In Defense of Pseudo-Labeling: An Uncertainty-Aware Pseudo-label Selection Framework for Semi-Supervised Learning', 'paperID': 'a21792db1c8d80c1d1f8525dab4959cc60b8e0ea', 'arxivId': '2101.06329', 'publication_year': 2021, 'abstract': None}
{'title': 'Out-distribution aware Self-training in an Open World Setting', 'paperID': 'f975ab30c76ba364ce813b2983be38f6328dc94d', 'arxivId': '2012.12372', 'publication_year': 2020, 'abstract': None}
{'title': 'They are Not Completely Useless: Towards Recycling Transferable Unlabeled Data for Class-Mismatched Semi-Supervised Learning', 'paperID': '1c45054cf0168a80a0b9e7f8171116c06a4a63f1', 'arxivId': '2011.13529', 'publication_year': 2020, 'abstract': None}
{'title': 'CoMatch: Semi-supervised Learning with Contrastive Graph Regularization', 'paperID': '669cbe118d868941172dbebfcaca9a479301d23b', 'arxivId': '2011.11183', 'publication_year': 2020, 'abstract': None}
{'title': 'Dense Contrastive Learning for Self-Supervised Visual Pre-Training', 'paperID': '6f92dcefc5f6b4346f619ae7546a8bd2d6decade', 'arxivId': '2011.09157', 'publication_year': 2020, 'abstract': None}
{'title': 'Multi-Task Curriculum Framework for Open-Set Semi-Supervised Learning', 'paperID': '1d32fbfba0d85489f924bed5c6a41fdc28d08914', 'arxivId': '2007.11330', 'publication_year': 2020, 'abstract': None}
{'title': 'FeatMatch: Feature-Based Augmentation for Semi-Supervised Learning', 'paperID': '3b4fd630260685b500c50e40fd801b6689dca570', 'arxivId': '2007.08505', 'publication_year': 2020, 'abstract': None}
{'title': 'Safe Deep Semi-Supervised Learning for Unseen-Class Unlabeled Data', 'paperID': '67f8f7fd1b8fea0214b032f94209650a73afece6', 'arxivId': None, 'publication_year': 2020, 'abstract': None}
{'title': 'Not All Unlabeled Data are Equal: Learning to Weight Data in Semi-supervised Learning', 'paperID': '9566da1b6af07462bc0ba54f24e47ba8ea82adcf', 'arxivId': '2007.01293', 'publication_year': 2020, 'abstract': None}
{'title': 'Supervision Accelerates Pre-training in Contrastive Semi-Supervised Learning of Visual Representations.', 'paperID': 'dc8b1486707e23a90d9d8e21e909d252e36cfe1c', 'arxivId': None, 'publication_year': 2020, 'abstract': None}
{'title': 'Big Self-Supervised Models are Strong Semi-Supervised Learners', 'paperID': '3e7f5f4382ac6f9c4fef6197dd21abf74456acd1', 'arxivId': '2006.10029', 'publication_year': 2020, 'abstract': None}
{'title': 'Semi-Supervised Learning under Class Distribution Mismatch', 'paperID': 'f3df804a7eef204b0c4fc4b81166dec9b4abc073', 'arxivId': None, 'publication_year': 2020, 'abstract': None}
{'title': 'Milking CowMask for Semi-Supervised Image Classification', 'paperID': '6d2d39ff427f080ba52b976347f365b6a28b63c8', 'arxivId': '2003.12022', 'publication_year': 2020, 'abstract': None}
{'title': 'Meta Pseudo Labels', 'paperID': '43497fe8aa7c730e075b08facc2aa560a6d4dd85', 'arxivId': '2003.10580', 'publication_year': 2020, 'abstract': None}
{'title': 'Curriculum Labeling: Revisiting Pseudo-Labeling for Semi-Supervised Learning', 'paperID': '39e0a6bceec1fe851128c47fedf35a2d4f22b332', 'arxivId': None, 'publication_year': 2020, 'abstract': None}
{'title': 'RealMix: Towards Realistic Semi-Supervised Deep Learning Algorithms', 'paperID': '72e16f845af7e2cfec11e73068210c62c850c193', 'arxivId': '1912.08766', 'publication_year': 2019, 'abstract': None}
{'title': 'ReMixMatch: Semi-Supervised Learning with Distribution Alignment and Augmentation Anchoring', 'paperID': '068eb2019cbb91421b7746af38da5e4c82f5e89c', 'arxivId': '1911.09785', 'publication_year': 2019, 'abstract': None}
{'title': 'A survey on semi-supervised learning', 'paperID': '3448e3c55cf3b1f25aab4719eb094a95dbe7f05e', 'arxivId': None, 'publication_year': 2019, 'abstract': None}
{'title': 'Semi-Supervised Learning', 'paperID': '554aabebf17b11046ac734aac8ef5a71872e93e3', 'arxivId': None, 'publication_year': 2019, 'abstract': None}
{'title': 'Pseudo-Labeling and Confirmation Bias in Deep Semi-Supervised Learning', 'paperID': '35e8312d8bdcffb8e0c956d20d5a581cad1c1b8a', 'arxivId': '1908.02983', 'publication_year': 2019, 'abstract': None}
{'title': 'Semi-Supervised Learning with Scarce Annotations', 'paperID': '6998bf98247a6ad13f005c136e0852e72b49f819', 'arxivId': '1905.08845', 'publication_year': 2019, 'abstract': None}
{'title': 'S4L: Self-Supervised Semi-Supervised Learning', 'paperID': 'd782eb6e017835e9b0a04ed2b83f34ea00506576', 'arxivId': '1905.03670', 'publication_year': 2019, 'abstract': None}
{'title': 'Billion-scale semi-supervised learning for image classification', 'paperID': '88ee291cf1f57fd0f4914a80b986a08a90d887f1', 'arxivId': '1905.00546', 'publication_year': 2019, 'abstract': None}
{'title': 'Unsupervised Data Augmentation for Consistency Training', 'paperID': '0feea94f89d395436bf41bd10c797447eecbc128', 'arxivId': '1904.12848', 'publication_year': 2019, 'abstract': None}
{'title': 'Label Propagation for Deep Semi-Supervised Learning', 'paperID': 'cafcdab811c7834c9c09960e09f9feb045efc945', 'arxivId': '1904.04717', 'publication_year': 2019, 'abstract': None}
{'title': 'Reducing Network Agnostophobia', 'paperID': 'd98ec42c5bc64b06b5d6e259467528e0121ae69b', 'arxivId': '1811.04110', 'publication_year': 2018, 'abstract': None}
{'title': 'Large Batch Training of Convolutional Networks', 'paperID': '1e3d18beaf3921f561e1b999780f29f2b23f3b7d', 'arxivId': '1708.03888', 'publication_year': 2017, 'abstract': None}
{'title': 'Semi-supervised kernel density estimation for video annotation', 'paperID': '6de7c154619ad07354356fd3d54b44e719c3a466', 'arxivId': None, 'publication_year': 2009, 'abstract': None}
{'title': 'Semi-supervised Learning by Entropy Minimization', 'paperID': 'ad67ccee45b801b0138016e2f44a566344e77320', 'arxivId': None, 'publication_year': 2004, 'abstract': None}
{'title': 'Learning with Local and Global Consistency', 'paperID': '46770a8e7e2af28f5253e5961f709be74e34c1f6', 'arxivId': None, 'publication_year': 2003, 'abstract': None}
{'title': 'The use of the area under the ROC curve in the evaluation of machine learning algorithms', 'paperID': '48ddd9101a90fe65e3061de69626741b843ff5e4', 'arxivId': None, 'publication_year': 1997, 'abstract': None}
{'title': 'Remarks on Some Nonparametric Estimates of a Density Function', 'paperID': '2c455f0da2bd86a9b9ea432d1485049073d7c63d', 'arxivId': None, 'publication_year': 1956, 'abstract': None}
{'title': 'Open-world Contrastive Learning', 'paperID': 'a94ff616652351beab958ceb8a2f9e6fe1b70f9e', 'arxivId': None, 'publication_year': 2022, 'abstract': None}
{'title': 'Universal Semi-Supervised Learning', 'paperID': '8e10a391605da43d211f490e7eeedb3934acd76a', 'arxivId': None, 'publication_year': 2021, 'abstract': None}
{'title': 'i-Mix: A Domain-Agnostic Strategy for Contrastive Representation Learning', 'paperID': 'c709a3ac669aa334d6a0e9544f9191c5516da8a2', 'arxivId': None, 'publication_year': 2021, 'abstract': None}
{'title': 'Active Learning Literature Survey', 'paperID': '818826f356444f3daa3447755bf63f171f39ec47', 'arxivId': None, 'publication_year': 2009, 'abstract': None}
{'title': 'Label Propagation and Quadratic Criterion', 'paperID': 'd6d7de1293f880c6edc73ff06eb2a5050404fe41', 'arxivId': None, 'publication_year': 2006, 'abstract': None}
{'title': 'RoPAWS: Robust Semi-supervised Representation Learning from Uncurated Data', 'paperID': '76f4416826b3393cf8f28ffd1a3191706d2b4286', 'arxivId': '2302.14483', 'publication_year': '2023', 'abstract': "Semi-supervised learning aims to train a model using limited labels. State-of-the-art semi-supervised methods for image classification such as PAWS rely on self-supervised representations learned with large-scale unlabeled but curated data. However, PAWS is often less effective when using real-world unlabeled data that is uncurated, e.g., contains out-of-class data. We propose RoPAWS, a robust extension of PAWS that can work with real-world unlabeled data. We first reinterpret PAWS as a generative classifier that models densities using kernel density estimation. From this probabilistic perspective, we calibrate its prediction based on the densities of labeled and unlabeled data, which leads to a simple closed-form solution from the Bayes' rule. We demonstrate that RoPAWS significantly improves PAWS for uncurated Semi-iNat by +5.3% and curated ImageNet by +0.4%."}
{'title': 'Adversarially trained neural representations may already be as robust as corresponding biological neural representations', 'paperID': '3307684cb55b64cce614c89a3f39938597fdc0f7', 'arxivId': '2206.11228', 'publication_year': 2022, 'abstract': None}
{'title': 'A ConvNet for the 2020s', 'paperID': '177e957f5cd93229c9794ea652c646d2557b4a69', 'arxivId': '2201.03545', 'publication_year': 2022, 'abstract': None}
{'title': 'Neural Population Geometry Reveals the Role of Stochasticity in Robust Perception', 'paperID': 'bacf294345b841586be6f128180f51b665aabb6b', 'arxivId': '2111.06979', 'publication_year': 2021, 'abstract': None}
{'title': 'Towards robust vision by multi-task learning on monkey visual cortex', 'paperID': 'f86e786c73891219efd24852212100992f0df764', 'arxivId': '2107.14344', 'publication_year': 2021, 'abstract': None}
{'title': 'Fooling the primate brain with minimal, targeted image manipulation', 'paperID': '7ab48793239205e7118021838e124d0419817bcc', 'arxivId': '2011.05623', 'publication_year': 2020, 'abstract': None}
{'title': 'The inferior temporal cortex is a potential cortical precursor of orthographic processing in untrained monkeys', 'paperID': '2c02895872c7aca00738a8ddd8b387da83a8acde', 'arxivId': None, 'publication_year': 2020, 'abstract': None}
{'title': 'Wiring Up Vision: Minimizing Supervised Synaptic Updates Needed to Produce a Primate Ventral Stream', 'paperID': '19d68db5346c837bb428160619356e36045b351c', 'arxivId': None, 'publication_year': 2020, 'abstract': None}
{'title': 'Fast Recurrent Processing via Ventrolateral Prefrontal Cortex Is Needed by the Primate Ventral Stream for Robust Core Visual Object Recognition', 'paperID': '574379e1310e1b5bb5f19a6824be34a1cfcd4616', 'arxivId': None, 'publication_year': 2020, 'abstract': None}
{'title': 'Engineering a Less Artificial Intelligence', 'paperID': '76cc14b26f01dc5e509c3f8b48181d80e1280d04', 'arxivId': None, 'publication_year': 2019, 'abstract': None}
{'title': 'Brain-Like Object Recognition with High-Performing Shallow Recurrent ANNs', 'paperID': '146d40346ed686f54087386f66666adaf6a6efaf', 'arxivId': '1909.06161', 'publication_year': 2019, 'abstract': None}
{'title': 'Learning From Brains How to Regularize Machines', 'paperID': '882728fd5424aecb7b4e63ee1dd0120599fcbe10', 'arxivId': '1911.05072', 'publication_year': 2019, 'abstract': None}
{'title': 'A critique of pure learning and what artificial neural networks can learn from animal brains', 'paperID': '32abbcb3aa75ac34a92624dc779a9f7a82ee981c', 'arxivId': None, 'publication_year': 2019, 'abstract': None}
{'title': "Improved object recognition using neural networks trained to mimic the brain's statistical properties", 'paperID': '47c8e35e1b4fad8eac5be6471ca521c1d0add77e', 'arxivId': None, 'publication_year': 2019, 'abstract': None}
{'title': 'Similarity of Neural Network Representations Revisited', 'paperID': '726320cdbd04804ffa8f3a78c095bd1b55a2a695', 'arxivId': '1905.00414', 'publication_year': 2019, 'abstract': None}
{'title': 'How biological attention mechanisms improve task performance in a large-scale visual system model', 'paperID': 'a11671d66c98b36d9d7684b047ae072b23e06794', 'arxivId': None, 'publication_year': 2018, 'abstract': None}
{'title': 'Adversarial Robustness Toolbox v1.0.0', 'paperID': 'af05afea7a7e99b8b20a743a49d5b33efc041100', 'arxivId': '1807.01069', 'publication_year': 2018, 'abstract': None}
{'title': 'Evidence that recurrent circuits are critical to the ventral stream’s execution of core object recognition behavior', 'paperID': '749118e990a532dddf9f573676e9d178f8442e2d', 'arxivId': None, 'publication_year': 2018, 'abstract': None}
{'title': 'Task-Driven Convolutional Recurrent Models of the Visual System', 'paperID': '6d86a97a7b392baac602a8df7224cb83880b071f', 'arxivId': '1807.00053', 'publication_year': 2018, 'abstract': None}
{'title': 'Large-Scale, High-Resolution Comparison of the Core Visual Object Recognition Behavior of Humans, Monkeys, and State-of-the-Art Deep Artificial Neural Networks', 'paperID': 'ba08dcd28837e83b54e9e7d192d756f52bdda042', 'arxivId': None, 'publication_year': 2018, 'abstract': None}
{'title': 'Neuroscience-Inspired Artificial Intelligence', 'paperID': '4f4556e75ff5a1aaad4123a46b1010eb09bfdf19', 'arxivId': None, 'publication_year': 2017, 'abstract': None}
{'title': 'Recurrent computations for visual pattern completion', 'paperID': '126b8cccd1bcf2afc442ab3856855aeecacfcb03', 'arxivId': '1706.02240', 'publication_year': 2017, 'abstract': None}
{'title': 'Keeping the Bad Guys Out: Protecting and Vaccinating Deep Learning with JPEG Compression', 'paperID': '8ab5d59c6534039e6854cdb60a8519e0e96bde03', 'arxivId': '1705.02900', 'publication_year': 2017, 'abstract': None}
{'title': 'Biologically inspired protection of deep networks from adversarial attacks', 'paperID': '600a5d60cb96eda2a9849413e747547d70dfb00a', 'arxivId': '1703.09202', 'publication_year': 2017, 'abstract': None}
{'title': 'Towards deep learning with segregated dendrites', 'paperID': 'd6c850b41500be8cfadb5aa710934d9c5c7bc100', 'arxivId': '1610.00161', 'publication_year': 2016, 'abstract': None}
{'title': 'Toward an Integration of Deep Learning and Neuroscience', 'paperID': '2dec4f52b1ce552b416f086d4ea1040626675dfa', 'arxivId': '1606.03813', 'publication_year': 2016, 'abstract': None}
{'title': 'Explicit information for category-orthogonal object properties increases along the ventral stream', 'paperID': '09eb087fc5730589e59673aafa0dfc788768611a', 'arxivId': None, 'publication_year': 2016, 'abstract': None}
{'title': 'Simple Learned Weighted Sums of Inferior Temporal Neuronal Firing Rates Accurately Predict Human Core Object Recognition Performance', 'paperID': '0dbd2e1018bdb61e5d39e8121747f2040bc0bad2', 'arxivId': None, 'publication_year': 2015, 'abstract': None}
{'title': 'Comparison of Object Recognition Behavior in Human and Monkey', 'paperID': 'f174c5f87594134ae71292e87c8263a5bb737a41', 'arxivId': None, 'publication_year': 2014, 'abstract': None}
{'title': 'Hierarchical Modular Optimization of Convolutional Networks Achieves Representations Similar to Macaque IT and Human Ventral Stream', 'paperID': 'c8b31d37225e082395f212200eaaf68918195b41', 'arxivId': None, 'publication_year': 2013, 'abstract': None}
{'title': 'Networks', 'paperID': '342fe6a6338e73fd4d34c4f37f41e3bbad274dd2', 'arxivId': None, 'publication_year': 2007, 'abstract': None}
{'title': 'Bag of Tricks for Training Brain-Like Deep Neural Networks', 'paperID': 'a1576850b6f0378c3e288e02c37dd1693f32d776', 'arxivId': None, 'publication_year': 2022, 'abstract': None}
{'title': 'Surround Modulation: A Bio-inspired Connectivity Structure for Convolutional Neural Networks', 'paperID': 'dd8a9122658ef38318d1d42e91435a6885044064', 'arxivId': None, 'publication_year': 2019, 'abstract': None}
{'title': 'Aligning Model and Macaque Inferior Temporal Cortex Representations Improves Model-to-Human Behavioral Alignment and Adversarial Robustness', 'paperID': '4ce6d229d5f44239c948fd56ad744c012aae22e0', 'arxivId': None, 'publication_year': '2022', 'abstract': 'While some state-of-the-art artificial neural network systems in computer vision are strikingly accurate models of the corresponding primate visual processing, there are still many discrepancies between these models and the behavior of primates on object recognition tasks. Many current models suffer from extreme sensitivity to adversarial attacks and often do not align well with the image-by-image behavioral error patterns observed in humans. Previous research has provided strong evidence that primate object recognition behavior can be very accurately predicted by neural population activity in the inferior temporal (IT) cortex, a brain area in the late stages of the visual processing hierarchy. Therefore, here we directly test whether making the late stage representations of models more similar to that of macaque IT produces new models that exhibit more robust, primate-like behavior. We conducted chronic, large-scale multi-electrode recordings across the IT cortex in six non-human primates (rhesus macaques). We then use these data to fine-tune (end-to-end) the model “IT” representations such that they are more aligned with the biological IT representations, while preserving accuracy on object recognition tasks. We generate a cohort of models with a range of IT similarity scores validated on held-out animals across two image sets with distinct statistics. Across a battery of optimization conditions, we observed a strong correlation between the models’ IT-likeness and alignment with human behavior, as well as an increase in its adversarial robustness. We further assessed the limitations of this approach and find that the improvements in behavioral alignment and adversarial robustness generalize across different image statistics, but not to object categories outside of those covered in our IT training set. Taken together, our results demonstrate that building models that are more aligned with the primate brain leads to more robust and human-like behavior, and call for larger neural data-sets to further augment these gains.'}
{'title': 'ROCO: A General Framework for Evaluating Robustness of Combinatorial Optimization Solvers on Graphs', 'paperID': '2e2c56325c3caac544285f46187c33439b211962', 'arxivId': None, 'publication_year': None, 'abstract': None}
{'title': 'Simple and Fast Group Robustness by Automatic Feature Reweighting', 'paperID': '82701185d8873ff1a3cdfd59c99879a6e391faa1', 'arxivId': '2306.11074', 'publication_year': 2023, 'abstract': None}
{'title': 'Change is Hard: A Closer Look at Subpopulation Shift', 'paperID': '3ded0685b2330103336601df1f7cfaf5a7cbf9bf', 'arxivId': '2302.12254', 'publication_year': 2023, 'abstract': None}
{'title': 'Surgical Fine-Tuning Improves Adaptation to Distribution Shifts', 'paperID': '2fe24fa62c5d57c5bd4c93b25740d0779530987f', 'arxivId': '2210.11466', 'publication_year': 2022, 'abstract': None}
{'title': 'On Feature Learning in the Presence of Spurious Correlations', 'paperID': '13a8c23a09f0fb0b10f8b096025e1df4850cf853', 'arxivId': '2210.11369', 'publication_year': 2022, 'abstract': None}
{'title': 'Diversify and Disambiguate: Learning From Underspecified Data', 'paperID': 'fa21a215468e881820266d1df362340987bc3fa8', 'arxivId': '2202.03418', 'publication_year': 2022, 'abstract': None}
{'title': 'Controlling Directions Orthogonal to a Classifier', 'paperID': 'c2c26d7e6b3679cd0a48ca8eace3ffed24f273a3', 'arxivId': '2201.11259', 'publication_year': 2022, 'abstract': None}
{'title': 'A Comprehensive Study of Image Classification Model Sensitivity to Foregrounds, Backgrounds, and Visual Attributes', 'paperID': '88b5acbec09ed39eecdca136f75ff90feb2fc3a3', 'arxivId': '2201.10766', 'publication_year': 2022, 'abstract': None}
{'title': 'Optimal Representations for Covariate Shift', 'paperID': '5382d9bc17aabfd47b7c7d9873d2b64fdde48305', 'arxivId': '2201.00057', 'publication_year': 2021, 'abstract': None}
{'title': 'BARACK: Partially Supervised Group Robustness With Guarantees', 'paperID': '49750bf1dd5e66025c18adfce5ce7fef445fb9d4', 'arxivId': '2201.00072', 'publication_year': 2021, 'abstract': None}
{'title': 'Salient ImageNet: How to discover spurious features in Deep Learning?', 'paperID': '5f893ad86470cb935d702f980f5af8d8e013c7ae', 'arxivId': '2110.04301', 'publication_year': 2021, 'abstract': None}
{'title': 'Exploring the Limits of Large Scale Pre-training', 'paperID': 'c206a6e7f51f5e1b6bfc479a174b66ad88ada2db', 'arxivId': '2110.02095', 'publication_year': 2021, 'abstract': None}
{'title': 'On the Opportunities and Risks of Foundation Models', 'paperID': '4f68e07c6c3173480053fd52391851d6f80d651b', 'arxivId': '2108.07258', 'publication_year': 2021, 'abstract': None}
{'title': 'Learning Bias-Invariant Representation by Cross-Sample Mutual Information Minimization', 'paperID': 'af1809de802d36236fcc0e34d5359d544a14894e', 'arxivId': '2108.05449', 'publication_year': 2021, 'abstract': None}
{'title': 'Fast Adaptation with Linearized Neural Networks', 'paperID': '05f83f959f5b5f43d7168348328ee394656bbfbf', 'arxivId': '2103.01439', 'publication_year': 2021, 'abstract': None}
{'title': 'EnD: Entangling and Disentangling deep representations for bias correction', 'paperID': '3d8ff14c93a29f24d9dfb0cf908d9968d83126e4', 'arxivId': '2103.02023', 'publication_year': 2021, 'abstract': None}
{'title': 'Linear unit-tests for invariance discovery', 'paperID': 'a89b001c83fbc9c298e386e291c1a8e204d725be', 'arxivId': '2102.10867', 'publication_year': 2021, 'abstract': None}
{'title': 'Shape or Texture: Understanding Discriminative Features in CNNs', 'paperID': 'fa3d0599f8a082add349b5b09a208136489dae34', 'arxivId': '2101.11604', 'publication_year': 2021, 'abstract': None}
{'title': 'Explaining The Efficacy of Counterfactually-Augmented Data', 'paperID': '24fcdaf969089e6a411f7cebc9274bbc53c25e42', 'arxivId': '2010.02114', 'publication_year': 2020, 'abstract': None}
{'title': 'What is being transferred in transfer learning?', 'paperID': '5baa3e00d66bc42db7e3908f0b70875cff9d0193', 'arxivId': '2008.11687', 'publication_year': 2020, 'abstract': None}
{'title': 'Exploring Algorithmic Fairness in Robust Graph Covering Problems', 'paperID': '9086d3f7f1ddf0872a3850969b8cfaecacc0cc19', 'arxivId': '2006.06865', 'publication_year': 2020, 'abstract': None}
{'title': 'Unshuffling Data for Improved Generalization in Visual Question Answering', 'paperID': '55daceb1d28be049b457ec53bc3ffa582c021317', 'arxivId': '2002.11894', 'publication_year': 2020, 'abstract': None}
{'title': 'A Large-scale Study of Representation Learning with the Visual Task Adaptation Benchmark', 'paperID': '85b9e68eb27069e87181050035f40b79438dd220', 'arxivId': '1910.04867', 'publication_year': 2019, 'abstract': None}
{'title': 'SciPy 1.0: fundamental algorithms for scientific computing in Python', 'paperID': '854eca61a57d2c1ea1019663caf022bc8fd0b909', 'arxivId': None, 'publication_year': 2019, 'abstract': None}
{'title': 'Maximum Weighted Loss Discrepancy', 'paperID': '43238d6f4da1318fa8f7d2dcd27fe13abafe9556', 'arxivId': '1906.03518', 'publication_year': 2019, 'abstract': None}
{'title': 'REPAIR: Removing Representation Bias by Dataset Resampling', 'paperID': 'e91dca6e99f2d392953524986f2125be2008d9fc', 'arxivId': '1904.07911', 'publication_year': 2019, 'abstract': None}
{'title': 'Not Using the Car to See the Sidewalk — Quantifying and Controlling the Effects of Context in Classification and Segmentation', 'paperID': '8920c700e388a00c51bcd7ef6353c968cbf31e07', 'arxivId': '1812.06707', 'publication_year': 2018, 'abstract': None}
{'title': 'Strike (With) a Pose: Neural Networks Are Easily Fooled by Strange Poses of Familiar Objects', 'paperID': '207c073e427ff50b72a3f53975f5c6251551c4cb', 'arxivId': '1811.11553', 'publication_year': 2018, 'abstract': None}
{'title': 'RESOUND: Towards Action Recognition Without Representation Bias', 'paperID': '74c19438c78a136677a7cb9004c53684a4ae56ff', 'arxivId': None, 'publication_year': 2018, 'abstract': None}
{'title': 'On Fairness and Calibration', 'paperID': 'f4615ae853fa0e8effbc5b36f7455c43520345aa', 'arxivId': '1709.02012', 'publication_year': 2017, 'abstract': None}
{'title': 'What makes ImageNet good for transfer learning?', 'paperID': '540b5b4919d345e4da3cc4f3e8a7862329bf41a2', 'arxivId': '1608.08614', 'publication_year': 2016, 'abstract': None}
{'title': 'Improving Weakly-Supervised Object Localization By Micro-Annotation', 'paperID': 'df7a7f248621c16da71007ceba7088a97204f39b', 'arxivId': '1605.05538', 'publication_year': 2016, 'abstract': None}
{'title': 'Fast R-CNN', 'paperID': '7ffdbc358b63378f07311e883dddacc9faeeaf4b', 'arxivId': '1504.08083', 'publication_year': 2015, 'abstract': None}
{'title': 'Automated Experiments on Ad Privacy Settings', 'paperID': 'b5044cf4c9f06b51aebc526aef7afebac61e079b', 'arxivId': None, 'publication_year': 2015, 'abstract': None}
{'title': 'CNN Features Off-the-Shelf: An Astounding Baseline for Recognition', 'paperID': '6270baedeba28001cd1b563a199335720d6e0fe0', 'arxivId': '1403.6382', 'publication_year': 2014, 'abstract': None}
{'title': 'Torchvision the machine-vision package of torch', 'paperID': '41bebd1951e57588e7829e44fab1bac0cc9251d2', 'arxivId': None, 'publication_year': 2010, 'abstract': None}
{'title': 'Matplotlib: A 2D Graphics Environment', 'paperID': '412a0bb5a3baa91b62053d82c562bc172df0439f', 'arxivId': None, 'publication_year': 2007, 'abstract': None}
{'title': 'Local Features and Kernels for Classification of Texture and Object Categories: A Comprehensive Study', 'paperID': 'dee20a7ce7745fc367c8bc7ede4f7b8c22efa52d', 'arxivId': None, 'publication_year': 2006, 'abstract': None}
{'title': 'Increasing Robustness to Spurious Correlations using Forgettable Examples', 'paperID': '1f0e1657063ea38cf225eaf1c1187ae7b2e4a0e0', 'arxivId': None, 'publication_year': 2021, 'abstract': None}
{'title': 'Predicting Inductive Biases of Pre-Trained Models', 'paperID': 'a33b4a2002161a18bc7eb929566d77fd5178c2e9', 'arxivId': None, 'publication_year': 2021, 'abstract': None}
{'title': 'Jupyter Notebooks - a publishing format for reproducible computational workflows', 'paperID': 'e47868841d87efe261451a43b00d6c81cf7fb7a3', 'arxivId': None, 'publication_year': 2016, 'abstract': None}
{'title': 'The elephant in the room.', 'paperID': 'eeb85a8b6f6a8301f8d1de35af2533def4a57f30', 'arxivId': None, 'publication_year': 2013, 'abstract': None}
{'title': 'Data Structures for Statistical Computing in Python', 'paperID': 'f6dac1c52d3b07c993fe52513b8964f86e8fe381', 'arxivId': None, 'publication_year': 2010, 'abstract': None}
{'title': 'Local Features and Kernels for Classication of Texture and Object Categories: A Comprehensive Study', 'paperID': '423815a794503aa04a4418015baae83f09556ea3', 'arxivId': None, 'publication_year': 2006, 'abstract': None}
{'title': 'Certified Defences Against Adversarial Patch Attacks on Semantic Segmentation', 'paperID': '9cf8990a8b089059452cf59cc561d23b02611282', 'arxivId': '2209.05980', 'publication_year': 2022, 'abstract': None}
{'title': 'On Collective Robustness of Bagging Against Data Poisoning', 'paperID': '0802e293e297a8e3b97b2716ad3591b249a8f850', 'arxivId': '2205.13176', 'publication_year': 2022, 'abstract': None}
{'title': 'ANCER: Anisotropic Certification via Sample-wise Volume Maximization', 'paperID': 'ccae570e9a47227c4141dbc1469a555e5895137b', 'arxivId': '2107.04570', 'publication_year': 2021, 'abstract': None}
{'title': 'Scalable Certified Segmentation via Randomized Smoothing', 'paperID': '3836d46d72ab198b074ade63cec4b54f0b1c4ebe', 'arxivId': '2107.00228', 'publication_year': 2021, 'abstract': None}
{'title': 'Fast and precise certification of transformers', 'paperID': '7f26030dbdbbd398b3d79d2a09d1c6bea2a771bc', 'arxivId': None, 'publication_year': 2021, 'abstract': None}
{'title': 'SparseBERT: Rethinking the Importance Analysis in Self-attention', 'paperID': '4badd753be64c5c5b57dd2bb2e515fbe0c0720d8', 'arxivId': '2102.12871', 'publication_year': 2021, 'abstract': None}
{'title': 'Scalable Polyhedral Verification of Recurrent Neural Networks', 'paperID': '05a97b7215d65ed0a7c5aa513d73960f94d74646', 'arxivId': '2005.13300', 'publication_year': 2020, 'abstract': None}
{'title': '(De)Randomized Smoothing for Certifiable Defense against Patch Attacks', 'paperID': '944dded7fcd1bb055cbdf11575e3a2de0ab42886', 'arxivId': '2002.10733', 'publication_year': 2020, 'abstract': None}
{'title': 'Adversarial Attacks on Graph Neural Networks via Meta Learning', 'paperID': '6f5b1076ebacd30849d86e5f5787e3d43b65911f', 'arxivId': '1902.08412', 'publication_year': 2019, 'abstract': None}
{'title': 'Albumentations: fast and flexible image augmentations', 'paperID': '17555c227941654bc19d613742e2508f209c6d86', 'arxivId': '1809.06839', 'publication_year': 2018, 'abstract': None}
{'title': 'Understanding the effective receptive field in semantic image segmentation', 'paperID': 'c05733052172753c8736e07fa8004dbaacfb623d', 'arxivId': None, 'publication_year': 2018, 'abstract': None}
{'title': 'Rethinking Atrous Convolution for Semantic Image Segmentation', 'paperID': 'ee4a012a4b12d11d7ab8c0e79c61e807927a163c', 'arxivId': '1706.05587', 'publication_year': 2017, 'abstract': None}
{'title': 'Understanding the Effective Receptive Field in Deep Convolutional Neural Networks', 'paperID': '01a4f33da8ad94ced3cf58548b28dbbb44148571', 'arxivId': '1701.04128', 'publication_year': 2016, 'abstract': None}
{'title': 'Rényi divergence measures for commonly used univariate continuous distributions', 'paperID': 'a6cdbafcecbdea079d41f415ae43ef079fcf8156', 'arxivId': None, 'publication_year': 2013, 'abstract': None}
{'title': 'Semantic contours from inverse detectors', 'paperID': '82fae97673a353271b1d4c001afda1af6ef6dc23', 'arxivId': None, 'publication_year': 2011, 'abstract': None}
{'title': 'A Fast and High Quality Multilevel Scheme for Partitioning Irregular Graphs', 'paperID': 'df86d2a8c217776786bac9019d8b20029e4c0dd5', 'arxivId': None, 'publication_year': 1998, 'abstract': None}
{'title': 'CONFIDENCE LIMITS FOR THE EXPECTED VALUE OF AN ARBITRARY BOUNDED RANDOM VARIABLE WITH A CONTINUOUS DISTRIBUTION FUNCTION', 'paperID': 'ae256391cd1f68cbaeb2eccb4e06b3ccf1952aea', 'arxivId': None, 'publication_year': 1969, 'abstract': None}
{'title': 'Asymptotic Minimax Character of the Sample Distribution Function and of the Classical Multinomial Estimator', 'paperID': '00936a6bb9d35908640da9043b3f5a955014d478', 'arxivId': None, 'publication_year': 1956, 'abstract': None}
{'title': 'Teoria Statistica Delle Classi e Calcolo Delle Probabilità', 'paperID': '8e04c9530ea31889e2d351ae3cca4ddbb2bfac2d', 'arxivId': None, 'publication_year': 2022, 'abstract': None}
{'title': 'Center Smoothing: Provable Robustness for Functions with Metric-Space Outputs', 'paperID': '48601acaba95934762e6641f3b1c4237eed9c2bb', 'arxivId': None, 'publication_year': 2021, 'abstract': None}
{'title': 'Robustness Verification of Semantic Segmentation Neural Networks Using Relaxed Reachability', 'paperID': '43ba3e55d295d0312126c34bccfa70c5fa62d556', 'arxivId': None, 'publication_year': 2021, 'abstract': None}
{'title': 'Segmentation Models', 'paperID': '8e223217255892d660e7752eaf568f64bc2d6e71', 'arxivId': None, 'publication_year': 2016, 'abstract': None}
{'title': 'A Simple Sequentially Rejective Multiple Test Procedure', 'paperID': 'b0ebbcf713b3ddf3f94325bc58dc39ff76fdc412', 'arxivId': None, 'publication_year': 1979, 'abstract': None}
{'title': 'Localized Randomized Smoothing for Collective Robustness Certification', 'paperID': '7ee017cf2cbd83fe23f94280b0931bbf5416b1f0', 'arxivId': '2210.16140', 'publication_year': '2022', 'abstract': 'Models for image segmentation, node classification and many other tasks map a single input to multiple labels. By perturbing this single shared input (e.g. the image) an adversary can manipulate several predictions (e.g. misclassify several pixels). Collective robustness certification is the task of provably bounding the number of robust predictions under this threat model. The only dedicated method that goes beyond certifying each output independently is limited to strictly local models, where each prediction is associated with a small receptive field. We propose a more general collective robustness certificate for all types of models. We further show that this approach is beneficial for the larger class of softly local models, where each output is dependent on the entire input but assigns different levels of importance to different input regions (e.g. based on their proximity in the image). The certificate is based on our novel localized randomized smoothing approach, where the random perturbation strength for different input regions is proportional to their importance for the outputs. Localized smoothing Pareto-dominates existing certificates on both image segmentation and node classification tasks, simultaneously offering higher accuracy and stronger certificates.'}
{'title': 'Distributionally Robust Post-hoc Classifiers under Prior Shifts', 'paperID': 'e31b40fcb240a3b6d41890c6e30d8bd8556cdcf8', 'arxivId': None, 'publication_year': None, 'abstract': None}
{'title': 'On the Robustness of Deep Clustering Models: Adversarial Attacks and Defenses', 'paperID': '89e4b7ead1a64b75812b5c4eb9f979c555950ca8', 'arxivId': '2210.01940', 'publication_year': 2022, 'abstract': None}
{'title': 'Dynamic Hypergraph Convolutional Network', 'paperID': '0df18a7d6fab4d7598acdc0fab7c9c300f8d6c33', 'arxivId': None, 'publication_year': 2022, 'abstract': None}
{'title': 'Achieving Fairness at No Utility Cost via Data Reweighing', 'paperID': '1b20a501c60d83ad0001778d654f45a7a42441fd', 'arxivId': '2202.00787', 'publication_year': 2022, 'abstract': None}
{'title': 'Fairness Degrading Adversarial Attacks Against Clustering Algorithms', 'paperID': 'caeb2571671c50769610ba5b49a92b2f2b7bcd5c', 'arxivId': '2110.12020', 'publication_year': 2021, 'abstract': None}
{'title': 'Decoupled Representation Learning for Attributed Networks', 'paperID': '552d01b2a4e5f2308466485698e244ff00aa917e', 'arxivId': None, 'publication_year': 2021, 'abstract': None}
{'title': 'The Impact of Price Segmentation based on Customer Characteristics, Product Bundle or Product Features on Price Fairness Perceptions', 'paperID': 'f9018d184837ad055c8769376b199b57a911dfec', 'arxivId': None, 'publication_year': 2021, 'abstract': None}
{'title': 'Fair Classification with Adversarial Perturbations', 'paperID': 'dd2a44ced60bf871070c3381c73e8258f922bae8', 'arxivId': '2106.05964', 'publication_year': 2021, 'abstract': None}
{'title': 'Deep Clustering based Fair Outlier Detection', 'paperID': '575ea16c0ccee925498f8b7a022a635bcbf21e40', 'arxivId': '2106.05127', 'publication_year': 2021, 'abstract': None}
{'title': 'Graph-MLP: Node Classification without Message Passing in Graph', 'paperID': 'c48209be1906c7580b0cd0a2877daefdf7dba066', 'arxivId': '2106.04051', 'publication_year': 2021, 'abstract': None}
{'title': 'Fair Clustering Using Antidote Data', 'paperID': 'ff38ca20ae5cbbbc3b67063d00d9b55d67d331df', 'arxivId': '2106.00600', 'publication_year': 2021, 'abstract': None}
{'title': 'Deep Fair Discriminative Clustering', 'paperID': '76d8108855f30b8a66a84e65f9197592fcc3229e', 'arxivId': '2105.14146', 'publication_year': 2021, 'abstract': None}
{'title': 'Exacerbating Algorithmic Bias through Fairness Attacks', 'paperID': 'f29bb1e3f5e98a6887c2414a2036858a076a5915', 'arxivId': '2012.08723', 'publication_year': 2020, 'abstract': None}
{'title': 'KFC: A Scalable Approximation Algorithm for k-center Fair Clustering', 'paperID': 'a520622e874ac180e7ae838e613bad4b2c6aecbe', 'arxivId': '2010.13949', 'publication_year': 2020, 'abstract': None}
{'title': 'A Black-box Adversarial Attack for Poisoning Clustering', 'paperID': '713c1c77e7b87d6c191b49769888baa92adcbb23', 'arxivId': '2009.05474', 'publication_year': 2020, 'abstract': None}
{'title': 'Fair Classification with Noisy Protected Attributes: A Framework with Provable Guarantees', 'paperID': '4b09b2c7205369d7dde0899f025e1e05675d790f', 'arxivId': None, 'publication_year': 2020, 'abstract': None}
{'title': 'Deep Fair Clustering for Visual Learning', 'paperID': 'fd1201b44d28f6c2d722c8c4faada6bb82d79ebf', 'arxivId': None, 'publication_year': 2020, 'abstract': None}
{'title': 'Fair Algorithms for Hierarchical Agglomerative Clustering', 'paperID': '7acf5709973c1f28d6b93730e251b1cd6fd0cd97', 'arxivId': '2005.03197', 'publication_year': 2020, 'abstract': None}
{'title': 'Poisoning Attacks on Algorithmic Fairness', 'paperID': '905e690b6a77856f3b28e12b90a2d17810e48e64', 'arxivId': '2004.07401', 'publication_year': 2020, 'abstract': None}
{'title': 'Suspicion-Free Adversarial Attacks on Clustering Algorithms', 'paperID': '91f75567276b1b8f9a18abe27d99f24904bd5171', 'arxivId': '1911.07015', 'publication_year': 2019, 'abstract': None}
{'title': 'Fair Coresets and Streaming Algorithms for Fair k-means', 'paperID': 'e71908585cbad83a7dd1abde85b1575d2c6e6e6d', 'arxivId': None, 'publication_year': 2019, 'abstract': None}
{'title': 'Consensus Clustering: An Embedding Perspective, Extension and Beyond', 'paperID': 'b8436b9989c057ff3c6fec2f69011eacb97d1253', 'arxivId': '1906.00120', 'publication_year': 2019, 'abstract': None}
{'title': 'Scalable Fair Clustering', 'paperID': 'a377aa14e7f7f6c432edc0d8bdd695fb338f3fe2', 'arxivId': '1902.03519', 'publication_year': 2019, 'abstract': None}
{'title': 'Towards Fair Deep Clustering With Multi-State Protected Variables', 'paperID': '3a81f485ef485fa66ffb2c5fd8c35cd6313647ea', 'arxivId': '1901.10053', 'publication_year': 2019, 'abstract': None}
{'title': 'Landing on the right job : a machine learning approach to match candidates with jobs applying semantic embeddings', 'paperID': 'dea85076038fa212d94c6441225c2d6cd6f4a99f', 'arxivId': None, 'publication_year': 2019, 'abstract': None}
{'title': 'Guarantees for Spectral Clustering with Fairness Constraints', 'paperID': 'ec846f23a6b1588efaf18a82146dbde67bc332d8', 'arxivId': '1901.08668', 'publication_year': 2019, 'abstract': None}
{'title': 'Fair k-Center Clustering for Data Summarization', 'paperID': '9c26bbf34bdab544a000038d628a8fb232d60cb6', 'arxivId': '1901.08628', 'publication_year': 2019, 'abstract': None}
{'title': 'Fair Clustering Through Fairlets', 'paperID': '28f637cb5bf7c5bdbeb3317f563e48e95a27c92d', 'arxivId': '1802.05733', 'publication_year': 2018, 'abstract': None}
{'title': 'Gaussian Error Linear Units (GELUs)', 'paperID': 'de5e7320729f5d3cbb6709eb6329ec41ace8c95d', 'arxivId': '1606.08415', 'publication_year': 2016, 'abstract': None}
{'title': 'Derivative-Free Optimization via Classification', 'paperID': 'f9cda74ec68c52d68c6bf21399d6c0d6f14828e5', 'arxivId': None, 'publication_year': 2016, 'abstract': None}
{'title': 'Unsupervised Deep Embedding for Clustering Analysis', 'paperID': 'f44ff4fc0ed0142cb18472a5ba421bb538aa837e', 'arxivId': '1511.06335', 'publication_year': 2015, 'abstract': None}
{'title': 'Attacking DBSCAN for Fun and Profit', 'paperID': '9468a53d7314b16727956640f0d86a72a456d5bc', 'arxivId': None, 'publication_year': 2015, 'abstract': None}
{'title': 'Poisoning Complete-Linkage Hierarchical Clustering', 'paperID': 'dbe884a0fa006fa312883886aa59f961d0851127', 'arxivId': None, 'publication_year': 2014, 'abstract': None}
{'title': 'Big Data and Predictive Reasonable Suspicion', 'paperID': '98683d97b648182318944970464d8447264b29a3', 'arxivId': None, 'publication_year': 2014, 'abstract': None}
{'title': 'Is data clustering in adversarial settings secure?', 'paperID': 'c46ff777ade986eb56c57ae2e5d9a2039d4847ae', 'arxivId': '1811.09982', 'publication_year': 2013, 'abstract': None}
{'title': 'Probabilistic consensus clustering using evidence accumulation', 'paperID': '5359e752a33e9416209dccfd8c2415940a46d2df', 'arxivId': None, 'publication_year': 2013, 'abstract': None}
{'title': 'A Comparative Study of Efficient Initialization Methods for the K-Means Clustering Algorithm', 'paperID': 'a2986864eb361e4e66bd4c10f8fd3bf129408147', 'arxivId': '1209.1960', 'publication_year': 2012, 'abstract': None}
{'title': 'Adapting Visual Category Models to New Domains', 'paperID': '5d9a3036181676e187c9c0ff995d8bed1db3557d', 'arxivId': None, 'publication_year': 2010, 'abstract': None}
{'title': 'Credit rating by hybrid machine learning techniques', 'paperID': '2d9107e6dead98af2f3099618eb58767e7d4961a', 'arxivId': None, 'publication_year': 2010, 'abstract': None}
{'title': 'A tutorial on spectral clustering', 'paperID': 'eda90bd43f4256986688e525b45b833a3addab97', 'arxivId': '0711.0189', 'publication_year': 2007, 'abstract': None}
{'title': 'The Relationships Among Various Nonnegative Matrix Factorization Methods for Clustering', 'paperID': '12e46e8bebeb36875d19bc6d61cde3531bb39ca5', 'arxivId': None, 'publication_year': 2006, 'abstract': None}
{'title': 'Combining multiple clusterings using evidence accumulation', 'paperID': '5403a5c2839fad66e3f907518b11f41a56ec4e21', 'arxivId': None, 'publication_year': 2005, 'abstract': None}
{'title': 'Acquiring linear subspaces for face recognition under variable lighting', 'paperID': '7f5b5e5b70ef61b90a030dfc26815deb6846b57e', 'arxivId': None, 'publication_year': 2005, 'abstract': None}
{'title': 'Survey of clustering algorithms', 'paperID': '08b43d84e6747e370ef307e2ada50675b414514a', 'arxivId': None, 'publication_year': 2005, 'abstract': None}
{'title': 'Solving cluster ensemble problems by bipartite graph partitioning', 'paperID': 'b59a8bf45add9a7bae9e8c978862f8d3c1077b61', 'arxivId': None, 'publication_year': 2004, 'abstract': None}
{'title': 'Cluster Ensembles --- A Knowledge Reuse Framework for Combining Multiple Partitions', 'paperID': 'b8c282f76923d89e00dcd17ec425d496ade6ddc7', 'arxivId': None, 'publication_year': 2003, 'abstract': None}
{'title': 'A Density-Based Algorithm for Discovering Clusters in Large Spatial Databases with Noise', 'paperID': '5c8fe9a0412a078e30eb7e5eeb0068655b673e86', 'arxivId': None, 'publication_year': 1996, 'abstract': None}
{'title': 'Methods of combining multiple classifiers and their applications to handwriting recognition', 'paperID': 'ec25da04ef7f09396ca00da3f9b5f2d9670cb6fc', 'arxivId': None, 'publication_year': 1992, 'abstract': None}
{'title': 'Hierarchical optimization: An introduction', 'paperID': '65d68b7edb405a3681c412168cb28dafe3a3991f', 'arxivId': None, 'publication_year': 1992, 'abstract': None}
{'title': 'Computational Difficulties of Bilevel Linear Programming', 'paperID': 'cd3bd9ff2c8101b53069b7bef97117b9eb4cfcb7', 'arxivId': None, 'publication_year': 1990, 'abstract': None}
{'title': 'Least squares quantization in PCM', 'paperID': '9241ea3d8cb85633d314ecb74b31567b8e73f6af', 'arxivId': None, 'publication_year': 1982, 'abstract': None}
{'title': 'The Kolmogorov-Smirnov Test for Goodness of Fit', 'paperID': 'c57a214bfbaaf4b56844ccebf31694f3e2564829', 'arxivId': None, 'publication_year': 1951, 'abstract': None}
{'title': 'An Overview of Fairness in Clustering', 'paperID': '554b3fd2342476f46f4877fa235e7fb9bf67ec12', 'arxivId': None, 'publication_year': 2021, 'abstract': None}
{'title': 'A Machine Learning approach for automation of Resume Recommendation system', 'paperID': '392244f6c2edf5e157856e99ffdddb4b94eb6dd4', 'arxivId': None, 'publication_year': 2020, 'abstract': None}
{'title': 'A Mathematical Theory of Communication', 'paperID': '6d12a1d23b21a9b170118a56386552bc5d4727de', 'arxivId': None, 'publication_year': 2006, 'abstract': None}
{'title': 'Robust Fair Clustering: A Novel Fairness Attack and Defense Framework', 'paperID': '6545eebb1162c70751119e173f8d51f5c112fcc1', 'arxivId': '2210.01953', 'publication_year': '2022', 'abstract': 'Clustering algorithms are widely used in many societal resource allocation applications, such as loan approvals and candidate recruitment, among others, and hence, biased or unfair model outputs can adversely impact individuals that rely on these applications. To this end, many fair clustering approaches have been recently proposed to counteract this issue. Due to the potential for significant harm, it is essential to ensure that fair clustering algorithms provide consistently fair outputs even under adversarial influence. However, fair clustering algorithms have not been studied from an adversarial attack perspective. In contrast to previous research, we seek to bridge this gap and conduct a robustness analysis against fair clustering by proposing a novel black-box fairness attack. Through comprehensive experiments, we find that state-of-the-art models are highly susceptible to our attack as it can reduce their fairness performance significantly. Finally, we propose Consensus Fair Clustering (CFC), the first robust fair clustering approach that transforms consensus clustering into a fair graph partitioning problem, and iteratively learns to generate fair cluster outputs. Experimentally, we observe that CFC is highly robust to the proposed attack and is thus a truly robust fair clustering alternative.'}
{'title': 'Scaling Up Your Kernels to 31×31: Revisiting Large Kernel Design in CNNs', 'paperID': '9f1b0e4c42a5a85d4c023030557ade4419f82ecf', 'arxivId': '2203.06717', 'publication_year': 2022, 'abstract': None}
{'title': 'Patches Are All You Need?', 'paperID': '3425495ee3b6ead009f35aeb70edeac4e6eb2d10', 'arxivId': '2201.09792', 'publication_year': 2022, 'abstract': None}
{'title': 'RepMLPNet: Hierarchical Vision MLP with Re-parameterized Locality', 'paperID': '730a34374384f8abb886e464758b1a145edef938', 'arxivId': '2112.11081', 'publication_year': 2021, 'abstract': None}
{'title': 'iBOT: Image BERT Pre-Training with Online Tokenizer', 'paperID': '9653c070724e44f023e8cc3ec79f0b9e6d59480d', 'arxivId': '2111.07832', 'publication_year': 2021, 'abstract': None}
{'title': 'ResNet strikes back: An improved training procedure in timm', 'paperID': 'f454f6b5f2ca9749ddf442eb5134612ef7f758c1', 'arxivId': '2110.00476', 'publication_year': 2021, 'abstract': None}
{'title': 'Go Wider Instead of Deeper', 'paperID': 'ffcd58f453f207d48075627da011f62782334c8f', 'arxivId': '2107.11817', 'publication_year': 2021, 'abstract': None}
{'title': 'Scaling Vision Transformers', 'paperID': '2a805d0e1b067444a554c5169d189fa1f649f411', 'arxivId': '2106.04560', 'publication_year': 2021, 'abstract': None}
{'title': 'Going deeper with Image Transformers', 'paperID': 'b364cdb02d18b9d9a3c097f5ea446f7e9ab10325', 'arxivId': '2103.17239', 'publication_year': 2021, 'abstract': None}
{'title': 'High-Performance Large-Scale Image Recognition Without Normalization', 'paperID': 'c16835c8e535ebd9c10a550ca9455fe384a14449', 'arxivId': '2102.06171', 'publication_year': 2021, 'abstract': None}
{'title': 'Tokens-to-Token ViT: Training Vision Transformers from Scratch on ImageNet', 'paperID': 'dbe077f8521ecbe0a1477d6148c726d4f053d9c9', 'arxivId': '2101.11986', 'publication_year': 2021, 'abstract': None}
{'title': 'RepVGG: Making VGG-style ConvNets Great Again', 'paperID': '2b8088253e2378fce001a090fe923b81e8dedf25', 'arxivId': '2101.03697', 'publication_year': 2021, 'abstract': None}
{'title': 'Augment Your Batch: Improving Generalization Through Instance Repetition', 'paperID': '0cdd2925e62477be96b457b4ac778260e7d42c80', 'arxivId': None, 'publication_year': 2020, 'abstract': None}
{'title': 'RandAugment: Practical data augmentation with no separate search', 'paperID': 'dfa553707b215910f028d2a58ab79116626cc94a', 'arxivId': None, 'publication_year': 2019, 'abstract': None}
{'title': 'Benchmarking Neural Network Robustness to Common Corruptions and Surface Variations', 'paperID': 'a97bb99c1c70d3e0037c5cb66a4f19ce9cc4fb5f', 'arxivId': '1807.01697', 'publication_year': 2018, 'abstract': None}
{'title': 'Non-local Neural Networks', 'paperID': '8899094797e82c5c185a0893896320ef77f60e64', 'arxivId': '1711.07971', 'publication_year': 2017, 'abstract': None}
{'title': 'Comparison of Batch Normalization and Weight Normalization Algorithms for the Large-scale Image Classification', 'paperID': 'e4c31c4dc29fa4bedf2cec10b01f3678eadbef7a', 'arxivId': '1709.08145', 'publication_year': 2017, 'abstract': None}
{'title': 'MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications', 'paperID': '3647d6d0f151dc05626449ee09cc7bce55be497e', 'arxivId': '1704.04861', 'publication_year': 2017, 'abstract': None}
{'title': 'Deep Networks with Stochastic Depth', 'paperID': '51db1f3c8dfc7d4077da39c96bb90a6358128111', 'arxivId': '1603.09382', 'publication_year': 2016, 'abstract': None}
{'title': 'Improving Language Understanding by Generative Pre-Training', 'paperID': 'cd18800a0fe0b668a1cc19f2ec95b5003d0a5035', 'arxivId': None, 'publication_year': 2018, 'abstract': None}
{'title': 'Can CNNs Be More Robust Than Transformers?', 'paperID': 'fd4c076e0229ccd1a992cb89285d14fd4adcb7ad', 'arxivId': '2206.03452', 'publication_year': '2022', 'abstract': 'The recent success of Vision Transformers is shaking the long dominance of Convolutional Neural Networks (CNNs) in image recognition for a decade. Specifically, in terms of robustness on out-of-distribution samples, recent research finds that Transformers are inherently more robust than CNNs, regardless of different training setups. Moreover, it is believed that such superiority of Transformers should largely be credited to their self-attention-like architectures per se. In this paper, we question that belief by closely examining the design of Transformers. Our findings lead to three highly effective architecture designs for boosting robustness, yet simple enough to be implemented in several lines of code, namely a) patchifying input images, b) enlarging kernel size, and c) reducing activation layers and normalization layers. Bringing these components together, we are able to build pure CNN architectures without any attention-like operations that are as robust as, or even more robust than, Transformers. We hope this work can help the community better understand the design of robust neural architectures. The code is publicly available at https://github.com/UCSC-VLAA/RobustCNN.'}
{'title': 'CLINICAL: Targeted Active Learning for Imbalanced Medical Image Classification', 'paperID': '31ab0786652bc87fbd6ef7aacf41914ab278e7d9', 'arxivId': '2210.01520', 'publication_year': 2022, 'abstract': None}
{'title': 'More Data Can Lead Us Astray: Active Data Acquisition in the Presence of Label Bias', 'paperID': '666b2da70e774f06692d15470d0e30b8f8fe1fdc', 'arxivId': '2207.07723', 'publication_year': 2022, 'abstract': None}
{'title': 'Bias Mitigation for Machine Learning Classifiers: A Comprehensive Survey', 'paperID': '002040f8c411fc4a077a0f9a726f80e95509a388', 'arxivId': '2207.07068', 'publication_year': 2022, 'abstract': None}
{'title': 'Learning Debiased Classifier with Biased Committee', 'paperID': '8e31ce148dc7abee1a9790b3897942740aca0da2', 'arxivId': '2206.10843', 'publication_year': 2022, 'abstract': None}
{'title': 'Revisiting the Importance of Amplifying Bias for Debiasing', 'paperID': '76a4272b3008ebeb66631681da2a6b9f77d0b6c8', 'arxivId': '2205.14594', 'publication_year': 2022, 'abstract': None}
{'title': 'Fair Representation Learning through Implicit Path Alignment', 'paperID': '0f0a396d0479c98fece998077f0ea285791c6470', 'arxivId': '2205.13316', 'publication_year': 2022, 'abstract': None}
{'title': 'Conditional Supervised Contrastive Learning for Fair Text Classification', 'paperID': '992a067ef40893607dfc5a412265bf70c4804952', 'arxivId': '2205.11485', 'publication_year': 2022, 'abstract': None}
{'title': 'A Simple Approach to Improve Single-Model Deep Uncertainty via Distance-Awareness', 'paperID': '60f2ae3b448b035e957603e84d1a073ad708879b', 'arxivId': '2205.00403', 'publication_year': 2022, 'abstract': None}
{'title': 'Fair Contrastive Learning for Facial Attribute Classification', 'paperID': '0df927c8bfb175c0c8e20de2cd6c11f48e648be4', 'arxivId': '2203.16209', 'publication_year': 2022, 'abstract': None}
{'title': 'Conditional Contrastive Learning with Kernel', 'paperID': '9e9dc4b54b20882f871cf3b1438df33162bb5414', 'arxivId': '2202.05458', 'publication_year': 2022, 'abstract': None}
{'title': 'Adaptive Sampling Strategies to Construct Equitable Training Datasets', 'paperID': '4e23bcd3791b3130c54bf2be420f45ed1365df51', 'arxivId': '2202.01327', 'publication_year': 2022, 'abstract': None}
{'title': 'Simple and near-optimal algorithms for hidden stratification and multi-group learning', 'paperID': 'c8847713b5beb84bd152d59735100df5a0ac6c36', 'arxivId': '2112.12181', 'publication_year': 2021, 'abstract': None}
{'title': 'Active Learning for Domain Adaptation: An Energy-based Approach', 'paperID': '0282c031d07bf12d807392601371af86a56cce27', 'arxivId': '2112.01406', 'publication_year': 2021, 'abstract': None}
{'title': 'Does Data Repair Lead to Fair Models? Curating Contextually Fair Data To Reduce Model Bias', 'paperID': 'a5c7bd7ccd2e3db114dd467304eb4e6e928c0ef8', 'arxivId': '2110.10389', 'publication_year': 2021, 'abstract': None}
{'title': 'A survey on datasets for fairness‐aware machine learning', 'paperID': '04eab1a82321aa8c4a1e6f66367ce333183f25bc', 'arxivId': '2110.00530', 'publication_year': 2021, 'abstract': None}
{'title': 'Contrastive Learning for Fair Representations', 'paperID': '92e7aea7704fb1daf2f733bdfecfd523ebd3c034', 'arxivId': '2109.10645', 'publication_year': 2021, 'abstract': None}
{'title': 'On the Impact of Spurious Correlation for Out-of-distribution Detection', 'paperID': 'a98cc4d37b0af9be710c5b6f4a3579331e6fcfbe', 'arxivId': '2109.05642', 'publication_year': 2021, 'abstract': None}
{'title': 'Minimax Group Fairness: Algorithms and Experiments', 'paperID': '9490bc8ae617d9816326ef759bc1efccdafd9553', 'arxivId': None, 'publication_year': 2021, 'abstract': None}
{'title': 'Learning Debiased Representation via Disentangled Feature Augmentation', 'paperID': '93f9a75dc212ce2180b295b5d3feae112bfb5c41', 'arxivId': '2107.01372', 'publication_year': 2021, 'abstract': None}
{'title': 'Fairness via Representation Neutralization', 'paperID': '4c2e9b401e6fe3b3b81799ae0837048fccaef0a6', 'arxivId': '2106.12674', 'publication_year': 2021, 'abstract': None}
{'title': 'Low Budget Active Learning via Wasserstein Distance: An Integer Programming Approach', 'paperID': '1ec19d5a07f7baa20c0d68ee53d290bf88b9dc23', 'arxivId': '2106.02968', 'publication_year': 2021, 'abstract': None}
{'title': 'Correlated Input-Dependent Label Noise in Large-Scale Image Classification', 'paperID': '6ac8e0915df41692bdceef7f18bc1c50271630fc', 'arxivId': '2105.10305', 'publication_year': 2021, 'abstract': None}
{'title': 'What Are Bayesian Neural Network Posteriors Really Like?', 'paperID': '26190ccd4753d6c0d25499ea34475205ebdd8240', 'arxivId': '2104.14421', 'publication_year': 2021, 'abstract': None}
{'title': 'Can Active Learning Preemptively Mitigate Fairness Issues?', 'paperID': 'de4904d2b2c0f460db7595cdfee394dd3d13b7a7', 'arxivId': '2104.06879', 'publication_year': 2021, 'abstract': None}
{'title': 'FairFil: Contrastive Neural Debiasing Method for Pretrained Text Encoders', 'paperID': 'df157cb42b574c3f46b269504c18375bfa5bc5b1', 'arxivId': '2103.06413', 'publication_year': 2021, 'abstract': None}
{'title': 'Discrepancy-Based Active Learning for Domain Adaptation', 'paperID': '6d49abd4a9d563e6cf86ae5e2a808ecd4d67c3fa', 'arxivId': '2103.03757', 'publication_year': 2021, 'abstract': None}
{'title': 'Representation Matters: Assessing the Importance of Subgroup Allocations in Training Data', 'paperID': '6d0c2163b0e7de19d3dbed2ce8a2b546f4293b91', 'arxivId': '2103.03399', 'publication_year': 2021, 'abstract': None}
{'title': 'Out of Distribution Generalization in Machine Learning', 'paperID': '6dd17c6354e10f437f5b8ade2aff6bec3934629f', 'arxivId': '2103.02667', 'publication_year': 2021, 'abstract': None}
{'title': 'On Feature Collapse and Deep Kernel Learning for Single Forward Pass Uncertainty', 'paperID': '58de6cf06651017fba729cfbc37ed28ab2eaf507', 'arxivId': '2102.11409', 'publication_year': 2021, 'abstract': None}
{'title': 'Technical Challenges for Training Fair Neural Networks', 'paperID': 'c046a2f2498cca557c5d9353fae7d35331bef599', 'arxivId': '2102.06764', 'publication_year': 2021, 'abstract': None}
{'title': 'On Statistical Bias In Active Learning: How and When To Fix It', 'paperID': '1920ed0e7799410009d11cd7584550b9a57d5c93', 'arxivId': '2101.11665', 'publication_year': 2021, 'abstract': None}
{'title': 'Controllable Guarantees for Fair Outcomes via Contrastive Information Estimation', 'paperID': 'b74c5b7c97ded089caa481964207ba5e0e65b659', 'arxivId': '2101.04108', 'publication_year': 2021, 'abstract': None}
{'title': 'FAIR: Fair Adversarial Instance Re-weighting', 'paperID': 'c9367b790869e1f285ace7a2d64e7c4df439104b', 'arxivId': '2011.07495', 'publication_year': 2020, 'abstract': None}
{'title': 'Understanding Double Descent Requires a Fine-Grained Bias-Variance Decomposition', 'paperID': '9242df9324089bd9c511211fd3f4a846d5af83e1', 'arxivId': '2011.03321', 'publication_year': 2020, 'abstract': None}
{'title': 'A Survey of Deep Active Learning', 'paperID': '94eb8e46767ae77e265b0a20dcc0d9f69d2d6e2b', 'arxivId': '2009.00236', 'publication_year': 2020, 'abstract': None}
{'title': 'What Neural Networks Memorize and Why: Discovering the Long Tail via Influence Estimation', 'paperID': '9f7e317c6ef0bb15aacc9b19f0f0d00fee6c9a36', 'arxivId': None, 'publication_year': 2020, 'abstract': None}
{'title': 'Cross-validation Confidence Intervals for Test Error', 'paperID': '9e075fd385f24434b1235d33bb9be12125046612', 'arxivId': '2007.12671', 'publication_year': 2020, 'abstract': None}
{'title': 'Promoting Fairness in Learned Models by Learning to Active Learn under Parity Constraints', 'paperID': '6d0552d5bed08b535001b4bc1cb2b9bf917ee99d', 'arxivId': None, 'publication_year': 2020, 'abstract': None}
{'title': 'Minimax Pareto Fairness: A Multi Objective Perspective', 'paperID': 'b99bd19bed56de300dfa241b9698a35e95b95925', 'arxivId': '2011.01821', 'publication_year': 2020, 'abstract': None}
{'title': 'Active Sampling for Min-Max Fairness', 'paperID': '8ab4fd2c96e422acabc584774708d773009af8fb', 'arxivId': '2006.06879', 'publication_year': 2020, 'abstract': None}
{'title': 'Mind the Trade-off: Debiasing NLU Models without Degrading the In-distribution Performance', 'paperID': '939c1554d7c8456e1a03c38be5b2cb225dd26128', 'arxivId': '2005.00315', 'publication_year': 2020, 'abstract': None}
{'title': 'Learning Unbiased Representations via Mutual Information Backpropagation', 'paperID': '4c6207a203bcc7b725c41ed9c7451041530bf556', 'arxivId': '2003.06430', 'publication_year': 2020, 'abstract': None}
{'title': 'Equalization Loss for Long-Tailed Object Recognition', 'paperID': '6b7fac87b4ef98eceabfc47fd00a7190b1a48900', 'arxivId': '2003.05176', 'publication_year': 2020, 'abstract': None}
{'title': 'Slice Tuner: A Selective Data Acquisition Framework for Accurate and Fair Machine Learning Models', 'paperID': '21207fbe0431c6ca971af74d5fc7fe7fdaddeef4', 'arxivId': '2003.04549', 'publication_year': 2020, 'abstract': None}
{'title': 'Bayesian Deep Learning and a Probabilistic Perspective of Generalization', 'paperID': 'af9280741ef627f0d6c8437605d002d3bfc2d1b1', 'arxivId': '2002.08791', 'publication_year': 2020, 'abstract': None}
{'title': 'How Good is the Bayes Posterior in Deep Neural Networks Really?', 'paperID': '4d8e5ea39213287d36889d9b791e6fb13313cc5e', 'arxivId': '2002.02405', 'publication_year': 2020, 'abstract': None}
{'title': 'Fair Active Learning', 'paperID': '525cd3354a54aa9fad67c8cb91a30c7ef9e1c9dd', 'arxivId': '2006.13025', 'publication_year': 2020, 'abstract': None}
{'title': 'Deep Active Learning: Unified and Principled Method for Query and Training', 'paperID': '632bcd5842e9d11a0ad414911c4571030c0bb529', 'arxivId': '1911.09162', 'publication_year': 2019, 'abstract': None}
{'title': 'Prestopping: How Does Early Stopping Help Generalization against Label Noise?', 'paperID': '2700e81e00e241eba83ed9f73866e4ad7b0a60df', 'arxivId': '1911.08059', 'publication_year': 2019, 'abstract': None}
{'title': 'Don’t Take the Easy Way Out: Ensemble Based Methods for Avoiding Known Dataset Biases', 'paperID': 'ba783d92d0eaf6a7bff6ced7660150ce38016bbc', 'arxivId': '1909.03683', 'publication_year': 2019, 'abstract': None}
{'title': 'BatchBALD: Efficient and Diverse Batch Acquisition for Deep Bayesian Active Learning', 'paperID': 'ad3a75fa2a26e6f69b7059466828f49492d31789', 'arxivId': '1906.08158', 'publication_year': 2019, 'abstract': None}
{'title': 'Inherent Tradeoffs in Learning Fair Representation', 'paperID': 'c2c9d0c59433102625ee4889a3e99e8710616182', 'arxivId': '1906.08386', 'publication_year': 2019, 'abstract': None}
{'title': 'Deep Batch Active Learning by Diverse, Uncertain Gradient Lower Bounds', 'paperID': 'cf5a21684aefb1b8db6e0490167636d245396095', 'arxivId': '1906.03671', 'publication_year': 2019, 'abstract': None}
{'title': 'On the Fairness of Disentangled Representations', 'paperID': 'b25a30451518d372817967a72e125d638c85379e', 'arxivId': '1905.13662', 'publication_year': 2019, 'abstract': None}
{'title': 'Uncovering and Mitigating Algorithmic Bias through Learned Latent Structure', 'paperID': 'f471c7693e6f25f11bb5550a25ea1ca1e5367b5d', 'arxivId': None, 'publication_year': 2019, 'abstract': None}
{'title': 'Why Is My Classifier Discriminatory?', 'paperID': 'fd674e10770eb72e66a20e1c752c62dc7c12c0a4', 'arxivId': '1805.12002', 'publication_year': 2018, 'abstract': None}
{'title': 'Deep Bayesian Active Learning with Image Data', 'paperID': 'da5c65b0ac8b525c3d3d4889bf44d8a48d254a07', 'arxivId': '1703.02910', 'publication_year': 2017, 'abstract': None}
{'title': 'Unsupervised Feature Extraction by Time-Contrastive Learning and Nonlinear ICA', 'paperID': '3ad068ebde8f1d3a450a8c7e64a3428507bc2f51', 'arxivId': '1605.06336', 'publication_year': 2016, 'abstract': None}
{'title': 'Deep Kernel Learning', 'paperID': '34ab95637e7723302058f6526e33dc73857b9af2', 'arxivId': '1511.02222', 'publication_year': 2015, 'abstract': None}
{'title': 'Capturing Long-Tail Distributions of Object Subcategories', 'paperID': '45510f80bf9654e186e0ecab7c33daaf0b317d72', 'arxivId': None, 'publication_year': 2014, 'abstract': None}
{'title': 'Active Transfer Learning under Model Shift', 'paperID': '90c721be4aab0aa786479a3693ab0f59af2bce96', 'arxivId': None, 'publication_year': 2014, 'abstract': None}
{'title': 'Near-Optimal Bounds for Cross-Validation via Loss Stability', 'paperID': '26efc762637b8dfe610717bea63a12be41aa80ba', 'arxivId': None, 'publication_year': 2013, 'abstract': None}
{'title': 'Density Ratio Estimation : A Comprehensive Review (Statistical Experiment and Its Related Topics)', 'paperID': 'ca79ac12b64160f0bb30436fcb50b79df2052ddf', 'arxivId': None, 'publication_year': 2010, 'abstract': None}
{'title': 'Domain Adaptation meets Active Learning', 'paperID': '06935a5c7b5a592e960f7bbac739750d8ebdcf01', 'arxivId': None, 'publication_year': 2010, 'abstract': None}
{'title': 'Noise-contrastive estimation: A new estimation principle for unnormalized statistical models', 'paperID': 'e3ce36b9deb47aa6bb2aa19c4bfa71283b505025', 'arxivId': None, 'publication_year': 2010, 'abstract': None}
{'title': 'Disparities in health care are driven by where minority patients seek care: examination of the hospital quality alliance measures.', 'paperID': '2a2a12fc95c43363afff53d13963cbeeeaa69ad8', 'arxivId': None, 'publication_year': 2007, 'abstract': None}
{'title': 'Beating the hold-out: bounds for K-fold and progressive cross-validation', 'paperID': 'db3497b66b1c6f3f5537b3275c98e4475b6638cd', 'arxivId': None, 'publication_year': 1999, 'abstract': None}
{'title': 'A Theory of Justice', 'paperID': '40b949055cb08461ecce261d2bd365e77b41f22e', 'arxivId': None, 'publication_year': 1971, 'abstract': None}
{'title': 'On Distributionally Robust Optimization and Data Rebalancing', 'paperID': '413dbf16b13ea10b6b02d4b8b7d89d44574dc6d2', 'arxivId': None, 'publication_year': 2022, 'abstract': None}
{'title': 'Evaluating and Improving Robustness of Self-Supervised Representations to Spurious Correlations', 'paperID': '02a0e07b73d34d057151a7aa716858222e8d4cef', 'arxivId': None, 'publication_year': 2022, 'abstract': None}
{'title': 'Uncertainty Estimation Using a Single Deep Deterministic Neural Network-ML Reproducibility Challenge 2020', 'paperID': '67a6db6990b06b00eb4f67b1efbb8961c74be54c', 'arxivId': None, 'publication_year': 2021, 'abstract': None}
{'title': 'Learning Debiased Models with Dynamic Gradient Alignment and Bias-conflicting Sample Mining', 'paperID': '63f453bb7bed011e054cb5120c9dc21142a317cc', 'arxivId': None, 'publication_year': 2021, 'abstract': None}
{'title': 'Conditional Contrastive Learning: Removing Undesirable Information in Self-Supervised Representations', 'paperID': 'c03a3dc40550a8075d233a827fd184d62b93b274', 'arxivId': None, 'publication_year': 2021, 'abstract': None}
{'title': 'Justice as Fairness: A Restatement', 'paperID': '6bb0714bb12ea3ca708426f0d7d567a5d84ead42', 'arxivId': None, 'publication_year': 2001, 'abstract': None}
{'title': 'A Unified Bias-Variance Decomposition and its Applications', 'paperID': 'e1ed9d24db5e8f7ab326aeb797e965a94f5ad6d3', 'arxivId': None, 'publication_year': 2000, 'abstract': None}
{'title': 'Introduction to Probability', 'paperID': '5f4469e2cdcbd0994ca793bf899d59be6b44bb88', 'arxivId': None, 'publication_year': 1997, 'abstract': None}
{'title': 'Pushing the Accuracy-Group Robustness Frontier with Introspective Self-play', 'paperID': 'b1ab0635586fc7677f9a54590e56dcb0717db664', 'arxivId': '2302.05807', 'publication_year': '2023', 'abstract': 'Standard empirical risk minimization (ERM) training can produce deep neural network (DNN) models that are accurate on average but under-perform in under-represented population subgroups, especially when there are imbalanced group distributions in the long-tailed training data. Therefore, approaches that improve the accuracy-group robustness trade-off frontier of a DNN model (i.e. improving worst-group accuracy without sacrificing average accuracy, or vice versa) is of crucial importance. Uncertainty-based active learning (AL) can potentially improve the frontier by preferentially sampling underrepresented subgroups to create a more balanced training dataset. However, the quality of uncertainty estimates from modern DNNs tend to degrade in the presence of spurious correlations and dataset bias, compromising the effectiveness of AL for sampling tail groups. In this work, we propose Introspective Self-play (ISP), a simple approach to improve the uncertainty estimation of a deep neural network under dataset bias, by adding an auxiliary introspection task requiring a model to predict the bias for each data point in addition to the label. We show that ISP provably improves the bias-awareness of the model representation and the resulting uncertainty estimates. On two real-world tabular and language tasks, ISP serves as a simple"plug-in"for AL model training, consistently improving both the tail-group sampling rate and the final accuracy-fairness trade-off frontier of popular AL methods.'}
{'title': 'Adversarial Robust Deep Reinforcement Learning Requires Redefining Robustness', 'paperID': '6143e809cd2e9c7a18c3bc8819419fd3b02fbcf2', 'arxivId': '2301.07487', 'publication_year': 2023, 'abstract': None}
{'title': 'Efficient Adversarial Training without Attacking: Worst-Case-Aware Robust Reinforcement Learning', 'paperID': '2c988d25233d41a1535e54dc0f3cfc9f52ef2c83', 'arxivId': '2210.05927', 'publication_year': 2022, 'abstract': None}
{'title': 'Efficient Off-Policy Safe Reinforcement Learning Using Trust Region Conditional Value At Risk', 'paperID': '6ffa21166c99b1156612ba831ef0e5f7755ee6b3', 'arxivId': None, 'publication_year': 2022, 'abstract': None}
{'title': 'A Review of Safe Reinforcement Learning: Methods, Theory and Applications', 'paperID': '9c5f056c4e7986064722bb522e46e3546be8da51', 'arxivId': '2205.10330', 'publication_year': 2022, 'abstract': None}
{'title': 'SAAC: Safe Reinforcement Learning as an Adversarial Game of Actor-Critics', 'paperID': '81bbf1bccd16e145ae3933e829aa41d2c8f7faa8', 'arxivId': '2204.09424', 'publication_year': 2022, 'abstract': None}
{'title': 'Robust Reinforcement Learning: A Review of Foundations and Recent Advances', 'paperID': '04f63c8e5067a0e4ffce5eb4e11d25674728f230', 'arxivId': None, 'publication_year': 2022, 'abstract': None}
{'title': 'Robust Reinforcement Learning as a Stackelberg Game via Adaptively-Regularized Adversarial Training', 'paperID': 'ccd7398564a9bdf29564a7f39ac18dbe1a31d65e', 'arxivId': '2202.09514', 'publication_year': 2022, 'abstract': None}
{'title': 'SAUTE RL: Almost Surely Safe Reinforcement Learning Using State Augmentation', 'paperID': 'fda6c22149d269cb2730e919ed4254a5a5f84ae0', 'arxivId': '2202.06558', 'publication_year': 2022, 'abstract': None}
{'title': 'Constrained Variational Policy Optimization for Safe Reinforcement Learning', 'paperID': '4b89f78987e5d0dba67a4f533945a838a5428ed9', 'arxivId': '2201.11927', 'publication_year': 2022, 'abstract': None}
{'title': 'Towards Safe Reinforcement Learning with a Safety Editor Policy', 'paperID': '0ba7f2e592dda172bc3d07f88cdcf2a57830deec', 'arxivId': '2201.12427', 'publication_year': 2022, 'abstract': None}
{'title': 'Constrained Policy Optimization via Bayesian World Models', 'paperID': 'f1e48bfb4464fedb94ced2d85b74991efcfe2856', 'arxivId': '2201.09802', 'publication_year': 2022, 'abstract': None}
{'title': 'Deep Reinforcement Learning Policies Learn Shared Adversarial Features Across MDPs', 'paperID': '186cabbc394c560a458f94bf4317a5517edd8041', 'arxivId': '2112.09025', 'publication_year': 2021, 'abstract': None}
{'title': 'Multi-Agent Constrained Policy Optimisation', 'paperID': '5ddd0b5f141d3bfb14f5fee56c21608700095844', 'arxivId': '2110.02793', 'publication_year': 2021, 'abstract': None}
{'title': 'Safe Learning in Robotics: From Learning-Based Control to Safe Reinforcement Learning', 'paperID': 'd6e783bce3b8e3ad082c2757235c34cb86c4e653', 'arxivId': '2108.06266', 'publication_year': 2021, 'abstract': None}
{'title': 'Learning Barrier Certificates: Towards Safe Reinforcement Learning with Zero Training-time Violations', 'paperID': '36d55c909e8c1be84f3a4f2631e3303ef5392fb0', 'arxivId': '2108.01846', 'publication_year': 2021, 'abstract': None}
{'title': 'WCSAC: Worst-Case Soft Actor Critic for Safety-Constrained Reinforcement Learning', 'paperID': '5b2370ebd3439ff60ea64a0c8db88fea2dd86a9c', 'arxivId': None, 'publication_year': 2021, 'abstract': None}
{'title': 'Context-Aware Safe Reinforcement Learning for Non-Stationary Environments', 'paperID': '815bf97b451396313824f22becf5a4db315667bc', 'arxivId': '2101.00531', 'publication_year': 2021, 'abstract': None}
{'title': 'First Order Constrained Optimization in Policy Space', 'paperID': '19e4e04e9c48bc86ddd849abdda2ec305c060694', 'arxivId': None, 'publication_year': 2020, 'abstract': None}
{'title': 'Safe Model-based Reinforcement Learning with Robust Cross-Entropy Method', 'paperID': '94b8ba09835f93fecf57d1fc3fd65181f7fc860e', 'arxivId': '2010.07968', 'publication_year': 2020, 'abstract': None}
{'title': 'Adversarial Machine Learning in Image Classification: A Survey Toward the Defender’s Perspective', 'paperID': 'c5de8b8d1ca58bca4f6edf4238bfb5c4332ed598', 'arxivId': '2009.03728', 'publication_year': 2020, 'abstract': None}
{'title': 'Responsive Safety in Reinforcement Learning by PID Lagrangian Methods', 'paperID': '629d0ce250581471f07083bbab95f23623b00201', 'arxivId': '2007.03964', 'publication_year': 2020, 'abstract': None}
{'title': 'Model-based Adversarial Meta-Reinforcement Learning', 'paperID': '638538253332ebeba83f8de1d66f1eb4d2fe61b5', 'arxivId': '2006.08875', 'publication_year': 2020, 'abstract': None}
{'title': 'Automatic Curriculum Learning For Deep RL: A Short Survey', 'paperID': '60a5be13ba59e21e4b8f335b3bcc341d93d8deea', 'arxivId': '2003.04664', 'publication_year': 2020, 'abstract': None}
{'title': 'Constrained Reinforcement Learning Has Zero Duality Gap', 'paperID': 'c919ae4366f5cc4901b854cc259101ccc13e6f3f', 'arxivId': '1910.13393', 'publication_year': 2019, 'abstract': None}
{'title': 'Convergent Policy Optimization for Safe Reinforcement Learning', 'paperID': 'bdf18bbec0980448b879df417e3141dc901f2e68', 'arxivId': '1910.12156', 'publication_year': 2019, 'abstract': None}
{'title': 'A taxonomy and survey of attacks against machine learning', 'paperID': '893aba1e37804bf6878d3966dee747b42352ff09', 'arxivId': None, 'publication_year': 2019, 'abstract': None}
{'title': 'DAC: The Double Actor-Critic Architecture for Learning Options', 'paperID': '5c0d2e9caa303c51920c3d85e3acf4a64ca94414', 'arxivId': '1904.12691', 'publication_year': 2019, 'abstract': None}
{'title': 'Learning Abstract Options', 'paperID': '51e7b68ca6f78e4a212af7c1d0c44382b38b9a85', 'arxivId': '1810.11583', 'publication_year': 2018, 'abstract': None}
{'title': 'Domain Randomization for Simulation-Based Policy Optimization with Transferability Assessment', 'paperID': '4ec94d6968bcb0a030a658d7347ce15e64588528', 'arxivId': None, 'publication_year': 2018, 'abstract': None}
{'title': 'Reinforcement Learning with Perturbed Rewards', 'paperID': '13481ca12437363220282e3255eab109f0eeebcc', 'arxivId': '1810.01032', 'publication_year': 2018, 'abstract': None}
{'title': 'Reward Constrained Policy Optimization', 'paperID': 'cb7c479a36520da1caeeec67db10772351a390c6', 'arxivId': '1805.11074', 'publication_year': 2018, 'abstract': None}
{'title': 'Accelerated Primal-Dual Policy Optimization for Safe Reinforcement Learning', 'paperID': '18d43061bef62bace6b738fed3b1c44eea2d2147', 'arxivId': '1802.06480', 'publication_year': 2018, 'abstract': None}
{'title': 'Safe Exploration in Continuous Action Spaces', 'paperID': '7f567df97dc7e099d96e6c590ddf5aef8c5b11c4', 'arxivId': '1801.08757', 'publication_year': 2018, 'abstract': None}
{'title': 'Mastering the game of Go without human knowledge', 'paperID': 'c27db32efa8137cbf654902f8f728f338e55cd1c', 'arxivId': None, 'publication_year': 2017, 'abstract': None}
{'title': 'Safe Reinforcement Learning via Shielding', 'paperID': 'e4b4066e46fd160cb84e246b0895a4cd674d8ce4', 'arxivId': '1708.08611', 'publication_year': 2017, 'abstract': None}
{'title': 'Trial without Error: Towards Safe Reinforcement Learning via Human Intervention', 'paperID': '30ff82cebce6fdc2957043c4085a426414474d78', 'arxivId': '1707.05173', 'publication_year': 2017, 'abstract': None}
{'title': 'Accessorize to a Crime: Real and Stealthy Attacks on State-of-the-Art Face Recognition', 'paperID': '7f57e9939560562727344c1c987416285ef76cda', 'arxivId': None, 'publication_year': 2016, 'abstract': None}
{'title': 'Improved Techniques for Training GANs', 'paperID': '571b0750085ae3d939525e62af510ee2cee9d5ea', 'arxivId': '1606.03498', 'publication_year': 2016, 'abstract': None}
{'title': 'Safe and Efficient Off-Policy Reinforcement Learning', 'paperID': 'dc3e905bfb27d21675ee1720413e007b014b37d3', 'arxivId': '1606.02647', 'publication_year': 2016, 'abstract': None}
{'title': 'Reinforcement Learning in Robust Markov Decision Processes', 'paperID': 'e201e95b88a230c5d57a71bcd62b6307bfa11c1b', 'arxivId': None, 'publication_year': 2013, 'abstract': None}
{'title': 'An Online Actor–Critic Algorithm with Function Approximation for Constrained Markov Decision Processes', 'paperID': 'f332ecd5d54adf0530a39dae189cf6b160ad5c0e', 'arxivId': None, 'publication_year': 2012, 'abstract': None}
{'title': 'Distributionally Robust Markov Decision Processes', 'paperID': '9b99be8b739fe944d32724ab1eb656f832e8b618', 'arxivId': None, 'publication_year': 2010, 'abstract': None}
{'title': 'Constrained Markov decision processes with total cost criteria: Lagrangian approach and dual linear program', 'paperID': '6e986e365597a6e812298d7d86b0c7f220a2f01a', 'arxivId': None, 'publication_year': 1998, 'abstract': None}
{'title': 'A theorem on contraction mappings', 'paperID': '01b723087df56234645a7330ab838345c86cdc18', 'arxivId': None, 'publication_year': 1969, 'abstract': None}
{'title': 'Enhancing Safe Exploration Using Safety State Augmentation', 'paperID': 'a4a7d8716a0b541028bf702d5fb86d027bb9fceb', 'arxivId': None, 'publication_year': 2022, 'abstract': None}
{'title': 'Model-free Safe Control for Zero-Violation Reinforcement Learning', 'paperID': '3be5199010012448af287767297d81aa4a87567c', 'arxivId': None, 'publication_year': 2021, 'abstract': None}
{'title': 'Benchmarking Safe Exploration in Deep Reinforcement Learning', 'paperID': '4d0f6a6ffcd6ab04732ff76420fd9f8a7bb649c3', 'arxivId': None, 'publication_year': 2019, 'abstract': None}
{'title': 'A comprehensive survey on safe reinforcement learning', 'paperID': 'c0f2c4104ef6e36bb67022001179887e6600d24d', 'arxivId': None, 'publication_year': 2015, 'abstract': None}
{'title': 'An Introduction to Reinforcement Learning', 'paperID': 'd193b76178412e99e310e90668a498fa8fe11a5c', 'arxivId': None, 'publication_year': 2013, 'abstract': None}
{'title': 'On the sample complexity of reinforcement learning.', 'paperID': 'a9e5a40b0ff5c40d2db7b73490922e115576adb5', 'arxivId': None, 'publication_year': 2003, 'abstract': None}
{'title': 'On the Robustness of Safe Reinforcement Learning under Observational Perturbations', 'paperID': '274f0cee47c8a5bbc38c32de6787adee6a08f69e', 'arxivId': '2205.14691', 'publication_year': '2022', 'abstract': 'Safe reinforcement learning (RL) trains a policy to maximize the task reward while satisfying safety constraints. While prior works focus on the performance optimality, we find that the optimal solutions of many safe RL problems are not robust and safe against carefully designed observational perturbations. We formally analyze the unique properties of designing effective observational adversarial attackers in the safe RL setting. We show that baseline adversarial attack techniques for standard RL tasks are not always effective for safe RL and propose two new approaches - one maximizes the cost and the other maximizes the reward. One interesting and counter-intuitive finding is that the maximum reward attack is strong, as it can both induce unsafe behaviors and make the attack stealthy by maintaining the reward. We further propose a robust training framework for safe RL and evaluate it via comprehensive experiments. This paper provides a pioneer work to investigate the safety and robustness of RL under observational attacks for future safe RL studies. Code is available at: \\url{https://github.com/liuzuxin/safe-rl-robustness}'}
{'title': 'Short-Term Plasticity Neurons Learning to Learn and Forget', 'paperID': 'c3d1b9f6f2192ede9503b3bf24888caa1a5f772b', 'arxivId': '2206.14048', 'publication_year': 2022, 'abstract': None}
{'title': 'Meta-learning synaptic plasticity and memory addressing for continual familiarity detection', 'paperID': '71e07483bc04b6771dde0ebee38036cb5c05c11e', 'arxivId': None, 'publication_year': 2021, 'abstract': None}
{'title': 'Biological learning in key-value memory networks', 'paperID': 'b47264a0b34b940e1cc16390553a75144d3caab5', 'arxivId': '2110.13976', 'publication_year': 2021, 'abstract': None}
{'title': 'Meta-Learning with Task-Adaptive Loss Function for Few-Shot Learning', 'paperID': '8427455565ca12bcb6572ff7f29eb58515f36f28', 'arxivId': '2110.03909', 'publication_year': 2021, 'abstract': None}
{'title': 'Going Beyond Linear Transformers with Recurrent Fast Weight Programmers', 'paperID': '86589b6286ef3c55b8b4fccfb41a3b30b7afdf61', 'arxivId': '2106.06295', 'publication_year': 2021, 'abstract': None}
{'title': 'Linear Transformers Are Secretly Fast Weight Programmers', 'paperID': '1a703f08da01cf737cce3fb9064259b3f4b44e9c', 'arxivId': '2102.11174', 'publication_year': 2021, 'abstract': None}
{'title': 'Learning Associative Inference Using Fast Weight Memory', 'paperID': '5e11e806d24dd80ecf0f91e7aacedbba8d9fd6fc', 'arxivId': '2011.07831', 'publication_year': 2020, 'abstract': None}
{'title': 'A survey of deep meta-learning', 'paperID': '332c44793b70776b9b966128c52e694222b1ab73', 'arxivId': '2010.03522', 'publication_year': 2020, 'abstract': None}
{'title': 'Discovering Reinforcement Learning Algorithms', 'paperID': '3ce9c183cb046ee3e25d1694c8dd95d354c16a45', 'arxivId': '2007.08794', 'publication_year': 2020, 'abstract': None}
{'title': 'Meta-Learning through Hebbian Plasticity in Random Networks', 'paperID': '3a76603f03b45903bb030b2efd79984693625dc2', 'arxivId': '2007.02686', 'publication_year': 2020, 'abstract': None}
{'title': 'H-Mem: Harnessing synaptic plasticity with Hebbian Memory Networks', 'paperID': '22020679bc46666ac4b734164a8f2d78475ec596', 'arxivId': None, 'publication_year': 2020, 'abstract': None}
{'title': 'Meta-Learning in Neural Networks: A Survey', 'paperID': '020bb2ba5f3923858cd6882ba5c5a44ea8041ab6', 'arxivId': '2004.05439', 'publication_year': 2020, 'abstract': None}
{'title': 'Synaptic Plasticity Forms and Functions.', 'paperID': '97ab16d0e4a98f8275932f0a684e4fdcd70fb2d3', 'arxivId': None, 'publication_year': 2020, 'abstract': None}
{'title': 'Bidirectional synaptic plasticity rapidly modifies hippocampal representations', 'paperID': '0b322835c000dc7c351540cd9c9f70233bdbde9f', 'arxivId': None, 'publication_year': 2020, 'abstract': None}
{'title': 'Improving Generalization in Meta Reinforcement Learning using Learned Objectives', 'paperID': '2c819870111efb9fa70e359c15e2031e992c2b4a', 'arxivId': '1910.04098', 'publication_year': 2019, 'abstract': None}
{'title': 'Meta-Learning Deep Energy-Based Memory Models', 'paperID': '3839e3b4a64fd60e16861655acb4cb788730b609', 'arxivId': '1910.02720', 'publication_year': 2019, 'abstract': None}
{'title': 'Metalearned Neural Memory', 'paperID': 'a513bb6e1967f5a31ad4f38954e66d4169b613e5', 'arxivId': '1907.09720', 'publication_year': 2019, 'abstract': None}
{'title': 'Is plasticity of synapses the mechanism of long-term memory storage?', 'paperID': '6fd5e95657e06727048e60d2e8d50a996942fa16', 'arxivId': None, 'publication_year': 2019, 'abstract': None}
{'title': 'Meta Learning via Learned Loss', 'paperID': '339e2610de8487ccb54af05cb59b63854d25f02d', 'arxivId': '1906.05374', 'publication_year': 2019, 'abstract': None}
{'title': 'Meta-Learning With Differentiable Convex Optimization', 'paperID': 'fc437af6204008647ea49f81058d5fdaddf75ead', 'arxivId': '1904.03758', 'publication_year': 2019, 'abstract': None}
{'title': 'DropBlock: A regularization method for convolutional networks', 'paperID': 'e4b64a75d321311447e11c363b45cc07bb74acc2', 'arxivId': '1810.12890', 'publication_year': 2018, 'abstract': None}
{'title': 'Dendritic cortical microcircuits approximate the backpropagation algorithm', 'paperID': '4a684d8ff381be9334195e850d09b2a027447230', 'arxivId': '1810.11393', 'publication_year': 2018, 'abstract': None}
{'title': 'Backpropamine: training self-modifying neural networks with differentiable neuromodulated plasticity', 'paperID': '146c231532d4e38de95e63368dcd09d0f8cea291', 'arxivId': '2002.10585', 'publication_year': 2018, 'abstract': None}
{'title': 'Differentiable plasticity: training plastic neural networks with backpropagation', 'paperID': '249ac07c5b87f44b85500e2d26b68a7edb93e83d', 'arxivId': '1804.02464', 'publication_year': 2018, 'abstract': None}
{'title': 'Control of synaptic plasticity in deep cortical networks', 'paperID': '1fbd17c2b9a60b0f37ae61bce2704c408a507bff', 'arxivId': None, 'publication_year': 2018, 'abstract': None}
{'title': 'Evolved Policy Gradients', 'paperID': 'c9660db0c94edfb2b1f3ab4f08eb80acd83a1c07', 'arxivId': '1802.04821', 'publication_year': 2018, 'abstract': None}
{'title': 'Behavioral time scale synaptic plasticity underlies CA1 place fields', 'paperID': '37f6b9f6d45783547e0ccb3a1e3e811670391a8d', 'arxivId': None, 'publication_year': 2017, 'abstract': None}
{'title': 'Encoding of Discriminative Fear Memory by Input-Specific LTP in the Amygdala', 'paperID': '036194c441c4c00375b08a286b9e83bc5083f785', 'arxivId': None, 'publication_year': 2017, 'abstract': None}
{'title': 'Using Fast Weights to Attend to the Recent Past', 'paperID': 'c91ae35dbcb6d479580ecd235eabf98374acdb55', 'arxivId': '1610.06258', 'publication_year': 2016, 'abstract': None}
{'title': 'HyperNetworks', 'paperID': '563783de03452683a9206e85fe6d661714436686', 'arxivId': '1609.09106', 'publication_year': 2016, 'abstract': None}
{'title': 'Learning to learn by gradient descent by gradient descent', 'paperID': '395dd01c0d24777c660cf195c4cfadcdf51fb7e8', 'arxivId': '1606.04474', 'publication_year': 2016, 'abstract': None}
{'title': 'Coordinated and Compartmentalized Neuromodulation Shapes Sensory Processing in Drosophila', 'paperID': 'a03c7087175d2f7eb60b25d5e0cb742f3a908eac', 'arxivId': None, 'publication_year': 2015, 'abstract': None}
{'title': 'Sleep Facilitates Memory by Blocking Dopamine Neuron-Mediated Forgetting', 'paperID': 'd4021f1c446790e4db5bb3501c2aa68757f831f8', 'arxivId': None, 'publication_year': 2015, 'abstract': None}
{'title': 'Role of Dopamine Neurons in Reward and Aversion: A Synaptic Plasticity Perspective', 'paperID': 'eca2f7495847dc3cd2afeb37202459f1e769fcf4', 'arxivId': None, 'publication_year': 2015, 'abstract': None}
{'title': 'Neuromodulation of neurons and synapses', 'paperID': '75848d00cf8d019766529ae7fb8e31b2941224e8', 'arxivId': None, 'publication_year': 2014, 'abstract': None}
{'title': 'Engineering a memory with LTD and LTP', 'paperID': '925ada6dcfd0d99185e9b214c2db7063dd91f3b3', 'arxivId': None, 'publication_year': 2014, 'abstract': None}
{'title': 'Dynamic learning and memory, synaptic plasticity and neurogenesis: an update', 'paperID': '76fdd84496a52d0a9248c2628062b6b3c64c43e7', 'arxivId': None, 'publication_year': 2014, 'abstract': None}
{'title': 'Synaptic plasticity, memory and the hippocampus: a neural network approach to causality', 'paperID': 'e22dd3f125c3044605decaabb4f59cd76a5f0a91', 'arxivId': None, 'publication_year': 2012, 'abstract': None}
{'title': 'Dopamine Is Required for Learning and Forgetting in Drosophila', 'paperID': 'ca38bcf30beab44cce3ea387570c2b6065e6ff28', 'arxivId': None, 'publication_year': 2012, 'abstract': None}
{'title': 'Dopamine in Motor Cortex Is Necessary for Skill Learning and Synaptic Plasticity', 'paperID': 'f9035ab5d58eae9564757995a3039dc46c325b57', 'arxivId': None, 'publication_year': 2009, 'abstract': None}
{'title': 'Striatal Plasticity and Basal Ganglia Circuit Function', 'paperID': '45ba546a85526d901e5979d89f3cee0c05c3189b', 'arxivId': None, 'publication_year': 2008, 'abstract': None}
{'title': 'NMDA receptors, place cells and hippocampal spatial memory', 'paperID': '579b43dc10517cdb368beb79f37535017a31f849', 'arxivId': None, 'publication_year': 2004, 'abstract': None}
{'title': 'Neuromodulatory transmitter systems in the cortex and their role in cortical plasticity', 'paperID': '68fa35b4b69a71abccf845d13bc80e06bdd90403', 'arxivId': None, 'publication_year': 2002, 'abstract': None}
{'title': 'Learning-induced LTP in neocortex.', 'paperID': '9adf78008992846bcdc80cb58d7ef948ed7ba6d1', 'arxivId': None, 'publication_year': 2000, 'abstract': None}
{'title': 'Shifting Inductive Bias with Success-Story Algorithm, Adaptive Levin Search, and Incremental Self-Improvement', 'paperID': '6e7241121c688abbd9329bdcebce4b6320fc619d', 'arxivId': None, 'publication_year': 1997, 'abstract': None}
{'title': 'The organization of behavior: A neuropsychological theory', 'paperID': 'b9164335be5808ddd59786869a9f992331af5218', 'arxivId': None, 'publication_year': 1951, 'abstract': None}
{'title': 'On the Optimization of a Synaptic Learning Rule', 'paperID': '8784f905f4f9fb6fa4a3cc9b0faa5b5479c687ec', 'arxivId': None, 'publication_year': 2007, 'abstract': None}
{'title': 'Synaptic computation', 'paperID': '41351e5b997dc2555d330e54493c54583437c75a', 'arxivId': None, 'publication_year': 2004, 'abstract': None}
{'title': 'Synaptic plasticity and memory: an evaluation of the hypothesis.', 'paperID': 'bf0afaef99a2786692ccbdbe1fdca49c342586cd', 'arxivId': None, 'publication_year': 2000, 'abstract': None}
{'title': 'Selective impairment of learning and blockade of long-term potentiation by an N-methyl-D-aspartate receptor antagonist, AP5', 'paperID': 'f4356aeaaa2b7425d90ca45223097f3a8bb3503a', 'arxivId': None, 'publication_year': 1986, 'abstract': None}
{'title': 'Hebbian and Gradient-based Plasticity Enables Robust Memory and Rapid Learning in RNNs', 'paperID': '989830e67b55120b098afe12958b8c53d1b49f5b', 'arxivId': '2302.03235', 'publication_year': '2023', 'abstract': 'Rapidly learning from ongoing experiences and remembering past events with a flexible memory system are two core capacities of biological intelligence. While the underlying neural mechanisms are not fully understood, various evidence supports that synaptic plasticity plays a critical role in memory formation and fast learning. Inspired by these results, we equip Recurrent Neural Networks (RNNs) with plasticity rules to enable them to adapt their parameters according to ongoing experiences. In addition to the traditional local Hebbian plasticity, we propose a global, gradient-based plasticity rule, which allows the model to evolve towards its self-determined target. Our models show promising results on sequential and associative memory tasks, illustrating their ability to robustly form and retain memories. In the meantime, these models can cope with many challenging few-shot learning problems. Comparing different plasticity rules under the same framework shows that Hebbian plasticity is well-suited for several memory and associative learning tasks; however, it is outperformed by gradient-based plasticity on few-shot regression tasks which require the model to infer the underlying mapping. Code is available at https://github.com/yuvenduan/PlasticRNNs.'}
{'title': 'Are Defenses for Graph Neural Networks Robust?', 'paperID': '3efa96570a10fecba0f93e0f62e95d41ce7b624b', 'arxivId': '2301.13694', 'publication_year': 2023, 'abstract': None}
{'title': 'GraphWorld: Fake Graphs Bring Real Insights for GNNs', 'paperID': 'ca9f9e50e907ae4cf8be0b6d566a3083465cec5b', 'arxivId': '2203.00112', 'publication_year': 2022, 'abstract': None}
{'title': 'Graph Attention Retrospective', 'paperID': '9bc2a62ad82282296dd7131805fa83071469418e', 'arxivId': '2202.13060', 'publication_year': 2022, 'abstract': None}
{'title': 'Graph Robustness Benchmark: Benchmarking the Adversarial Robustness of Graph Machine Learning', 'paperID': 'd3759f651e26bffbc4ca3e41c7453d6800e0c682', 'arxivId': '2111.04314', 'publication_year': 2021, 'abstract': None}
{'title': 'Unsolved Problems in ML Safety', 'paperID': '05c2e1ee203be217f100d2da05bdcc52004f00b6', 'arxivId': '2109.13916', 'publication_year': 2021, 'abstract': None}
{'title': 'How Attentive are Graph Attention Networks?', 'paperID': 'ab30672c8c5e4787f6a5985f26a8f281f0db2fb8', 'arxivId': '2105.14491', 'publication_year': 2021, 'abstract': None}
{'title': 'OGB-LSC: A Large-Scale Challenge for Machine Learning on Graphs', 'paperID': '9389af659f14239319186dff1cef49e8ece742c8', 'arxivId': '2103.09430', 'publication_year': 2021, 'abstract': None}
{'title': 'Graph Convolution for Semi-Supervised Classification: Improved Linear Separability and Out-of-Distribution Generalization', 'paperID': '8d69d51455d53344984b9719fb924685ba0145ab', 'arxivId': '2102.06966', 'publication_year': 2021, 'abstract': None}
{'title': 'Combining Label Propagation and Simple Models Out-performs Graph Neural Networks', 'paperID': 'f1e5e65941617604923225cc4bf464e370fcae67', 'arxivId': '2010.13993', 'publication_year': 2020, 'abstract': None}
{'title': 'Adversarial Attack on Large Scale Graph', 'paperID': '435bc42450259a22cfba92b40217b8d26f4a7ed5', 'arxivId': '2009.03488', 'publication_year': 2020, 'abstract': None}
{'title': 'Towards an Efficient and General Framework of Robust Training for Graph Neural Networks', 'paperID': '797d6b26a1a4aa98c8bbc93533707c65ad189c11', 'arxivId': '2002.10947', 'publication_year': 2020, 'abstract': None}
{'title': 'Fundamental Tradeoffs between Invariance and Sensitivity to Adversarial Perturbations', 'paperID': '08afb316faf7b2d6c8582881458350698fd3e554', 'arxivId': '2002.04599', 'publication_year': 2020, 'abstract': None}
{'title': 'Adversarial Examples for Graph Data: Deep Insights into Attack and Defense', 'paperID': '26a0e0d17910c6676fcfa1cebe0cb7f5cd17080c', 'arxivId': None, 'publication_year': 2019, 'abstract': None}
{'title': 'Simplifying Graph Convolutional Networks', 'paperID': '7e71eedb078181873a56f2adcfef9dddaeb95602', 'arxivId': '1902.07153', 'publication_year': 2019, 'abstract': None}
{'title': 'Fast Gradient Attack on Network Embedding', 'paperID': '5c0fe48ce1530d9757efca49d78709fc77caaf6c', 'arxivId': '1809.02797', 'publication_year': 2018, 'abstract': None}
{'title': 'Contextual Stochastic Block Models', 'paperID': '313dc4c4cdf81d8631948b9ce8195b3a6c291534', 'arxivId': '1807.09596', 'publication_year': 2018, 'abstract': None}
{'title': 'Community Recovery in a Preferential Attachment Graph', 'paperID': 'c7d141145ceb60c08d8400f4cc7357e6e288d5e4', 'arxivId': None, 'publication_year': 2018, 'abstract': None}
{'title': 'Inductive Representation Learning on Large Graphs', 'paperID': '6b7d6e6416343b2a122f8416e69059ce919026ef', 'arxivId': '1706.02216', 'publication_year': 2017, 'abstract': None}
{'title': 'Community detection and stochastic block models: recent developments', 'paperID': '41f6bbf03e9c2bf1bb2e3cea442a0f08b6d807d0', 'arxivId': None, 'publication_year': 2017, 'abstract': None}
{'title': 'Hiding individuals and communities in a social network', 'paperID': '6729b698fc28d191f3006690d973974a13c2f501', 'arxivId': '1608.00375', 'publication_year': 2016, 'abstract': None}
{'title': 'Preferential Attachment in Graphs with Affinities', 'paperID': 'b7ccb41a2354aa9fa0223ce507d1ba024c2bd58a', 'arxivId': None, 'publication_year': 2015, 'abstract': None}
{'title': 'Covariate-assisted spectral clustering', 'paperID': 'ba40f5c23d8901ea1f8eaa7e85eb76c47d123624', 'arxivId': '1411.2158', 'publication_year': 2014, 'abstract': None}
{'title': 'Geometric preferential attachment in non-uniform metric spaces', 'paperID': '2bdde0c06e2ac4a78a5c04809129cc0871c0ec2d', 'arxivId': '1208.4938', 'publication_year': 2012, 'abstract': None}
{'title': 'Stochastic blockmodels and community structure in networks', 'paperID': '5625bbaf7dfdf5b675c5213c917939870b5aa0a2', 'arxivId': '1008.3926', 'publication_year': 2010, 'abstract': None}
{'title': 'Power-Law Distributions in Empirical Data', 'paperID': '7dcc27e011874c43463b80257d8ff3d797411844', 'arxivId': '0706.1062', 'publication_year': 2007, 'abstract': None}
{'title': 'An evolving network model with community structure', 'paperID': '9c92232af79f81931b0ff58888eb857dcbecd8b8', 'arxivId': 'physics/0510239', 'publication_year': 2005, 'abstract': None}
{'title': 'Mixing patterns in networks.', 'paperID': '0ed877bab75b32042a887715380c84ac27e64a8b', 'arxivId': 'cond-mat/0209450', 'publication_year': 2002, 'abstract': None}
{'title': 'Statistical mechanics of complex networks', 'paperID': 'dce8146987557735a19771aefa1f027211a2c275', 'arxivId': 'cond-mat/0106096', 'publication_year': 2001, 'abstract': None}
{'title': 'Predict then Propagate: Combining neural networks with personalized pagerank for classification on graphs', 'paperID': 'e720bbf5e2d36740dc44534fdc99134f860051de', 'arxivId': None, 'publication_year': 2018, 'abstract': None}
{'title': 'Revisiting Robustness in Graph Machine Learning', 'paperID': '6584f26629877392b0a34b7db448f7d9d7a4fda7', 'arxivId': '2305.00851', 'publication_year': '2023', 'abstract': 'Many works show that node-level predictions of Graph Neural Networks (GNNs) are unrobust to small, often termed adversarial, changes to the graph structure. However, because manual inspection of a graph is difficult, it is unclear if the studied perturbations always preserve a core assumption of adversarial examples: that of unchanged semantic content. To address this problem, we introduce a more principled notion of an adversarial graph, which is aware of semantic content change. Using Contextual Stochastic Block Models (CSBMs) and real-world graphs, our results uncover: $i)$ for a majority of nodes the prevalent perturbation models include a large fraction of perturbed graphs violating the unchanged semantics assumption; $ii)$ surprisingly, all assessed GNNs show over-robustness - that is robustness beyond the point of semantic change. We find this to be a complementary phenomenon to adversarial examples and show that including the label-structure of the training graph into the inference process of GNNs significantly reduces over-robustness, while having a positive effect on test accuracy and adversarial robustness. Theoretically, leveraging our new semantics-aware notion of robustness, we prove that there is no robustness-accuracy tradeoff for inductively classifying a newly added node.'}
{'title': 'Certified Robustness in Federated Learning', 'paperID': '2e533f2d1b44166277576baa8e9c159c04d668d1', 'arxivId': '2206.02535', 'publication_year': 2022, 'abstract': None}
{'title': 'Test-Time Robust Personalization for Federated Learning', 'paperID': '8b2ee805275ec92d032e0e5848b3196727b6c431', 'arxivId': '2205.10920', 'publication_year': 2022, 'abstract': None}
{'title': 'Federated Learning Aggregation: New Robust Algorithms with Guarantees', 'paperID': '37af8eee5de461d2d03eaac2fd864715016cb5a3', 'arxivId': '2205.10864', 'publication_year': 2022, 'abstract': None}
{'title': 'Certified Federated Adversarial Training', 'paperID': 'c5f2da771e523b2fb6dc1937cff1925e3a7421ae', 'arxivId': '2112.10525', 'publication_year': 2021, 'abstract': None}
{'title': 'Edge-Cloud Polarization and Collaboration: A Comprehensive Survey for AI', 'paperID': '157bddb85786b980c962e649bed33d8ebbf7b4a1', 'arxivId': '2111.06061', 'publication_year': 2021, 'abstract': None}
{'title': 'Neural Architecture Dilation for Adversarial Robustness', 'paperID': 'cc662dc89da9a7090c30fdb903d50ee93918020b', 'arxivId': '2108.06885', 'publication_year': 2021, 'abstract': None}
{'title': 'Reliable Adversarial Distillation with Unreliable Teachers', 'paperID': '6bb6359ad507653e2785d9fe924fc1feff39e0e9', 'arxivId': '2106.04928', 'publication_year': 2021, 'abstract': None}
{'title': 'Federated Hyperparameter Tuning: Challenges, Baselines, and Connections to Weight-Sharing', 'paperID': '39dc3b78ca88ce661a669fbbe331c589bceadb6a', 'arxivId': '2106.04502', 'publication_year': 2021, 'abstract': None}
{'title': 'Model-Contrastive Federated Learning', 'paperID': '748c4f1945b0d994ecef38c8aac01db1c6dc7029', 'arxivId': '2103.16257', 'publication_year': 2021, 'abstract': None}
{'title': 'Adversarial training in communication constrained federated learning', 'paperID': '11df75768d755f59ec3267a280e2830e35b8e59b', 'arxivId': '2103.01319', 'publication_year': 2021, 'abstract': None}
{'title': 'Towards Understanding Ensemble, Knowledge Distillation and Self-Distillation in Deep Learning', 'paperID': '255e6239bcc51047d020d41ce0179c1270f3c22f', 'arxivId': '2012.09816', 'publication_year': 2020, 'abstract': None}
{'title': 'FAT: Federated Adversarial Training', 'paperID': '2173ac718365f5fd52e1f9e6bc567c5a2ce9a15a', 'arxivId': '2012.01791', 'publication_year': 2020, 'abstract': None}
{'title': 'Defending Poisoning Attacks in Federated Learning via Adversarial Training Method', 'paperID': 'dfa824c28e6f4a160e93d6b366fea97d1b0e3b52', 'arxivId': None, 'publication_year': 2020, 'abstract': None}
{'title': 'Tackling the Objective Inconsistency Problem in Heterogeneous Federated Optimization', 'paperID': '4b6661347d5b58250130b89145dbd34ce310f2a0', 'arxivId': '2007.07481', 'publication_year': 2020, 'abstract': None}
{'title': 'How benign is benign overfitting?', 'paperID': 'dfb6250ae1c8f4d0ec3e28ed84596f77704485ab', 'arxivId': '2007.04028', 'publication_year': 2020, 'abstract': None}
{'title': 'Robust Federated Learning: The Case of Affine Distribution Shifts', 'paperID': '48aced1b11e6a3e16dd1f1ed9d0823e8eae48729', 'arxivId': '2006.08907', 'publication_year': 2020, 'abstract': None}
{'title': 'On the Convergence of FedAvg on Non-IID Data', 'paperID': 'c802ceb7a9ff904220c48ee44ae9b671be6d6379', 'arxivId': '1907.02189', 'publication_year': 2019, 'abstract': None}
{'title': 'Adversarially Robust Distillation', 'paperID': '38098abafe05fe839af09e41104998109e741e95', 'arxivId': '1905.09747', 'publication_year': 2019, 'abstract': None}
{'title': 'LEAF: A Benchmark for Federated Settings', 'paperID': '8dcbcaaf337d7bd22e580f1bb7a795ed4bb604fd', 'arxivId': '1812.01097', 'publication_year': 2018, 'abstract': None}
{'title': 'Federated Learning with Non-IID Data', 'paperID': '5cfc112c932e38df95a0ba35009688735d1a386b', 'arxivId': '1806.00582', 'publication_year': 2018, 'abstract': None}
{'title': 'SGD and Hogwild! Convergence Without the Bounded Gradients Assumption', 'paperID': 'd17a3e9f34125ba6454e365ffe403ce8a91f2632', 'arxivId': '1802.03801', 'publication_year': 2018, 'abstract': None}
{'title': 'Federated Multi-Task Learning', 'paperID': '276194e96ebd620b5cff35a9168bdda39a0be57b', 'arxivId': '1705.10467', 'publication_year': 2017, 'abstract': None}
{'title': 'Crowdsourcing in Computer Vision', 'paperID': '84c95a8db377c25d4280f188e9477569ab57281b', 'arxivId': '1611.02145', 'publication_year': 2016, 'abstract': None}
{'title': 'Network In Network', 'paperID': '5e83ab70d0cbc003471e87ec306d27d9c80ecb16', 'arxivId': '1312.4400', 'publication_year': 2013, 'abstract': None}
{'title': 'Communication-efficient algorithms for statistical optimization', 'paperID': '2820973cf69daba62547f76de082bed5e1c646e6', 'arxivId': '1209.4129', 'publication_year': 2012, 'abstract': None}
{'title': 'Federated Robustness Propagation: Sharing Adversarial Robustness in Federated Learning', 'paperID': '9ea05ebeb9280c36da9c251c0bc9c7b24a167722', 'arxivId': None, 'publication_year': 2021, 'abstract': None}
{'title': 'Combating Exacerbated Heterogeneity for Robust Models in Federated Learning', 'paperID': '25ffa7c814856551843025632f092239152aa43e', 'arxivId': '2303.00250', 'publication_year': '2023', 'abstract': 'Privacy and security concerns in real-world applications have led to the development of adversarially robust federated models. However, the straightforward combination between adversarial training and federated learning in one framework can lead to the undesired robustness deterioration. We discover that the attribution behind this phenomenon is that the generated adversarial data could exacerbate the data heterogeneity among local clients, making the wrapped federated learning perform poorly. To deal with this problem, we propose a novel framework called Slack Federated Adversarial Training (SFAT), assigning the client-wise slack during aggregation to combat the intensified heterogeneity. Theoretically, we analyze the convergence of the proposed method to properly relax the objective when combining federated learning and adversarial training. Experimentally, we verify the rationality and effectiveness of SFAT on various benchmarked and real-world datasets with different adversarial training and federated optimization methods. The code is publicly available at https://github.com/ZFancy/SFAT.'}
{'title': 'Importance Tempering: Group Robustness for Overparameterized Models', 'paperID': 'f40511f8e4453d1173102f79aa8a612827d262f7', 'arxivId': '2209.08745', 'publication_year': 2022, 'abstract': None}
{'title': 'Learning to Split for Automatic Bias Detection', 'paperID': '6d285ebd30f57c5ae6d0e6d085977aeedcab7079', 'arxivId': '2204.13749', 'publication_year': 2022, 'abstract': None}
{'title': 'Is Importance Weighting Incompatible with Interpolating Classifiers?', 'paperID': 'a4e3a467804781a3c5a427f4032bf180ea8bf585', 'arxivId': '2112.12986', 'publication_year': 2021, 'abstract': None}
{'title': 'Boosted CVaR Classification', 'paperID': '76c2a2b883b3a801b16b8765eb54ab61a63f405c', 'arxivId': '2110.13948', 'publication_year': 2021, 'abstract': None}
{'title': 'Unsupervised Learning of Debiased Representations with Pseudo-Attributes', 'paperID': '0be20a4976e8dd7836124b29e553f6c0c19289c2', 'arxivId': '2108.02943', 'publication_year': 2021, 'abstract': None}
{'title': 'Learning from Noisy Labels with Deep Neural Networks: A Survey', 'paperID': '5ffe9b1d8219438f0343995ad3ea1a888e3d9f8e', 'arxivId': '2007.08199', 'publication_year': 2020, 'abstract': None}
{'title': 'Greedy adversarial equilibrium: an efficient alternative to nonconvex-nonconcave min-max optimization', 'paperID': '006e1d8ca4fba1fea02a3a0df0e226b11dbc9581', 'arxivId': None, 'publication_year': 2020, 'abstract': None}
{'title': 'High‐dimensional Statistics: A Non‐asymptotic Viewpoint, Martin J.Wainwright, Cambridge University Press, 2019, xvii 552 pages, £57.99, hardback ISBN: 978‐1‐1084‐9802‐9', 'paperID': '47628dde478a58668ea8ba1ea9a432c5f5ddb652', 'arxivId': None, 'publication_year': 2020, 'abstract': None}
{'title': 'Distribution Density, Tails, and Outliers in Machine Learning: Metrics and Applications', 'paperID': 'ad2fe0bf54e8d0cbe4a1afe6260fd886db74f1a5', 'arxivId': '1910.13427', 'publication_year': 2019, 'abstract': None}
{'title': 'Bayesian regularization: From Tikhonov to horseshoe', 'paperID': '132f3e7cf9dc169d2f42d2fd678600b1de122d52', 'arxivId': '1902.06269', 'publication_year': 2019, 'abstract': None}
{'title': 'Faster Rates for Convex-Concave Games', 'paperID': '1a5c4496d7e6c7c0d5c6c187505fbbc419bf3b92', 'arxivId': '1805.06792', 'publication_year': 2018, 'abstract': None}
{'title': 'Preventing Fairness Gerrymandering: Auditing and Learning for Subgroup Fairness', 'paperID': '19930147204c97be4d0964e166e8fe72ac1d6c3d', 'arxivId': '1711.05144', 'publication_year': 2017, 'abstract': None}
{'title': 'Robust Classification Under Sample Selection Bias', 'paperID': '6e4a2703dfcd02e5703caa388d2e0418a7e9f66b', 'arxivId': None, 'publication_year': 2014, 'abstract': None}
{'title': 'Divide and Conquer Kernel Ridge Regression', 'paperID': '3413db5b8cc25a2ac37345d984fe87ca6b8b7354', 'arxivId': None, 'publication_year': 2013, 'abstract': None}
{'title': 'PAC-BAYESIAN SUPERVISED CLASSIFICATION: The Thermodynamics of Statistical Learning', 'paperID': '598b49e0b8e6a4c9a38b8e92164397fb83df7ce8', 'arxivId': '0712.0248', 'publication_year': 2007, 'abstract': None}
{'title': 'Robust Supervised Learning', 'paperID': '26edc9ae4612c1743285deddf2004b5f4657fbce', 'arxivId': None, 'publication_year': 2005, 'abstract': None}
{'title': 'Some PAC-Bayesian Theorems', 'paperID': '0e2f6482e7230e1d12af88d6b8afcef3d5d733e3', 'arxivId': None, 'publication_year': 1998, 'abstract': None}
{'title': 'Covering numbers for real-valued function classes', 'paperID': '0e6ce43aceab1c52056f8c41d9d6b01634620c51', 'arxivId': None, 'publication_year': 1997, 'abstract': None}
{'title': 'Minimum Description Length Principle', 'paperID': '4e3cb267bb4b0ae833c2309759234e0d4ca80074', 'arxivId': None, 'publication_year': 2010, 'abstract': None}
{'title': 'Bitrate-Constrained DRO: Beyond Worst Case Robustness To Unknown Group Shifts', 'paperID': '5e4437c0ef2bcfa06102341938d63e68762527a6', 'arxivId': '2302.02931', 'publication_year': '2023', 'abstract': "Training machine learning models robust to distribution shifts is critical for real-world applications. Some robust training algorithms (e.g., Group DRO) specialize to group shifts and require group information on all training points. Other methods (e.g., CVaR DRO) that do not need group annotations can be overly conservative, since they naively upweight high loss points which may form a contrived set that does not correspond to any meaningful group in the real world (e.g., when the high loss points are randomly mislabeled training points). In this work, we address limitations in prior approaches by assuming a more nuanced form of group shift: conditioned on the label, we assume that the true group function (indicator over group) is simple. For example, we may expect that group shifts occur along low bitrate features (e.g., image background, lighting). Thus, we aim to learn a model that maintains high accuracy on simple group functions realized by these low bitrate features, that need not spend valuable model capacity achieving high accuracy on contrived groups of examples. Based on this, we consider the two-player game formulation of DRO where the adversary's capacity is bitrate-constrained. Our resulting practical algorithm, Bitrate-Constrained DRO (BR-DRO), does not require group information on training samples yet matches the performance of Group DRO on datasets that have training group annotations and that of CVaR DRO on long-tailed distributions. Our theoretical analysis reveals that in some settings BR-DRO objective can provably yield statistically efficient and less conservative solutions than unconstrained CVaR DRO."}
{'title': 'Learning Where To Look - Generative NAS is Surprisingly Efficient', 'paperID': 'dafa72ca28bf035c884ae4a6952791e48c76acbb', 'arxivId': '2203.08734', 'publication_year': 2022, 'abstract': None}
{'title': 'RobustART: Benchmarking Robustness on Architecture Design and Training Techniques', 'paperID': 'fd3bee898ae69bd956af9f4aabd3f7b478de2cbd', 'arxivId': '2109.05211', 'publication_year': 2021, 'abstract': None}
{'title': 'AdvRush: Searching for Adversarially Robust Neural Architectures', 'paperID': '3bc361f9fa99366e1b8e851e508c12dcefb3b3b9', 'arxivId': '2108.01289', 'publication_year': 2021, 'abstract': None}
{'title': 'Generative Adversarial Neural Architecture Search', 'paperID': '0335f6dfafb2dc8c76726ab282cb3a4ad8e0d9ec', 'arxivId': '2105.09356', 'publication_year': 2021, 'abstract': None}
{'title': 'DSRNA: Differentiable Search of Robust Neural Architectures', 'paperID': '178a5726bccf0d9422609c74ba07b3b8b2c6ac37', 'arxivId': '2012.06122', 'publication_year': 2020, 'abstract': None}
{'title': 'Smooth Variational Graph Embeddings for Efficient Neural Architecture Search', 'paperID': '01dd3853c321cfc68c8e0a458018049ce1e83462', 'arxivId': '2010.04683', 'publication_year': 2020, 'abstract': None}
{'title': 'TransNAS-Bench-101: Improving transferability and Generalizability of Cross-Task Neural Architecture Search', 'paperID': 'd01ca0b8b6d02e2833b8d1a71b28de153cdbc397', 'arxivId': '2105.11871', 'publication_year': 2020, 'abstract': None}
{'title': 'On Adversarial Robustness: A Neural Architecture Search perspective', 'paperID': '20694a67d86bd98b51e1590402172ea7c8893709', 'arxivId': '2007.08428', 'publication_year': 2020, 'abstract': None}
{'title': 'Exploring the loss landscape in neural architecture search', 'paperID': '6f51319f22c3c02ab15cb26f5b332667ed1b7cd8', 'arxivId': '2005.02960', 'publication_year': 2020, 'abstract': None}
{'title': 'When NAS Meets Robustness: In Search of Robust Architectures Against Adversarial Attacks', 'paperID': '908d07792e64234a083138d4b966a24bd2c604aa', 'arxivId': '1911.10695', 'publication_year': 2019, 'abstract': None}
{'title': 'BANANAS: Bayesian Optimization with Neural Architectures for Neural Architecture Search', 'paperID': '013a741927569ae9b40875a9e58d2c5ba6dbb3a8', 'arxivId': '1910.11858', 'publication_year': 2019, 'abstract': None}
{'title': 'GradVis: Visualization and Second Order Analysis of Optimization Surfaces during the Training of Deep Neural Networks', 'paperID': '5e33ddbad2b96d37c669385f10347dbeb301de6f', 'arxivId': '1909.12108', 'publication_year': 2019, 'abstract': None}
{'title': 'DEEPSEC: A Uniform Platform for Security Analysis of Deep Learning Model', 'paperID': 'fda5f4facce9d5567c090d7ac733158e0fe93dc7', 'arxivId': None, 'publication_year': 2019, 'abstract': None}
{'title': 'NAS-Bench-101: Towards Reproducible Neural Architecture Search', 'paperID': '6e4fd9b4b2b673c981cda528d8039a221ad35225', 'arxivId': '1902.09635', 'publication_year': 2019, 'abstract': None}
{'title': 'Learning Deep Generative Models of Graphs', 'paperID': 'f32f16ca3c27ff945198c6551a5d35fae3b1a660', 'arxivId': '1803.03324', 'publication_year': 2018, 'abstract': None}
{'title': 'Neural Architecture Search with Bayesian Optimisation and Optimal Transport', 'paperID': '7864c8cd08ff4da9acc37de2576e9cdbabe03107', 'arxivId': '1802.07191', 'publication_year': 2018, 'abstract': None}
{'title': 'A Study and Comparison of Human and Deep Learning Recognition Performance under Visual Distortions', 'paperID': '89b4111f14cdf342188f96d3962581fd0afa042f', 'arxivId': '1705.02498', 'publication_year': 2017, 'abstract': None}
{'title': 'Random Search for Hyper-Parameter Optimization', 'paperID': '188e247506ad992b8bc62d6c74789e89891a984f', 'arxivId': None, 'publication_year': 2012, 'abstract': None}
{'title': 'Interpretable Neural Architecture Search via Bayesian Optimisation with Weisfeiler-Lehman Kernels', 'paperID': '2764af5084331e91e386d498ed53a2f4ce0eb354', 'arxivId': None, 'publication_year': 2021, 'abstract': None}
{'title': 'Neural Architecture Design and Robustness: A Dataset', 'paperID': 'c5772e031f2b7110dac99acae3425ea56b952856', 'arxivId': '2306.06712', 'publication_year': '2023', 'abstract': "Deep learning models have proven to be successful in a wide range of machine learning tasks. Yet, they are often highly sensitive to perturbations on the input data which can lead to incorrect decisions with high confidence, hampering their deployment for practical use-cases. Thus, finding architectures that are (more) robust against perturbations has received much attention in recent years. Just like the search for well-performing architectures in terms of clean accuracy, this usually involves a tedious trial-and-error process with one additional challenge: the evaluation of a network's robustness is significantly more expensive than its evaluation for clean accuracy. Thus, the aim of this paper is to facilitate better streamlined research on architectural design choices with respect to their impact on robustness as well as, for example, the evaluation of surrogate measures for robustness. We therefore borrow one of the most commonly considered search spaces for neural architecture search for image classification, NAS-Bench-201, which contains a manageable size of 6466 non-isomorphic network designs. We evaluate all these networks on a range of common adversarial attacks and corruption types and introduce a database on neural architecture design and robustness evaluations. We further present three exemplary use cases of this dataset, in which we (i) benchmark robustness measurements based on Jacobian and Hessian matrices for their robustness predictability, (ii) perform neural architecture search on robust accuracies, and (iii) provide an initial analysis of how architectural design choices affect robustness. We find that carefully crafting the topology of a network can have substantial impact on its robustness, where networks with the same parameter count range in mean adversarial robust accuracy from 20%-41%. Code and data is available at http://robustness.vision/."}
{'title': 'Elucidating the Design Space of Diffusion-Based Generative Models', 'paperID': '2f4c451922e227cbbd4f090b74298445bbd900d0', 'arxivId': '2206.00364', 'publication_year': 2022, 'abstract': None}
{'title': 'Diffusion Models for Adversarial Purification', 'paperID': '9b41d745fe3a76443bd0420bc5f2df28be2bd65f', 'arxivId': '2205.07460', 'publication_year': 2022, 'abstract': None}
{'title': 'Robust and Accurate - Compositional Architectures for Randomized Smoothing', 'paperID': '48630fa9fe7444b7fa910dab08ff23fc926f0e3b', 'arxivId': '2204.00487', 'publication_year': 2022, 'abstract': None}
{'title': 'Diffusion Models Beat GANs on Image Synthesis', 'paperID': '64ea8f180d0682e6c18d1eb688afdb2027c02794', 'arxivId': '2105.05233', 'publication_year': 2021, 'abstract': None}
{'title': 'Deep Unsupervised Learning using Nonequilibrium Thermodynamics', 'paperID': '2dcef55a07f8607a819c21fe84131ea269cc2e3c', 'arxivId': '1503.03585', 'publication_year': 2015, 'abstract': None}
{'title': 'PROVABLE DEFENSE BY DENOISED SMOOTHING WITH LEARNED SCORE FUNCTION', 'paperID': '30e8e647d10287a0f28cf733e1f15b4ad912645a', 'arxivId': None, 'publication_year': 2021, 'abstract': None}
{'title': 'Prioritized Training on Points that are Learnable, Worth Learning, and Not Yet Learnt', 'paperID': '6a8db14262ca2017cb253e12b8daeb57989a38df', 'arxivId': '2206.07137', 'publication_year': 2022, 'abstract': None}
{'title': 'Lottery Tickets on a Data Diet: Finding Initializations with Sparse Trainable Networks', 'paperID': '7ca1ee1f506c10dc156f5fa43d715e7a0985819a', 'arxivId': '2206.01278', 'publication_year': 2022, 'abstract': None}
{'title': 'Few-shot Learning with Noisy Labels', 'paperID': '52c327eba81faf42f4b4bc71613cd840f33d06e7', 'arxivId': '2204.05494', 'publication_year': 2022, 'abstract': None}
{'title': 'Sensitivity-Informed Provable Pruning of Neural Networks', 'paperID': '448aebe43a20f6e19e04e238e5e4d78690fc538f', 'arxivId': None, 'publication_year': 2022, 'abstract': None}
{'title': 'Batch Active Learning at Scale', 'paperID': '998bc35af7c44a37f0eaca96c181b6aed9b7d489', 'arxivId': '2107.14263', 'publication_year': 2021, 'abstract': None}
{'title': 'Deep Learning on a Data Diet: Finding Important Examples Early in Training', 'paperID': 'a6e25ca9ee9d3e45c6d1957c0dc3324a9816c34e', 'arxivId': '2107.07075', 'publication_year': 2021, 'abstract': None}
{'title': 'Does Knowledge Distillation Really Work?', 'paperID': '5f0f4a3fa3cff7ffcedabbc9ed0dad2dd71f7028', 'arxivId': '2106.05945', 'publication_year': 2021, 'abstract': None}
{'title': 'Knowledge distillation: A good teacher is patient and consistent', 'paperID': '97d8823ca3c9bd932cec8ad6f3b194168e7cec92', 'arxivId': '2106.05237', 'publication_year': 2021, 'abstract': None}
{'title': 'Computation-Efficient Knowledge Distillation via Uncertainty-Aware Mixup', 'paperID': 'd1a1f2cb21296d42cdcffd1141ff8aa7f6d91618', 'arxivId': '2012.09413', 'publication_year': 2020, 'abstract': None}
{'title': 'GIRAFFE: Representing Scenes as Compositional Generative Neural Feature Fields', 'paperID': '69a1d72bac9dfb18940ff97ae91643d6c8158e6d', 'arxivId': '2011.12100', 'publication_year': 2020, 'abstract': None}
{'title': 'MixKD: Towards Efficient Distillation of Large-scale Language Models', 'paperID': '1013750582c20bbdf1164127b5f26b1e06e817e3', 'arxivId': '2011.00593', 'publication_year': 2020, 'abstract': None}
{'title': 'Knowledge Distillation: A Survey', 'paperID': '1728cb805a9573b59330890ba9723e73d6c3c974', 'arxivId': '2006.05525', 'publication_year': 2020, 'abstract': None}
{'title': 'Why distillation helps: a statistical perspective', 'paperID': 'cd808e3e96aef9d18aae6efa842f0e5ebd329a01', 'arxivId': '2005.10419', 'publication_year': 2020, 'abstract': None}
{'title': 'Meta Label Correction for Noisy Label Learning', 'paperID': '96c6f34594279844ca8fd901649fa06491ef822c', 'arxivId': '1911.03809', 'publication_year': 2019, 'abstract': None}
{'title': 'Distilling Effective Supervision From Severe Label Noise', 'paperID': '373edd20ffbe31850ec805c43af1dd7e4f0d7672', 'arxivId': None, 'publication_year': 2019, 'abstract': None}
{'title': 'On the Efficacy of Knowledge Distillation', 'paperID': '8de7f044a673d1f5e3b454d0663811f91aa9811a', 'arxivId': '1910.01348', 'publication_year': 2019, 'abstract': None}
{'title': 'Certainty driven consistency loss on multi-teacher networks for semi-supervised learning', 'paperID': '1fa6ebc976d3283a659d48aabac8246eb8a45c19', 'arxivId': '1901.05657', 'publication_year': 2019, 'abstract': None}
{'title': 'Adversarial Active Learning for Deep Networks: a Margin Based Approach', 'paperID': '114c1ed1ae2e2a4b3d775c5a55d2c916f9d85972', 'arxivId': '1802.09841', 'publication_year': 2018, 'abstract': None}
{'title': 'Active Learning for Convolutional Neural Networks: A Core-Set Approach', 'paperID': 'c342c71cb23199f112d0bc644fcce56a7306bf94', 'arxivId': None, 'publication_year': 2017, 'abstract': None}
{'title': 'Dependent Randomized Rounding for Matroid Polytopes and Applications', 'paperID': '8291709487502991a839ae35bc90e1223413fe05', 'arxivId': '0909.4348', 'publication_year': 2009, 'abstract': None}
{'title': 'Entropy-based active learning for object recognition', 'paperID': '777b96abef29da63d9b4b1a583fa25c24a5ee029', 'arxivId': None, 'publication_year': 2008, 'abstract': None}
{'title': 'Margin Based Active Learning', 'paperID': '55801c892f628156a73e86ab271b03fe5d0c41fc', 'arxivId': None, 'publication_year': 2007, 'abstract': None}
{'title': 'Margin-Based Active Learning for Structured Output Spaces', 'paperID': '8f13f2964c255f99cfe03bef02b74a3f1be138d8', 'arxivId': None, 'publication_year': 2006, 'abstract': None}
{'title': 'Zur Theorie der Gesellschaftsspiele', 'paperID': '90d88e38b1fc555012394824d7e9a36171fc0d23', 'arxivId': None, 'publication_year': 1928, 'abstract': None}
{'title': 'QActor: Active Learning on Noisy Labels', 'paperID': '241ecd3c3720723534505b4a03f9f9e03a3897a6', 'arxivId': None, 'publication_year': 2021, 'abstract': None}
{'title': 'Robust Active Distillation', 'paperID': '175a2ed466f02c8fcef66b7ead61578700173e7c', 'arxivId': '2210.01213', 'publication_year': '2022', 'abstract': 'Distilling knowledge from a large teacher model to a lightweight one is a widely successful approach for generating compact, powerful models in the semi-supervised learning setting where a limited amount of labeled data is available. In large-scale applications, however, the teacher tends to provide a large number of incorrect soft-labels that impairs student performance. The sheer size of the teacher additionally constrains the number of soft-labels that can be queried due to prohibitive computational and/or financial costs. The difficulty in achieving simultaneous \\emph{efficiency} (i.e., minimizing soft-label queries) and \\emph{robustness} (i.e., avoiding student inaccuracies due to incorrect labels) hurts the widespread application of knowledge distillation to many modern tasks. In this paper, we present a parameter-free approach with provable guarantees to query the soft-labels of points that are simultaneously informative and correctly labeled by the teacher. At the core of our work lies a game-theoretic formulation that explicitly considers the inherent trade-off between the informativeness and correctness of input instances. We establish bounds on the expected performance of our approach that hold even in worst-case distillation instances. We present empirical evaluations on popular benchmarks that demonstrate the improved distillation performance enabled by our work relative to that of state-of-the-art active learning and active distillation methods.'}
{'title': 'Discovering Informative and Robust Positives for Video Domain Adaptation', 'paperID': '256d7fb66db5a835f8ba32f10f56899b7f318c17', 'arxivId': None, 'publication_year': None, 'abstract': None}
{'title': 'Tackling covariate shift with node-based Bayesian neural networks', 'paperID': 'c1495d5c26ed9b2dac290bf64c31ff8170928a20', 'arxivId': '2206.02435', 'publication_year': 2022, 'abstract': None}
{'title': 'The Bayesian Learning Rule', 'paperID': '7f401bb88652c5880289c24f8de214374f5df9f8', 'arxivId': '2107.04562', 'publication_year': 2021, 'abstract': None}
{'title': 'Laplace Redux - Effortless Bayesian Deep Learning', 'paperID': '8415db10a4e2354b7d57b75848f1485ce5d0e7ce', 'arxivId': '2106.14806', 'publication_year': 2021, 'abstract': None}
{'title': 'Dangers of Bayesian Model Averaging under Covariate Shift', 'paperID': '70134eb7cf302d1a2c5e9ff98c21b54e04868fea', 'arxivId': '2106.11905', 'publication_year': 2021, 'abstract': None}
{'title': 'Repulsive Deep Ensembles are Bayesian', 'paperID': 'af309f8dc435151f3f70fdbb23e67dd5ba3e518f', 'arxivId': '2106.11642', 'publication_year': 2021, 'abstract': None}
{'title': 'Being a Bit Frequentist Improves Bayesian Neural Networks', 'paperID': '1718aa3c038b8658c3958dd83f0bb286a2428086', 'arxivId': '2106.10065', 'publication_year': 2021, 'abstract': None}
{'title': 'Disentangling the Roles of Curation, Data-Augmentation and the Prior in the Cold Posterior Effect', 'paperID': '883fd1cad73f37a41196f6eeb92a07e85af8ec8c', 'arxivId': '2106.06596', 'publication_year': 2021, 'abstract': None}
{'title': 'Bayesian OOD detection with aleatoric uncertainty and outlier exposure', 'paperID': '271f06215b6500c8a25c2f61b5316d037fe3a9ec', 'arxivId': '2102.12959', 'publication_year': 2021, 'abstract': None}
{'title': 'Momentum Residual Neural Networks', 'paperID': '0c334b610b9ce71a0e3d41ed697604412e5c2aef', 'arxivId': '2102.07870', 'publication_year': 2021, 'abstract': None}
{'title': 'Gradient Regularization as Approximate Variational Inference', 'paperID': 'a364503050330f95443803b6efe0e212596d9d44', 'arxivId': None, 'publication_year': 2020, 'abstract': None}
{'title': 'A statistical theory of cold posteriors in deep neural networks', 'paperID': '6f5a417658bfa3ef86e787e837e2c47b10a2a699', 'arxivId': '2008.05912', 'publication_year': 2020, 'abstract': None}
{'title': 'Improving robustness against common corruptions by covariate shift adaptation', 'paperID': '11a1e9e8e2c4913046306d5eb31216f9d54df892', 'arxivId': '2006.16971', 'publication_year': 2020, 'abstract': None}
{'title': 'Evaluating Prediction-Time Batch Normalization for Robustness under Covariate Shift', 'paperID': '69bad7481b4c7dab2f0ac7c518c2be7256e699bf', 'arxivId': '2006.10963', 'publication_year': 2020, 'abstract': None}
{'title': 'Global inducing point variational posteriors for Bayesian neural networks and deep Gaussian processes', 'paperID': '20df27e7f38c2481723c247be798ad3d418304f6', 'arxivId': '2005.08140', 'publication_year': 2020, 'abstract': None}
{'title': 'Filter Response Normalization Layer: Eliminating Batch Dependence in the Training of Deep Neural Networks', 'paperID': '3947e574353cd1a6ec436c1e8afa07addacec4f9', 'arxivId': '1911.09737', 'publication_year': 2019, 'abstract': None}
{'title': 'Test-Time Training with Self-Supervision for Generalization under Distribution Shifts', 'paperID': '9ef24a6e06da2b6e65f0a60838b5c0a692e6c5d6', 'arxivId': None, 'publication_year': 2019, 'abstract': None}
{'title': 'Measuring Calibration in Deep Learning', 'paperID': '3b656bba99dbcf6c6d8fd764d53ea64cd38c7050', 'arxivId': '1904.01685', 'publication_year': 2019, 'abstract': None}
{'title': 'Unsupervised Domain Adaptation Using Feature-Whitening and Consensus Loss', 'paperID': 'a7a8922b0b0d6f3d439520544da7db1fd6e0dce6', 'arxivId': '1903.03215', 'publication_year': 2019, 'abstract': None}
{'title': 'Cyclical Stochastic Gradient MCMC for Bayesian Deep Learning', 'paperID': '079ce2910925dbe4272c36c7e59cfa7ce959bc24', 'arxivId': '1902.03932', 'publication_year': 2019, 'abstract': None}
{'title': 'Statistics - Growing Data Sets and Growing Demand for Statistics', 'paperID': 'f6d6367f8f267e78b2e3ddfb8b46a4819622c064', 'arxivId': None, 'publication_year': 2018, 'abstract': None}
{'title': 'Deep Convolutional Networks as shallow Gaussian Processes', 'paperID': '459c8f314986db959fad1ab962bc0bbb0e430344', 'arxivId': '1808.05587', 'publication_year': 2018, 'abstract': None}
{'title': 'Bayesian filtering unifies adaptive and non-adaptive neural network optimization methods', 'paperID': 'dc9119dffc17382793d5d5690f5df7f189b9a175', 'arxivId': '1807.07540', 'publication_year': 2018, 'abstract': None}
{'title': 'Decorrelated Batch Normalization', 'paperID': 'e8270f523375d22fd417bb583a5b50411e5d5f58', 'arxivId': '1804.08450', 'publication_year': 2018, 'abstract': None}
{'title': 'Application of Principal Component Analysis to Image Compression', 'paperID': '7ffb9c2bf11e3e0f76c756ce7b0b6eead94a582d', 'arxivId': None, 'publication_year': 2018, 'abstract': None}
{'title': 'AutoDIAL: Automatic Domain Alignment Layers', 'paperID': '5606902be2e141a96458edbf9f9aca790fbf05c0', 'arxivId': '1704.08082', 'publication_year': 2017, 'abstract': None}
{'title': 'Dermatologist-level classification of skin cancer with deep neural networks', 'paperID': 'e1ec11a1cb3d9745fb18d3bf74247f95a6663d08', 'arxivId': None, 'publication_year': 2017, 'abstract': None}
{'title': 'Revisiting Batch Normalization For Practical Domain Adaptation', 'paperID': '24da6180db314619060d7b8fc798390f0c7a139a', 'arxivId': '1603.04779', 'publication_year': 2016, 'abstract': None}
{'title': 'Probabilistic Backpropagation for Scalable Learning of Bayesian Neural Networks', 'paperID': '7e17a3c231dc37d162b9ad74043afc1cee4ee2dd', 'arxivId': '1502.05336', 'publication_year': 2015, 'abstract': None}
{'title': 'Practical Variational Inference for Neural Networks', 'paperID': '5a9ef216bf11f222438fff130c778267d39a9564', 'arxivId': None, 'publication_year': 2011, 'abstract': None}
{'title': 'Tractable Function-Space Variational Inference in Bayesian Neural Networks', 'paperID': '6498ef6ada16e3740c526a35d5ff1d48f2f64935', 'arxivId': None, 'publication_year': 2022, 'abstract': None}
{'title': 'Tent: Fully Test-Time Adaptation by Entropy Minimization', 'paperID': '180c78b132f6369a384d22a9529551d86c8788d3', 'arxivId': None, 'publication_year': 2021, 'abstract': None}
{'title': 'Robustness to corruption in pre-trained Bayesian neural networks', 'paperID': 'ef92ca5d1826b8abfc71dfb7752721de8b061ccc', 'arxivId': '2206.12361', 'publication_year': '2022', 'abstract': 'We develop ShiftMatch, a new training-data-dependent likelihood for robustness to corruption in Bayesian neural networks (BNNs). ShiftMatch is inspired by the training-data-dependent"EmpCov"priors from Izmailov et al. (2021a), and efficiently matches test-time spatial correlations to those at training time. Critically, ShiftMatch is designed to leave the neural network\'s training time likelihood unchanged, allowing it to use publicly available samples from pre-trained BNNs. Using pre-trained HMC samples, ShiftMatch gives strong performance improvements on CIFAR-10-C, outperforms EmpCov priors (though ShiftMatch uses extra information from a minibatch of corrupted test points), and is perhaps the first Bayesian method capable of convincingly outperforming plain deep ensembles.'}
{'title': 'Chasing All-Round Graph Representation Robustness: Model, Training, and Optimization', 'paperID': '89eb2fd47d93dd15354c84c41df599669c68b829', 'arxivId': None, 'publication_year': None, 'abstract': None}
{'title': 'Extracting Robust Models with Uncertain Examples', 'paperID': '7fd631dd3783704f8a58ffbd13cf41d307169982', 'arxivId': None, 'publication_year': None, 'abstract': None}
{'title': 'Balancing Unobserved Confounding with a Few Unbiased Ratings in Debiased Recommendations', 'paperID': '208b580fcee87d8b0494b5fcde4f2ca269018399', 'arxivId': '2304.09085', 'publication_year': 2023, 'abstract': None}
{'title': 'A Generalized Doubly Robust Learning Framework for Debiasing Post-Click Conversion Rate Prediction', 'paperID': 'bb619a4013100526f7d23972ffc2d971aeca006b', 'arxivId': '2211.06684', 'publication_year': 2022, 'abstract': None}
{'title': 'Addressing Unmeasured Confounder for Recommendation with Sensitivity Analysis', 'paperID': '0c5c135d9ae812dddcbc07f81c7ca18bdac4f756', 'arxivId': None, 'publication_year': 2022, 'abstract': None}
{'title': 'Multiple Robust Learning for Recommendation', 'paperID': '50ba1ee99c52448b0abdc0143315449fa4f5664b', 'arxivId': '2207.10796', 'publication_year': 2022, 'abstract': None}
{'title': 'On the Opportunity of Causal Learning in Recommendation Systems: Foundation, Estimation, Prediction and Challenges', 'paperID': '4c15a32869bbd020e1f0f3a15e73665b5e14a079', 'arxivId': '2201.06716', 'publication_year': 2022, 'abstract': None}
{'title': 'Propensity Score Regression for Causal Inference With Treatment Heterogeneity', 'paperID': '7ad5426ab5bc09c7c5b1a3bb3c8c55cf41236e30', 'arxivId': '2109.07722', 'publication_year': 2021, 'abstract': None}
{'title': 'Mitigating Confounding Bias in Recommendation via Information Bottleneck', 'paperID': '434afac50609d1354f7010afad6bed5dcb725adf', 'arxivId': None, 'publication_year': 2021, 'abstract': None}
{'title': 'Enhanced Doubly Robust Learning for Debiasing Post-Click Conversion Rate Estimation', 'paperID': '9376040172d0506e2a2f44cba6880c0b066a860b', 'arxivId': '2105.13623', 'publication_year': 2021, 'abstract': None}
{'title': 'Model-Assisted Inference for Covariate-Specific Treatment Effects with High-dimensional Data', 'paperID': '3eede21a6b405fb7c697cd6d6982df30dafb2d16', 'arxivId': '2105.11362', 'publication_year': 2021, 'abstract': None}
{'title': 'Causal Intervention for Leveraging Popularity Bias in Recommendation', 'paperID': 'afea12302cab67757e61dfb13aec6d864ccbfc4b', 'arxivId': '2105.06067', 'publication_year': 2021, 'abstract': None}
{'title': 'AutoDebias: Learning to Debias for Recommendation', 'paperID': '1e0a6c8fb7cf57f05fbb37e701922f07ff644b2f', 'arxivId': '2105.04170', 'publication_year': 2021, 'abstract': None}
{'title': 'Semiparametric estimation for average causal effects using propensity score-based spline', 'paperID': '6e843e6d2f863abe3f4bf55b5942376953201300', 'arxivId': None, 'publication_year': 2021, 'abstract': None}
{'title': 'Combating Selection Biases in Recommender Systems with a Few Unbiased Ratings', 'paperID': '6b62c1b97fff1c9a95964263a6036e7aea4faf41', 'arxivId': None, 'publication_year': 2021, 'abstract': None}
{'title': 'Bias and Debias in Recommender System: A Survey and Future Directions', 'paperID': '9779f919685adee936835eff46914d3d69d9ccb9', 'arxivId': '2010.03240', 'publication_year': 2020, 'abstract': None}
{'title': 'Doubly Robust Estimator for Ranking Metrics with Post-Click Conversions', 'paperID': '138310d7f1ce03fc90437e5a250338eb692f54c3', 'arxivId': None, 'publication_year': 2020, 'abstract': None}
{'title': 'Causal Inference for Recommender Systems', 'paperID': 'ca94b305307b8df8997fc14ffaf90fa96623cc1e', 'arxivId': None, 'publication_year': 2020, 'abstract': None}
{'title': 'Information Theoretic Counterfactual Learning from Missing-Not-At-Random Feedback', 'paperID': '77119c507e9bb041fa06452ee193208b690cc9c3', 'arxivId': '2009.02623', 'publication_year': 2020, 'abstract': None}
{'title': 'A General Knowledge Distillation Framework for Counterfactual Recommendation via Uniform Data', 'paperID': '6deae79dec438eaaa524bca3b82c6b8d93553b20', 'arxivId': None, 'publication_year': 2020, 'abstract': None}
{'title': 'Improving Ad Click Prediction by Considering Non-displayed Events', 'paperID': '55e0d3689916c2d0a4ed9c7750e6110ac5f649e1', 'arxivId': None, 'publication_year': 2019, 'abstract': None}
{'title': 'Large-scale Causal Approaches to Debiasing Post-click Conversion Rate Estimation with Multi-task Learning', 'paperID': '228693df677bc83d397d72254de662e93863aaf3', 'arxivId': '1910.09337', 'publication_year': 2019, 'abstract': None}
{'title': 'Unbiased Recommender Learning from Missing-Not-At-Random Implicit Feedback', 'paperID': '14d034b9cc6c74bd16b1388402342efb44649df0', 'arxivId': '1909.03601', 'publication_year': 2019, 'abstract': None}
{'title': 'Asymmetric Tri-training for Debiasing Missing-Not-At-Random Explicit Feedback', 'paperID': '1eab1ac24f6fcf3d2fea34086f9b3c2bb55ff2a4', 'arxivId': '1910.01444', 'publication_year': 2019, 'abstract': None}
{'title': 'Adapting Neural Networks for the Estimation of Treatment Effects', 'paperID': 'a278c07c8bd2921e59dd862cd91a0540dd340030', 'arxivId': '1906.02120', 'publication_year': 2019, 'abstract': None}
{'title': 'Doubly Robust Joint Learning for Recommendation on Data Missing Not at Random', 'paperID': '26bdee2a6bc66ebfbccb31f11ac99cee4fe758c0', 'arxivId': None, 'publication_year': 2019, 'abstract': None}
{'title': 'Unbiased Learning to Rank with Unbiased Propensity Estimation', 'paperID': 'f45cfe62446fc2d1b5ad9c351a2438faaa9c6553', 'arxivId': '1804.05938', 'publication_year': 2018, 'abstract': None}
{'title': 'Targeted Learning in Data Science. Causal Inference for Complex Longitudinal Studies.', 'paperID': '71b12ce56bc79831d09d75eda30b2b34bb8d245d', 'arxivId': None, 'publication_year': 2018, 'abstract': None}
{'title': 'Causal embeddings for recommendation', 'paperID': 'c8211bc846a42de016fc6b31e17bda2d33016ef2', 'arxivId': '1706.07639', 'publication_year': 2017, 'abstract': None}
{'title': 'Are You Influenced by Others When Rating?: Improve Rating Prediction by Conformity Modeling', 'paperID': 'a3a2de9fb051723080b57e3e61870a5b2c0643f0', 'arxivId': None, 'publication_year': 2016, 'abstract': None}
{'title': 'Recommendations as Treatments: Debiasing Learning and Evaluation', 'paperID': 'e108e3925e5abf9423ec95fd634a3a9417fcc3eb', 'arxivId': '1602.05352', 'publication_year': 2016, 'abstract': None}
{'title': 'The Self-Normalized Estimator for Counterfactual Learning', 'paperID': '42ba8ecee544a7ed87b201bca3f88d742ecfe6a1', 'arxivId': None, 'publication_year': 2015, 'abstract': None}
{'title': 'Probabilistic Matrix Factorization with Non-random Missing Data', 'paperID': '1313e362d366a1f6e13c9ba8b2548f675226f4f4', 'arxivId': None, 'publication_year': 2014, 'abstract': None}
{'title': 'A double robust approach to causal effects in case-control studies.', 'paperID': 'e158ea00669155bf8614a70604f04fbb6753f447', 'arxivId': None, 'publication_year': 2014, 'abstract': None}
{'title': 'A General Implementation of TMLE for Longitudinal Data Applied to Causal Inference in Survival Analysis', 'paperID': '18205fb6d7d49e0f96b78debb396315001c33a2f', 'arxivId': None, 'publication_year': 2012, 'abstract': None}
{'title': 'Targeted Learning: Causal Inference for Observational and Experimental Data', 'paperID': '98f3a77510de4d72a38359e61de69f22baa53970', 'arxivId': None, 'publication_year': 2011, 'abstract': None}
{'title': 'Training and testing of recommender systems on data missing not at random', 'paperID': 'f0636bad1e8d3c1a19894d1995b03b26bf6033f1', 'arxivId': None, 'publication_year': 2010, 'abstract': None}
{'title': 'Matrix Factorization Techniques for Recommender Systems', 'paperID': 'd4bbcc842f22547eaf5884251eaa68251895dccb', 'arxivId': None, 'publication_year': 2009, 'abstract': None}
{'title': 'Comment: Understanding OR, PS and DR', 'paperID': 'feaedbc49ea2791e717de76b9c8afe96a06de41d', 'arxivId': '0804.2969', 'publication_year': 2007, 'abstract': None}
{'title': 'Demystifying Double Robustness: A Comparison of Alternative Strategies for Estimating a Population Mean from Incomplete Data', 'paperID': 'fd855edabd177f903df92a82514bfaa68335ba0b', 'arxivId': '0804.2958', 'publication_year': 2007, 'abstract': None}
{'title': 'On the Application of Probability Theory to Agricultural Experiments. Essay on Principles. Section 9', 'paperID': '5e85cd9baebc529281a66e0bbeaaa7f44c92c9d6', 'arxivId': None, 'publication_year': 1990, 'abstract': None}
{'title': '[On the Application of Probability Theory to Agricultural Experiments. Essay on Principles. Section 9.] Comment: Neyman (1923) and Causal Inference in Experiments and Observational Studies', 'paperID': 'fe86c9ef608d5cd33c496d182879192287cf8569', 'arxivId': None, 'publication_year': 1990, 'abstract': None}
{'title': 'Estimating causal effects of treatments in randomized and nonrandomized studies.', 'paperID': '545122e2990590524459ec9b59ccac6ce71e3b6a', 'arxivId': None, 'publication_year': 1974, 'abstract': None}
{'title': 'Stabilized Doubly Robust Learning for Recommendation on Data Missing Not at Random', 'paperID': '9f501be340839457bd963c8dfd5096ba451594c0', 'arxivId': None, 'publication_year': 2022, 'abstract': None}
{'title': 'Doubly-Robust Estimation for Unbiased Learning-to-Rank from Position-Biased Click Feedback', 'paperID': 'f5f2ff8f7ad44aba3eec5d8a287cc1b6c498042b', 'arxivId': None, 'publication_year': 2022, 'abstract': None}
{'title': 'Handbook of Missing Data Methodology', 'paperID': 'ad2f23ebbd072af02d973bf8d7b01c8cd2d4addc', 'arxivId': None, 'publication_year': 2019, 'abstract': None}
{'title': 'Design Of Observational Studies', 'paperID': '209844292cabe3cfb84e2f8dbd90d3e48bc8b41c', 'arxivId': None, 'publication_year': 2016, 'abstract': None}
{'title': 'Causal Inference for Statistics, Social, and Biomedical Sciences: Sensitivity Analysis and Bounds', 'paperID': 'f9748f18f14a4a2995e780e6ea50bd1af6768672', 'arxivId': None, 'publication_year': 2015, 'abstract': None}
{'title': 'Higher-order Targeted Minimum Loss-based Estimation', 'paperID': 'a7b6848a8b07bf21fb7936b6f21b02299056697e', 'arxivId': None, 'publication_year': 2014, 'abstract': None}
{'title': 'An Application of Collaborative Targeted Maximum Likelihood Estimation in Causal Inference and Genomics', 'paperID': '91939331adcd898603ca321060a67caf62d4d48b', 'arxivId': None, 'publication_year': 2010, 'abstract': None}
{'title': 'TDR-CL: Targeted Doubly Robust Collaborative Learning for Debiased Recommendations', 'paperID': '84b9802042f29f4490eb36c2ac69a8ce9cdb2196', 'arxivId': '2203.10258', 'publication_year': '2022', 'abstract': "Bias is a common problem inherent in recommender systems, which is entangled with users' preferences and poses a great challenge to unbiased learning. For debiasing tasks, the doubly robust (DR) method and its variants show superior performance due to the double robustness property, that is, DR is unbiased when either imputed errors or learned propensities are accurate. However, our theoretical analysis reveals that DR usually has a large variance. Meanwhile, DR would suffer unexpectedly large bias and poor generalization caused by inaccurate imputed errors and learned propensities, which usually occur in practice. In this paper, we propose a principled approach that can effectively reduce bias and variance simultaneously for existing DR approaches when the error imputation model is misspecified. In addition, we further propose a novel semi-parametric collaborative learning approach that decomposes imputed errors into parametric and nonparametric parts and updates them collaboratively, resulting in more accurate predictions. Both theoretical analysis and experiments demonstrate the superiority of the proposed methods compared with existing debiasing methods."}
{'title': 'Towards Robust Object Detection Invariant to Real-World Domain Shifts', 'paperID': '928ca39340784fafca5411d5d45a322463a1aea6', 'arxivId': None, 'publication_year': None, 'abstract': None}
{'title': 'Distributionally-robust Recommendations for Improving Worst-case User Experience', 'paperID': '098cb8e0ff46fd05b193cc465d1e577ceb365e9b', 'arxivId': None, 'publication_year': 2022, 'abstract': None}
{'title': 'Unbiased Learning for the Causal Effect of Recommendation', 'paperID': '8ee4a0164f4f95eb012c3f565d0866e5f4f7d64b', 'arxivId': '2008.04563', 'publication_year': 2020, 'abstract': None}
{'title': 'Feedback Loop and Bias Amplification in Recommender Systems', 'paperID': 'b258a20ef49bbed030dfd78c58b7b5fe284e9d04', 'arxivId': None, 'publication_year': 2020, 'abstract': None}
{'title': 'Uplift-based evaluation and optimization of recommenders', 'paperID': '8fdc29ceb4cc4b773c9a8f0a022191f982135762', 'arxivId': None, 'publication_year': 2019, 'abstract': None}
{'title': 'Neural Collaborative Filtering', 'paperID': 'ad42c33c299ef1c53dfd4697e3f7f98ed0ca31dd', 'arxivId': '1708.05031', 'publication_year': 2017, 'abstract': None}
{'title': 'Evaluation of recommendations: rating-prediction and ranking', 'paperID': '2592d9d68f2b29da197c16b2c7f6519ee6304ad6', 'arxivId': None, 'publication_year': 2013, 'abstract': None}
{'title': 'SLIM: Sparse Linear Methods for Top-N Recommender Systems', 'paperID': '3b0c39b323a8cc1a90b3fdee83dad2fd417bd0ce', 'arxivId': None, 'publication_year': 2011, 'abstract': None}
{'title': 'Doubly Robust Estimation in Missing Data and Causal Inference Models', 'paperID': 'a85acbe6ff39173031d877eaf79af3ca52bbc20f', 'arxivId': None, 'publication_year': 2005, 'abstract': None}
{'title': 'Doubly Robust Prediction and Evaluation Methods Improve Uplift Modeling for Observational Data', 'paperID': '4cb2971b451749835d353989254b8b0209ab8d70', 'arxivId': None, 'publication_year': 2019, 'abstract': None}
{'title': 'Unbiased Pairwise Learning from Implicit Feedback', 'paperID': '2eb1685b35e0de1f450b870b1a31be8d58f7b284', 'arxivId': None, 'publication_year': 2019, 'abstract': None}
{'title': 'StableDR: Stabilized Doubly Robust Learning for Recommendation on Data Missing Not at Random', 'paperID': 'c1ff3661f3edf5e0571da6d8aaf852cd6df84318', 'arxivId': '2205.04701', 'publication_year': '2022', 'abstract': 'In recommender systems, users always choose the favorite items to rate, which leads to data missing not at random and poses a great challenge for unbiased evaluation and learning of prediction models. Currently, the doubly robust (DR) methods have been widely studied and demonstrate superior performance. However, in this paper, we show that DR methods are unstable and have unbounded bias, variance, and generalization bounds to extremely small propensities. Moreover, the fact that DR relies more on extrapolation will lead to suboptimal performance. To address the above limitations while retaining double robustness, we propose a stabilized doubly robust (StableDR) learning approach with a weaker reliance on extrapolation. Theoretical analysis shows that StableDR has bounded bias, variance, and generalization error bound simultaneously under inaccurate imputed errors and arbitrarily small propensities. In addition, we propose a novel learning approach for StableDR that updates the imputation, propensity, and prediction models cyclically, achieving more stable and accurate predictions. Extensive experiments show that our approaches significantly outperform the existing methods.'}
{'title': 'Your Contrastive Learning Is Secretly Doing Stochastic Neighbor Embedding', 'paperID': '740b343fac0e9bc5b1906c99c1071b67f4c163e1', 'arxivId': '2205.14814', 'publication_year': 2022, 'abstract': None}
{'title': 'Beyond Separability: Analyzing the Linear Transferability of Contrastive Representations to Related Subpopulations', 'paperID': '1de398ad15d72baef5d3fc4274c6ecf6557d7a3d', 'arxivId': '2204.02683', 'publication_year': 2022, 'abstract': None}
{'title': 'Connect, Not Collapse: Explaining Contrastive Learning for Unsupervised Domain Adaptation', 'paperID': '5ce79f612034d36a955e0e4ebaf5c57fe29d4b31', 'arxivId': '2204.00570', 'publication_year': 2022, 'abstract': None}
{'title': 'Towards the Generalization of Contrastive Self-Supervised Learning', 'paperID': '3ed2b5a9c8e42f3bf93dfd40426e4df205420ac7', 'arxivId': '2111.00743', 'publication_year': 2021, 'abstract': None}
{'title': 'Self-Supervised Learning Disentangled Group Representation as Feature', 'paperID': '1da867c102a407171e64e2b28cb2f9ce63325ee6', 'arxivId': '2110.15255', 'publication_year': 2021, 'abstract': None}
{'title': 'On the Surrogate Gap between Contrastive and Supervised Losses', 'paperID': '0f2aeeb62b6f0e6fd6034715bac08904a59f9ffa', 'arxivId': '2110.02501', 'publication_year': 2021, 'abstract': None}
{'title': 'Generative Models as a Data Source for Multiview Representation Learning', 'paperID': '3743249bf829cbe0de72cc49371f51c40d7cf56c', 'arxivId': '2106.05258', 'publication_year': 2021, 'abstract': None}
{'title': 'Towards a Theoretical Framework of Out-of-Distribution Generalization', 'paperID': '60571e69c2263094478efba76cc8f26f9ad84852', 'arxivId': '2106.04496', 'publication_year': 2021, 'abstract': None}
{'title': 'Self-Supervised Learning with Data Augmentations Provably Isolates Content from Style', 'paperID': '5b00442bd7e12ac1c614127f1f6429c8df3747bc', 'arxivId': '2106.04619', 'publication_year': 2021, 'abstract': None}
{'title': 'How Well Do Self-Supervised Models Transfer?', 'paperID': '00969b4dcf8f9b21895bd038a51a038018da84f0', 'arxivId': '2011.13377', 'publication_year': 2020, 'abstract': None}
{'title': 'Learning Causal Semantic Representation for Out-of-Distribution Prediction', 'paperID': 'bf5c55630b5f79806ea9ad68d86f5ff0cf1b2fb0', 'arxivId': '2011.01681', 'publication_year': 2020, 'abstract': None}
{'title': 'On Disentangled Representations Learned from Correlated Data', 'paperID': '192029e99ae4364968803abc5885c7a159f8a9ff', 'arxivId': '2006.07886', 'publication_year': 2020, 'abstract': None}
{'title': 'Adversarial Self-Supervised Contrastive Learning', 'paperID': 'c7316921fa83d4b4c433fd04ed42839d641acbe0', 'arxivId': '2006.07589', 'publication_year': 2020, 'abstract': None}
{'title': 'Domain Extrapolation via Regret Minimization', 'paperID': '0ad5f44fc605d1d2759a22c05a4883b9ec05b234', 'arxivId': '2006.03908', 'publication_year': 2020, 'abstract': None}
{'title': 'Stable Prediction with Model Misspecification and Agnostic Distribution Shift', 'paperID': '642c5831e2a497752475a8c9fded9dbb90513482', 'arxivId': '2001.11713', 'publication_year': 2020, 'abstract': None}
{'title': 'Stable Learning via Sample Reweighting', 'paperID': '98c15f7aa696f8e2eb134fb6e3f6a9263f30a804', 'arxivId': '1911.12580', 'publication_year': 2019, 'abstract': None}
{'title': 'How robust are pre-trained models to distribution shift?', 'paperID': 'ff62f1782e73c4c0766c24bcaf557fe497f6469e', 'arxivId': None, 'publication_year': 2022, 'abstract': None}
{'title': 'A Simple Framework', 'paperID': '137a74592aa36ffa5200c88a990ae4ef1a883fc6', 'arxivId': None, 'publication_year': 2015, 'abstract': None}
{'title': 'Collecting a Large-scale Dataset of Fine-grained Cars', 'paperID': 'eae500ce89f7cc5cd48a58c4ba7edb2f02826b85', 'arxivId': None, 'publication_year': 2013, 'abstract': None}
{'title': 'Investigating the role of', 'paperID': 'bd716e1214d53acb88512bffd647ffbf729026f7', 'arxivId': None, 'publication_year': 2011, 'abstract': None}
{'title': 'ArCL: Enhancing Contrastive Learning with Augmentation-Robust Representations', 'paperID': '20eaccbe4d6ffc3652594fb8783f64a653cb881a', 'arxivId': '2303.01092', 'publication_year': '2023', 'abstract': 'Self-Supervised Learning (SSL) is a paradigm that leverages unlabeled data for model training. Empirical studies show that SSL can achieve promising performance in distribution shift scenarios, where the downstream and training distributions differ. However, the theoretical understanding of its transferability remains limited. In this paper, we develop a theoretical framework to analyze the transferability of self-supervised contrastive learning, by investigating the impact of data augmentation on it. Our results reveal that the downstream performance of contrastive learning depends largely on the choice of data augmentation. Moreover, we show that contrastive learning fails to learn domain-invariant features, which limits its transferability. Based on these theoretical insights, we propose a novel method called Augmentation-robust Contrastive Learning (ArCL), which guarantees to learn domain-invariant features and can be easily integrated with existing contrastive learning algorithms. We conduct experiments on several datasets and show that ArCL significantly improves the transferability of contrastive learning.'}
{'title': 'The Power of Uniform Sampling for Coresets', 'paperID': '427f949906c52f7df1b77cdc50196d0e81b3598f', 'arxivId': '2209.01901', 'publication_year': 2022, 'abstract': None}
{'title': 'Performance of Johnson--Lindenstrauss Transform for $k$-Means and $k$-Medians Clustering', 'paperID': '27ba2c4350887185504c4c9e4e66152ca3a802cf', 'arxivId': None, 'publication_year': 2022, 'abstract': None}
{'title': 'Towards optimal lower bounds for k-median and k-means coresets', 'paperID': '0b02637eabcc140f865253ffc785e47903bcadfd', 'arxivId': '2202.12793', 'publication_year': 2022, 'abstract': None}
{'title': 'A new coreset framework for clustering', 'paperID': '19927da753e52738ee3190785cb93c82067fb3f0', 'arxivId': '2104.06133', 'publication_year': 2021, 'abstract': None}
{'title': 'A local search algorithm for k-means with outliers', 'paperID': '8953285591d97c68b401027194e7438a4efeb822', 'arxivId': None, 'publication_year': 2021, 'abstract': None}
{'title': 'k-Means: Outliers-Resistant Clustering+++', 'paperID': '049286d20f66e0ec9c2bbd9fd9116f41e0872828', 'arxivId': None, 'publication_year': 2020, 'abstract': None}
{'title': 'Coresets for Clustering in Excluded-minor Graphs and Beyond', 'paperID': '589a9140f68b800686e0100e2bd6b1b6e3c813db', 'arxivId': '2004.07718', 'publication_year': 2020, 'abstract': None}
{'title': 'Fully-Dynamic Coresets', 'paperID': '270178c8c3a65cbe5151d4b56093e1b31195e851', 'arxivId': '2004.14891', 'publication_year': 2020, 'abstract': None}
{'title': 'Coresets for clustering in Euclidean spaces: importance sampling is nearly optimal', 'paperID': '6a1fa57790b975d827fd1237d6fd174eabaff7f7', 'arxivId': '2004.06263', 'publication_year': 2020, 'abstract': None}
{'title': 'Layered Sampling for Robust Optimization Problems', 'paperID': 'c1b43d49dde0933d9fdecb34f40016cc19c6c711', 'arxivId': '2002.11904', 'publication_year': 2020, 'abstract': None}
{'title': 'Coresets for Clustering in Graphs of Bounded Treewidth', 'paperID': '4b70752c19a64707c7bbae348191e740800c4b67', 'arxivId': '1907.04733', 'publication_year': 2019, 'abstract': None}
{'title': 'Coresets for Clustering with Fairness Constraints', 'paperID': '1b287e17483abcb98678ddede572a56312ea06f0', 'arxivId': '1906.08484', 'publication_year': 2019, 'abstract': None}
{'title': 'Coresets for Ordered Weighted Clustering', 'paperID': '721ad812f4b9211fd5e5c637bf1213c37bf20324', 'arxivId': '1903.04351', 'publication_year': 2019, 'abstract': None}
{'title': 'Performance of Johnson-Lindenstrauss transform for k-means and k-medians clustering', 'paperID': 'faa6d9b78cfdcf2d33979d93ca0ee80793b3a1d4', 'arxivId': '1811.03195', 'publication_year': 2018, 'abstract': None}
{'title': 'Optimal terminal dimensionality reduction in Euclidean space', 'paperID': '7175950bd7427a98cd57e3148c494bd9eaca19e3', 'arxivId': '1810.09250', 'publication_year': 2018, 'abstract': None}
{'title': 'Strong Coresets for k-Median and Subspace Approximation: Goodbye Dimension', 'paperID': '3163c7d4562ac62573af6eb008e5a4154c0a17bd', 'arxivId': '1809.02961', 'publication_year': 2018, 'abstract': None}
{'title': 'Low Rank Approximation in the Presence of Outliers', 'paperID': 'ff67cceccf34fbfc5728f7cb5c3f25019fa29d91', 'arxivId': '1804.10696', 'publication_year': 2018, 'abstract': None}
{'title': 'Epsilon-Coresets for Clustering (with Outliers) in Doubling Metrics', 'paperID': 'b6b02cbc2979d16ec371568513a3c07afa82b01a', 'arxivId': '1804.02530', 'publication_year': 2018, 'abstract': None}
{'title': 'Constant approximation for k-median and k-means with outliers via iterative rounding', 'paperID': '160603fd5e58c82deaa3e8557a2a4dd329c70272', 'arxivId': '1711.01323', 'publication_year': 2017, 'abstract': None}
{'title': 'Approximation Schemes for Clustering with Outliers', 'paperID': '06e26e8d7999af9aca0b342c4e8e553b4979cdbb', 'arxivId': '1707.04295', 'publication_year': 2017, 'abstract': None}
{'title': 'Local Search Methods for k-Means with Outliers', 'paperID': 'c8a7ac02eb26260fe5559df8d2bc98b4323ba7f7', 'arxivId': None, 'publication_year': 2017, 'abstract': None}
{'title': 'New Frameworks for Offline and Streaming Coreset Constructions', 'paperID': '74d62dd6be70c7e06ac48ca5f8953cd811d857d1', 'arxivId': '1612.00889', 'publication_year': 2016, 'abstract': None}
{'title': 'On the Least Trimmed Squares Estimator', 'paperID': '97067d88eebc098b76ff19eb498b5d414b49e474', 'arxivId': None, 'publication_year': 2014, 'abstract': None}
{'title': 'Turning big data into tiny data: Constant-size coresets for k-means, PCA and projective clustering', 'paperID': 'ceb55d64d564dae512fa07c5cee5386dac083e4f', 'arxivId': '1807.04518', 'publication_year': 2013, 'abstract': None}
{'title': 'Data reduction for weighted and outlier-resistant clustering', 'paperID': '04ac298d0516535289950588dfe850bbe8c68d7e', 'arxivId': None, 'publication_year': 2012, 'abstract': None}
{'title': 'Geometric Approximation Algorithms', 'paperID': 'dcd5249802ffb7c005776c5f18c20dc12e699171', 'arxivId': None, 'publication_year': 2011, 'abstract': None}
{'title': 'A unified framework for approximating and clustering data', 'paperID': '89ffb191d8c370ca74ee57e6dcd63ae04628f84d', 'arxivId': '1106.1379', 'publication_year': 2011, 'abstract': None}
{'title': 'A constant factor approximation algorithm for k-median clustering with outliers', 'paperID': '6890040ee813e041d4777f921c743fa86db8b1a6', 'arxivId': None, 'publication_year': 2008, 'abstract': None}
{'title': 'Robust Regression and Outlier Detection', 'paperID': 'ae3f31c841c460b15a81bf51655f4c0e39cacc79', 'arxivId': None, 'publication_year': 2005, 'abstract': None}
{'title': 'On coresets for k-means and k-median clustering', 'paperID': '2a380830759161fae7d10858441999c7fa000570', 'arxivId': None, 'publication_year': 2004, 'abstract': None}
{'title': 'Algorithms for facility location problems with outliers', 'paperID': '0b490334ae4d06330bcfecbf7184b7c458a1f6e9', 'arxivId': None, 'publication_year': 2001, 'abstract': None}
{'title': 'Improved bounds on the sample complexity of learning', 'paperID': '8aabf3f17f357ccf85c2f0280a60f05ea628218c', 'arxivId': None, 'publication_year': 2000, 'abstract': None}
{'title': 'Improved Coresets and Sublinear Algorithms for Power Means in Euclidean Spaces', 'paperID': '2c963d2f8a0bfcc0b67af9a90e95f4c77253cdec', 'arxivId': None, 'publication_year': 2021, 'abstract': None}
{'title': 'Robust k-means++', 'paperID': '6060d67b191aa833923f66c09be6b73d5e56aa0f', 'arxivId': None, 'publication_year': 2020, 'abstract': None}
{'title': 'Improved Algorithms for Clustering with Outliers', 'paperID': 'd3522be0aa8ef5c05e150bb3f63aba20f21d555b', 'arxivId': None, 'publication_year': 2019, 'abstract': None}
{'title': 'Greedy Sampling for Approximate Clustering in the Presence of Outliers', 'paperID': 'c9b55c422cf5f4f0a08ada022714d9695af136bc', 'arxivId': None, 'publication_year': 2019, 'abstract': None}
{'title': 'k-means-: A Unified Approach to Clustering and Outlier Detection', 'paperID': 'e385d9f832162080025d681aaa8f6bc01ccadc4a', 'arxivId': None, 'publication_year': 2013, 'abstract': None}
{'title': 'Distributed k-means and k-median clustering on general communication topologies', 'paperID': '41b279aa2cb4823b590f79fe0e8739b1be059297', 'arxivId': None, 'publication_year': 2013, 'abstract': None}
{'title': 'Near-optimal Coresets for Robust Clustering', 'paperID': '0aec562c8cc3d1004ea86f601b6b42734454466b', 'arxivId': '2210.10394', 'publication_year': '2022', 'abstract': "We consider robust clustering problems in $\\mathbb{R}^d$, specifically $k$-clustering problems (e.g., $k$-Median and $k$-Means with $m$ outliers, where the cost for a given center set $C \\subset \\mathbb{R}^d$ aggregates the distances from $C$ to all but the furthest $m$ data points, instead of all points as in classical clustering. We focus on the $\\epsilon$-coreset for robust clustering, a small proxy of the dataset that preserves the clustering cost within $\\epsilon$-relative error for all center sets. Our main result is an $\\epsilon$-coreset of size $O(m + \\mathrm{poly}(k \\epsilon^{-1}))$ that can be constructed in near-linear time. This significantly improves previous results, which either suffers an exponential dependence on $(m + k)$ [Feldman and Schulman, SODA'12], or has a weaker bi-criteria guarantee [Huang et al., FOCS'18]. Furthermore, we show this dependence in $m$ is nearly-optimal, and the fact that it is isolated from other factors may be crucial for dealing with large number of outliers. We construct our coresets by adapting to the outlier setting a recent framework [Braverman et al., FOCS'22] which was designed for capacity-constrained clustering, overcoming a new challenge that the participating terms in the cost, particularly the excluded $m$ outlier points, are dependent on the center set $C$. We validate our coresets on various datasets, and we observe a superior size-accuracy tradeoff compared with popular baselines including uniform sampling and sensitivity sampling. We also achieve a significant speedup of existing approximation algorithms for robust clustering using our coresets."}
{'title': 'Adversarial training with informed data selection', 'paperID': 'c1d9f0ea53ef6d9a44ff46b071fb45cd3de58fbd', 'arxivId': '2301.04472', 'publication_year': 2022, 'abstract': None}
{'title': 'Interpolation can hurt robust generalization even when there is no noise', 'paperID': '93733d2e31a9e9318282391c1962e2855698ca61', 'arxivId': '2108.02883', 'publication_year': 2021, 'abstract': None}
{'title': 'Real-Time Hand Gesture Recognition Based on Deep Learning YOLOv3 Model', 'paperID': '559930ae79ea2dfcefb8658a2dcdf8c849cc897d', 'arxivId': None, 'publication_year': 2021, 'abstract': None}
{'title': 'Data Quality Matters For Adversarial Training: An Empirical Study', 'paperID': '16b6c80a2a113a90868ea37c1f7aabd85ce04fe7', 'arxivId': '2102.07437', 'publication_year': 2021, 'abstract': None}
{'title': 'Adversarial Perturbations Are Not So Weird: Entanglement of Robust and Non-Robust Features in Neural Network Classifiers', 'paperID': '4cdca901e6324198501ebda9100a1877d19ebb88', 'arxivId': '2102.05110', 'publication_year': 2021, 'abstract': None}
{'title': 'Recent Advances in Adversarial Training for Adversarial Robustness', 'paperID': '17af9510a38e4dec93398707f11d833c8af36254', 'arxivId': '2102.01356', 'publication_year': 2021, 'abstract': None}
{'title': 'Dual Manifold Adversarial Robustness: Defense against Lp and non-Lp Adversarial Attacks', 'paperID': '2e165871bdfe21fe8389087696030ac33edd7f17', 'arxivId': '2009.02470', 'publication_year': 2020, 'abstract': None}
{'title': 'Manifold Projection for Adversarial Defense on Face Recognition', 'paperID': '078ac3d05afb953585ae17e914c6b4d0571f6421', 'arxivId': None, 'publication_year': 2020, 'abstract': None}
{'title': 'Hand Gesture Recognition Based on Computer Vision: A Review of Techniques', 'paperID': 'b4efbd4e0885d8a2e98acb5a23acbc134e08e8d1', 'arxivId': None, 'publication_year': 2020, 'abstract': None}
{'title': 'On the Loss Landscape of Adversarial Training: Identifying Challenges and How to Overcome Them', 'paperID': '7451d83e3eac30ba719ecea9a051af33dd10fc66', 'arxivId': '2006.08403', 'publication_year': 2020, 'abstract': None}
{'title': 'Provable tradeoffs in adversarially robust classification', 'paperID': '72c19697e0edf92f838103029ce77b88cce6d685', 'arxivId': '2006.05161', 'publication_year': 2020, 'abstract': None}
{'title': 'Towards Understanding Fast Adversarial Training', 'paperID': '1378789c465d8de3e8ec5032be89ab672feaada2', 'arxivId': '2006.03089', 'publication_year': 2020, 'abstract': None}
{'title': 'Implicit Bias of Gradient Descent based Adversarial Training on Separable Data', 'paperID': '5f7d3a9299c78dde60106324c7a145afaba82bb2', 'arxivId': None, 'publication_year': 2020, 'abstract': None}
{'title': 'Precise Tradeoffs in Adversarial Training for Linear Regression', 'paperID': 'bff4ae911351a5c7dd9af394aa7f2647bf42dd4a', 'arxivId': '2002.10477', 'publication_year': 2020, 'abstract': None}
{'title': 'Implicit Bias of Gradient Descent for Wide Two-layer Neural Networks Trained with the Logistic Loss', 'paperID': '58eee79dd9e1e9aa482656fa3d256b64620dd30a', 'arxivId': '2002.04486', 'publication_year': 2020, 'abstract': None}
{'title': 'More Data Can Expand the Generalization Gap Between Adversarially Robust and Standard Models', 'paperID': '0a16a0396a9cbe298a110b69b3b2006692f2b78b', 'arxivId': '2002.04725', 'publication_year': 2020, 'abstract': None}
{'title': 'Adversarial Domain Adaptation with Domain Mixup', 'paperID': '78fd36163d6fc32dce1ad7d5b8c1203e6b212fcf', 'arxivId': '1912.01805', 'publication_year': 2019, 'abstract': None}
{'title': 'Towards Large Yet Imperceptible Adversarial Image Perturbations With Perceptual Color Distance', 'paperID': '54c15364b5873e39257c221112fdf22299ed9e8a', 'arxivId': '1911.02466', 'publication_year': 2019, 'abstract': None}
{'title': 'A real-time gesture recognition system using near-infrared imagery', 'paperID': '987d1d8eb739f8deb449fdc4f4c29cac9499b74e', 'arxivId': None, 'publication_year': 2019, 'abstract': None}
{'title': 'Defending Against Physically Realizable Attacks on Image Classification', 'paperID': '302ba3a3de585baa7c5692eebd14d5328b0a780a', 'arxivId': '1909.09552', 'publication_year': 2019, 'abstract': None}
{'title': 'The implicit bias of gradient descent on nonseparable data', 'paperID': '76c2679deb0b7689c658c199254963889d4d2b69', 'arxivId': None, 'publication_year': 2019, 'abstract': None}
{'title': 'Uniform convergence may be unable to explain generalization in deep learning', 'paperID': '2b627185499791048681e8d24190c31dea928f16', 'arxivId': '1902.04742', 'publication_year': 2019, 'abstract': None}
{'title': 'Adversarial Risk Bounds via Function Transformation', 'paperID': 'a857007d5d240fe3cf6ffe96e57e163a1105e00e', 'arxivId': None, 'publication_year': 2018, 'abstract': None}
{'title': 'Stochastic Gradient Descent on Separable Data: Exact Convergence with a Fixed Learning Rate', 'paperID': 'd8b477a120798e3c8983de485c1a8cff06ff33db', 'arxivId': '1806.01796', 'publication_year': 2018, 'abstract': None}
{'title': 'Towards Imperceptible and Robust Adversarial Example Attacks against Neural Networks', 'paperID': '516afc7d5a427f0b53ca459fe2624a1aae2ee00d', 'arxivId': '1801.04693', 'publication_year': 2018, 'abstract': None}
{'title': 'Hand gesture recognition: An overview', 'paperID': '739915dff9f3eb1b52d435ba52b5890737e5df99', 'arxivId': None, 'publication_year': 2013, 'abstract': None}
{'title': 'Margins, Shrinkage, and Boosting', 'paperID': '2cf3142e55965c6dce7e3ee2f93d1fb2d5aba416', 'arxivId': '1303.4172', 'publication_year': 2013, 'abstract': None}
{'title': 'Caltech-UCSD Birds 200', 'paperID': 'a48a56b0727d09f599676524fe190308d9e88bf1', 'arxivId': None, 'publication_year': 2010, 'abstract': None}
{'title': 'Why adversarial training can hurt robust accuracy', 'paperID': '1dd1795f6fa368b61c78c3afccf194bbcf25ed3a', 'arxivId': '2203.02006', 'publication_year': '2022', 'abstract': 'Machine learning classifiers with high test accuracy often perform poorly under adversarial attacks. It is commonly believed that adversarial training alleviates this issue. In this paper, we demonstrate that, surprisingly, the opposite may be true -- Even though adversarial training helps when enough data is available, it may hurt robust generalization in the small sample size regime. We first prove this phenomenon for a high-dimensional linear classification setting with noiseless observations. Our proof provides explanatory insights that may also transfer to feature learning models. Further, we observe in experiments on standard image datasets that the same behavior occurs for perceptible attacks that effectively reduce class information such as mask attacks and object corruptions.'}
{'title': 'Neural Topological Ordering for Computation Graphs', 'paperID': 'feaae6b90a94d2a7e6a23132fed9c5001773c892', 'arxivId': '2207.05899', 'publication_year': 2022, 'abstract': None}
{'title': 'Biological Sequence Design with GFlowNets', 'paperID': '94f27efa3d983ce0b79954928134263768929dcb', 'arxivId': '2203.04115', 'publication_year': 2022, 'abstract': None}
{'title': 'Bayesian Structure Learning with Generative Flow Networks', 'paperID': 'cdf4a982bf6dc373eb6463263ab5fd147c61c8ca', 'arxivId': '2202.13903', 'publication_year': 2022, 'abstract': None}
{'title': 'Generative Flow Networks for Discrete Probabilistic Modeling', 'paperID': '6e264eeff9127306775495c44f4d48839943a70a', 'arxivId': '2202.01361', 'publication_year': 2022, 'abstract': None}
{'title': 'Trajectory Balance: Improved Credit Assignment in GFlowNets', 'paperID': 'b877d25296cf390cc6b63b0e477d8febb5a81e09', 'arxivId': '2201.13259', 'publication_year': 2022, 'abstract': None}
{'title': 'Flow Network based Generative Models for Non-Iterative Diverse Candidate Generation', 'paperID': 'cb5323ef22a5a38cfba318abadcadee822ccf8a9', 'arxivId': '2106.04399', 'publication_year': 2021, 'abstract': None}
{'title': 'Score-Based Generative Modeling through Stochastic Differential Equations', 'paperID': '633e2fbfc0b21e959a244100937c5853afca4853', 'arxivId': '2011.13456', 'publication_year': 2020, 'abstract': None}
{'title': 'Learning to Dispatch for Job Shop Scheduling via Deep Reinforcement Learning', 'paperID': 'd594764273c02b5a3bbdc4a8d49979a23ad1f125', 'arxivId': '2010.12367', 'publication_year': 2020, 'abstract': None}
{'title': 'Transferable Graph Optimizers for ML Compilers', 'paperID': '378bfce88ed3139f48fba4deeafc96846c31251d', 'arxivId': '2010.12438', 'publication_year': 2020, 'abstract': None}
{'title': 'How Neural Networks Extrapolate: From Feedforward to Graph Neural Networks', 'paperID': '6b989b8327db3a7212141c59c1569f0219775058', 'arxivId': '2009.11848', 'publication_year': 2020, 'abstract': None}
{'title': 'Optimizing Memory Placement using Evolutionary Graph Reinforcement Learning', 'paperID': '95cb5128f2cb9fb7fb94f2ce62cf1fb62361cc77', 'arxivId': '2007.07298', 'publication_year': 2020, 'abstract': None}
{'title': 'Pymoo: Multi-Objective Optimization in Python', 'paperID': '61e27dbae190b82639c57f180ecf97e4c46fcad9', 'arxivId': '2002.04504', 'publication_year': 2020, 'abstract': None}
{'title': 'Placeto: Learning Generalizable Device Placement Algorithms for Distributed Machine Learning', 'paperID': '2319e4f2d73c78820d498a347d74ed5ef3a185d3', 'arxivId': '1906.08879', 'publication_year': 2019, 'abstract': None}
{'title': 'Reinforced Genetic Algorithm Learning for Optimizing Computation Graphs', 'paperID': 'bc48ecef55aeb5a31899b1995d7ae95da40ddb73', 'arxivId': '1905.02494', 'publication_year': 2019, 'abstract': None}
{'title': 'Learning scheduling algorithms for data processing clusters', 'paperID': 'ac91892a8a6b6c3e97aa92b6fa8d54b42cade0ee', 'arxivId': '1810.01963', 'publication_year': 2018, 'abstract': None}
{'title': 'Observe and Look Further: Achieving Consistent Performance on Atari', 'paperID': 'b4c8aef6cd1946d7aacd9524286637d2f825160b', 'arxivId': '1805.11593', 'publication_year': 2018, 'abstract': None}
{'title': 'Machine Learning in Compiler Optimisation', 'paperID': '6989e13df80edfc6e638e8d8502cb0739d494ca6', 'arxivId': '1805.03441', 'publication_year': 2018, 'abstract': None}
{'title': 'TVM: An Automated End-to-End Optimizing Compiler for Deep Learning', 'paperID': 'df013a17ab84d5403361da4538a04d574f58be83', 'arxivId': '1802.04799', 'publication_year': 2018, 'abstract': None}
{'title': 'FiLM: Visual Reasoning with a General Conditioning Layer', 'paperID': '7cfa5c97164129ce3630511f639040d28db1d4b7', 'arxivId': '1709.07871', 'publication_year': 2017, 'abstract': None}
{'title': 'Biased random-key genetic algorithms for\xa0combinatorial optimization', 'paperID': 'fc66d024648a89e124c637c13dd5d9c9866a1ab0', 'arxivId': None, 'publication_year': 2011, 'abstract': None}
{'title': 'Static scheduling algorithms for allocating directed task graphs to multiprocessors', 'paperID': 'ada56e1f7575d7f542215c48625c161ab060bed0', 'arxivId': None, 'publication_year': 1999, 'abstract': None}
{'title': 'Collective dynamics of ‘small-world’ networks', 'paperID': 'd61031326150ba23f90e6587c13d99188209250e', 'arxivId': None, 'publication_year': 1998, 'abstract': None}
{'title': 'The Communication Challenge for MPP: Intel Paragon and Meiko CS-2', 'paperID': 'd160d309b7d6cc1eb4382bba08ca61cd302fe735', 'arxivId': None, 'publication_year': 1994, 'abstract': None}
{'title': 'A Genetic Algorithm for Multiprocessor Scheduling', 'paperID': '5fae5afb1e9e959b880bff6e2cf457e112192396', 'arxivId': None, 'publication_year': 1994, 'abstract': None}
{'title': 'LogP: towards a realistic model of parallel computation', 'paperID': '6bc70aec3415944b461bef65b8444cd84d11667c', 'arxivId': None, 'publication_year': 1993, 'abstract': None}
{'title': 'A bridging model for parallel computation', 'paperID': '8665c9b459e4161825baf1f25b5141f41a5085ff', 'arxivId': None, 'publication_year': 1990, 'abstract': None}
{'title': 'Stochastic blockmodels: First steps', 'paperID': '996263c3ddbb50f0198354827445abd214f83030', 'arxivId': None, 'publication_year': 1983, 'abstract': None}
{'title': 'Heuristic Algorithms for Scheduling Independent Tasks on Nonidentical Processors', 'paperID': 'e99553b4cc9c88084c14ec718c5011882b253a8c', 'arxivId': None, 'publication_year': 1977, 'abstract': None}
{'title': 'Computer Architecture: A Quantitative Approach', 'paperID': '890469e625fe728adfa690a3945ebca4c11a8998', 'arxivId': None, 'publication_year': 1969, 'abstract': None}
{'title': 'Synthesis and Optimization of Digital Circuits', 'paperID': '42bfff334382a96adb376f55d1bb1acbad0a6647', 'arxivId': None, 'publication_year': 1994, 'abstract': None}
{'title': 'On the evolution of random graphs', 'paperID': 'a5aad5abb32f6b15f31b92312bb3b0f7b6470977', 'arxivId': None, 'publication_year': 1984, 'abstract': None}
{'title': 'Combinatorial Optimization: Algorithms and Complexity', 'paperID': '1565c128b727550a73bc4e105a3353420112485d', 'arxivId': None, 'publication_year': 1981, 'abstract': None}
{'title': 'Robust Scheduling with GFlowNets', 'paperID': '035b158f1f165930aaf7877fb54515ce29a17f9e', 'arxivId': '2302.05446', 'publication_year': '2023', 'abstract': 'Finding the best way to schedule operations in a computation graph is a classical NP-hard problem which is central to compiler optimization. However, evaluating the goodness of a schedule on the target hardware can be very time-consuming. Traditional approaches as well as previous machine learning ones typically optimize proxy metrics, which are fast to evaluate but can lead to bad schedules when tested on the target hardware. In this work, we propose a new approach to scheduling by sampling proportionally to the proxy metric using a novel GFlowNet method. We introduce a technique to control the trade-off between diversity and goodness of the proposed schedules at inference time and demonstrate empirically that the pure optimization baselines can lead to subpar performance with respect to our approach when tested on a target model. Furthermore, we show that conditioning the GFlowNet on the computation graph enables generalization to unseen scheduling problems for both synthetic and real-world compiler datasets.'}
{'title': 'Motley: Benchmarking Heterogeneity and Personalization in Federated Learning', 'paperID': '36084dcbe0dac8057557674a102f75b20d92aa8a', 'arxivId': '2206.09262', 'publication_year': 2022, 'abstract': None}
{'title': 'DRFLM: Distributionally Robust Federated Learning with Inter-client Noise via Local Mixup', 'paperID': 'c8e1b5ae0373381f08007807bed3bf7f6d1c2cc3', 'arxivId': '2204.07742', 'publication_year': 2022, 'abstract': None}
{'title': 'Continual Test-Time Domain Adaptation', 'paperID': '0430dbcbfed0a737881d22340fb044028ed851a9', 'arxivId': '2203.13591', 'publication_year': 2022, 'abstract': None}
{'title': 'Gradient Masked Averaging for Federated Learning', 'paperID': 'f27dd07a57d5f9562acc4d1acedaab763dfeeaa0', 'arxivId': '2201.11986', 'publication_year': 2022, 'abstract': None}
{'title': 'Towards Federated Learning on Time-Evolving Heterogeneous Data', 'paperID': 'a880b83457c018e725a408717bd70d0483c16d81', 'arxivId': '2112.13246', 'publication_year': 2021, 'abstract': None}
{'title': 'FLIX: A Simple and Communication-Efficient Alternative to Local Methods in Federated Learning', 'paperID': '943905454e9b06ca6c234e71efc678766a85f154', 'arxivId': '2111.11556', 'publication_year': 2021, 'abstract': None}
{'title': 'Personalized Federated Learning through Local Memorization', 'paperID': '91ba25b062661f58db2b54407009323c36e84223', 'arxivId': '2111.09360', 'publication_year': 2021, 'abstract': None}
{'title': 'MEMO: Test Time Robustness via Adaptation and Augmentation', 'paperID': '6e2a5c59f8119374bc68e3dab075d660700b8155', 'arxivId': '2110.09506', 'publication_year': 2021, 'abstract': None}
{'title': 'On Bridging Generic and Personalized Federated Learning', 'paperID': '77a27cd55900bc12c9e548fffcac160227d8448b', 'arxivId': '2107.00778', 'publication_year': 2021, 'abstract': None}
{'title': 'Personalized Federated Learning with Gaussian Processes', 'paperID': 'a5c5fbb0679613cf21c42009ebf1c70d7ac209a0', 'arxivId': '2106.15482', 'publication_year': 2021, 'abstract': None}
{'title': 'FedScale: Benchmarking Model and System Performance of Federated Learning', 'paperID': 'f356b19619e2d9ebeb96839f0e87a07071248179', 'arxivId': '2105.11367', 'publication_year': 2021, 'abstract': None}
{'title': 'FedNLP: Benchmarking Federated Learning Methods for Natural Language Processing Tasks', 'paperID': '9db10692e1255fe8c8cbfb68b4a3aa84e6667a49', 'arxivId': '2104.08815', 'publication_year': 2021, 'abstract': None}
{'title': 'Escaping the Big Data Paradigm with Compact Transformers', 'paperID': '4b06c7e29280b1c6bc05c9df39023b48fef02c93', 'arxivId': '2104.05704', 'publication_year': 2021, 'abstract': None}
{'title': 'Personalized Federated Learning using Hypernetworks', 'paperID': '148de9bf06862825290d6801728758bc5c6aa72b', 'arxivId': '2103.04628', 'publication_year': 2021, 'abstract': None}
{'title': 'Towards Personalized Federated Learning', 'paperID': '481dd25896ac531707870c9b8c179cce20013401', 'arxivId': '2103.00710', 'publication_year': 2021, 'abstract': None}
{'title': 'Exploiting Shared Representations for Personalized Federated Learning', 'paperID': 'ffd393dacee23e476bd8eb0802dec86f2296b36c', 'arxivId': '2102.07078', 'publication_year': 2021, 'abstract': None}
{'title': 'Linear Convergence in Federated Learning: Tackling Client Heterogeneity and Sparse Gradients', 'paperID': '405f2de412eff9e04ba2ae74fe21fdb692c9da60', 'arxivId': '2102.07053', 'publication_year': 2021, 'abstract': None}
{'title': 'Federated Reconstruction: Partially Local Federated Learning', 'paperID': '0b8a5e2e6590e019e7bcd2a4c6c10bcaf86f2fcd', 'arxivId': '2102.03448', 'publication_year': 2021, 'abstract': None}
{'title': 'Personalized Federated Learning with First Order Model Optimization', 'paperID': '2064242b39e0b0285dc04a076026890a2d613a4d', 'arxivId': '2012.08565', 'publication_year': 2020, 'abstract': None}
{'title': 'Ditto: Fair and Robust Federated Learning Through Personalization', 'paperID': '1f9a93240e73e2f48764dae843f4a9668baadba7', 'arxivId': '2012.04221', 'publication_year': 2020, 'abstract': None}
{'title': 'Fairness-aware Agnostic Federated Learning', 'paperID': 'f18acd343c641cf1d438f5b917087d67f84bcd16', 'arxivId': '2010.05057', 'publication_year': 2020, 'abstract': None}
{'title': 'Mime: Mimicking Centralized Stochastic Algorithms in Federated Learning', 'paperID': '4a066d008f9013004e941c9f19b959efea3e6330', 'arxivId': '2008.03606', 'publication_year': 2020, 'abstract': None}
{'title': 'FedML: A Research Library and Benchmark for Federated Machine Learning', 'paperID': '18dd17656c42322e943deaedc4eee6400debe7c2', 'arxivId': '2007.13518', 'publication_year': 2020, 'abstract': None}
{'title': 'Balanced Meta-Softmax for Long-Tailed Visual Recognition', 'paperID': 'd3806e9fefce863dfec7f6f83537bfb24edb278c', 'arxivId': '2007.10740', 'publication_year': 2020, 'abstract': None}
{'title': 'Personalized Cross-Silo Federated Learning on Non-IID Data', 'paperID': '679237737ab2392a87a1f3c44d62b2e37f36bf01', 'arxivId': '2007.03797', 'publication_year': 2020, 'abstract': None}
{'title': 'Ensemble Distillation for Robust Model Fusion in Federated Learning', 'paperID': '053f4d6715a4dba6f8103456fc1bb5fd6a5266c4', 'arxivId': '2006.07242', 'publication_year': 2020, 'abstract': None}
{'title': 'An Efficient Framework for Clustered Federated Learning', 'paperID': '06bc35120d2775bb4c26d6fd1ba68d1befcd84cb', 'arxivId': '2006.04088', 'publication_year': 2020, 'abstract': None}
{'title': 'Personalized Federated Learning with Moreau Envelopes', 'paperID': '70f1b279f96a9ba8e15f599635ba0e3ec449ef5f', 'arxivId': '2006.08848', 'publication_year': 2020, 'abstract': None}
{'title': 'Heterogeneous Domain Generalization Via Domain Mixup', 'paperID': 'd8728a567685e14e148a805b51a084d0f93763b8', 'arxivId': '2009.05448', 'publication_year': 2020, 'abstract': None}
{'title': 'Three Approaches for Personalization with Applications to Federated Learning', 'paperID': '2d470f3f86bae26460339bef85420095e04c852b', 'arxivId': '2002.10619', 'publication_year': 2020, 'abstract': None}
{'title': 'Federated Learning of a Mixture of Global and Local Models', 'paperID': '69e017d4a1a25081e2d3335dc0c19ba7c877244d', 'arxivId': '2002.05516', 'publication_year': 2020, 'abstract': None}
{'title': 'Federated Evaluation of On-device Personalization', 'paperID': '355869339c2eb7cb95f341350ad7a72e854ed712', 'arxivId': '1910.10252', 'publication_year': 2019, 'abstract': None}
{'title': 'Clustered Federated Learning: Model-Agnostic Distributed Multitask Optimization Under Privacy Constraints', 'paperID': '08bd705920792314e3ef806c28d0a7f40505634f', 'arxivId': '1910.01991', 'publication_year': 2019, 'abstract': None}
{'title': 'SlowMo: Improving Communication-Efficient Distributed SGD with Slow Momentum', 'paperID': 'e20848622d5145744127b82367f9b671c7ddb08e', 'arxivId': '1910.00643', 'publication_year': 2019, 'abstract': None}
{'title': 'The Non-IID Data Quagmire of Decentralized Machine Learning', 'paperID': '206261db1196e4e391ca42077f6fca6b3ece34d0', 'arxivId': '1910.00189', 'publication_year': 2019, 'abstract': None}
{'title': 'Improving Federated Learning Personalization via Model Agnostic Meta Learning', 'paperID': '743bb270d501bb4c4c2760ee68f8864344c83114', 'arxivId': '1909.12488', 'publication_year': 2019, 'abstract': None}
{'title': 'Fair Resource Allocation in Federated Learning', 'paperID': '90fdbe550c6c04b4bd082e4f5714ed40d61738a6', 'arxivId': '1905.10497', 'publication_year': 2019, 'abstract': None}
{'title': 'Bayesian Nonparametric Federated Learning of Neural Networks', 'paperID': '5ac658ff79e30358a2f4a8ac4486090c3b7a2289', 'arxivId': '1905.12022', 'publication_year': 2019, 'abstract': None}
{'title': 'A generic framework for privacy preserving deep learning', 'paperID': '76c6d39edecdb943ce0f68f5a44e6608db96e383', 'arxivId': '1811.04017', 'publication_year': 2018, 'abstract': None}
{'title': "Don't Use Large Mini-Batches, Use Local SGD", 'paperID': '93ef5b740fa1b54929ead6eb177e0698d7f19719', 'arxivId': '1808.07217', 'publication_year': 2018, 'abstract': None}
{'title': 'Federated Meta-Learning with Fast Convergence and Efficient Communication', 'paperID': '4514be5d1e4719c4701527ca6569899d8be297ef', 'arxivId': '1802.07876', 'publication_year': 2018, 'abstract': None}
{'title': 'Layer Normalization', 'paperID': '97fb4e3d45bb098e27e0071448b6152217bd35a5', 'arxivId': '1607.06450', 'publication_year': 2016, 'abstract': None}
{'title': 'Classifier Technology and the Illusion of Progress', 'paperID': 'd12fbc23cff452074a286b099cd475fdd3dcd91a', 'arxivId': 'math/0606441', 'publication_year': 2006, 'abstract': None}
{'title': 'Diurnal or Nocturnal? Federated Learning of Multi-branch Networks from Periodically Shifting Distributions', 'paperID': '4f3bbc2f389e6650f27b14aef05c928156883a24', 'arxivId': None, 'publication_year': 2022, 'abstract': None}
{'title': 'Test-Time Classifier Adjustment Module for Model-Agnostic Domain Generalization', 'paperID': 'f3522f72b44ba67a04133a718a26e1c6c59fe9c1', 'arxivId': None, 'publication_year': 2021, 'abstract': None}
{'title': 'Inference-Time Personalized Federated Learning', 'paperID': 'fc6198f6cbd342dae590126b8aa69fb5d139f08d', 'arxivId': None, 'publication_year': 2021, 'abstract': None}
{'title': 'TTT++: When Does Self-Supervised Test-Time Training Fail or Thrive?', 'paperID': '257e70eb918515135336039f5a0fb75a3fe36c31', 'arxivId': None, 'publication_year': 2021, 'abstract': None}
{'title': 'Test-Agnostic Long-Tailed Recognition by Test-Time Aggregating Diverse Experts with Self-Supervision', 'paperID': '020f2ed0895d26bef7f8a959f84abf1a6cc7344a', 'arxivId': None, 'publication_year': 2021, 'abstract': None}
{'title': 'FedProto: Federated Prototype Learning over Heterogeneous Devices', 'paperID': 'aef9f7e5ac09fcf155d64b0e0c93b940610d2e0f', 'arxivId': None, 'publication_year': 2021, 'abstract': None}
{'title': 'A Survey of Fairness-Aware Federated Learning', 'paperID': 'ae744b40c02758525c07ba353a37df3aa3ef72a1', 'arxivId': None, 'publication_year': 2021, 'abstract': None}
{'title': 'Personalized Federated Learning with Theoretical Guarantees: A Model-Agnostic Meta-Learning Approach', 'paperID': 'f56ae74c8c0842064654aeecb93d42bb3456b5b6', 'arxivId': None, 'publication_year': 2020, 'abstract': None}
{'title': 'Toward Understanding the Feature Learning Process of Self-supervised Contrastive Learning', 'paperID': '3ef9e9905d2454de61e6a257d37c0865dc227db5', 'arxivId': '2105.15134', 'publication_year': 2021, 'abstract': None}
{'title': 'Can Pretext-Based Self-Supervised Learning Be Boosted by Downstream Data? A Theoretical Analysis', 'paperID': '1902faede5212e62aa8f15f50c3981c1f0505113', 'arxivId': '2103.03568', 'publication_year': 2021, 'abstract': None}
{'title': 'Contrastive Learning Inverts the Data Generating Process', 'paperID': 'a56759300364982894bad81ab08ca3642cf6b06d', 'arxivId': '2102.08850', 'publication_year': 2021, 'abstract': None}
{'title': 'A Survey on Contrastive Self-supervised Learning', 'paperID': '02f3c052a9cf675a6f033eac56c9dacb0a10ea28', 'arxivId': '2011.00362', 'publication_year': 2020, 'abstract': None}
{'title': 'Theoretical Analysis of Self-Training with Deep Networks on Unlabeled Data', 'paperID': '5a41200eeee536e101b6e462014e7396f4841c28', 'arxivId': '2010.03622', 'publication_year': 2020, 'abstract': None}
{'title': 'A Mathematical Exploration of Why Language Models Help Solve Downstream Tasks', 'paperID': '01400290c7db96c4d665d1c29519c42ba47401e0', 'arxivId': '2010.03648', 'publication_year': 2020, 'abstract': None}
{'title': 'Understanding Self-supervised Learning with Dual Deep Networks', 'paperID': '5a2fb119d469358094792d8b36d8b027ae9fb737', 'arxivId': '2010.00578', 'publication_year': 2020, 'abstract': None}
{'title': 'Self-Supervised Learning: Generative or Contrastive', 'paperID': '370b680057a6e324e67576a6bf1bf580af9fdd74', 'arxivId': '2006.08218', 'publication_year': 2020, 'abstract': None}
{'title': 'Self-supervised Learning from a Multi-view Perspective', 'paperID': '7bd050967c18ec5161aa5ed244f3348cbd464642', 'arxivId': None, 'publication_year': 2020, 'abstract': None}
{'title': 'Interval', 'paperID': 'b332d9aab535990a502881bd13ee15ea970b95ce', 'arxivId': None, 'publication_year': 2018, 'abstract': None}
{'title': 'Provable Algorithms for Inference in Topic Models', 'paperID': '085c001e87f1d6a5d2a91371135ada990024db70', 'arxivId': '1605.08491', 'publication_year': 2016, 'abstract': None}
{'title': 'Probabilistic programming in Python using PyMC3', 'paperID': '8085b60ce1771647f11ccc4728397275b502f359', 'arxivId': None, 'publication_year': 2016, 'abstract': None}
{'title': 'Distributed Representations of Words and Phrases and their Compositionality', 'paperID': '87f40e6f3022adbc1f1905e3e506abad05a9964f', 'arxivId': '1310.4546', 'publication_year': 2013, 'abstract': None}
{'title': 'A Tensor Spectral Approach to Learning Mixed Membership Community Models', 'paperID': '197fe6c21bca61d501a611707461f057d1a52bee', 'arxivId': None, 'publication_year': 2013, 'abstract': None}
{'title': 'Tensor decompositions for learning latent variable models', 'paperID': 'a6ce434896d238e1b200a617815ea3e5141dfeeb', 'arxivId': '1210.7559', 'publication_year': 2012, 'abstract': None}
{'title': 'Fast and Robust Recursive Algorithmsfor Separable Nonnegative Matrix Factorization', 'paperID': '6aae389341d01d73ddc7d2b6a5f819b1c6e0aade', 'arxivId': '1208.1237', 'publication_year': 2012, 'abstract': None}
{'title': 'Factoring nonnegative matrices with linear programs', 'paperID': '519ad2716c3e91066cd114f671493c282051e19d', 'arxivId': '1206.1270', 'publication_year': 2012, 'abstract': None}
{'title': 'A Spectral Algorithm for Latent Dirichlet Allocation', 'paperID': 'df63264515b89242471224bbec564d7a2e9b704e', 'arxivId': '1204.6703', 'publication_year': 2012, 'abstract': None}
{'title': 'Learning Topic Models -- Going beyond SVD', 'paperID': '50e7a1256aa9954c1764019b96ef38dc30fb1bbb', 'arxivId': '1204.1956', 'publication_year': 2012, 'abstract': None}
{'title': 'A Method of Moments for Mixture Models and Hidden Markov Models', 'paperID': 'd2aa99aec727af4779c7b805fca06db56faf40fc', 'arxivId': '1203.0683', 'publication_year': 2012, 'abstract': None}
{'title': 'Complexity of Inference in Latent Dirichlet Allocation', 'paperID': '0a02a033f0020cd75e8bce64c45851d02ba5e854', 'arxivId': None, 'publication_year': 2011, 'abstract': None}
{'title': 'Computing a nonnegative matrix factorization -- provably', 'paperID': '6456d62f3a918d0b1171e09b648df879da481c8c', 'arxivId': '1111.0952', 'publication_year': 2011, 'abstract': None}
{'title': 'Random Features for Large-Scale Kernel Machines', 'paperID': '7a59fde27461a3ef4a21a249cc403d0d96e4a0d7', 'arxivId': None, 'publication_year': 2007, 'abstract': None}
{'title': 'A correlated topic model of Science', 'paperID': 'e981f16fde9185373634b53d94baa1f9185ff890', 'arxivId': '0708.3601', 'publication_year': 2007, 'abstract': None}
{'title': 'Pachinko allocation: DAG-structured mixture models of topic correlations', 'paperID': 'c18cf392c7d645d9d9e6cbadb8f50a4dbbabdf75', 'arxivId': None, 'publication_year': 2006, 'abstract': None}
{'title': 'Using mixture models for collaborative filtering', 'paperID': 'cc79e88e467f5fc76fe897fbe829fa43f5f6a0c4', 'arxivId': None, 'publication_year': 2004, 'abstract': None}
{'title': 'Latent Dirichlet Allocation', 'paperID': 'f198043a866e9187925a8d8db9a55e3bfdd47f2c', 'arxivId': None, 'publication_year': 2001, 'abstract': None}
{'title': 'Latent semantic indexing: a probabilistic analysis', 'paperID': '546fdb984bd63214dac8f552ef8d8ae6fa7c7d1a', 'arxivId': None, 'publication_year': 1998, 'abstract': None}
{'title': 'Understanding The Robustness of Self-supervised Learning Through Topic Modeling', 'paperID': 'fb57a29cce4c6e4d6971ccc2f928289703566145', 'arxivId': '2203.03539', 'publication_year': '2022', 'abstract': 'Self-supervised learning has significantly improved the performance of many NLP tasks. However, how can self-supervised learning discover useful representations, and why is it better than traditional approaches such as probabilistic models are still largely unknown. In this paper, we focus on the context of topic modeling and highlight a key advantage of self-supervised learning - when applied to data generated by topic models, self-supervised learning can be oblivious to the specific model, and hence is less susceptible to model misspecification. In particular, we prove that commonly used self-supervised objectives based on reconstruction or contrastive samples can both recover useful posterior information for general topic models. Empirically, we show that the same objectives can perform on par with posterior inference using the correct model, while outperforming posterior inference using misspecified models.'}
{'title': 'Improving the Adversarial Robustness of Neural ODE Image Classifiers by Tuning the Tolerance Parameter', 'paperID': '8e3d88acaad40ec48b19c0f9932f6a52b43953e5', 'arxivId': None, 'publication_year': 2022, 'abstract': None}
{'title': 'Certified Training: Small Boxes are All You Need', 'paperID': 'a2f519580930421aec9501d5cbbc365893877750', 'arxivId': '2210.04871', 'publication_year': 2022, 'abstract': None}
{'title': 'Reachability Analysis of a General Class of Neural Ordinary Differential Equations', 'paperID': '9898d773a0bc3749e50aa2a540d9569a544aa6ad', 'arxivId': '2207.06531', 'publication_year': 2022, 'abstract': None}
{'title': 'Complete Verification via Multi-Neuron Relaxation Guided Branch-and-Bound', 'paperID': 'd7aff3e7c84e8440b49a3cd36f686c6486094956', 'arxivId': '2205.00263', 'publication_year': 2022, 'abstract': None}
{'title': 'Robust Classification Using Contractive Hamiltonian Neural ODEs', 'paperID': '18a133cbcd3048e085e7273d0e63c22eb99cc864', 'arxivId': '2203.11805', 'publication_year': 2022, 'abstract': None}
{'title': 'Formal Control Synthesis for Stochastic Neural Network Dynamic Models', 'paperID': '7ebec0ae173fd451d09e86fe7cec2bc7c43bb19d', 'arxivId': '2203.05903', 'publication_year': 2022, 'abstract': None}
{'title': 'LyaNet: A Lyapunov Framework for Training Neural ODEs', 'paperID': 'e34b654052a16ac9b2335267f7c56d9623bed19e', 'arxivId': '2202.02526', 'publication_year': 2022, 'abstract': None}
{'title': 'Stable Neural ODE with Lyapunov-Stable Equilibrium Points for Defending Against Adversarial Attacks', 'paperID': 'f62dd30782234a237deab6ec4e1368d452a00d49', 'arxivId': '2110.12976', 'publication_year': 2021, 'abstract': None}
{'title': 'Safe Control with Neural Network Dynamic Models', 'paperID': 'bf0537b35036ebf16616aa626c169b5814c2f766', 'arxivId': '2110.01110', 'publication_year': 2021, 'abstract': None}
{'title': 'PRIMA: general and precise neural network certification via scalable convex hull approximations', 'paperID': 'a0b05ab4f9d06890d1933dc4429cfeceebc4ce0c', 'arxivId': '2103.03638', 'publication_year': 2021, 'abstract': None}
{'title': 'On The Verification of Neural ODEs with Stochastic Guarantees', 'paperID': '0033cbb16ea8996520f2e239298070975b3f31ae', 'arxivId': '2012.08863', 'publication_year': 2020, 'abstract': None}
{'title': 'Fast and Complete: Enabling Complete Neural Network Verification with Rapid and Massively Parallel Incomplete Verifiers', 'paperID': '01fe33d7147cfb08d4542402089535ed911b4024', 'arxivId': '2011.13824', 'publication_year': 2020, 'abstract': None}
{'title': 'Adversarial Robustness of Stabilized NeuralODEs Might be from Obfuscated Gradients', 'paperID': 'a3d64aa7660367b9d08185a84f9d48fa6903b53b', 'arxivId': '2009.13145', 'publication_year': 2020, 'abstract': None}
{'title': 'Torchattacks : A Pytorch Repository for Adversarial Attacks', 'paperID': '1f4b3283faf534ef92d7d7fa798b26480605ead9', 'arxivId': '2010.01950', 'publication_year': 2020, 'abstract': None}
{'title': 'Monotone operator equilibrium networks', 'paperID': '407f3c4ffda9e0ad4ecdb1830f062aaea88e5912', 'arxivId': '2006.08591', 'publication_year': 2020, 'abstract': None}
{'title': 'Latent ODEs for Irregularly-Sampled Time Series', 'paperID': '25bb538adb125803a6f3f5632f31720d657adb13', 'arxivId': '1907.03907', 'publication_year': 2019, 'abstract': None}
{'title': 'GRU-ODE-Bayes: Continuous modeling of sporadically-observed time series', 'paperID': '63c99c04869a52ac69850e21732b26d8633852ea', 'arxivId': '1905.12374', 'publication_year': 2019, 'abstract': None}
{'title': 'Boosting Robustness Certification of Neural Networks', 'paperID': '4963fe1027aebe63217bd2904decf24f59379e1f', 'arxivId': None, 'publication_year': 2018, 'abstract': None}
{'title': 'On the Properties of Neural Machine Translation: Encoder–Decoder Approaches', 'paperID': '1eb09fecd75eb27825dce4f964b97f4f5cc399d7', 'arxivId': '1409.1259', 'publication_year': 2014, 'abstract': None}
{'title': 'Reachability analysis of nonlinear systems using conservative polynomialization and non-convex sets', 'paperID': '82fe52ff73ccbd4476910da6d8389e1949b0c2ef', 'arxivId': None, 'publication_year': 2013, 'abstract': None}
{'title': 'Predicting in-hospital mortality of ICU patients: The PhysioNet/Computing in cardiology challenge 2012', 'paperID': 'ed8235bff4cc8a1943f665f68158e30a8c3a72f7', 'arxivId': None, 'publication_year': 2012, 'abstract': None}
{'title': 'Ecological and Lyapunov Stability*', 'paperID': 'abb1eb165c7df869407f801f0dbd7438782c93a3', 'arxivId': None, 'publication_year': 2008, 'abstract': None}
{'title': 'Error Estimation and Control for ODEs', 'paperID': 'b86131ef9fccfeeacf4945dcac6bc1b9ffe98088', 'arxivId': None, 'publication_year': 2005, 'abstract': None}
{'title': 'A family of embedded Runge-Kutta formulae', 'paperID': 'df1c1cb4a547b9b207613d81765d4693dde9590b', 'arxivId': None, 'publication_year': 1980, 'abstract': None}
{'title': 'FI-ODE: Certified and Robust Forward Invariance in Neural ODEs', 'paperID': 'dfa9667b1e5e3731b984cb6ebd683cc7ec6165af', 'arxivId': None, 'publication_year': 2022, 'abstract': None}
{'title': 'Effective Certification of Monotone Deep Equilibrium Models', 'paperID': '9b0c795343485bd39e39cac69ffc0e00ae0f8882', 'arxivId': None, 'publication_year': 2021, 'abstract': None}
{'title': 'Scaling the Convex Barrier with Active Sets', 'paperID': '69e1fab8fb4d599420cea6803f02e06fe9e0d11b', 'arxivId': None, 'publication_year': 2021, 'abstract': None}
{'title': 'A 3(2) pair of Runge - Kutta formulas', 'paperID': '248b3f8544d016f073337330b9c4a62e6dcb37b5', 'arxivId': None, 'publication_year': 1989, 'abstract': None}
{'title': 'Efficient Certified Training and Robustness Verification of Neural ODEs', 'paperID': 'b07ba82ede28d57e2e84f17fee8fef3edc24e451', 'arxivId': '2303.05246', 'publication_year': '2023', 'abstract': 'Neural Ordinary Differential Equations (NODEs) are a novel neural architecture, built around initial value problems with learned dynamics which are solved during inference. Thought to be inherently more robust against adversarial perturbations, they were recently shown to be vulnerable to strong adversarial attacks, highlighting the need for formal guarantees. However, despite significant progress in robustness verification for standard feed-forward architectures, the verification of high dimensional NODEs remains an open problem. In this work, we address this challenge and propose GAINS, an analysis framework for NODEs combining three key ideas: (i) a novel class of ODE solvers, based on variable but discrete time steps, (ii) an efficient graph representation of solver trajectories, and (iii) a novel abstraction algorithm operating on this graph representation. Together, these advances enable the efficient analysis and certified training of high-dimensional NODEs, by reducing the runtime from an intractable $O(\\exp(d)+\\exp(T))$ to ${O}(d+T^2 \\log^2T)$ in the dimensionality $d$ and integration time $T$. In an extensive evaluation on computer vision (MNIST and FMNIST) and time-series forecasting (PHYSIO-NET) problems, we demonstrate the effectiveness of both our certified training and verification methods.'}
{'title': 'Robust Bayesian Recourse', 'paperID': '536c78a8350de0d5916ba13abdb5a74627b9e1b8', 'arxivId': '2206.10833', 'publication_year': 2022, 'abstract': None}
{'title': 'A Survey of Algorithmic Recourse: Contrastive Explanations and Consequential Recommendations', 'paperID': '56f531eb3a8eaa03a6dbcf74a6c12c80b2e90f45', 'arxivId': None, 'publication_year': 2022, 'abstract': None}
{'title': 'Counterfactual Plans under Distributional Ambiguity', 'paperID': '262e060ddfa7db0563b083d31552b2855e2daa1e', 'arxivId': '2201.12487', 'publication_year': 2022, 'abstract': None}
{'title': 'Counterfactual Explanations and Algorithmic Recourses for Machine Learning: A Review', 'paperID': 'f9145d932ae9e454d9a45ae23fdb0ec0171e4ef4', 'arxivId': '2010.10596', 'publication_year': 2020, 'abstract': None}
{'title': 'Beyond Individualized Recourse: Interpretable and Interactive Summaries of Actionable Recourses', 'paperID': '2a4b609a7e0df199332222c05caf4c58d2f4cb6c', 'arxivId': None, 'publication_year': 2020, 'abstract': None}
{'title': 'Reducing Conservatism in Robust Optimization', 'paperID': 'a696e13c63d70b62fd8e420dc82efd4e460b2cbb', 'arxivId': None, 'publication_year': 2020, 'abstract': None}
{'title': 'Algorithmic Recourse: from Counterfactual Explanations to Interventions', 'paperID': '0367827a9162f981ee02c4b3130f58085fba93f1', 'arxivId': '2002.06278', 'publication_year': 2020, 'abstract': None}
{'title': 'The philosophical basis of algorithmic recourse', 'paperID': '4627d3fd86423fe911ee40b8eb35b1e389ab41fd', 'arxivId': None, 'publication_year': 2020, 'abstract': None}
{'title': 'On the computation of counterfactual explanations - A survey', 'paperID': 'aea8658a9c9dfc54d9163705971f875b6409c212', 'arxivId': '1911.07749', 'publication_year': 2019, 'abstract': None}
{'title': 'Sharing the Value-at-Risk Under Distributional Ambiguity', 'paperID': 'a6b7767ef515391f1e4efd0c5345fc9517954225', 'arxivId': None, 'publication_year': 2019, 'abstract': None}
{'title': 'Efficient Search for Diverse Coherent Explanations', 'paperID': '0cfd1f4a43824b88909a44c04b5edb251c0886a6', 'arxivId': '1901.04909', 'publication_year': 2019, 'abstract': None}
{'title': '“Should This Loan be Approved or Denied?”: A Large Dataset with Class Assignment Guidelines', 'paperID': 'b0608845e3d482e0d5d74892be6b7035e3b47672', 'arxivId': None, 'publication_year': 2018, 'abstract': None}
{'title': 'Data-Driven Stochastic Programming Using Phi-Divergences', 'paperID': 'e4ada56f5fdc24f405e32804d2a15a5823397758', 'arxivId': None, 'publication_year': 2015, 'abstract': None}
{'title': 'Distributionally robust multi-item newsvendor problems with multimodal demand distributions', 'paperID': 'fc82c98c4012d2c01a125d74c1aba45095dc9709', 'arxivId': None, 'publication_year': 2015, 'abstract': None}
{'title': 'Globalized Robust Optimization for Nonlinear Uncertain Inequalities', 'paperID': '40b12a42d91f494fad351cbfbf228b4da2d49981', 'arxivId': None, 'publication_year': 2015, 'abstract': None}
{'title': 'Machine learning - a probabilistic perspective', 'paperID': '25badc676197a70aaf9911865eb03469e402ba57', 'arxivId': None, 'publication_year': 2012, 'abstract': None}
{'title': 'Using data mining to predict secondary school student performance', 'paperID': '61d468d5254730bbecf822c6b60d7d6595d9889c', 'arxivId': None, 'publication_year': 2008, 'abstract': None}
{'title': 'Statistical Inference Based on Divergence Measures', 'paperID': 'd2a859c85cfb0172a57ec636797a6dd28157eff8', 'arxivId': None, 'publication_year': 2005, 'abstract': None}
{'title': 'Worst-Case Value-At-Risk and Robust Portfolio Optimization: A Conic Programming Approach', 'paperID': '172fc53432c0b1b8bd3d0da1be6f9363f27cfaa9', 'arxivId': None, 'publication_year': 2003, 'abstract': None}
{'title': 'THE APPLICATION OF CLUSTER ANALYSIS IN STRATEGIC MANAGEMENT RESEARCH: AN ANALYSIS AND CRITIQUE', 'paperID': 'ea0d095c2baba90f0f3b0c8ce56c8983570c277f', 'arxivId': None, 'publication_year': 1996, 'abstract': None}
{'title': 'Who belongs in the family?', 'paperID': '47706e9fdfe6b7d33d09579e60d6c9732cfa90e7', 'arxivId': None, 'publication_year': 1953, 'abstract': None}
{'title': 'A Survey of Contrastive and Counterfactual Explanation Generation Methods for Explainable Artificial Intelligence', 'paperID': 'e016ee7bfc73cb5b8a92f6c517389be837c035eb', 'arxivId': None, 'publication_year': 2021, 'abstract': None}
{'title': 'On a Formula for the L2 Wasserstein Metric between Measures on Euclidean and Hilbert Spaces', 'paperID': '53955424e3c73b463cb6049c836b86041c3202d6', 'arxivId': None, 'publication_year': 1990, 'abstract': None}
{'title': 'Distributionally Robust Recourse Action', 'paperID': '928d22cc193ccae8e1bf345c1f2ce253a261a077', 'arxivId': '2302.11211', 'publication_year': '2023', 'abstract': 'A recourse action aims to explain a particular algorithmic decision by showing one specific way in which the instance could be modified to receive an alternate outcome. Existing recourse generation methods often assume that the machine learning model does not change over time. However, this assumption does not always hold in practice because of data distribution shifts, and in this case, the recourse action may become invalid. To redress this shortcoming, we propose the Distributionally Robust Recourse Action (DiRRAc) framework, which generates a recourse action that has a high probability of being valid under a mixture of model shifts. We formulate the robustified recourse setup as a min-max optimization problem, where the max problem is specified by Gelbrich distance over an ambiguity set around the distribution of model parameters. Then we suggest a projected gradient descent algorithm to find a robust recourse according to the min-max objective. We show that our DiRRAc framework can be extended to hedge against the misspecification of the mixture weights. Numerical experiments with both synthetic and three real-world datasets demonstrate the benefits of our proposed framework over state-of-the-art recourse methods.'}
{'title': 'A Word is Worth A Thousand Dollars: Adversarial Attack on Tweets Fools Stock Prediction', 'paperID': '31c78bb85486ba8f1780b21e06be0f8f0f4dfaa0', 'arxivId': '2205.01094', 'publication_year': 2022, 'abstract': None}
{'title': 'Robust Probabilistic Time Series Forecasting', 'paperID': '8d49aa31faa13efd826023aa48667ecd2489ca40', 'arxivId': '2202.11910', 'publication_year': 2022, 'abstract': None}
{'title': 'Multivariate Quantile Function Forecaster', 'paperID': '356069daf4d4628559da92c9245aad39e578e090', 'arxivId': '2202.11316', 'publication_year': 2022, 'abstract': None}
{'title': 'Learning Quantile Functions without Quantile Crossing for Distribution-free Time Series Forecasting', 'paperID': '506ed2b755c8b207c4678d05c292e43b4d30605b', 'arxivId': '2111.06581', 'publication_year': 2021, 'abstract': None}
{'title': 'Informer: Beyond Efficient Transformer for Long Sequence Time-Series Forecasting', 'paperID': '35a9749df07a2ab97c51af4d260b095b00da7676', 'arxivId': '2012.07436', 'publication_year': 2020, 'abstract': None}
{'title': 'Adversarial Examples in Deep Learning for Multivariate Time Series Regression', 'paperID': '4c29342faf58ca042fb57c4ad049ce99448b6cf7', 'arxivId': '2009.11911', 'publication_year': 2020, 'abstract': None}
{'title': 'Structured Policy Iteration for Linear Quadratic Regulator', 'paperID': '8fb65cfca2806827e85ca5aec2e479f102eccf96', 'arxivId': '2007.06202', 'publication_year': 2020, 'abstract': None}
{'title': 'Optimal Operation of a Plug-in Hybrid Vehicle with Battery Thermal and Degradation Model', 'paperID': '42062cd1b91871c26c6ac49b57a4d0eba79e468e', 'arxivId': None, 'publication_year': 2020, 'abstract': None}
{'title': 'Adversarial Attacks on Multivariate Time Series', 'paperID': '1062876e599654afeaa491149abb40d95d3064df', 'arxivId': '2004.00410', 'publication_year': 2020, 'abstract': None}
{'title': 'Adversarial Attacks on Probabilistic Autoregressive Forecasting Models', 'paperID': '9628969fbe46586b6817a23243f2140ef8136811', 'arxivId': '2003.03778', 'publication_year': 2020, 'abstract': None}
{'title': 'Time Series Data Augmentation for Deep Learning: A Survey', 'paperID': '6d2d78d2015e6057b99691ae097a7362ec4e3bb6', 'arxivId': '2002.12478', 'publication_year': 2020, 'abstract': None}
{'title': 'Linear Quadratic Regulator for Resource-Efficient Cloud Services', 'paperID': '5a2b135fa17a877b0ac403074fd1aabbf5bd14b5', 'arxivId': None, 'publication_year': 2019, 'abstract': None}
{'title': 'High-Dimensional Multivariate Forecasting with Low-Rank Gaussian Copula Processes', 'paperID': '002e7ffbee5539486fb607ac11301819959e47a5', 'arxivId': '1910.03002', 'publication_year': 2019, 'abstract': None}
{'title': 'Deep Factors for Forecasting', 'paperID': '6a5f817fd8be2d89b492a3592b9f4e69d818b537', 'arxivId': '1905.12417', 'publication_year': 2019, 'abstract': None}
{'title': 'Probabilistic Forecasting with Spline Quantile Function RNNs', 'paperID': '4139b78573dbf054fabadc7c948a92cc5e5e59eb', 'arxivId': None, 'publication_year': 2019, 'abstract': None}
{'title': 'Trend analysis of climate time series: A review of methods', 'paperID': 'be48c10cc596c44fbe81fd3cdc9b04439530aaea', 'arxivId': None, 'publication_year': 2019, 'abstract': None}
{'title': 'Recurrent Neural Filters: Learning Independent Bayesian Filtering Steps for Time Series Prediction', 'paperID': '3b30a24f528da942b9306d2089088ab232d567ae', 'arxivId': '1901.08096', 'publication_year': 2019, 'abstract': None}
{'title': 'An Empirical Evaluation of Generic Convolutional and Recurrent Networks for Sequence Modeling', 'paperID': '921196c32213a229245a9705ee4768bc941e7a26', 'arxivId': '1803.01271', 'publication_year': 2018, 'abstract': None}
{'title': 'Forecasting at Scale', 'paperID': 'ab1f816ce79817a09487ea7866c95ce930d37497', 'arxivId': None, 'publication_year': 2018, 'abstract': None}
{'title': 'Probabilistic Demand Forecasting at Scale', 'paperID': '7a971b8e5a7bc267ee0617e9747f24b85bf5659f', 'arxivId': None, 'publication_year': 2017, 'abstract': None}
{'title': 'DeepAR: Probabilistic Forecasting with Autoregressive Recurrent Networks', 'paperID': '4eebe0d12aefeedf3ca85256bc8aa3b4292d47d9', 'arxivId': '1704.04110', 'publication_year': 2017, 'abstract': None}
{'title': 'Network Inference via the Time-Varying Graphical Lasso', 'paperID': '597cfe5df3d08a0bcd26e7d3128d8317265f9ced', 'arxivId': '1703.01958', 'publication_year': 2017, 'abstract': None}
{'title': 'WaveNet: A Generative Model for Raw Audio', 'paperID': 'df0402517a7338ae28bc54acaac400de6b456a46', 'arxivId': '1609.03499', 'publication_year': 2016, 'abstract': None}
{'title': 'Time Series: Theory and Methods', 'paperID': '80050cc9090cb42e5b26a8d0f11a1ce19d2b0fc8', 'arxivId': None, 'publication_year': 2013, 'abstract': None}
{'title': 'Robust Forecasting with Exponential and Holt-Winters Smoothing', 'paperID': 'fb07c8b50c3ff8e7f50582ca0896cafcef00dfff', 'arxivId': None, 'publication_year': 2007, 'abstract': None}
{'title': 'Recurrent neural networks and robust time series prediction', 'paperID': 'f19b99c04b09ab5d45040cedaa3591af6ac674d9', 'arxivId': None, 'publication_year': 1994, 'abstract': None}
{'title': 'Robust Estimation of High-Dimensional Vector Autoregressive Models', 'paperID': 'cbfca32c732929ecb65853a2a61948955058bf1d', 'arxivId': None, 'publication_year': 2021, 'abstract': None}
{'title': 'Normalizing Kalman Filters for Multivariate Time Series Analysis', 'paperID': 'd84c010f48bb4dfd9ef71d96d9b50799c19d35e8', 'arxivId': None, 'publication_year': 2020, 'abstract': None}
{'title': 'Deep State Space Models for Time Series Forecasting', 'paperID': 'ae4df460a413f3b1d9a0dfa47917751af9db2597', 'arxivId': None, 'publication_year': 2018, 'abstract': None}
{'title': 'Robust Multivariate Time-Series Forecasting: Adversarial Attacks and Defense Mechanisms', 'paperID': '84dc2a159c062ceedae62c4a3c682f18ead59812', 'arxivId': '2207.09572', 'publication_year': '2022', 'abstract': 'This work studies the threats of adversarial attack on multivariate probabilistic forecasting models and viable defense mechanisms. Our studies discover a new attack pattern that negatively impact the forecasting of a target time series via making strategic, sparse (imperceptible) modifications to the past observations of a small number of other time series. To mitigate the impact of such attack, we have developed two defense strategies. First, we extend a previously developed randomized smoothing technique in classification to multivariate forecasting scenarios. Second, we develop an adversarial training algorithm that learns to create adversarial examples and at the same time optimizes the forecasting model to improve its robustness against such adversarial simulation. Extensive experiments on real-world datasets confirm that our attack schemes are powerful and our defense algorithms are more effective compared with baseline defense mechanisms.'}
{'title': 'Test-Time Prompt Tuning for Zero-Shot Generalization in Vision-Language Models', 'paperID': '12ad6e798487223f4c17aac69c9853bca8bc7830', 'arxivId': '2209.07511', 'publication_year': 2022, 'abstract': None}
{'title': 'Efficient Test-Time Model Adaptation without Forgetting', 'paperID': 'e9c9ea9c463c3a4a0589b196a7ac708698723c9c', 'arxivId': '2204.02610', 'publication_year': 2022, 'abstract': None}
{'title': 'Towards Robust Rain Removal Against Adversarial Attacks: A Comprehensive Benchmark Analysis and Beyond', 'paperID': '9e383228f5ccc9cdfb96c3eba0b925fc755ab8e2', 'arxivId': '2203.16931', 'publication_year': 2022, 'abstract': None}
{'title': '3D Common Corruptions and Data Augmentation', 'paperID': '140a158aa77e0e5281bf4fb3b8fa44696a2dd209', 'arxivId': '2203.01441', 'publication_year': 2022, 'abstract': None}
{'title': 'Self-supervised Test-time Adaptation on Video Data', 'paperID': '7a993f18bc3481919beb4589aa35195428ff294f', 'arxivId': None, 'publication_year': 2022, 'abstract': None}
{'title': 'MViTv2: Improved Multiscale Vision Transformers for Classification and Detection', 'paperID': '9137efc758f80dd22bb56f82cca5c94f78a5db3e', 'arxivId': '2112.01526', 'publication_year': 2021, 'abstract': None}
{'title': 'AugMax: Adversarial Composition of Random Augmentations for Robust Training', 'paperID': '4c13e8071dafeed6a257e4e127b24ffc637bcf81', 'arxivId': '2110.13771', 'publication_year': 2021, 'abstract': None}
{'title': 'Benchmarking the Robustness of Spatial-Temporal Models Against Corruptions', 'paperID': 'd6331336dddc0a0342b2e9a0c24aadad240a3f4b', 'arxivId': '2110.06513', 'publication_year': 2021, 'abstract': None}
{'title': 'Variational Disentanglement for Domain Generalization', 'paperID': '5e83e5e332c8189102364f45204afe5f282b9188', 'arxivId': '2109.05826', 'publication_year': 2021, 'abstract': None}
{'title': 'MoViNets: Mobile Video Networks for Efficient Video Recognition', 'paperID': '0820694e95d1a9bfe364727a5f568f139cf5a980', 'arxivId': '2103.11511', 'publication_year': 2021, 'abstract': None}
{'title': 'Is Space-Time Attention All You Need for Video Understanding?', 'paperID': 'c143ea9e30b1f2d93a9c060253845423f9e60e1f', 'arxivId': '2102.05095', 'publication_year': 2021, 'abstract': None}
{'title': 'TDN: Temporal Difference Networks for Efficient Action Recognition', 'paperID': '2ad2981a53393dc5987419a22cbe1ee3d7fa6e42', 'arxivId': '2012.10071', 'publication_year': 2020, 'abstract': None}
{'title': 'Domain Generalization for Medical Imaging Classification with Linear-Dependency Regularization', 'paperID': '814a47de0d0743c4d41dd404c076541ea3c34645', 'arxivId': '2009.12829', 'publication_year': 2020, 'abstract': None}
{'title': 'Neural Networks with Recurrent Generative Feedback', 'paperID': '8d19137fa2d7eb68473b4f51453cb34af67b72bb', 'arxivId': '2007.09200', 'publication_year': 2020, 'abstract': None}
{'title': 'X3D: Expanding Architectures for Efficient Video Recognition', 'paperID': '908cca0abefc35acc38033603714fbb1bcadc49d', 'arxivId': '2004.04730', 'publication_year': 2020, 'abstract': None}
{'title': 'Do We Really Need to Access the Source Data? Source Hypothesis Transfer for Unsupervised Domain Adaptation', 'paperID': '6e1bb490ae54b42f13d14d69b2012edda4664949', 'arxivId': '2002.08546', 'publication_year': 2020, 'abstract': None}
{'title': 'More Is Less: Learning Efficient Video Representations by Big-Little Network and Depthwise Temporal Aggregation', 'paperID': '9c77ffc223e47388155a6e3bf58ae294f51f9ccb', 'arxivId': '1912.00869', 'publication_year': 2019, 'abstract': None}
{'title': 'Benchmarking the Robustness of Semantic Segmentation Models', 'paperID': 'b97d8b27224efb6655091393f27441b6ed8e6395', 'arxivId': '1908.05005', 'publication_year': 2019, 'abstract': None}
{'title': 'Temporal Attentive Alignment for Large-Scale Video Domain Adaptation', 'paperID': '89917e19175eb4f3bca02e0bace8f99d6910b054', 'arxivId': '1907.12743', 'publication_year': 2019, 'abstract': None}
{'title': 'Robustness Guarantees for Deep Neural Networks on Videos', 'paperID': 'fd3f4b31b77a296a9a239437e441deee17d62c2d', 'arxivId': '1907.00098', 'publication_year': 2019, 'abstract': None}
{'title': 'Temporal Cycle-Consistency Learning', 'paperID': '75662c7ab05db37c52a2d750af2a8b712bbf3d53', 'arxivId': '1904.07846', 'publication_year': 2019, 'abstract': None}
{'title': 'SlowFast Networks for Video Recognition', 'paperID': '8b47b9c3c35b2b2a78bff7822605b3040f87d699', 'arxivId': '1812.03982', 'publication_year': 2018, 'abstract': None}
{'title': 'TSM: Temporal Shift Module for Efficient Video Understanding', 'paperID': '4bbfd46721c145852e443ae4aad35148b814bf91', 'arxivId': '1811.08383', 'publication_year': 2018, 'abstract': None}
{'title': '"Zero-Shot" Super-Resolution Using Deep Internal Learning', 'paperID': 'e4092ce5b2c5a1997be2702335f7d33ba7a353ef', 'arxivId': None, 'publication_year': 2017, 'abstract': None}
{'title': 'Rethinking Spatiotemporal Feature Learning: Speed-Accuracy Trade-offs in Video Classification', 'paperID': '815aa52cfc02961d82415f080384594639a21984', 'arxivId': '1712.04851', 'publication_year': 2017, 'abstract': None}
{'title': 'Learning Spatio-Temporal Features with 3D Residual Networks for Action Recognition', 'paperID': '07c83f544d0604e6bab5d741b0bf9a3621d133da', 'arxivId': '1708.07632', 'publication_year': 2017, 'abstract': None}
{'title': 'Comparing deep neural networks against humans: object recognition when the signal gets weaker', 'paperID': 'fb41177076327c40dee612f30996739e20cf1bd7', 'arxivId': '1706.06969', 'publication_year': 2017, 'abstract': None}
{'title': 'The “Something Something” Video Database for Learning and Evaluating Visual Common Sense', 'paperID': 'b68811a9b5cafe4795a11c1048541750068b7ad0', 'arxivId': '1706.04261', 'publication_year': 2017, 'abstract': None}
{'title': 'Quo Vadis, Action Recognition? A New Model and the Kinetics Dataset', 'paperID': 'b61a3f8b80bbd44f24544dc915f52fd30bbdf485', 'arxivId': '1705.07750', 'publication_year': 2017, 'abstract': None}
{'title': 'Temporal Segment Networks: Towards Good Practices for Deep Action Recognition', 'paperID': 'ea3d7de6c0880e14455b9acb28f1bc1234321456', 'arxivId': '1608.00859', 'publication_year': 2016, 'abstract': None}
{'title': 'A smoothness constraint on the development of object recognition', 'paperID': 'e5cf901b79981c1104f68613e3186cb13384cfdc', 'arxivId': None, 'publication_year': 2016, 'abstract': None}
{'title': 'The development of newborn object recognition in fast and slow visual worlds', 'paperID': '65a93f76720ac96f47dda1e48bbb930d1da6ea5c', 'arxivId': None, 'publication_year': 2016, 'abstract': None}
{'title': 'Learning Image Representations Tied to Ego-Motion', 'paperID': 'c426ba865e9158a0f7962a86a50575aa943051b1', 'arxivId': '1505.02206', 'publication_year': 2015, 'abstract': None}
{'title': 'Unsupervised Learning of Spatiotemporally Coherent Metrics', 'paperID': '53e14bb909ef71388c8ca189c9db84b52af2db44', 'arxivId': '1412.6056', 'publication_year': 2014, 'abstract': None}
{'title': 'Large-Scale Video Classification with Convolutional Neural Networks', 'paperID': '6d4c9c923e9f145d1c01a2de2afc38ec23c44253', 'arxivId': None, 'publication_year': 2014, 'abstract': None}
{'title': 'Two-Stream Convolutional Networks for Action Recognition in Videos', 'paperID': '67dccc9a856b60bdc4d058d83657a089b8ad4486', 'arxivId': '1406.2199', 'publication_year': 2014, 'abstract': None}
{'title': 'Slow Feature Analysis: Unsupervised Learning of Invariances', 'paperID': '5127759530ce213f488af2859190697770f557f3', 'arxivId': None, 'publication_year': 2002, 'abstract': None}
{'title': 'Collaborative Learning of Gesture Recognition and 3D Hand Pose Estimation with Multi-order Feature Analysis', 'paperID': 'dcafbfa5030fe96fb7e39764d72742ccb58dc6a2', 'arxivId': None, 'publication_year': 2020, 'abstract': None}
{'title': 'Gradient 𝓁1 Regularization for Quantization Robustness', 'paperID': '8085bf032d71856bdc68fdb02cbc730875ba6ce5', 'arxivId': None, 'publication_year': 2020, 'abstract': None}
{'title': 'The comparison of L 1 and L 2 -norm minimization methods', 'paperID': '0d0abe5f0b2d9611f35b9782224ce8017072b0d8', 'arxivId': None, 'publication_year': 2010, 'abstract': None}
{'title': 'Unsupervised Natural Experience Rapidly Alters Invariant Object Representation in Visual Cortex', 'paperID': '944a221e5cdc27501ed865bb002fc53d47a91a5d', 'arxivId': None, 'publication_year': 2008, 'abstract': None}
{'title': 'Temporal Coherent Test Time Optimization for Robust Video Classification', 'paperID': 'b28083b620deb716b24797daf662d1950bcfec94', 'arxivId': '2302.14309', 'publication_year': '2023', 'abstract': 'Deep neural networks are likely to fail when the test data is corrupted in real-world deployment (e.g., blur, weather, etc.). Test-time optimization is an effective way that adapts models to generalize to corrupted data during testing, which has been shown in the image domain. However, the techniques for improving video classification corruption robustness remain few. In this work, we propose a Temporal Coherent Test-time Optimization framework (TeCo) to utilize spatio-temporal information in test-time optimization for robust video classification. To exploit information in video with self-supervised learning, TeCo uses global content from video clips and optimizes models for entropy minimization. TeCo minimizes the entropy of the prediction based on the global content from video clips. Meanwhile, it also feeds local content to regularize the temporal coherence at the feature level. TeCo retains the generalization ability of various video classification models and achieves significant improvements in corruption robustness across Mini Kinetics-C and Mini SSV2-C. Furthermore, TeCo sets a new baseline in video classification corruption robustness via test-time optimization.'}
{'title': 'Provable Robustness against Wasserstein Distribution Shifts via Input Randomization', 'paperID': '3055d5e50bb5ae8bda9d3e603d61d57e623366d2', 'arxivId': None, 'publication_year': None, 'abstract': None}
{'title': 'Better Diffusion Models Further Improve Adversarial Training', 'paperID': '884be3f18a201af62e0cecd1324dad065b0b39ba', 'arxivId': '2302.04638', 'publication_year': 2023, 'abstract': None}
{'title': 'Opacus: User-Friendly Differential Privacy Library in PyTorch', 'paperID': 'bea1187a1f8a68f1a93f0c2fa10d31f93a30f84e', 'arxivId': '2109.12298', 'publication_year': 2021, 'abstract': None}
{'title': 'Probabilistic Margins for Instance Reweighting in Adversarial Training', 'paperID': '83070fd24ad5d37d5e82f794fc37cd2b84fc6858', 'arxivId': '2106.07904', 'publication_year': 2021, 'abstract': None}
{'title': 'Are Adversarial Examples Created Equal? A Learnable Weighted Minimax Risk for Robustness under Non-uniform Attacks', 'paperID': 'eef656a1683e9ea18a40a3a858b085101a088d8d', 'arxivId': '2010.12989', 'publication_year': 2020, 'abstract': None}
{'title': 'Characterizing the Decision Boundary of Deep Neural Networks', 'paperID': '6802553e4c2b646ff59aa4abbf8588708dddf85c', 'arxivId': '1912.11460', 'publication_year': 2019, 'abstract': None}
{'title': 'Controlling Neural Level Sets', 'paperID': '15e80e4a4896aa9cf1546d44fddb06e46866200c', 'arxivId': '1905.11911', 'publication_year': 2019, 'abstract': None}
{'title': 'Parametric Level Set Methods for Inverse Problems', 'paperID': 'c187cd7a0379baa843a5ae89a296c8e404acbd14', 'arxivId': '1007.2467', 'publication_year': 2010, 'abstract': None}
{'title': 'Level set methods and dynamic implicit surfaces', 'paperID': 'c896b6c0e8e6be8ba28142e096d705241ce94b9a', 'arxivId': None, 'publication_year': 2002, 'abstract': None}
{'title': 'Searching for Activation Functions', 'paperID': 'c8c4ab59ac29973a00df4e5c8df3773a3c59995a', 'arxivId': None, 'publication_year': 2018, 'abstract': None}
{'title': 'Exploring and Exploiting Decision Boundary Dynamics for Adversarial Robustness', 'paperID': '2272b37bae59c30ca218abfeecdb0a61270c48f1', 'arxivId': '2302.03015', 'publication_year': '2023', 'abstract': "The robustness of a deep classifier can be characterized by its margins: the decision boundary's distances to natural data points. However, it is unclear whether existing robust training methods effectively increase the margin for each vulnerable point during training. To understand this, we propose a continuous-time framework for quantifying the relative speed of the decision boundary with respect to each individual point. Through visualizing the moving speed of the decision boundary under Adversarial Training, one of the most effective robust training algorithms, a surprising moving-behavior is revealed: the decision boundary moves away from some vulnerable points but simultaneously moves closer to others, decreasing their margins. To alleviate these conflicting dynamics of the decision boundary, we propose Dynamics-aware Robust Training (DyART), which encourages the decision boundary to engage in movement that prioritizes increasing smaller margins. In contrast to prior works, DyART directly operates on the margins rather than their indirect approximations, allowing for more targeted and effective robustness improvement. Experiments on the CIFAR-10 and Tiny-ImageNet datasets verify that DyART alleviates the conflicting dynamics of the decision boundary and obtains improved robustness under various perturbation sizes compared to the state-of-the-art defenses. Our code is available at https://github.com/Yuancheng-Xu/Dynamics-Aware-Robust-Training."}
{'title': 'Robust Perception through Equivariance', 'paperID': '82d19ceba300875f108a91539ca555dfad142a99', 'arxivId': '2212.06079', 'publication_year': 2022, 'abstract': None}
{'title': 'Visual Prompting via Image Inpainting', 'paperID': '0a25c137edc7c9752aa6d99ae4084683c3fe6b56', 'arxivId': '2209.00647', 'publication_year': 2022, 'abstract': None}
{'title': 'Landscape Learning for Neural Network Inversion', 'paperID': '5dad3748e8d4d8c659005903062e5d8e855fa86c', 'arxivId': '2206.09027', 'publication_year': 2022, 'abstract': None}
{'title': 'Prompt Consistency for Zero-Shot Task Generalization', 'paperID': '07c70ca55793984ffdf31582a05170ef3d62381a', 'arxivId': '2205.00049', 'publication_year': 2022, 'abstract': None}
{'title': 'Using Multiple Self-Supervised Tasks Improves Model Robustness', 'paperID': '191038455e19980163ac1ec3acd3c295fc2952b6', 'arxivId': '2204.03714', 'publication_year': 2022, 'abstract': None}
{'title': 'Do As I Can, Not As I Say: Grounding Language in Robotic Affordances', 'paperID': 'cb5e3f085caefd1f3d5e08637ab55d39e61234fc', 'arxivId': '2204.01691', 'publication_year': 2022, 'abstract': None}
{'title': 'Exploring Visual Prompts for Adapting Large-Scale Models', 'paperID': 'aa8c61c9f6bb21c57e49611ccb995cfda1b53b10', 'arxivId': '2203.17274', 'publication_year': 2022, 'abstract': None}
{'title': 'Fine-tuning Image Transformers using Learnable Memory', 'paperID': 'b9ea0a971ff6cb031fa3842e3daf65263b890b28', 'arxivId': '2203.15243', 'publication_year': 2022, 'abstract': None}
{'title': 'Visual Prompt Tuning', 'paperID': 'adb272fbdea3631059cf88ab764bb6c2ce29f965', 'arxivId': '2203.12119', 'publication_year': 2022, 'abstract': None}
{'title': 'Conditional Prompt Learning for Vision-Language Models', 'paperID': 'b879450f50a6113f44a5baf0bcd5b4331eeb7bbc', 'arxivId': '2203.05557', 'publication_year': 2022, 'abstract': None}
{'title': 'Transferring Adversarial Robustness Through Robust Representation Matching', 'paperID': '88399dde6052de10a23fe43cc7d6d659493b0c7e', 'arxivId': '2202.09994', 'publication_year': 2022, 'abstract': None}
{'title': 'Combined Scaling for Zero-shot Transfer Learning', 'paperID': 'd257547d681f3a153f4bbf85f5955b5a0189e500', 'arxivId': '2111.10050', 'publication_year': 2021, 'abstract': None}
{'title': 'Adversarial Attacks are Reversible with Natural Supervision', 'paperID': 'd59fb7b76578e725d3179aa236ba8a26c5e7b844', 'arxivId': '2103.14222', 'publication_year': 2021, 'abstract': None}
{'title': 'Scaling Up Visual and Vision-Language Representation Learning With Noisy Text Supervision', 'paperID': '141a5033d9994242b18bb3b217e79582f1ee9306', 'arxivId': '2102.05918', 'publication_year': 2021, 'abstract': None}
{'title': 'A Deep Dive into Adversarial Robustness in Zero-Shot Learning', 'paperID': 'e3f67b654b96d17fdb643f22c6763f3bc7872783', 'arxivId': '2008.07651', 'publication_year': 2020, 'abstract': None}
{'title': 'The Hateful Memes Challenge: Detecting Hate Speech in Multimodal Memes', 'paperID': '3f6570fd55dc5855f93a56150e6d99c7944a1c1e', 'arxivId': '2005.04790', 'publication_year': 2020, 'abstract': None}
{'title': 'Zero-Shot Learning from Adversarial Feature Residual to Compact Visual Feature', 'paperID': '53a2ecf14a7c698875a0f4987840589a6b6478f1', 'arxivId': '2008.12962', 'publication_year': 2020, 'abstract': None}
{'title': 'Attribute Attention for Semantic Disambiguation in Zero-Shot Learning', 'paperID': '664af8114f89c3f9f53d80185c3dd23d231599ef', 'arxivId': None, 'publication_year': 2019, 'abstract': None}
{'title': 'A Meta-Learning Framework for Generalized Zero-Shot Learning', 'paperID': '48079a155e69816deb706590a500c7019f3228ac', 'arxivId': '1909.04344', 'publication_year': 2019, 'abstract': None}
{'title': 'Dual Adversarial Semantics-Consistent Network for Generalized Zero-Shot Learning', 'paperID': '5aa478f93cd6af02b2fd05ade91c07a873dabcb2', 'arxivId': '1907.05570', 'publication_year': 2019, 'abstract': None}
{'title': 'Attentive Region Embedding Network for Zero-Shot Learning', 'paperID': '40e44c7737cdf254b9701e690549639f7ac5326f', 'arxivId': None, 'publication_year': 2019, 'abstract': None}
{'title': 'Bidirectional Inference Networks: A Class of Deep Bayesian Networks for Health Profiling', 'paperID': '91d8795790baf687e4b928c720314bb0fc900dea', 'arxivId': '1902.02037', 'publication_year': 2019, 'abstract': None}
{'title': 'Generalized Zero- and Few-Shot Learning via Aligned Variational Autoencoders', 'paperID': '00ffb4121cbd03d09ad4672a20eecd25703540ea', 'arxivId': '1812.01784', 'publication_year': 2018, 'abstract': None}
{'title': 'Generative Dual Adversarial Network for Generalized Zero-Shot Learning', 'paperID': 'fad53f59a3a3803838c50f331de8865e4385d87e', 'arxivId': '1811.04857', 'publication_year': 2018, 'abstract': None}
{'title': 'Rotation Equivariant CNNs for Digital Pathology', 'paperID': '2a96afaf3261a87f0daa51699b4b3cf169e092c4', 'arxivId': '1806.03962', 'publication_year': 2018, 'abstract': None}
{'title': 'Feature Generating Networks for Zero-Shot Learning', 'paperID': 'cb3f5defe2120076ebbcc89b9256bbfcb8b4d8a1', 'arxivId': '1712.00981', 'publication_year': 2017, 'abstract': None}
{'title': 'EuroSAT: A Novel Dataset and Deep Learning Benchmark for Land Use and Land Cover Classification', 'paperID': '9c88c2357abcd58cc330179c1965fe0a8c067ebc', 'arxivId': '1709.00029', 'publication_year': 2017, 'abstract': None}
{'title': 'An embarrassingly simple approach to zero-shot learning', 'paperID': '4b18303edf701e41a288da36f8f1ba129da67eb7', 'arxivId': None, 'publication_year': 2015, 'abstract': None}
{'title': 'Evaluation of output embeddings for fine-grained image classification', 'paperID': 'caccc069e658ea397c9faf673e74c959c734ff53', 'arxivId': None, 'publication_year': 2014, 'abstract': None}
{'title': 'DeViSE: A Deep Visual-Semantic Embedding Model', 'paperID': '4aa4069693bee00d1b0759ca3df35e59284e9845', 'arxivId': None, 'publication_year': 2013, 'abstract': None}
{'title': 'Zero-shot Learning with Semantic Output Codes', 'paperID': '0f6911bc1e6abee8bbf9dd3f8d54d40466429da7', 'arxivId': None, 'publication_year': 2009, 'abstract': None}
{'title': 'Learning to detect unseen object classes by between-class attribute transfer', 'paperID': '0566bf06a0368b518b8b474166f7b1dfef3f9283', 'arxivId': None, 'publication_year': 2009, 'abstract': None}
{'title': 'Caltech-256 Object Category Dataset', 'paperID': '5a5effa909cdeafaddbbb7855037e02f8e25d632', 'arxivId': None, 'publication_year': 2007, 'abstract': None}
{'title': 'Efficient Transfer Learning for Visual Tasks via Continuous Optimization of Prompts', 'paperID': 'f59370679f35e461d6257aea8ff28d01a22f0249', 'arxivId': None, 'publication_year': 2022, 'abstract': None}
{'title': 'On the Relationship between Generalization and Robustness to Adversarial Examples', 'paperID': '6e46300d9721159a3c7cd884c62d01b3dd257c74', 'arxivId': None, 'publication_year': 2021, 'abstract': None}
{'title': 'CNN Region featuresInput image Guided loss SGA SGA Class semantic features Semantic embedding label Attention features Attention features Embedded loss Softm', 'paperID': 'ffbff2edb9994ceac5d7b08d0049424974d20eae', 'arxivId': None, 'publication_year': 2018, 'abstract': None}
{'title': 'Understanding Zero-shot Adversarial Robustness for Large-Scale Models', 'paperID': '16596dd03fa40ba278f9533ea9986982dcc81fb6', 'arxivId': '2212.07016', 'publication_year': '2022', 'abstract': "Pretrained large-scale vision-language models like CLIP have exhibited strong generalization over unseen tasks. Yet imperceptible adversarial perturbations can significantly reduce CLIP's performance on new tasks. In this work, we identify and explore the problem of \\emph{adapting large-scale models for zero-shot adversarial robustness}. We first identify two key factors during model adaption -- training losses and adaptation methods -- that affect the model's zero-shot adversarial robustness. We then propose a text-guided contrastive adversarial training loss, which aligns the text embeddings and the adversarial visual features with contrastive learning on a small set of training data. We apply this training loss to two adaption methods, model finetuning and visual prompt tuning. We find that visual prompt tuning is more effective in the absence of texts, while finetuning wins in the existence of text guidance. Overall, our approach significantly improves the zero-shot adversarial robustness over CLIP, seeing an average improvement of over 31 points over ImageNet and 15 zero-shot datasets. We hope this work can shed light on understanding the zero-shot adversarial robustness of large-scale models."}
{'title': 'Challenges of Machine Learning Applied to Safety-Critical Cyber-Physical Systems', 'paperID': '8f419ebe41828b31dca15365a067d33b97f5574e', 'arxivId': None, 'publication_year': 2020, 'abstract': None}
{'title': 'Secure Deep Learning Engineering: A Software Quality Assurance Perspective', 'paperID': '29227576be8dd5c058b3e30d618a7efcda71ed86', 'arxivId': '1810.04538', 'publication_year': 2018, 'abstract': None}
{'title': 'Humans can decipher adversarial images', 'paperID': 'fe1d78ac0c02cfc6a2319c4997f0e03ff55a1569', 'arxivId': '1809.04120', 'publication_year': 2018, 'abstract': None}
{'title': 'Analysis of classifiers’ robustness to adversarial perturbations', 'paperID': 'f02441fccec9ed54dd7e21a17736933c84853011', 'arxivId': '1502.02590', 'publication_year': 2015, 'abstract': None}
{'title': 'Some remarks on isoperimetry of Gaussian type', 'paperID': '92b773923b69abea465cd77d42711e5b9947766e', 'arxivId': None, 'publication_year': 2000, 'abstract': None}
{'title': 'On an Isoperimetric Problem for Hamming Graphs', 'paperID': 'd822e347820921c4d70e619b61bffc6944de9458', 'arxivId': None, 'publication_year': 1999, 'abstract': None}
{'title': 'Mean, Median and Mode in Binomial Distributions', 'paperID': '2da962bf85bfdb132209d81f0cdc4e4933ecfbd8', 'arxivId': None, 'publication_year': 1980, 'abstract': None}
{'title': 'A Remark on Stirling’s Formula', 'paperID': '377797f2f838cef001eadb34b25eb576d4f3ac61', 'arxivId': None, 'publication_year': 1955, 'abstract': None}
{'title': 'Fundamental limits on the robustness of image classifiers', 'paperID': 'ade34f95e9350477aa7f103e9607a8f770bffe6f', 'arxivId': None, 'publication_year': None, 'abstract': 'We prove that image classifiers are fundamentally sensitive to small perturbations in their inputs. Specifically, we show that given some image space of n -by- n images, all but a tiny fraction of images in any image class induced over that space can be moved outside that class by adding some perturbation whose p -norm is O ( n 1 / max( p, 1) ) , as long as that image class takes up at most half of the image space. We then show that O ( n 1 / max( p, 1) ) is asymptotically optimal. Finally, we show that an increase in the bit depth of the image space leads to a loss in robustness. We supplement our results with a discussion of their implications for vision systems'}
{'title': 'Improved marginal likelihood estimation via power posteriors and importance sampling', 'paperID': 'b1d95800cbbe5451ac303d0ca45b30ecac8fd15a', 'arxivId': None, 'publication_year': 2021, 'abstract': None}
{'title': 'Robust generalised Bayesian inference for\xa0intractable likelihoods', 'paperID': '1f9c368316ba57215f8bdea6d4617ea298f73632', 'arxivId': '2104.07359', 'publication_year': 2021, 'abstract': None}
{'title': 'Teams: Heterogeneity, Sorting, and Complementarity', 'paperID': '25a3cbb5e4569ffaf03c6ac8b1f3b91e0847439c', 'arxivId': '2102.01802', 'publication_year': 2021, 'abstract': None}
{'title': 'Non-exponentially weighted aggregation: regret bounds for unbounded loss functions', 'paperID': '1cd641fcc7797666368b78dae3d9b998e4fa0b7e', 'arxivId': '2009.03017', 'publication_year': 2020, 'abstract': None}
{'title': 'Frequentist Consistency of Generalized Variational Inference', 'paperID': '64bd7faa0044a240cfe3103554f2bd92f0049544', 'arxivId': '1912.04946', 'publication_year': 2019, 'abstract': None}
{'title': 'Asymptotic Normality, Concentration, and Coverage of Generalized Posteriors', 'paperID': '23af2d124b52288d1172558e45199c87e7fa8892', 'arxivId': '1907.09611', 'publication_year': 2019, 'abstract': None}
{'title': 'Variational Bayes under Model Misspecification', 'paperID': '0a538c7e1f943a30f048eec0a3b0dfff25062b1a', 'arxivId': '1905.10859', 'publication_year': 2019, 'abstract': None}
{'title': 'Generalized Variational Inference: Three arguments for deriving new Posteriors', 'paperID': '4aaf784dd3c65ee000e4d94d4cdc7f828f760339', 'arxivId': '1904.02063', 'publication_year': 2019, 'abstract': None}
{'title': 'Improving Explorability in Variational Inference with Annealed Variational Objectives', 'paperID': '79b5cd6e30b1c0c917958aeadbd194372e6a1fdb', 'arxivId': '1809.01818', 'publication_year': 2018, 'abstract': None}
{'title': 'Variational Bayes inference in high-dimensional time-varying parameter models', 'paperID': 'ef74bfee5f16891ca1cd43ba04a7106310b488b6', 'arxivId': None, 'publication_year': 2018, 'abstract': None}
{'title': 'Concentration of tempered posteriors and of their variational approximations', 'paperID': 'f9832eb4d8dc7cde63676a195f778167c8cafc31', 'arxivId': '1706.09293', 'publication_year': 2017, 'abstract': None}
{'title': 'Fundamentals of Nonparametric Bayesian Inference', 'paperID': '0c9248465ffdff9404cbf6d3dfdce14a5bc891a8', 'arxivId': None, 'publication_year': 2017, 'abstract': None}
{'title': 'Frequentist Consistency of Variational Bayes', 'paperID': '534403a65fa011cc29a09e29864a88cd6216a0dd', 'arxivId': '1705.03439', 'publication_year': 2017, 'abstract': None}
{'title': 'Approximate Variational Estimation for a Model of Network Formation', 'paperID': '3f00b4b1cc85196374472de34eeda34367dd606f', 'arxivId': '1702.00308', 'publication_year': 2017, 'abstract': None}
{'title': 'Assigning a value to a power likelihood in a general Bayesian model', 'paperID': '9f5ccbe7529a63c61daaabc1174ec499bfe6967d', 'arxivId': '1701.08515', 'publication_year': 2017, 'abstract': None}
{'title': 'Maximum Likelihood Estimation in Possibly Misspecified Dynamic Models with Time Inhomogeneous Markov Regimes', 'paperID': '437f030fd6a64d6fe56a21b76926a3172d950108', 'arxivId': None, 'publication_year': 2016, 'abstract': None}
{'title': 'Gaussian Approximations for Probability Measures on Rd', 'paperID': 'dd22616483014b5033c5c2ed748799717838a917', 'arxivId': '1611.08642', 'publication_year': 2016, 'abstract': None}
{'title': 'Bayesian fractional posteriors', 'paperID': '592f65f1ab8d4949d53bc1f94ab8cd1f53caf7b0', 'arxivId': '1611.01125', 'publication_year': 2016, 'abstract': None}
{'title': 'Robust Probabilistic Modeling with Bayesian Data Reweighting', 'paperID': '434954d40776c87d8b354677ac393cb121f5c80b', 'arxivId': None, 'publication_year': 2016, 'abstract': None}
{'title': 'Robust Bayes estimation using the density power divergence', 'paperID': '7ff104b9e80bb70cc8e5a3d058eb2cf3d892632a', 'arxivId': None, 'publication_year': 2016, 'abstract': None}
{'title': 'Variational Inference: A Review for Statisticians', 'paperID': '6f24d7a6e1c88828e18d16c6db20f5329f6a6827', 'arxivId': None, 'publication_year': 2016, 'abstract': None}
{'title': 'A General Method for Robust Bayesian Modeling', 'paperID': '19de6b41be976f7035fa8927932a0a89bf359a42', 'arxivId': '1510.05078', 'publication_year': 2015, 'abstract': None}
{'title': 'Robust Bayesian Inference via Coarsening', 'paperID': '401d9f30130271cc76b8c2f62b122f523459fa72', 'arxivId': '1506.06101', 'publication_year': 2015, 'abstract': None}
{'title': 'Inconsistency of Bayesian Inference for Misspecified Linear Models, and a Proposal for Repairing It', 'paperID': 'eea300d771ebdb5966ddf67c10df00e867e198f7', 'arxivId': '1412.3730', 'publication_year': 2014, 'abstract': None}
{'title': 'RISK OF BAYESIAN INFERENCE IN MISSPECIFIED MODELS, AND THE SANDWICH COVARIANCE MATRIX', 'paperID': '5528877fa98a12a3bbc0d0b2159a78de08ef1ab8', 'arxivId': None, 'publication_year': 2013, 'abstract': None}
{'title': 'A Bernstein–von Mises theorem for smooth functionals in semiparametric models', 'paperID': '812f12569ac77bc53052df89a9d613bbfd7ecbf6', 'arxivId': '1305.4482', 'publication_year': 2013, 'abstract': None}
{'title': 'Safe Learning: bridging the gap between Bayes, MDL and statistical learning theory via empirical convexity', 'paperID': '10b938f7981ec5f243b4ba3bb231f073a7bcfad2', 'arxivId': None, 'publication_year': 2011, 'abstract': None}
{'title': 'Bayesian model robustness via disparities', 'paperID': '9ffe0e272a5a57022644927344e91a98851c39a6', 'arxivId': '1112.4213', 'publication_year': 2011, 'abstract': None}
{'title': 'Topological Spaces: including a treatment of multi-valued functions', 'paperID': '2ce6ef4a18a28039e1148ee27b949527211de8ea', 'arxivId': None, 'publication_year': 2010, 'abstract': None}
{'title': 'Axiomatic Foundations of Multiplier Preferences', 'paperID': 'd0bc88745d70bdc2411a7618362fa7be13ae19ac', 'arxivId': None, 'publication_year': 2009, 'abstract': None}
{'title': 'Asymptotic Theory of Statistics and Probability', 'paperID': '94d642ba3b0f46109dfe531509a910475fb33366', 'arxivId': None, 'publication_year': 2008, 'abstract': None}
{'title': 'Ambiguity Aversion, Robustness, and the Variational Representation of Preferences', 'paperID': '961a2295798d53dd4df5edf9e61d997f73141a23', 'arxivId': None, 'publication_year': 2006, 'abstract': None}
{'title': 'From ɛ-entropy to KL-entropy: Analysis of minimum information complexity density estimation', 'paperID': 'ac4b7a6dad66a9a09e69019936d1c182f7f2a6e0', 'arxivId': 'math/0702653', 'publication_year': 2006, 'abstract': None}
{'title': 'PAC-Bayesian Stochastic Model Selection', 'paperID': '1af5c57357bbe22364ce106c23ea7b016c316f96', 'arxivId': None, 'publication_year': 2003, 'abstract': None}
{'title': 'An MCMC Approach to Classical Estimation', 'paperID': '4991ea3eb6e75191ef0b522119323ea0e64361d7', 'arxivId': '2301.07782', 'publication_year': 2002, 'abstract': None}
{'title': 'Robust Control and Model Uncertainty', 'paperID': 'e88b04fc6cbe295e0b7a28063e391e7717a5c5a2', 'arxivId': None, 'publication_year': 2001, 'abstract': None}
{'title': 'Minimum complexity density estimation', 'paperID': 'fca98082fa9ff8e9dbae9922491ae54976a0ccef', 'arxivId': None, 'publication_year': 1991, 'abstract': None}
{'title': 'Aggregating strategies', 'paperID': '8f80ae7531ae8c8e06f53ca78d5ad8a2dfbc8697', 'arxivId': None, 'publication_year': 1990, 'abstract': None}
{'title': 'Matrix analysis', 'paperID': '721f54f6fa32f5f02c5124a2b73ce5f4280b4eaf', 'arxivId': None, 'publication_year': 1985, 'abstract': None}
{'title': 'The Bernstein-Von-Mises theorem under misspecification', 'paperID': '3cc7cb5622c17867035c6d61bffad9a723fea0fe', 'arxivId': None, 'publication_year': 2012, 'abstract': None}
{'title': 'On measuring sensitivity to parametric model misspecification', 'paperID': '926c3c4b211fcb666674ad4104263857377a7ffc', 'arxivId': None, 'publication_year': 2001, 'abstract': None}
{'title': 'On Bayesian consistency', 'paperID': 'c9c4160f8696e265f3ea0a25fba872f4fafd2a6e', 'arxivId': None, 'publication_year': 2001, 'abstract': None}
{'title': 'Asymptotic Normality of the Posterior in Relative Entropy', 'paperID': 'c0f964b2a6cab2483b824b3a4868a135cfbbd01b', 'arxivId': None, 'publication_year': 1999, 'abstract': None}
{'title': 'Maximum Likelihood Estimation of Misspecified Models', 'paperID': '395bc88e0c22c646acd1d95d69ccca9c03e4113d', 'arxivId': None, 'publication_year': 1982, 'abstract': None}
{'title': 'The behavior of maximum likelihood estimates under nonstandard conditions', 'paperID': '64b4ddcf066597a200423c55652f11ce89780063', 'arxivId': None, 'publication_year': 1967, 'abstract': None}
{'title': 'On the Robustness to Misspecification of α-posteriors and Their Variational Approximations', 'paperID': '143c6e80c97d51719b7659da00446ece95515bb7', 'arxivId': '2104.08324', 'publication_year': '2021', 'abstract': '$\\alpha$-posteriors and their variational approximations distort standard posterior inference by downweighting the likelihood and introducing variational approximation errors. We show that such distortions, if tuned appropriately, reduce the Kullback-Leibler (KL) divergence from the true, but perhaps infeasible, posterior distribution when there is potential parametric model misspecification. To make this point, we derive a Bernstein-von Mises theorem showing convergence in total variation distance of $\\alpha$-posteriors and their variational approximations to limiting Gaussian distributions. We use these distributions to evaluate the KL divergence between true and reported posteriors. We show this divergence is minimized by choosing $\\alpha$ strictly smaller than one, assuming there is a vanishingly small probability of model misspecification. The optimized value becomes smaller as the the misspecification becomes more severe. The optimized KL divergence increases logarithmically in the degree of misspecification and not linearly as with the usual posterior.'}
{'title': 'Robust Graph Dictionary Learning', 'paperID': '9078452e8b927597bc0aef46c64b475ea06e2a72', 'arxivId': None, 'publication_year': None, 'abstract': None}
{'title': 'Learning MLPs on Graphs: A Unified View of Effectiveness, Robustness, and Efficiency', 'paperID': '889ea8c9210f49ff6e1690f5c06e626bbb1d17b0', 'arxivId': None, 'publication_year': None, 'abstract': None}
